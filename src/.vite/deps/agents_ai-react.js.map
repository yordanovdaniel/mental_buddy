{
  "version": 3,
  "sources": ["../../node_modules/throttleit/index.js", "../../node_modules/use-sync-external-store/cjs/use-sync-external-store-shim.development.js", "../../node_modules/use-sync-external-store/shim/index.js", "../../node_modules/agents/node_modules/@vercel/oidc/dist/get-context.js", "../../node_modules/agents/node_modules/@vercel/oidc/dist/index-browser.js", "../../node_modules/nanoid/url-alphabet/index.js", "../../node_modules/nanoid/index.browser.js", "../../node_modules/@ai-sdk/react/src/use-chat.ts", "../../node_modules/@ai-sdk/react/src/chat.react.ts", "../../node_modules/@ai-sdk/react/src/throttle.ts", "../../node_modules/@ai-sdk/react/src/use-completion.ts", "../../node_modules/@ai-sdk/react/src/use-object.ts", "../../node_modules/swr/dist/index/index.mjs", "../../node_modules/swr/dist/_internal/config-context-client-BoS53ST9.mjs", "../../node_modules/swr/dist/_internal/events.mjs", "../../node_modules/dequal/lite/index.mjs", "../../node_modules/swr/dist/_internal/constants.mjs", "../../node_modules/swr/dist/_internal/index.mjs", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/combine-headers.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/convert-async-iterator-to-readable-stream.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/delay.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/extract-response-headers.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/generate-id.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/get-error-message.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/get-from-api.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/handle-fetch-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/is-abort-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/get-runtime-environment-user-agent.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/normalize-headers.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/with-user-agent-suffix.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/version.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/inject-json-instruction.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/is-url-supported.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/load-api-key.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/load-optional-setting.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/load-setting.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/media-type-to-extension.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/parse-json.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/secure-json-parse.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/validate-types.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/validator.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/parse-json-event-stream.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/parse-provider-options.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/post-to-api.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/types/tool.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/provider-defined-tool-factory.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/remove-undefined-entries.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/resolve.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/response-handler.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-schema.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/get-relative-path.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/options.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/select-parser.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/any.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/array.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/bigint.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/boolean.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/branded.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/catch.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/date.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/default.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/effects.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/enum.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/intersection.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/literal.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/record.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/string.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/map.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/native-enum.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/never.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/null.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/union.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/nullable.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/number.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/object.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/optional.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/pipeline.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/promise.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/set.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/tuple.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/undefined.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/unknown.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parsers/readonly.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/parse-def.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/refs.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/zod-to-json-schema.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/zod-to-json-schema/index.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/schema.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/uint8-utils.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/without-trailing-slash.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/is-async-iterable.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/types/execute-tool.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/provider-utils/src/index.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/gateway-provider.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/as-gateway-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/create-gateway-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/gateway-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/gateway-authentication-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/gateway-invalid-request-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/gateway-rate-limit-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/gateway-model-not-found-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/gateway-internal-server-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/gateway-response-error.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/extract-api-call-response.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/errors/parse-auth-method.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/gateway-fetch-metadata.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/gateway-language-model.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/gateway-embedding-model.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/vercel-environment.ts", "../../node_modules/agents/node_modules/ai/node_modules/@ai-sdk/gateway/src/version.ts", "../../node_modules/agents/node_modules/ai/src/index.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/generate-text.ts", "../../node_modules/agents/node_modules/ai/src/error/no-output-specified-error.ts", "../../node_modules/agents/node_modules/ai/src/logger/log-warnings.ts", "../../node_modules/agents/node_modules/ai/src/model/resolve-model.ts", "../../node_modules/agents/node_modules/ai/src/error/index.ts", "../../node_modules/agents/node_modules/ai/src/error/invalid-argument-error.ts", "../../node_modules/agents/node_modules/ai/src/error/invalid-stream-part-error.ts", "../../node_modules/agents/node_modules/ai/src/error/invalid-tool-input-error.ts", "../../node_modules/agents/node_modules/ai/src/error/no-image-generated-error.ts", "../../node_modules/agents/node_modules/ai/src/error/no-object-generated-error.ts", "../../node_modules/agents/node_modules/ai/src/error/no-output-generated-error.ts", "../../node_modules/agents/node_modules/ai/src/error/no-speech-generated-error.ts", "../../node_modules/agents/node_modules/ai/src/error/no-such-tool-error.ts", "../../node_modules/agents/node_modules/ai/src/error/tool-call-repair-error.ts", "../../node_modules/agents/node_modules/ai/src/error/unsupported-model-version-error.ts", "../../node_modules/agents/node_modules/ai/src/prompt/invalid-data-content-error.ts", "../../node_modules/agents/node_modules/ai/src/prompt/invalid-message-role-error.ts", "../../node_modules/agents/node_modules/ai/src/prompt/message-conversion-error.ts", "../../node_modules/agents/node_modules/ai/src/util/download/download-error.ts", "../../node_modules/agents/node_modules/ai/src/util/retry-error.ts", "../../node_modules/agents/node_modules/ai/src/prompt/convert-to-language-model-prompt.ts", "../../node_modules/agents/node_modules/ai/src/util/detect-media-type.ts", "../../node_modules/agents/node_modules/ai/src/util/download/download.ts", "../../node_modules/agents/node_modules/ai/src/version.ts", "../../node_modules/agents/node_modules/ai/src/util/download/download-function.ts", "../../node_modules/agents/node_modules/ai/src/prompt/data-content.ts", "../../node_modules/agents/node_modules/ai/src/prompt/split-data-url.ts", "../../node_modules/agents/node_modules/ai/src/prompt/prepare-call-settings.ts", "../../node_modules/agents/node_modules/ai/src/prompt/prepare-tools-and-tool-choice.ts", "../../node_modules/agents/node_modules/ai/src/util/is-non-empty-object.ts", "../../node_modules/agents/node_modules/ai/src/prompt/standardize-prompt.ts", "../../node_modules/agents/node_modules/ai/src/prompt/message.ts", "../../node_modules/agents/node_modules/ai/src/types/provider-metadata.ts", "../../node_modules/agents/node_modules/ai/src/types/json-value.ts", "../../node_modules/agents/node_modules/ai/src/prompt/content-part.ts", "../../node_modules/agents/node_modules/ai/src/prompt/wrap-gateway-error.ts", "../../node_modules/agents/node_modules/ai/src/telemetry/assemble-operation-name.ts", "../../node_modules/agents/node_modules/ai/src/telemetry/get-base-telemetry-attributes.ts", "../../node_modules/agents/node_modules/ai/src/telemetry/get-tracer.ts", "../../node_modules/agents/node_modules/ai/src/telemetry/noop-tracer.ts", "../../node_modules/agents/node_modules/ai/src/telemetry/record-span.ts", "../../node_modules/agents/node_modules/ai/src/telemetry/select-telemetry-attributes.ts", "../../node_modules/agents/node_modules/ai/src/telemetry/stringify-for-telemetry.ts", "../../node_modules/agents/node_modules/ai/src/types/usage.ts", "../../node_modules/agents/node_modules/ai/src/util/as-array.ts", "../../node_modules/agents/node_modules/ai/src/util/retry-with-exponential-backoff.ts", "../../node_modules/agents/node_modules/ai/src/util/prepare-retries.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/extract-text-content.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/generated-file.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/parse-tool-call.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/step-result.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/stop-condition.ts", "../../node_modules/agents/node_modules/ai/src/prompt/create-tool-model-output.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/to-response-messages.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/stream-text.ts", "../../node_modules/agents/node_modules/ai/src/util/prepare-headers.ts", "../../node_modules/agents/node_modules/ai/src/text-stream/create-text-stream-response.ts", "../../node_modules/agents/node_modules/ai/src/util/write-to-server-response.ts", "../../node_modules/agents/node_modules/ai/src/text-stream/pipe-text-stream-to-response.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/json-to-sse-transform-stream.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/ui-message-stream-headers.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/create-ui-message-stream-response.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/get-response-ui-message-id.ts", "../../node_modules/agents/node_modules/ai/src/ui/process-ui-message-stream.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/ui-message-chunks.ts", "../../node_modules/agents/node_modules/ai/src/util/merge-objects.ts", "../../node_modules/agents/node_modules/ai/src/util/parse-partial-json.ts", "../../node_modules/agents/node_modules/ai/src/util/fix-json.ts", "../../node_modules/agents/node_modules/ai/src/ui/ui-messages.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/handle-ui-message-stream-finish.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/pipe-ui-message-stream-to-response.ts", "../../node_modules/agents/node_modules/ai/src/util/async-iterable-stream.ts", "../../node_modules/agents/node_modules/ai/src/util/consume-stream.ts", "../../node_modules/agents/node_modules/ai/src/util/create-resolvable-promise.ts", "../../node_modules/agents/node_modules/ai/src/util/create-stitchable-stream.ts", "../../node_modules/agents/node_modules/ai/src/util/delayed-promise.ts", "../../node_modules/agents/node_modules/ai/src/util/now.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/run-tools-transformation.ts", "../../node_modules/agents/node_modules/ai/src/ui/convert-to-model-messages.ts", "../../node_modules/agents/node_modules/ai/src/agent/agent.ts", "../../node_modules/agents/node_modules/ai/src/embed/embed.ts", "../../node_modules/agents/node_modules/ai/src/embed/embed-many.ts", "../../node_modules/agents/node_modules/ai/src/util/split-array.ts", "../../node_modules/agents/node_modules/ai/src/generate-image/generate-image.ts", "../../node_modules/agents/node_modules/ai/src/generate-object/generate-object.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/extract-reasoning-content.ts", "../../node_modules/agents/node_modules/ai/src/generate-object/output-strategy.ts", "../../node_modules/agents/node_modules/ai/src/generate-object/parse-and-validate-object-result.ts", "../../node_modules/agents/node_modules/ai/src/generate-object/validate-object-generation-input.ts", "../../node_modules/agents/node_modules/ai/src/generate-object/stream-object.ts", "../../node_modules/agents/node_modules/ai/src/util/cosine-similarity.ts", "../../node_modules/agents/node_modules/ai/src/util/data-url.ts", "../../node_modules/agents/node_modules/ai/src/util/is-deep-equal-data.ts", "../../node_modules/agents/node_modules/ai/src/util/serial-job-executor.ts", "../../node_modules/agents/node_modules/ai/src/util/simulate-readable-stream.ts", "../../node_modules/agents/node_modules/ai/src/generate-speech/generate-speech.ts", "../../node_modules/agents/node_modules/ai/src/generate-speech/generated-audio-file.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/output.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/prune-messages.ts", "../../node_modules/agents/node_modules/ai/src/generate-text/smooth-stream.ts", "../../node_modules/agents/node_modules/ai/src/middleware/default-settings-middleware.ts", "../../node_modules/agents/node_modules/ai/src/util/get-potential-start-index.ts", "../../node_modules/agents/node_modules/ai/src/middleware/extract-reasoning-middleware.ts", "../../node_modules/agents/node_modules/ai/src/middleware/simulate-streaming-middleware.ts", "../../node_modules/agents/node_modules/ai/src/middleware/wrap-language-model.ts", "../../node_modules/agents/node_modules/ai/src/middleware/wrap-provider.ts", "../../node_modules/agents/node_modules/ai/src/registry/custom-provider.ts", "../../node_modules/agents/node_modules/ai/src/registry/no-such-provider-error.ts", "../../node_modules/agents/node_modules/ai/src/registry/provider-registry.ts", "../../node_modules/agents/node_modules/ai/src/transcribe/transcribe.ts", "../../node_modules/agents/node_modules/ai/src/error/no-transcript-generated-error.ts", "../../node_modules/agents/node_modules/ai/src/ui/call-completion-api.ts", "../../node_modules/agents/node_modules/ai/src/ui/process-text-stream.ts", "../../node_modules/agents/node_modules/ai/src/ui/chat.ts", "../../node_modules/agents/node_modules/ai/src/ui/convert-file-list-to-file-ui-parts.ts", "../../node_modules/agents/node_modules/ai/src/ui/default-chat-transport.ts", "../../node_modules/agents/node_modules/ai/src/ui/http-chat-transport.ts", "../../node_modules/agents/node_modules/ai/src/ui/last-assistant-message-is-complete-with-tool-calls.ts", "../../node_modules/agents/node_modules/ai/src/ui/transform-text-to-ui-message-stream.ts", "../../node_modules/agents/node_modules/ai/src/ui/text-stream-chat-transport.ts", "../../node_modules/agents/node_modules/ai/src/ui/validate-ui-messages.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/create-ui-message-stream.ts", "../../node_modules/agents/node_modules/ai/src/ui-message-stream/read-ui-message-stream.ts", "../../node_modules/agents/src/ai-react.tsx"],
  "sourcesContent": ["function throttle(function_, wait) {\n\tif (typeof function_ !== 'function') {\n\t\tthrow new TypeError(`Expected the first argument to be a \\`function\\`, got \\`${typeof function_}\\`.`);\n\t}\n\n\t// TODO: Add `wait` validation too in the next major version.\n\n\tlet timeoutId;\n\tlet lastCallTime = 0;\n\n\treturn function throttled(...arguments_) { // eslint-disable-line func-names\n\t\tclearTimeout(timeoutId);\n\n\t\tconst now = Date.now();\n\t\tconst timeSinceLastCall = now - lastCallTime;\n\t\tconst delayForNextCall = wait - timeSinceLastCall;\n\n\t\tif (delayForNextCall <= 0) {\n\t\t\tlastCallTime = now;\n\t\t\tfunction_.apply(this, arguments_);\n\t\t} else {\n\t\t\ttimeoutId = setTimeout(() => {\n\t\t\t\tlastCallTime = Date.now();\n\t\t\t\tfunction_.apply(this, arguments_);\n\t\t\t}, delayForNextCall);\n\t\t}\n\t};\n}\n\nmodule.exports = throttle;\n", "/**\n * @license React\n * use-sync-external-store-shim.development.js\n *\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\"use strict\";\n\"production\" !== process.env.NODE_ENV &&\n  (function () {\n    function is(x, y) {\n      return (x === y && (0 !== x || 1 / x === 1 / y)) || (x !== x && y !== y);\n    }\n    function useSyncExternalStore$2(subscribe, getSnapshot) {\n      didWarnOld18Alpha ||\n        void 0 === React.startTransition ||\n        ((didWarnOld18Alpha = !0),\n        console.error(\n          \"You are using an outdated, pre-release alpha of React 18 that does not support useSyncExternalStore. The use-sync-external-store shim will not work correctly. Upgrade to a newer pre-release.\"\n        ));\n      var value = getSnapshot();\n      if (!didWarnUncachedGetSnapshot) {\n        var cachedValue = getSnapshot();\n        objectIs(value, cachedValue) ||\n          (console.error(\n            \"The result of getSnapshot should be cached to avoid an infinite loop\"\n          ),\n          (didWarnUncachedGetSnapshot = !0));\n      }\n      cachedValue = useState({\n        inst: { value: value, getSnapshot: getSnapshot }\n      });\n      var inst = cachedValue[0].inst,\n        forceUpdate = cachedValue[1];\n      useLayoutEffect(\n        function () {\n          inst.value = value;\n          inst.getSnapshot = getSnapshot;\n          checkIfSnapshotChanged(inst) && forceUpdate({ inst: inst });\n        },\n        [subscribe, value, getSnapshot]\n      );\n      useEffect(\n        function () {\n          checkIfSnapshotChanged(inst) && forceUpdate({ inst: inst });\n          return subscribe(function () {\n            checkIfSnapshotChanged(inst) && forceUpdate({ inst: inst });\n          });\n        },\n        [subscribe]\n      );\n      useDebugValue(value);\n      return value;\n    }\n    function checkIfSnapshotChanged(inst) {\n      var latestGetSnapshot = inst.getSnapshot;\n      inst = inst.value;\n      try {\n        var nextValue = latestGetSnapshot();\n        return !objectIs(inst, nextValue);\n      } catch (error) {\n        return !0;\n      }\n    }\n    function useSyncExternalStore$1(subscribe, getSnapshot) {\n      return getSnapshot();\n    }\n    \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n      \"function\" ===\n        typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart &&\n      __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStart(Error());\n    var React = require(\"react\"),\n      objectIs = \"function\" === typeof Object.is ? Object.is : is,\n      useState = React.useState,\n      useEffect = React.useEffect,\n      useLayoutEffect = React.useLayoutEffect,\n      useDebugValue = React.useDebugValue,\n      didWarnOld18Alpha = !1,\n      didWarnUncachedGetSnapshot = !1,\n      shim =\n        \"undefined\" === typeof window ||\n        \"undefined\" === typeof window.document ||\n        \"undefined\" === typeof window.document.createElement\n          ? useSyncExternalStore$1\n          : useSyncExternalStore$2;\n    exports.useSyncExternalStore =\n      void 0 !== React.useSyncExternalStore ? React.useSyncExternalStore : shim;\n    \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n      \"function\" ===\n        typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&\n      __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop(Error());\n  })();\n", "'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('../cjs/use-sync-external-store-shim.production.js');\n} else {\n  module.exports = require('../cjs/use-sync-external-store-shim.development.js');\n}\n", "\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\nvar get_context_exports = {};\n__export(get_context_exports, {\n  SYMBOL_FOR_REQ_CONTEXT: () => SYMBOL_FOR_REQ_CONTEXT,\n  getContext: () => getContext\n});\nmodule.exports = __toCommonJS(get_context_exports);\nconst SYMBOL_FOR_REQ_CONTEXT = Symbol.for(\"@vercel/request-context\");\nfunction getContext() {\n  const fromSymbol = globalThis;\n  return fromSymbol[SYMBOL_FOR_REQ_CONTEXT]?.get?.() ?? {};\n}\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  SYMBOL_FOR_REQ_CONTEXT,\n  getContext\n});\n", "\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\nvar index_browser_exports = {};\n__export(index_browser_exports, {\n  getContext: () => import_get_context.getContext,\n  getVercelOidcToken: () => getVercelOidcToken,\n  getVercelOidcTokenSync: () => getVercelOidcTokenSync\n});\nmodule.exports = __toCommonJS(index_browser_exports);\nvar import_get_context = require(\"./get-context\");\nasync function getVercelOidcToken() {\n  return \"\";\n}\nfunction getVercelOidcTokenSync() {\n  return \"\";\n}\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  getContext,\n  getVercelOidcToken,\n  getVercelOidcTokenSync\n});\n", "export const urlAlphabet =\n  'useandom-26T198340PX75pxJACKVERYMINDBUSHWOLF_GQZbfghjklqvwyzrict'\n", "/* @ts-self-types=\"./index.d.ts\" */\nimport { urlAlphabet as scopedUrlAlphabet } from './url-alphabet/index.js'\nexport { urlAlphabet } from './url-alphabet/index.js'\nexport let random = bytes => crypto.getRandomValues(new Uint8Array(bytes))\nexport let customRandom = (alphabet, defaultSize, getRandom) => {\n  let mask = (2 << Math.log2(alphabet.length - 1)) - 1\n  let step = -~((1.6 * mask * defaultSize) / alphabet.length)\n  return (size = defaultSize) => {\n    let id = ''\n    while (true) {\n      let bytes = getRandom(step)\n      let j = step | 0\n      while (j--) {\n        id += alphabet[bytes[j] & mask] || ''\n        if (id.length >= size) return id\n      }\n    }\n  }\n}\nexport let customAlphabet = (alphabet, size = 21) =>\n  customRandom(alphabet, size | 0, random)\nexport let nanoid = (size = 21) => {\n  let id = ''\n  let bytes = crypto.getRandomValues(new Uint8Array((size |= 0)))\n  while (size--) {\n    id += scopedUrlAlphabet[bytes[size] & 63]\n  }\n  return id\n}\n", "import {\n  AbstractChat,\n  ChatInit,\n  type CreateUIMessage,\n  type UIMessage,\n} from 'ai';\nimport { useCallback, useEffect, useRef, useSyncExternalStore } from 'react';\nimport { Chat } from './chat.react';\n\nexport type { CreateUIMessage, UIMessage };\n\nexport type UseChatHelpers<UI_MESSAGE extends UIMessage> = {\n  /**\n   * The id of the chat.\n   */\n  readonly id: string;\n\n  /**\n   * Update the `messages` state locally. This is useful when you want to\n   * edit the messages on the client, and then trigger the `reload` method\n   * manually to regenerate the AI response.\n   */\n  setMessages: (\n    messages: UI_MESSAGE[] | ((messages: UI_MESSAGE[]) => UI_MESSAGE[]),\n  ) => void;\n\n  error: Error | undefined;\n} & Pick<\n  AbstractChat<UI_MESSAGE>,\n  | 'sendMessage'\n  | 'regenerate'\n  | 'stop'\n  | 'resumeStream'\n  | 'addToolResult'\n  | 'addToolOutput'\n  | 'status'\n  | 'messages'\n  | 'clearError'\n>;\n\nexport type UseChatOptions<UI_MESSAGE extends UIMessage> = (\n  | { chat: Chat<UI_MESSAGE> }\n  | ChatInit<UI_MESSAGE>\n) & {\n  /**\nCustom throttle wait in ms for the chat messages and data updates.\nDefault is undefined, which disables throttling.\n   */\n  experimental_throttle?: number;\n\n  /**\n   * Whether to resume an ongoing chat generation stream.\n   */\n  resume?: boolean;\n};\n\nexport function useChat<UI_MESSAGE extends UIMessage = UIMessage>({\n  experimental_throttle: throttleWaitMs,\n  resume = false,\n  ...options\n}: UseChatOptions<UI_MESSAGE> = {}): UseChatHelpers<UI_MESSAGE> {\n  const chatRef = useRef<Chat<UI_MESSAGE>>(\n    'chat' in options ? options.chat : new Chat(options),\n  );\n\n  const shouldRecreateChat =\n    ('chat' in options && options.chat !== chatRef.current) ||\n    ('id' in options && chatRef.current.id !== options.id);\n\n  if (shouldRecreateChat) {\n    chatRef.current = 'chat' in options ? options.chat : new Chat(options);\n  }\n\n  const optionsId = 'id' in options ? options.id : null;\n\n  const subscribeToMessages = useCallback(\n    (update: () => void) =>\n      chatRef.current['~registerMessagesCallback'](update, throttleWaitMs),\n    // optionsId is required to trigger re-subscription when the chat ID changes\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n    [throttleWaitMs, optionsId],\n  );\n\n  const messages = useSyncExternalStore(\n    subscribeToMessages,\n    () => chatRef.current.messages,\n    () => chatRef.current.messages,\n  );\n\n  const status = useSyncExternalStore(\n    chatRef.current['~registerStatusCallback'],\n    () => chatRef.current.status,\n    () => chatRef.current.status,\n  );\n\n  const error = useSyncExternalStore(\n    chatRef.current['~registerErrorCallback'],\n    () => chatRef.current.error,\n    () => chatRef.current.error,\n  );\n\n  const setMessages = useCallback(\n    (\n      messagesParam: UI_MESSAGE[] | ((messages: UI_MESSAGE[]) => UI_MESSAGE[]),\n    ) => {\n      if (typeof messagesParam === 'function') {\n        messagesParam = messagesParam(chatRef.current.messages);\n      }\n      chatRef.current.messages = messagesParam;\n    },\n    [chatRef],\n  );\n\n  useEffect(() => {\n    if (resume) {\n      chatRef.current.resumeStream();\n    }\n  }, [resume, chatRef]);\n\n  return {\n    id: chatRef.current.id,\n    messages,\n    setMessages,\n    sendMessage: chatRef.current.sendMessage,\n    regenerate: chatRef.current.regenerate,\n    clearError: chatRef.current.clearError,\n    stop: chatRef.current.stop,\n    error,\n    resumeStream: chatRef.current.resumeStream,\n    status,\n    /**\n     * @deprecated Use `addToolOutput` instead.\n     */\n    addToolResult: chatRef.current.addToolOutput,\n    addToolOutput: chatRef.current.addToolOutput,\n  };\n}\n", "import { AbstractChat, ChatInit, ChatState, ChatStatus, UIMessage } from 'ai';\nimport { throttle } from './throttle';\n\nclass ReactChatState<UI_MESSAGE extends UIMessage>\n  implements ChatState<UI_MESSAGE>\n{\n  #messages: UI_MESSAGE[];\n  #status: ChatStatus = 'ready';\n  #error: Error | undefined = undefined;\n\n  #messagesCallbacks = new Set<() => void>();\n  #statusCallbacks = new Set<() => void>();\n  #errorCallbacks = new Set<() => void>();\n\n  constructor(initialMessages: UI_MESSAGE[] = []) {\n    this.#messages = initialMessages;\n  }\n\n  get status(): ChatStatus {\n    return this.#status;\n  }\n\n  set status(newStatus: ChatStatus) {\n    this.#status = newStatus;\n    this.#callStatusCallbacks();\n  }\n\n  get error(): Error | undefined {\n    return this.#error;\n  }\n\n  set error(newError: Error | undefined) {\n    this.#error = newError;\n    this.#callErrorCallbacks();\n  }\n\n  get messages(): UI_MESSAGE[] {\n    return this.#messages;\n  }\n\n  set messages(newMessages: UI_MESSAGE[]) {\n    this.#messages = [...newMessages];\n    this.#callMessagesCallbacks();\n  }\n\n  pushMessage = (message: UI_MESSAGE) => {\n    this.#messages = this.#messages.concat(message);\n    this.#callMessagesCallbacks();\n  };\n\n  popMessage = () => {\n    this.#messages = this.#messages.slice(0, -1);\n    this.#callMessagesCallbacks();\n  };\n\n  replaceMessage = (index: number, message: UI_MESSAGE) => {\n    this.#messages = [\n      ...this.#messages.slice(0, index),\n      // We deep clone the message here to ensure the new React Compiler (currently in RC) detects deeply nested parts/metadata changes:\n      this.snapshot(message),\n      ...this.#messages.slice(index + 1),\n    ];\n    this.#callMessagesCallbacks();\n  };\n\n  snapshot = <T>(value: T): T => structuredClone(value);\n\n  '~registerMessagesCallback' = (\n    onChange: () => void,\n    throttleWaitMs?: number,\n  ): (() => void) => {\n    const callback = throttleWaitMs\n      ? throttle(onChange, throttleWaitMs)\n      : onChange;\n    this.#messagesCallbacks.add(callback);\n    return () => {\n      this.#messagesCallbacks.delete(callback);\n    };\n  };\n\n  '~registerStatusCallback' = (onChange: () => void): (() => void) => {\n    this.#statusCallbacks.add(onChange);\n    return () => {\n      this.#statusCallbacks.delete(onChange);\n    };\n  };\n\n  '~registerErrorCallback' = (onChange: () => void): (() => void) => {\n    this.#errorCallbacks.add(onChange);\n    return () => {\n      this.#errorCallbacks.delete(onChange);\n    };\n  };\n\n  #callMessagesCallbacks = () => {\n    this.#messagesCallbacks.forEach(callback => callback());\n  };\n\n  #callStatusCallbacks = () => {\n    this.#statusCallbacks.forEach(callback => callback());\n  };\n\n  #callErrorCallbacks = () => {\n    this.#errorCallbacks.forEach(callback => callback());\n  };\n}\n\nexport class Chat<\n  UI_MESSAGE extends UIMessage,\n> extends AbstractChat<UI_MESSAGE> {\n  #state: ReactChatState<UI_MESSAGE>;\n\n  constructor({ messages, ...init }: ChatInit<UI_MESSAGE>) {\n    const state = new ReactChatState(messages);\n    super({ ...init, state });\n    this.#state = state;\n  }\n\n  '~registerMessagesCallback' = (\n    onChange: () => void,\n    throttleWaitMs?: number,\n  ): (() => void) =>\n    this.#state['~registerMessagesCallback'](onChange, throttleWaitMs);\n\n  '~registerStatusCallback' = (onChange: () => void): (() => void) =>\n    this.#state['~registerStatusCallback'](onChange);\n\n  '~registerErrorCallback' = (onChange: () => void): (() => void) =>\n    this.#state['~registerErrorCallback'](onChange);\n}\n", "import throttleFunction from 'throttleit';\n\nexport function throttle<T extends (...args: any[]) => any>(\n  fn: T,\n  waitMs: number | undefined,\n): T {\n  return waitMs != null ? throttleFunction(fn, waitMs) : fn;\n}\n", "import {\n  CompletionRequestOptions,\n  UseCompletionOptions,\n  callCompletionApi,\n} from 'ai';\nimport { useCallback, useEffect, useId, useRef, useState } from 'react';\nimport useSWR from 'swr';\nimport { throttle } from './throttle';\n\nexport type { UseCompletionOptions };\n\nexport type UseCompletionHelpers = {\n  /** The current completion result */\n  completion: string;\n  /**\n   * Send a new prompt to the API endpoint and update the completion state.\n   */\n  complete: (\n    prompt: string,\n    options?: CompletionRequestOptions,\n  ) => Promise<string | null | undefined>;\n  /** The error object of the API request */\n  error: undefined | Error;\n  /**\n   * Abort the current API request but keep the generated tokens.\n   */\n  stop: () => void;\n  /**\n   * Update the `completion` state locally.\n   */\n  setCompletion: (completion: string) => void;\n  /** The current value of the input */\n  input: string;\n  /** setState-powered method to update the input value */\n  setInput: React.Dispatch<React.SetStateAction<string>>;\n  /**\n   * An input/textarea-ready onChange handler to control the value of the input\n   * @example\n   * ```jsx\n   * <input onChange={handleInputChange} value={input} />\n   * ```\n   */\n  handleInputChange: (\n    event:\n      | React.ChangeEvent<HTMLInputElement>\n      | React.ChangeEvent<HTMLTextAreaElement>,\n  ) => void;\n\n  /**\n   * Form submission handler to automatically reset input and append a user message\n   * @example\n   * ```jsx\n   * <form onSubmit={handleSubmit}>\n   *  <input onChange={handleInputChange} value={input} />\n   * </form>\n   * ```\n   */\n  handleSubmit: (event?: { preventDefault?: () => void }) => void;\n\n  /** Whether the API request is in progress */\n  isLoading: boolean;\n};\n\nexport function useCompletion({\n  api = '/api/completion',\n  id,\n  initialCompletion = '',\n  initialInput = '',\n  credentials,\n  headers,\n  body,\n  streamProtocol = 'data',\n  fetch,\n  onFinish,\n  onError,\n  experimental_throttle: throttleWaitMs,\n}: UseCompletionOptions & {\n  /**\n   * Custom throttle wait in ms for the completion and data updates.\n   * Default is undefined, which disables throttling.\n   */\n  experimental_throttle?: number;\n} = {}): UseCompletionHelpers {\n  // Generate an unique id for the completion if not provided.\n  const hookId = useId();\n  const completionId = id || hookId;\n\n  // Store the completion state in SWR, using the completionId as the key to share states.\n  const { data, mutate } = useSWR<string>([api, completionId], null, {\n    fallbackData: initialCompletion,\n  });\n\n  const { data: isLoading = false, mutate: mutateLoading } = useSWR<boolean>(\n    [completionId, 'loading'],\n    null,\n  );\n\n  const [error, setError] = useState<undefined | Error>(undefined);\n  const completion = data!;\n\n  // Abort controller to cancel the current API call.\n  const [abortController, setAbortController] =\n    useState<AbortController | null>(null);\n\n  const extraMetadataRef = useRef({\n    credentials,\n    headers,\n    body,\n  });\n\n  useEffect(() => {\n    extraMetadataRef.current = {\n      credentials,\n      headers,\n      body,\n    };\n  }, [credentials, headers, body]);\n\n  const triggerRequest = useCallback(\n    async (prompt: string, options?: CompletionRequestOptions) =>\n      callCompletionApi({\n        api,\n        prompt,\n        credentials: extraMetadataRef.current.credentials,\n        headers: { ...extraMetadataRef.current.headers, ...options?.headers },\n        body: {\n          ...extraMetadataRef.current.body,\n          ...options?.body,\n        },\n        streamProtocol,\n        fetch,\n        // throttle streamed ui updates:\n        setCompletion: throttle(\n          (completion: string) => mutate(completion, false),\n          throttleWaitMs,\n        ),\n        setLoading: mutateLoading,\n        setError,\n        setAbortController,\n        onFinish,\n        onError,\n      }),\n    [\n      mutate,\n      mutateLoading,\n      api,\n      extraMetadataRef,\n      setAbortController,\n      onFinish,\n      onError,\n      setError,\n      streamProtocol,\n      fetch,\n      throttleWaitMs,\n    ],\n  );\n\n  const stop = useCallback(() => {\n    if (abortController) {\n      abortController.abort();\n      setAbortController(null);\n    }\n  }, [abortController]);\n\n  const setCompletion = useCallback(\n    (completion: string) => {\n      mutate(completion, false);\n    },\n    [mutate],\n  );\n\n  const complete = useCallback<UseCompletionHelpers['complete']>(\n    async (prompt, options) => {\n      return triggerRequest(prompt, options);\n    },\n    [triggerRequest],\n  );\n\n  const [input, setInput] = useState(initialInput);\n\n  const handleSubmit = useCallback(\n    (event?: { preventDefault?: () => void }) => {\n      event?.preventDefault?.();\n      return input ? complete(input) : undefined;\n    },\n    [input, complete],\n  );\n\n  const handleInputChange = useCallback(\n    (e: any) => {\n      setInput(e.target.value);\n    },\n    [setInput],\n  );\n\n  return {\n    completion,\n    complete,\n    error,\n    setCompletion,\n    stop,\n    input,\n    setInput,\n    handleInputChange,\n    handleSubmit,\n    isLoading,\n  };\n}\n", "import {\n  FetchFunction,\n  InferSchema,\n  isAbortError,\n  safeValidateTypes,\n} from '@ai-sdk/provider-utils';\nimport {\n  asSchema,\n  DeepPartial,\n  isDeepEqualData,\n  parsePartialJson,\n  Schema,\n} from 'ai';\nimport { useCallback, useId, useRef, useState } from 'react';\nimport useSWR from 'swr';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4';\n\n// use function to allow for mocking in tests:\nconst getOriginalFetch = () => fetch;\n\nexport type Experimental_UseObjectOptions<\n  SCHEMA extends z4.core.$ZodType | z3.Schema | Schema,\n  RESULT,\n> = {\n  /**\n   * The API endpoint. It should stream JSON that matches the schema as chunked text.\n   */\n  api: string;\n\n  /**\n   * A Zod schema that defines the shape of the complete object.\n   */\n  schema: SCHEMA;\n\n  /**\n   * An unique identifier. If not provided, a random one will be\n   * generated. When provided, the `useObject` hook with the same `id` will\n   * have shared states across components.\n   */\n  id?: string;\n\n  /**\n   * An optional value for the initial object.\n   */\n  initialValue?: DeepPartial<RESULT>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n\n  /**\nCallback that is called when the stream has finished.\n     */\n  onFinish?: (event: {\n    /**\nThe generated object (typed according to the schema).\nCan be undefined if the final object does not match the schema.\n   */\n    object: RESULT | undefined;\n\n    /**\nOptional error object. This is e.g. a TypeValidationError when the final object does not match the schema.\n */\n    error: Error | undefined;\n  }) => Promise<void> | void;\n\n  /**\n   * Callback function to be called when an error is encountered.\n   */\n  onError?: (error: Error) => void;\n\n  /**\n   * Additional HTTP headers to be included in the request.\n   */\n  headers?: Record<string, string> | Headers;\n\n  /**\n   * The credentials mode to be used for the fetch request.\n   * Possible values are: 'omit', 'same-origin', 'include'.\n   * Defaults to 'same-origin'.\n   */\n  credentials?: RequestCredentials;\n};\n\nexport type Experimental_UseObjectHelpers<RESULT, INPUT> = {\n  /**\n   * Calls the API with the provided input as JSON body.\n   */\n  submit: (input: INPUT) => void;\n\n  /**\n   * The current value for the generated object. Updated as the API streams JSON chunks.\n   */\n  object: DeepPartial<RESULT> | undefined;\n\n  /**\n   * The error object of the API request if any.\n   */\n  error: Error | undefined;\n\n  /**\n   * Flag that indicates whether an API request is in progress.\n   */\n  isLoading: boolean;\n\n  /**\n   * Abort the current request immediately, keep the current partial object if any.\n   */\n  stop: () => void;\n\n  /**\n   * Clear the object state.\n   */\n  clear: () => void;\n};\n\nfunction useObject<\n  SCHEMA extends z4.core.$ZodType | z3.Schema | Schema,\n  RESULT = InferSchema<SCHEMA>,\n  INPUT = any,\n>({\n  api,\n  id,\n  schema, // required, in the future we will use it for validation\n  initialValue,\n  fetch,\n  onError,\n  onFinish,\n  headers,\n  credentials,\n}: Experimental_UseObjectOptions<\n  SCHEMA,\n  RESULT\n>): Experimental_UseObjectHelpers<RESULT, INPUT> {\n  // Generate an unique id if not provided.\n  const hookId = useId();\n  const completionId = id ?? hookId;\n\n  // Store the completion state in SWR, using the completionId as the key to share states.\n  const { data, mutate } = useSWR<DeepPartial<RESULT>>(\n    [api, completionId],\n    null,\n    { fallbackData: initialValue },\n  );\n\n  const [error, setError] = useState<undefined | Error>(undefined);\n  const [isLoading, setIsLoading] = useState(false);\n\n  // Abort controller to cancel the current API call.\n  const abortControllerRef = useRef<AbortController | null>(null);\n\n  const stop = useCallback(() => {\n    try {\n      abortControllerRef.current?.abort();\n    } catch (ignored) {\n    } finally {\n      setIsLoading(false);\n      abortControllerRef.current = null;\n    }\n  }, []);\n\n  const submit = async (input: INPUT) => {\n    try {\n      clearObject();\n\n      setIsLoading(true);\n\n      const abortController = new AbortController();\n      abortControllerRef.current = abortController;\n\n      const actualFetch = fetch ?? getOriginalFetch();\n      const response = await actualFetch(api, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          ...headers,\n        },\n        credentials,\n        signal: abortController.signal,\n        body: JSON.stringify(input),\n      });\n\n      if (!response.ok) {\n        throw new Error(\n          (await response.text()) ?? 'Failed to fetch the response.',\n        );\n      }\n\n      if (response.body == null) {\n        throw new Error('The response body is empty.');\n      }\n\n      let accumulatedText = '';\n      let latestObject: DeepPartial<RESULT> | undefined = undefined;\n\n      await response.body.pipeThrough(new TextDecoderStream()).pipeTo(\n        new WritableStream<string>({\n          async write(chunk) {\n            accumulatedText += chunk;\n\n            const { value } = await parsePartialJson(accumulatedText);\n            const currentObject = value as DeepPartial<RESULT>;\n\n            if (!isDeepEqualData(latestObject, currentObject)) {\n              latestObject = currentObject;\n\n              mutate(currentObject);\n            }\n          },\n\n          async close() {\n            setIsLoading(false);\n            abortControllerRef.current = null;\n\n            if (onFinish != null) {\n              const validationResult = await safeValidateTypes({\n                value: latestObject,\n                schema: asSchema(schema),\n              });\n\n              onFinish(\n                validationResult.success\n                  ? { object: validationResult.value, error: undefined }\n                  : { object: undefined, error: validationResult.error },\n              );\n            }\n          },\n        }),\n      );\n    } catch (error) {\n      if (isAbortError(error)) {\n        return;\n      }\n\n      if (onError && error instanceof Error) {\n        onError(error);\n      }\n\n      setIsLoading(false);\n      setError(error instanceof Error ? error : new Error(String(error)));\n    }\n  };\n\n  const clear = () => {\n    stop();\n    clearObject();\n  };\n\n  const clearObject = () => {\n    setError(undefined);\n    setIsLoading(false);\n    mutate(undefined);\n  };\n\n  return {\n    submit,\n    object: data,\n    error,\n    isLoading,\n    stop,\n    clear,\n  };\n}\n\nexport const experimental_useObject = useObject;\n", "import React, { useRef, useMemo, useCallback, useDebugValue } from 'react';\nimport { useSyncExternalStore } from 'use-sync-external-store/shim/index.js';\nimport { UNDEFINED as UNDEFINED$1, OBJECT as OBJECT$1, SWRConfig as SWRConfig$1, defaultConfig, withArgs, SWRGlobalState, serialize as serialize$1, createCacheHelper, isUndefined as isUndefined$1, isPromiseLike, getTimestamp, isFunction as isFunction$1, revalidateEvents, internalMutate, useIsomorphicLayoutEffect, subscribeCallback, IS_SERVER, rAF, IS_REACT_LEGACY, mergeObjects } from '../_internal/index.mjs';\nexport { mutate, preload, useSWRConfig } from '../_internal/index.mjs';\n\n// Shared state between server components and client components\nconst noop = ()=>{};\n// Using noop() as the undefined value as undefined can be replaced\n// by something else. Prettier ignore and extra parentheses are necessary here\n// to ensure that tsc doesn't remove the __NOINLINE__ comment.\n// prettier-ignore\nconst UNDEFINED = /*#__NOINLINE__*/ noop();\nconst OBJECT = Object;\nconst isUndefined = (v)=>v === UNDEFINED;\nconst isFunction = (v)=>typeof v == 'function';\n\n// use WeakMap to store the object->key mapping\n// so the objects can be garbage collected.\n// WeakMap uses a hashtable under the hood, so the lookup\n// complexity is almost O(1).\nconst table = new WeakMap();\nconst getTypeName = (value)=>OBJECT.prototype.toString.call(value);\nconst isObjectTypeName = (typeName, type)=>typeName === `[object ${type}]`;\n// counter of the key\nlet counter = 0;\n// A stable hash implementation that supports:\n// - Fast and ensures unique hash properties\n// - Handles unserializable values\n// - Handles object key ordering\n// - Generates short results\n//\n// This is not a serialization function, and the result is not guaranteed to be\n// parsable.\nconst stableHash = (arg)=>{\n    const type = typeof arg;\n    const typeName = getTypeName(arg);\n    const isDate = isObjectTypeName(typeName, 'Date');\n    const isRegex = isObjectTypeName(typeName, 'RegExp');\n    const isPlainObject = isObjectTypeName(typeName, 'Object');\n    let result;\n    let index;\n    if (OBJECT(arg) === arg && !isDate && !isRegex) {\n        // Object/function, not null/date/regexp. Use WeakMap to store the id first.\n        // If it's already hashed, directly return the result.\n        result = table.get(arg);\n        if (result) return result;\n        // Store the hash first for circular reference detection before entering the\n        // recursive `stableHash` calls.\n        // For other objects like set and map, we use this id directly as the hash.\n        result = ++counter + '~';\n        table.set(arg, result);\n        if (Array.isArray(arg)) {\n            // Array.\n            result = '@';\n            for(index = 0; index < arg.length; index++){\n                result += stableHash(arg[index]) + ',';\n            }\n            table.set(arg, result);\n        }\n        if (isPlainObject) {\n            // Object, sort keys.\n            result = '#';\n            const keys = OBJECT.keys(arg).sort();\n            while(!isUndefined(index = keys.pop())){\n                if (!isUndefined(arg[index])) {\n                    result += index + ':' + stableHash(arg[index]) + ',';\n                }\n            }\n            table.set(arg, result);\n        }\n    } else {\n        result = isDate ? arg.toJSON() : type == 'symbol' ? arg.toString() : type == 'string' ? JSON.stringify(arg) : '' + arg;\n    }\n    return result;\n};\n\nconst serialize = (key)=>{\n    if (isFunction(key)) {\n        try {\n            key = key();\n        } catch (err) {\n            // dependencies not ready\n            key = '';\n        }\n    }\n    // Use the original key as the argument of fetcher. This can be a string or an\n    // array of values.\n    const args = key;\n    // If key is not falsy, or not an empty array, hash it.\n    key = typeof key == 'string' ? key : (Array.isArray(key) ? key.length : key) ? stableHash(key) : '';\n    return [\n        key,\n        args\n    ];\n};\n\nconst unstable_serialize = (key)=>serialize(key)[0];\n\n/// <reference types=\"react/experimental\" />\nconst use = React.use || // This extra generic is to avoid TypeScript mixing up the generic and JSX sytax\n// and emitting an error.\n// We assume that this is only for the `use(thenable)` case, not `use(context)`.\n// https://github.com/facebook/react/blob/aed00dacfb79d17c53218404c52b1c7aa59c4a89/packages/react-server/src/ReactFizzThenable.js#L45\n((thenable)=>{\n    switch(thenable.status){\n        case 'pending':\n            throw thenable;\n        case 'fulfilled':\n            return thenable.value;\n        case 'rejected':\n            throw thenable.reason;\n        default:\n            thenable.status = 'pending';\n            thenable.then((v)=>{\n                thenable.status = 'fulfilled';\n                thenable.value = v;\n            }, (e)=>{\n                thenable.status = 'rejected';\n                thenable.reason = e;\n            });\n            throw thenable;\n    }\n});\nconst WITH_DEDUPE = {\n    dedupe: true\n};\nconst resolvedUndef = Promise.resolve(UNDEFINED$1);\nconst useSWRHandler = (_key, fetcher, config)=>{\n    const { cache, compare, suspense, fallbackData, revalidateOnMount, revalidateIfStale, refreshInterval, refreshWhenHidden, refreshWhenOffline, keepPreviousData } = config;\n    const [EVENT_REVALIDATORS, MUTATION, FETCH, PRELOAD] = SWRGlobalState.get(cache);\n    // `key` is the identifier of the SWR internal state,\n    // `fnArg` is the argument/arguments parsed from the key, which will be passed\n    // to the fetcher.\n    // All of them are derived from `_key`.\n    const [key, fnArg] = serialize$1(_key);\n    // If it's the initial render of this hook.\n    const initialMountedRef = useRef(false);\n    // If the hook is unmounted already. This will be used to prevent some effects\n    // to be called after unmounting.\n    const unmountedRef = useRef(false);\n    // Refs to keep the key and config.\n    const keyRef = useRef(key);\n    const fetcherRef = useRef(fetcher);\n    const configRef = useRef(config);\n    const getConfig = ()=>configRef.current;\n    const isActive = ()=>getConfig().isVisible() && getConfig().isOnline();\n    const [getCache, setCache, subscribeCache, getInitialCache] = createCacheHelper(cache, key);\n    const stateDependencies = useRef({}).current;\n    // Resolve the fallback data from either the inline option, or the global provider.\n    // If it's a promise, we simply let React suspend and resolve it for us.\n    const fallback = isUndefined$1(fallbackData) ? isUndefined$1(config.fallback) ? UNDEFINED$1 : config.fallback[key] : fallbackData;\n    const isEqual = (prev, current)=>{\n        for(const _ in stateDependencies){\n            const t = _;\n            if (t === 'data') {\n                if (!compare(prev[t], current[t])) {\n                    if (!isUndefined$1(prev[t])) {\n                        return false;\n                    }\n                    if (!compare(returnedData, current[t])) {\n                        return false;\n                    }\n                }\n            } else {\n                if (current[t] !== prev[t]) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    };\n    const getSnapshot = useMemo(()=>{\n        const shouldStartRequest = (()=>{\n            if (!key) return false;\n            if (!fetcher) return false;\n            // If `revalidateOnMount` is set, we take the value directly.\n            if (!isUndefined$1(revalidateOnMount)) return revalidateOnMount;\n            // If it's paused, we skip revalidation.\n            if (getConfig().isPaused()) return false;\n            if (suspense) return false;\n            return revalidateIfStale !== false;\n        })();\n        // Get the cache and merge it with expected states.\n        const getSelectedCache = (state)=>{\n            // We only select the needed fields from the state.\n            const snapshot = mergeObjects(state);\n            delete snapshot._k;\n            if (!shouldStartRequest) {\n                return snapshot;\n            }\n            return {\n                isValidating: true,\n                isLoading: true,\n                ...snapshot\n            };\n        };\n        const cachedData = getCache();\n        const initialData = getInitialCache();\n        const clientSnapshot = getSelectedCache(cachedData);\n        const serverSnapshot = cachedData === initialData ? clientSnapshot : getSelectedCache(initialData);\n        // To make sure that we are returning the same object reference to avoid\n        // unnecessary re-renders, we keep the previous snapshot and use deep\n        // comparison to check if we need to return a new one.\n        let memorizedSnapshot = clientSnapshot;\n        return [\n            ()=>{\n                const newSnapshot = getSelectedCache(getCache());\n                const compareResult = isEqual(newSnapshot, memorizedSnapshot);\n                if (compareResult) {\n                    // Mentally, we should always return the `memorizedSnapshot` here\n                    // as there's no change between the new and old snapshots.\n                    // However, since the `isEqual` function only compares selected fields,\n                    // the values of the unselected fields might be changed. That's\n                    // simply because we didn't track them.\n                    // To support the case in https://github.com/vercel/swr/pull/2576,\n                    // we need to update these fields in the `memorizedSnapshot` too\n                    // with direct mutations to ensure the snapshot is always up-to-date\n                    // even for the unselected fields, but only trigger re-renders when\n                    // the selected fields are changed.\n                    memorizedSnapshot.data = newSnapshot.data;\n                    memorizedSnapshot.isLoading = newSnapshot.isLoading;\n                    memorizedSnapshot.isValidating = newSnapshot.isValidating;\n                    memorizedSnapshot.error = newSnapshot.error;\n                    return memorizedSnapshot;\n                } else {\n                    memorizedSnapshot = newSnapshot;\n                    return newSnapshot;\n                }\n            },\n            ()=>serverSnapshot\n        ];\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n    }, [\n        cache,\n        key\n    ]);\n    // Get the current state that SWR should return.\n    const cached = useSyncExternalStore(useCallback((callback)=>subscribeCache(key, (current, prev)=>{\n            if (!isEqual(prev, current)) callback();\n        }), // eslint-disable-next-line react-hooks/exhaustive-deps\n    [\n        cache,\n        key\n    ]), getSnapshot[0], getSnapshot[1]);\n    const isInitialMount = !initialMountedRef.current;\n    const hasRevalidator = EVENT_REVALIDATORS[key] && EVENT_REVALIDATORS[key].length > 0;\n    const cachedData = cached.data;\n    const data = isUndefined$1(cachedData) ? fallback && isPromiseLike(fallback) ? use(fallback) : fallback : cachedData;\n    const error = cached.error;\n    // Use a ref to store previously returned data. Use the initial data as its initial value.\n    const laggyDataRef = useRef(data);\n    const returnedData = keepPreviousData ? isUndefined$1(cachedData) ? isUndefined$1(laggyDataRef.current) ? data : laggyDataRef.current : cachedData : data;\n    // - Suspense mode and there's stale data for the initial render.\n    // - Not suspense mode and there is no fallback data and `revalidateIfStale` is enabled.\n    // - `revalidateIfStale` is enabled but `data` is not defined.\n    const shouldDoInitialRevalidation = (()=>{\n        // if a key already has revalidators and also has error, we should not trigger revalidation\n        if (hasRevalidator && !isUndefined$1(error)) return false;\n        // If `revalidateOnMount` is set, we take the value directly.\n        if (isInitialMount && !isUndefined$1(revalidateOnMount)) return revalidateOnMount;\n        // If it's paused, we skip revalidation.\n        if (getConfig().isPaused()) return false;\n        // Under suspense mode, it will always fetch on render if there is no\n        // stale data so no need to revalidate immediately mount it again.\n        // If data exists, only revalidate if `revalidateIfStale` is true.\n        if (suspense) return isUndefined$1(data) ? false : revalidateIfStale;\n        // If there is no stale data, we need to revalidate when mount;\n        // If `revalidateIfStale` is set to true, we will always revalidate.\n        return isUndefined$1(data) || revalidateIfStale;\n    })();\n    // Resolve the default validating state:\n    // If it's able to validate, and it should revalidate when mount, this will be true.\n    const defaultValidatingState = !!(key && fetcher && isInitialMount && shouldDoInitialRevalidation);\n    const isValidating = isUndefined$1(cached.isValidating) ? defaultValidatingState : cached.isValidating;\n    const isLoading = isUndefined$1(cached.isLoading) ? defaultValidatingState : cached.isLoading;\n    // The revalidation function is a carefully crafted wrapper of the original\n    // `fetcher`, to correctly handle the many edge cases.\n    const revalidate = useCallback(async (revalidateOpts)=>{\n        const currentFetcher = fetcherRef.current;\n        if (!key || !currentFetcher || unmountedRef.current || getConfig().isPaused()) {\n            return false;\n        }\n        let newData;\n        let startAt;\n        let loading = true;\n        const opts = revalidateOpts || {};\n        // If there is no ongoing concurrent request, or `dedupe` is not set, a\n        // new request should be initiated.\n        const shouldStartNewRequest = !FETCH[key] || !opts.dedupe;\n        /*\n         For React 17\n         Do unmount check for calls:\n         If key has changed during the revalidation, or the component has been\n         unmounted, old dispatch and old event callbacks should not take any\n         effect\n\n        For React 18\n        only check if key has changed\n        https://github.com/reactwg/react-18/discussions/82\n      */ const callbackSafeguard = ()=>{\n            if (IS_REACT_LEGACY) {\n                return !unmountedRef.current && key === keyRef.current && initialMountedRef.current;\n            }\n            return key === keyRef.current;\n        };\n        // The final state object when the request finishes.\n        const finalState = {\n            isValidating: false,\n            isLoading: false\n        };\n        const finishRequestAndUpdateState = ()=>{\n            setCache(finalState);\n        };\n        const cleanupState = ()=>{\n            // Check if it's still the same request before deleting it.\n            const requestInfo = FETCH[key];\n            if (requestInfo && requestInfo[1] === startAt) {\n                delete FETCH[key];\n            }\n        };\n        // Start fetching. Change the `isValidating` state, update the cache.\n        const initialState = {\n            isValidating: true\n        };\n        // It is in the `isLoading` state, if and only if there is no cached data.\n        // This bypasses fallback data and laggy data.\n        if (isUndefined$1(getCache().data)) {\n            initialState.isLoading = true;\n        }\n        try {\n            if (shouldStartNewRequest) {\n                setCache(initialState);\n                // If no cache is being rendered currently (it shows a blank page),\n                // we trigger the loading slow event.\n                if (config.loadingTimeout && isUndefined$1(getCache().data)) {\n                    setTimeout(()=>{\n                        if (loading && callbackSafeguard()) {\n                            getConfig().onLoadingSlow(key, config);\n                        }\n                    }, config.loadingTimeout);\n                }\n                // Start the request and save the timestamp.\n                // Key must be truthy if entering here.\n                FETCH[key] = [\n                    currentFetcher(fnArg),\n                    getTimestamp()\n                ];\n            }\n            // Wait until the ongoing request is done. Deduplication is also\n            // considered here.\n            ;\n            [newData, startAt] = FETCH[key];\n            newData = await newData;\n            if (shouldStartNewRequest) {\n                // If the request isn't interrupted, clean it up after the\n                // deduplication interval.\n                setTimeout(cleanupState, config.dedupingInterval);\n            }\n            // If there're other ongoing request(s), started after the current one,\n            // we need to ignore the current one to avoid possible race conditions:\n            //   req1------------------>res1        (current one)\n            //        req2---------------->res2\n            // the request that fired later will always be kept.\n            // The timestamp maybe be `undefined` or a number\n            if (!FETCH[key] || FETCH[key][1] !== startAt) {\n                if (shouldStartNewRequest) {\n                    if (callbackSafeguard()) {\n                        getConfig().onDiscarded(key);\n                    }\n                }\n                return false;\n            }\n            // Clear error.\n            finalState.error = UNDEFINED$1;\n            // If there're other mutations(s), that overlapped with the current revalidation:\n            // case 1:\n            //   req------------------>res\n            //       mutate------>end\n            // case 2:\n            //         req------------>res\n            //   mutate------>end\n            // case 3:\n            //   req------------------>res\n            //       mutate-------...---------->\n            // we have to ignore the revalidation result (res) because it's no longer fresh.\n            // meanwhile, a new revalidation should be triggered when the mutation ends.\n            const mutationInfo = MUTATION[key];\n            if (!isUndefined$1(mutationInfo) && // case 1\n            (startAt <= mutationInfo[0] || // case 2\n            startAt <= mutationInfo[1] || // case 3\n            mutationInfo[1] === 0)) {\n                finishRequestAndUpdateState();\n                if (shouldStartNewRequest) {\n                    if (callbackSafeguard()) {\n                        getConfig().onDiscarded(key);\n                    }\n                }\n                return false;\n            }\n            // Deep compare with the latest state to avoid extra re-renders.\n            // For local state, compare and assign.\n            const cacheData = getCache().data;\n            // Since the compare fn could be custom fn\n            // cacheData might be different from newData even when compare fn returns True\n            finalState.data = compare(cacheData, newData) ? cacheData : newData;\n            // Trigger the successful callback if it's the original request.\n            if (shouldStartNewRequest) {\n                if (callbackSafeguard()) {\n                    getConfig().onSuccess(newData, key, config);\n                }\n            }\n        } catch (err) {\n            cleanupState();\n            const currentConfig = getConfig();\n            const { shouldRetryOnError } = currentConfig;\n            // Not paused, we continue handling the error. Otherwise, discard it.\n            if (!currentConfig.isPaused()) {\n                // Get a new error, don't use deep comparison for errors.\n                finalState.error = err;\n                // Error event and retry logic. Only for the actual request, not\n                // deduped ones.\n                if (shouldStartNewRequest && callbackSafeguard()) {\n                    currentConfig.onError(err, key, currentConfig);\n                    if (shouldRetryOnError === true || isFunction$1(shouldRetryOnError) && shouldRetryOnError(err)) {\n                        if (!getConfig().revalidateOnFocus || !getConfig().revalidateOnReconnect || isActive()) {\n                            // If it's inactive, stop. It will auto-revalidate when\n                            // refocusing or reconnecting.\n                            // When retrying, deduplication is always enabled.\n                            currentConfig.onErrorRetry(err, key, currentConfig, (_opts)=>{\n                                const revalidators = EVENT_REVALIDATORS[key];\n                                if (revalidators && revalidators[0]) {\n                                    revalidators[0](revalidateEvents.ERROR_REVALIDATE_EVENT, _opts);\n                                }\n                            }, {\n                                retryCount: (opts.retryCount || 0) + 1,\n                                dedupe: true\n                            });\n                        }\n                    }\n                }\n            }\n        }\n        // Mark loading as stopped.\n        loading = false;\n        // Update the current hook's state.\n        finishRequestAndUpdateState();\n        return true;\n    }, // `setState` is immutable, and `eventsCallback`, `fnArg`, and\n    // `keyValidating` are depending on `key`, so we can exclude them from\n    // the deps array.\n    //\n    // FIXME:\n    // `fn` and `config` might be changed during the lifecycle,\n    // but they might be changed every render like this.\n    // `useSWR('key', () => fetch('/api/'), { suspense: true })`\n    // So we omit the values from the deps array\n    // even though it might cause unexpected behaviors.\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n    [\n        key,\n        cache\n    ]);\n    // Similar to the global mutate but bound to the current cache and key.\n    // `cache` isn't allowed to change during the lifecycle.\n    const boundMutate = useCallback(// Use callback to make sure `keyRef.current` returns latest result every time\n    (...args)=>{\n        return internalMutate(cache, keyRef.current, ...args);\n    }, // eslint-disable-next-line react-hooks/exhaustive-deps\n    []);\n    // The logic for updating refs.\n    useIsomorphicLayoutEffect(()=>{\n        fetcherRef.current = fetcher;\n        configRef.current = config;\n        // Handle laggy data updates. If there's cached data of the current key,\n        // it'll be the correct reference.\n        if (!isUndefined$1(cachedData)) {\n            laggyDataRef.current = cachedData;\n        }\n    });\n    // After mounted or key changed.\n    useIsomorphicLayoutEffect(()=>{\n        if (!key) return;\n        const softRevalidate = revalidate.bind(UNDEFINED$1, WITH_DEDUPE);\n        let nextFocusRevalidatedAt = 0;\n        if (getConfig().revalidateOnFocus) {\n            const initNow = Date.now();\n            nextFocusRevalidatedAt = initNow + getConfig().focusThrottleInterval;\n        }\n        // Expose revalidators to global event listeners. So we can trigger\n        // revalidation from the outside.\n        const onRevalidate = (type, opts = {})=>{\n            if (type == revalidateEvents.FOCUS_EVENT) {\n                const now = Date.now();\n                if (getConfig().revalidateOnFocus && now > nextFocusRevalidatedAt && isActive()) {\n                    nextFocusRevalidatedAt = now + getConfig().focusThrottleInterval;\n                    softRevalidate();\n                }\n            } else if (type == revalidateEvents.RECONNECT_EVENT) {\n                if (getConfig().revalidateOnReconnect && isActive()) {\n                    softRevalidate();\n                }\n            } else if (type == revalidateEvents.MUTATE_EVENT) {\n                return revalidate();\n            } else if (type == revalidateEvents.ERROR_REVALIDATE_EVENT) {\n                return revalidate(opts);\n            }\n            return;\n        };\n        const unsubEvents = subscribeCallback(key, EVENT_REVALIDATORS, onRevalidate);\n        // Mark the component as mounted and update corresponding refs.\n        unmountedRef.current = false;\n        keyRef.current = key;\n        initialMountedRef.current = true;\n        // Keep the original key in the cache.\n        setCache({\n            _k: fnArg\n        });\n        // Trigger a revalidation\n        if (shouldDoInitialRevalidation) {\n            // Performance optimization: if a request is already in progress for this key,\n            // skip the revalidation to avoid redundant work\n            if (!FETCH[key]) {\n                if (isUndefined$1(data) || IS_SERVER) {\n                    // Revalidate immediately.\n                    softRevalidate();\n                } else {\n                    // Delay the revalidate if we have data to return so we won't block\n                    // rendering.\n                    rAF(softRevalidate);\n                }\n            }\n        }\n        return ()=>{\n            // Mark it as unmounted.\n            unmountedRef.current = true;\n            unsubEvents();\n        };\n    }, [\n        key\n    ]);\n    // Polling\n    useIsomorphicLayoutEffect(()=>{\n        let timer;\n        function next() {\n            // Use the passed interval\n            // ...or invoke the function with the updated data to get the interval\n            const interval = isFunction$1(refreshInterval) ? refreshInterval(getCache().data) : refreshInterval;\n            // We only start the next interval if `refreshInterval` is not 0, and:\n            // - `force` is true, which is the start of polling\n            // - or `timer` is not 0, which means the effect wasn't canceled\n            if (interval && timer !== -1) {\n                timer = setTimeout(execute, interval);\n            }\n        }\n        function execute() {\n            // Check if it's OK to execute:\n            // Only revalidate when the page is visible, online, and not errored.\n            if (!getCache().error && (refreshWhenHidden || getConfig().isVisible()) && (refreshWhenOffline || getConfig().isOnline())) {\n                revalidate(WITH_DEDUPE).then(next);\n            } else {\n                // Schedule the next interval to check again.\n                next();\n            }\n        }\n        next();\n        return ()=>{\n            if (timer) {\n                clearTimeout(timer);\n                timer = -1;\n            }\n        };\n    }, [\n        refreshInterval,\n        refreshWhenHidden,\n        refreshWhenOffline,\n        key\n    ]);\n    // Display debug info in React DevTools.\n    useDebugValue(returnedData);\n    // In Suspense mode, we can't return the empty `data` state.\n    // If there is an `error`, the `error` needs to be thrown to the error boundary.\n    // If there is no `error`, the `revalidation` promise needs to be thrown to\n    // the suspense boundary.\n    if (suspense) {\n        const hasKeyButNoData = key && isUndefined$1(data);\n        // SWR should throw when trying to use Suspense on the server with React 18,\n        // without providing any fallback data. This causes hydration errors. See:\n        // https://github.com/vercel/swr/issues/1832\n        if (!IS_REACT_LEGACY && IS_SERVER && hasKeyButNoData) {\n            throw new Error('Fallback data is required when using Suspense in SSR.');\n        }\n        // Always update fetcher and config refs even with the Suspense mode.\n        if (hasKeyButNoData) {\n            fetcherRef.current = fetcher;\n            configRef.current = config;\n            unmountedRef.current = false;\n        }\n        const req = PRELOAD[key];\n        const mutateReq = !isUndefined$1(req) && hasKeyButNoData ? boundMutate(req) : resolvedUndef;\n        use(mutateReq);\n        if (!isUndefined$1(error) && hasKeyButNoData) {\n            throw error;\n        }\n        const revalidation = hasKeyButNoData ? revalidate(WITH_DEDUPE) : resolvedUndef;\n        if (!isUndefined$1(returnedData) && hasKeyButNoData) {\n            // @ts-ignore modify react promise status\n            revalidation.status = 'fulfilled';\n            // @ts-ignore modify react promise value\n            revalidation.value = true;\n        }\n        use(revalidation);\n    }\n    const swrResponse = {\n        mutate: boundMutate,\n        get data () {\n            stateDependencies.data = true;\n            return returnedData;\n        },\n        get error () {\n            stateDependencies.error = true;\n            return error;\n        },\n        get isValidating () {\n            stateDependencies.isValidating = true;\n            return isValidating;\n        },\n        get isLoading () {\n            stateDependencies.isLoading = true;\n            return isLoading;\n        }\n    };\n    return swrResponse;\n};\nconst SWRConfig = OBJECT$1.defineProperty(SWRConfig$1, 'defaultValue', {\n    value: defaultConfig\n});\n/**\n * A hook to fetch data.\n *\n * @link https://swr.vercel.app\n * @example\n * ```jsx\n * import useSWR from 'swr'\n * function Profile() {\n *   const { data, error, isLoading } = useSWR('/api/user', fetcher)\n *   if (error) return <div>failed to load</div>\n *   if (isLoading) return <div>loading...</div>\n *   return <div>hello {data.name}!</div>\n * }\n * ```\n */ const useSWR = withArgs(useSWRHandler);\n\n// useSWR\n\nexport { SWRConfig, useSWR as default, unstable_serialize };\n", "'use client';\nimport React, { useEffect, useLayoutEffect, createContext, useContext, useMemo, useRef, createElement } from 'react';\nimport * as revalidateEvents from './events.mjs';\nimport { dequal } from 'dequal/lite';\n\n// Global state used to deduplicate requests and store listeners\nconst SWRGlobalState = new WeakMap();\n\n// Shared state between server components and client components\nconst noop = ()=>{};\n// Using noop() as the undefined value as undefined can be replaced\n// by something else. Prettier ignore and extra parentheses are necessary here\n// to ensure that tsc doesn't remove the __NOINLINE__ comment.\n// prettier-ignore\nconst UNDEFINED = /*#__NOINLINE__*/ noop();\nconst OBJECT = Object;\nconst isUndefined = (v)=>v === UNDEFINED;\nconst isFunction = (v)=>typeof v == 'function';\nconst mergeObjects = (a, b)=>({\n        ...a,\n        ...b\n    });\nconst isPromiseLike = (x)=>isFunction(x.then);\n\nconst EMPTY_CACHE = {};\nconst INITIAL_CACHE = {};\nconst STR_UNDEFINED = 'undefined';\n// NOTE: Use the function to guarantee it's re-evaluated between jsdom and node runtime for tests.\nconst isWindowDefined = typeof window != STR_UNDEFINED;\nconst isDocumentDefined = typeof document != STR_UNDEFINED;\nconst isLegacyDeno = isWindowDefined && 'Deno' in window;\nconst hasRequestAnimationFrame = ()=>isWindowDefined && typeof window['requestAnimationFrame'] != STR_UNDEFINED;\nconst createCacheHelper = (cache, key)=>{\n    const state = SWRGlobalState.get(cache);\n    return [\n        // Getter\n        ()=>!isUndefined(key) && cache.get(key) || EMPTY_CACHE,\n        // Setter\n        (info)=>{\n            if (!isUndefined(key)) {\n                const prev = cache.get(key);\n                // Before writing to the store, we keep the value in the initial cache\n                // if it's not there yet.\n                if (!(key in INITIAL_CACHE)) {\n                    INITIAL_CACHE[key] = prev;\n                }\n                state[5](key, mergeObjects(prev, info), prev || EMPTY_CACHE);\n            }\n        },\n        // Subscriber\n        state[6],\n        // Get server cache snapshot\n        ()=>{\n            if (!isUndefined(key)) {\n                // If the cache was updated on the client, we return the stored initial value.\n                if (key in INITIAL_CACHE) return INITIAL_CACHE[key];\n            }\n            // If we haven't done any client-side updates, we return the current value.\n            return !isUndefined(key) && cache.get(key) || EMPTY_CACHE;\n        }\n    ];\n} // export { UNDEFINED, OBJECT, isUndefined, isFunction, mergeObjects, isPromiseLike }\n;\n\n/**\n * Due to the bug https://bugs.chromium.org/p/chromium/issues/detail?id=678075,\n * it's not reliable to detect if the browser is currently online or offline\n * based on `navigator.onLine`.\n * As a workaround, we always assume it's online on the first load, and change\n * the status upon `online` or `offline` events.\n */ let online = true;\nconst isOnline = ()=>online;\n// For node and React Native, `add/removeEventListener` doesn't exist on window.\nconst [onWindowEvent, offWindowEvent] = isWindowDefined && window.addEventListener ? [\n    window.addEventListener.bind(window),\n    window.removeEventListener.bind(window)\n] : [\n    noop,\n    noop\n];\nconst isVisible = ()=>{\n    const visibilityState = isDocumentDefined && document.visibilityState;\n    return isUndefined(visibilityState) || visibilityState !== 'hidden';\n};\nconst initFocus = (callback)=>{\n    // focus revalidate\n    if (isDocumentDefined) {\n        document.addEventListener('visibilitychange', callback);\n    }\n    onWindowEvent('focus', callback);\n    return ()=>{\n        if (isDocumentDefined) {\n            document.removeEventListener('visibilitychange', callback);\n        }\n        offWindowEvent('focus', callback);\n    };\n};\nconst initReconnect = (callback)=>{\n    // revalidate on reconnected\n    const onOnline = ()=>{\n        online = true;\n        callback();\n    };\n    // nothing to revalidate, just update the status\n    const onOffline = ()=>{\n        online = false;\n    };\n    onWindowEvent('online', onOnline);\n    onWindowEvent('offline', onOffline);\n    return ()=>{\n        offWindowEvent('online', onOnline);\n        offWindowEvent('offline', onOffline);\n    };\n};\nconst preset = {\n    isOnline,\n    isVisible\n};\nconst defaultConfigOptions = {\n    initFocus,\n    initReconnect\n};\n\nconst IS_REACT_LEGACY = !React.useId;\nconst IS_SERVER = !isWindowDefined || isLegacyDeno;\n// Polyfill requestAnimationFrame\nconst rAF = (f)=>hasRequestAnimationFrame() ? window['requestAnimationFrame'](f) : setTimeout(f, 1);\n// React currently throws a warning when using useLayoutEffect on the server.\n// To get around it, we can conditionally useEffect on the server (no-op) and\n// useLayoutEffect in the browser.\nconst useIsomorphicLayoutEffect = IS_SERVER ? useEffect : useLayoutEffect;\n// This assignment is to extend the Navigator type to use effectiveType.\nconst navigatorConnection = typeof navigator !== 'undefined' && navigator.connection;\n// Adjust the config based on slow connection status (<= 70Kbps).\nconst slowConnection = !IS_SERVER && navigatorConnection && ([\n    'slow-2g',\n    '2g'\n].includes(navigatorConnection.effectiveType) || navigatorConnection.saveData);\n\n// use WeakMap to store the object->key mapping\n// so the objects can be garbage collected.\n// WeakMap uses a hashtable under the hood, so the lookup\n// complexity is almost O(1).\nconst table = new WeakMap();\nconst getTypeName = (value)=>OBJECT.prototype.toString.call(value);\nconst isObjectTypeName = (typeName, type)=>typeName === `[object ${type}]`;\n// counter of the key\nlet counter = 0;\n// A stable hash implementation that supports:\n// - Fast and ensures unique hash properties\n// - Handles unserializable values\n// - Handles object key ordering\n// - Generates short results\n//\n// This is not a serialization function, and the result is not guaranteed to be\n// parsable.\nconst stableHash = (arg)=>{\n    const type = typeof arg;\n    const typeName = getTypeName(arg);\n    const isDate = isObjectTypeName(typeName, 'Date');\n    const isRegex = isObjectTypeName(typeName, 'RegExp');\n    const isPlainObject = isObjectTypeName(typeName, 'Object');\n    let result;\n    let index;\n    if (OBJECT(arg) === arg && !isDate && !isRegex) {\n        // Object/function, not null/date/regexp. Use WeakMap to store the id first.\n        // If it's already hashed, directly return the result.\n        result = table.get(arg);\n        if (result) return result;\n        // Store the hash first for circular reference detection before entering the\n        // recursive `stableHash` calls.\n        // For other objects like set and map, we use this id directly as the hash.\n        result = ++counter + '~';\n        table.set(arg, result);\n        if (Array.isArray(arg)) {\n            // Array.\n            result = '@';\n            for(index = 0; index < arg.length; index++){\n                result += stableHash(arg[index]) + ',';\n            }\n            table.set(arg, result);\n        }\n        if (isPlainObject) {\n            // Object, sort keys.\n            result = '#';\n            const keys = OBJECT.keys(arg).sort();\n            while(!isUndefined(index = keys.pop())){\n                if (!isUndefined(arg[index])) {\n                    result += index + ':' + stableHash(arg[index]) + ',';\n                }\n            }\n            table.set(arg, result);\n        }\n    } else {\n        result = isDate ? arg.toJSON() : type == 'symbol' ? arg.toString() : type == 'string' ? JSON.stringify(arg) : '' + arg;\n    }\n    return result;\n};\n\nconst serialize = (key)=>{\n    if (isFunction(key)) {\n        try {\n            key = key();\n        } catch (err) {\n            // dependencies not ready\n            key = '';\n        }\n    }\n    // Use the original key as the argument of fetcher. This can be a string or an\n    // array of values.\n    const args = key;\n    // If key is not falsy, or not an empty array, hash it.\n    key = typeof key == 'string' ? key : (Array.isArray(key) ? key.length : key) ? stableHash(key) : '';\n    return [\n        key,\n        args\n    ];\n};\n\n// Global timestamp.\nlet __timestamp = 0;\nconst getTimestamp = ()=>++__timestamp;\n\nasync function internalMutate(...args) {\n    const [cache, _key, _data, _opts] = args;\n    // When passing as a boolean, it's explicitly used to disable/enable\n    // revalidation.\n    const options = mergeObjects({\n        populateCache: true,\n        throwOnError: true\n    }, typeof _opts === 'boolean' ? {\n        revalidate: _opts\n    } : _opts || {});\n    let populateCache = options.populateCache;\n    const rollbackOnErrorOption = options.rollbackOnError;\n    let optimisticData = options.optimisticData;\n    const rollbackOnError = (error)=>{\n        return typeof rollbackOnErrorOption === 'function' ? rollbackOnErrorOption(error) : rollbackOnErrorOption !== false;\n    };\n    const throwOnError = options.throwOnError;\n    // If the second argument is a key filter, return the mutation results for all\n    // filtered keys.\n    if (isFunction(_key)) {\n        const keyFilter = _key;\n        const matchedKeys = [];\n        const it = cache.keys();\n        for (const key of it){\n            if (// Skip the special useSWRInfinite and useSWRSubscription keys.\n            !/^\\$(inf|sub)\\$/.test(key) && keyFilter(cache.get(key)._k)) {\n                matchedKeys.push(key);\n            }\n        }\n        return Promise.all(matchedKeys.map(mutateByKey));\n    }\n    return mutateByKey(_key);\n    async function mutateByKey(_k) {\n        // Serialize key\n        const [key] = serialize(_k);\n        if (!key) return;\n        const [get, set] = createCacheHelper(cache, key);\n        const [EVENT_REVALIDATORS, MUTATION, FETCH, PRELOAD] = SWRGlobalState.get(cache);\n        const startRevalidate = ()=>{\n            const revalidators = EVENT_REVALIDATORS[key];\n            const revalidate = isFunction(options.revalidate) ? options.revalidate(get().data, _k) : options.revalidate !== false;\n            if (revalidate) {\n                // Invalidate the key by deleting the concurrent request markers so new\n                // requests will not be deduped.\n                delete FETCH[key];\n                delete PRELOAD[key];\n                if (revalidators && revalidators[0]) {\n                    return revalidators[0](revalidateEvents.MUTATE_EVENT).then(()=>get().data);\n                }\n            }\n            return get().data;\n        };\n        // If there is no new data provided, revalidate the key with current state.\n        if (args.length < 3) {\n            // Revalidate and broadcast state.\n            return startRevalidate();\n        }\n        let data = _data;\n        let error;\n        let isError = false;\n        // Update global timestamps.\n        const beforeMutationTs = getTimestamp();\n        MUTATION[key] = [\n            beforeMutationTs,\n            0\n        ];\n        const hasOptimisticData = !isUndefined(optimisticData);\n        const state = get();\n        // `displayedData` is the current value on screen. It could be the optimistic value\n        // that is going to be overridden by a `committedData`, or get reverted back.\n        // `committedData` is the validated value that comes from a fetch or mutation.\n        const displayedData = state.data;\n        const currentData = state._c;\n        const committedData = isUndefined(currentData) ? displayedData : currentData;\n        // Do optimistic data update.\n        if (hasOptimisticData) {\n            optimisticData = isFunction(optimisticData) ? optimisticData(committedData, displayedData) : optimisticData;\n            // When we set optimistic data, backup the current committedData data in `_c`.\n            set({\n                data: optimisticData,\n                _c: committedData\n            });\n        }\n        if (isFunction(data)) {\n            // `data` is a function, call it passing current cache value.\n            try {\n                data = data(committedData);\n            } catch (err) {\n                // If it throws an error synchronously, we shouldn't update the cache.\n                error = err;\n                isError = true;\n            }\n        }\n        // `data` is a promise/thenable, resolve the final data first.\n        if (data && isPromiseLike(data)) {\n            // This means that the mutation is async, we need to check timestamps to\n            // avoid race conditions.\n            data = await data.catch((err)=>{\n                error = err;\n                isError = true;\n            });\n            // Check if other mutations have occurred since we've started this mutation.\n            // If there's a race we don't update cache or broadcast the change,\n            // just return the data.\n            if (beforeMutationTs !== MUTATION[key][0]) {\n                if (isError) throw error;\n                return data;\n            } else if (isError && hasOptimisticData && rollbackOnError(error)) {\n                // Rollback. Always populate the cache in this case but without\n                // transforming the data.\n                populateCache = true;\n                // Reset data to be the latest committed data, and clear the `_c` value.\n                set({\n                    data: committedData,\n                    _c: UNDEFINED\n                });\n            }\n        }\n        // If we should write back the cache after request.\n        if (populateCache) {\n            if (!isError) {\n                // Transform the result into data.\n                if (isFunction(populateCache)) {\n                    const populateCachedData = populateCache(data, committedData);\n                    set({\n                        data: populateCachedData,\n                        error: UNDEFINED,\n                        _c: UNDEFINED\n                    });\n                } else {\n                    // Only update cached data and reset the error if there's no error. Data can be `undefined` here.\n                    set({\n                        data,\n                        error: UNDEFINED,\n                        _c: UNDEFINED\n                    });\n                }\n            }\n        }\n        // Reset the timestamp to mark the mutation has ended.\n        MUTATION[key][1] = getTimestamp();\n        // Update existing SWR Hooks' internal states:\n        Promise.resolve(startRevalidate()).then(()=>{\n            // The mutation and revalidation are ended, we can clear it since the data is\n            // not an optimistic value anymore.\n            set({\n                _c: UNDEFINED\n            });\n        });\n        // Throw error or return data\n        if (isError) {\n            if (throwOnError) throw error;\n            return;\n        }\n        return data;\n    }\n}\n\nconst revalidateAllKeys = (revalidators, type)=>{\n    for(const key in revalidators){\n        if (revalidators[key][0]) revalidators[key][0](type);\n    }\n};\nconst initCache = (provider, options)=>{\n    // The global state for a specific provider will be used to deduplicate\n    // requests and store listeners. As well as a mutate function that is bound to\n    // the cache.\n    // The provider's global state might be already initialized. Let's try to get the\n    // global state associated with the provider first.\n    if (!SWRGlobalState.has(provider)) {\n        const opts = mergeObjects(defaultConfigOptions, options);\n        // If there's no global state bound to the provider, create a new one with the\n        // new mutate function.\n        const EVENT_REVALIDATORS = Object.create(null);\n        const mutate = internalMutate.bind(UNDEFINED, provider);\n        let unmount = noop;\n        const subscriptions = Object.create(null);\n        const subscribe = (key, callback)=>{\n            const subs = subscriptions[key] || [];\n            subscriptions[key] = subs;\n            subs.push(callback);\n            return ()=>subs.splice(subs.indexOf(callback), 1);\n        };\n        const setter = (key, value, prev)=>{\n            provider.set(key, value);\n            const subs = subscriptions[key];\n            if (subs) {\n                for (const fn of subs){\n                    fn(value, prev);\n                }\n            }\n        };\n        const initProvider = ()=>{\n            if (!SWRGlobalState.has(provider)) {\n                // Update the state if it's new, or if the provider has been extended.\n                SWRGlobalState.set(provider, [\n                    EVENT_REVALIDATORS,\n                    Object.create(null),\n                    Object.create(null),\n                    Object.create(null),\n                    mutate,\n                    setter,\n                    subscribe\n                ]);\n                if (!IS_SERVER) {\n                    // When listening to the native events for auto revalidations,\n                    // we intentionally put a delay (setTimeout) here to make sure they are\n                    // fired after immediate JavaScript executions, which can be\n                    // React's state updates.\n                    // This avoids some unnecessary revalidations such as\n                    // https://github.com/vercel/swr/issues/1680.\n                    const releaseFocus = opts.initFocus(setTimeout.bind(UNDEFINED, revalidateAllKeys.bind(UNDEFINED, EVENT_REVALIDATORS, revalidateEvents.FOCUS_EVENT)));\n                    const releaseReconnect = opts.initReconnect(setTimeout.bind(UNDEFINED, revalidateAllKeys.bind(UNDEFINED, EVENT_REVALIDATORS, revalidateEvents.RECONNECT_EVENT)));\n                    unmount = ()=>{\n                        releaseFocus && releaseFocus();\n                        releaseReconnect && releaseReconnect();\n                        // When un-mounting, we need to remove the cache provider from the state\n                        // storage too because it's a side-effect. Otherwise, when re-mounting we\n                        // will not re-register those event listeners.\n                        SWRGlobalState.delete(provider);\n                    };\n                }\n            }\n        };\n        initProvider();\n        // This is a new provider, we need to initialize it and setup DOM events\n        // listeners for `focus` and `reconnect` actions.\n        // We might want to inject an extra layer on top of `provider` in the future,\n        // such as key serialization, auto GC, etc.\n        // For now, it's just a `Map` interface without any modifications.\n        return [\n            provider,\n            mutate,\n            initProvider,\n            unmount\n        ];\n    }\n    return [\n        provider,\n        SWRGlobalState.get(provider)[4]\n    ];\n};\n\n// error retry\nconst onErrorRetry = (_, __, config, revalidate, opts)=>{\n    const maxRetryCount = config.errorRetryCount;\n    const currentRetryCount = opts.retryCount;\n    // Exponential backoff\n    const timeout = ~~((Math.random() + 0.5) * (1 << (currentRetryCount < 8 ? currentRetryCount : 8))) * config.errorRetryInterval;\n    if (!isUndefined(maxRetryCount) && currentRetryCount > maxRetryCount) {\n        return;\n    }\n    setTimeout(revalidate, timeout, opts);\n};\nconst compare = dequal;\n// Default cache provider\nconst [cache, mutate] = initCache(new Map());\n// Default config\nconst defaultConfig = mergeObjects({\n    // events\n    onLoadingSlow: noop,\n    onSuccess: noop,\n    onError: noop,\n    onErrorRetry,\n    onDiscarded: noop,\n    // switches\n    revalidateOnFocus: true,\n    revalidateOnReconnect: true,\n    revalidateIfStale: true,\n    shouldRetryOnError: true,\n    // timeouts\n    errorRetryInterval: slowConnection ? 10000 : 5000,\n    focusThrottleInterval: 5 * 1000,\n    dedupingInterval: 2 * 1000,\n    loadingTimeout: slowConnection ? 5000 : 3000,\n    // providers\n    compare,\n    isPaused: ()=>false,\n    cache,\n    mutate,\n    fallback: {}\n}, // use web preset by default\npreset);\n\nconst mergeConfigs = (a, b)=>{\n    // Need to create a new object to avoid mutating the original here.\n    const v = mergeObjects(a, b);\n    // If two configs are provided, merge their `use` and `fallback` options.\n    if (b) {\n        const { use: u1, fallback: f1 } = a;\n        const { use: u2, fallback: f2 } = b;\n        if (u1 && u2) {\n            v.use = u1.concat(u2);\n        }\n        if (f1 && f2) {\n            v.fallback = mergeObjects(f1, f2);\n        }\n    }\n    return v;\n};\n\nconst SWRConfigContext = createContext({});\nconst SWRConfig = (props)=>{\n    const { value } = props;\n    const parentConfig = useContext(SWRConfigContext);\n    const isFunctionalConfig = isFunction(value);\n    const config = useMemo(()=>isFunctionalConfig ? value(parentConfig) : value, [\n        isFunctionalConfig,\n        parentConfig,\n        value\n    ]);\n    // Extend parent context values and middleware.\n    const extendedConfig = useMemo(()=>isFunctionalConfig ? config : mergeConfigs(parentConfig, config), [\n        isFunctionalConfig,\n        parentConfig,\n        config\n    ]);\n    // Should not use the inherited provider.\n    const provider = config && config.provider;\n    // initialize the cache only on first access.\n    const cacheContextRef = useRef(UNDEFINED);\n    if (provider && !cacheContextRef.current) {\n        cacheContextRef.current = initCache(provider(extendedConfig.cache || cache), config);\n    }\n    const cacheContext = cacheContextRef.current;\n    // Override the cache if a new provider is given.\n    if (cacheContext) {\n        extendedConfig.cache = cacheContext[0];\n        extendedConfig.mutate = cacheContext[1];\n    }\n    // Unsubscribe events.\n    useIsomorphicLayoutEffect(()=>{\n        if (cacheContext) {\n            cacheContext[2] && cacheContext[2]();\n            return cacheContext[3];\n        }\n    }, []);\n    return createElement(SWRConfigContext.Provider, mergeObjects(props, {\n        value: extendedConfig\n    }));\n};\n\nexport { noop as A, isPromiseLike as B, IS_REACT_LEGACY as I, OBJECT as O, SWRConfigContext as S, UNDEFINED as U, isFunction as a, SWRGlobalState as b, cache as c, defaultConfig as d, isUndefined as e, mergeConfigs as f, SWRConfig as g, initCache as h, isWindowDefined as i, mutate as j, compare as k, stableHash as l, mergeObjects as m, internalMutate as n, getTimestamp as o, preset as p, defaultConfigOptions as q, IS_SERVER as r, serialize as s, rAF as t, useIsomorphicLayoutEffect as u, slowConnection as v, isDocumentDefined as w, isLegacyDeno as x, hasRequestAnimationFrame as y, createCacheHelper as z };\n", "const FOCUS_EVENT = 0;\nconst RECONNECT_EVENT = 1;\nconst MUTATE_EVENT = 2;\nconst ERROR_REVALIDATE_EVENT = 3;\n\nexport { ERROR_REVALIDATE_EVENT, FOCUS_EVENT, MUTATE_EVENT, RECONNECT_EVENT };\n", "var has = Object.prototype.hasOwnProperty;\n\nexport function dequal(foo, bar) {\n\tvar ctor, len;\n\tif (foo === bar) return true;\n\n\tif (foo && bar && (ctor=foo.constructor) === bar.constructor) {\n\t\tif (ctor === Date) return foo.getTime() === bar.getTime();\n\t\tif (ctor === RegExp) return foo.toString() === bar.toString();\n\n\t\tif (ctor === Array) {\n\t\t\tif ((len=foo.length) === bar.length) {\n\t\t\t\twhile (len-- && dequal(foo[len], bar[len]));\n\t\t\t}\n\t\t\treturn len === -1;\n\t\t}\n\n\t\tif (!ctor || typeof foo === 'object') {\n\t\t\tlen = 0;\n\t\t\tfor (ctor in foo) {\n\t\t\t\tif (has.call(foo, ctor) && ++len && !has.call(bar, ctor)) return false;\n\t\t\t\tif (!(ctor in bar) || !dequal(foo[ctor], bar[ctor])) return false;\n\t\t\t}\n\t\t\treturn Object.keys(bar).length === len;\n\t\t}\n\t}\n\n\treturn foo !== foo && bar !== bar;\n}\n", "const INFINITE_PREFIX = '$inf$';\n\nexport { INFINITE_PREFIX };\n", "import { i as isWindowDefined, a as isFunction, S as SWRConfigContext, m as mergeObjects, d as defaultConfig, s as serialize, b as SWRGlobalState, c as cache, e as isUndefined, f as mergeConfigs } from './config-context-client-BoS53ST9.mjs';\nexport { I as IS_REACT_LEGACY, r as IS_SERVER, O as OBJECT, g as SWRConfig, U as UNDEFINED, k as compare, z as createCacheHelper, q as defaultConfigOptions, o as getTimestamp, y as hasRequestAnimationFrame, h as initCache, n as internalMutate, w as isDocumentDefined, x as isLegacyDeno, B as isPromiseLike, j as mutate, A as noop, p as preset, t as rAF, v as slowConnection, l as stableHash, u as useIsomorphicLayoutEffect } from './config-context-client-BoS53ST9.mjs';\nimport * as revalidateEvents from './events.mjs';\nexport { revalidateEvents };\nimport { INFINITE_PREFIX } from './constants.mjs';\nexport { INFINITE_PREFIX } from './constants.mjs';\nimport React, { useContext, useMemo } from 'react';\nexport * from './types.mjs';\n\n// @ts-expect-error\nconst enableDevtools = isWindowDefined && window.__SWR_DEVTOOLS_USE__;\nconst use = enableDevtools ? window.__SWR_DEVTOOLS_USE__ : [];\nconst setupDevTools = ()=>{\n    if (enableDevtools) {\n        // @ts-expect-error\n        window.__SWR_DEVTOOLS_REACT__ = React;\n    }\n};\n\nconst normalize = (args)=>{\n    return isFunction(args[1]) ? [\n        args[0],\n        args[1],\n        args[2] || {}\n    ] : [\n        args[0],\n        null,\n        (args[1] === null ? args[2] : args[1]) || {}\n    ];\n};\n\nconst useSWRConfig = ()=>{\n    const parentConfig = useContext(SWRConfigContext);\n    const mergedConfig = useMemo(()=>mergeObjects(defaultConfig, parentConfig), [\n        parentConfig\n    ]);\n    return mergedConfig;\n};\n\nconst preload = (key_, fetcher)=>{\n    const [key, fnArg] = serialize(key_);\n    const [, , , PRELOAD] = SWRGlobalState.get(cache);\n    // Prevent preload to be called multiple times before used.\n    if (PRELOAD[key]) return PRELOAD[key];\n    const req = fetcher(fnArg);\n    PRELOAD[key] = req;\n    return req;\n};\nconst middleware = (useSWRNext)=>(key_, fetcher_, config)=>{\n        // fetcher might be a sync function, so this should not be an async function\n        const fetcher = fetcher_ && ((...args)=>{\n            const [key] = serialize(key_);\n            const [, , , PRELOAD] = SWRGlobalState.get(cache);\n            if (key.startsWith(INFINITE_PREFIX)) {\n                // we want the infinite fetcher to be called.\n                // handling of the PRELOAD cache happens there.\n                return fetcher_(...args);\n            }\n            const req = PRELOAD[key];\n            if (isUndefined(req)) return fetcher_(...args);\n            delete PRELOAD[key];\n            return req;\n        });\n        return useSWRNext(key_, fetcher, config);\n    };\n\nconst BUILT_IN_MIDDLEWARE = use.concat(middleware);\n\n// It's tricky to pass generic types as parameters, so we just directly override\n// the types here.\nconst withArgs = (hook)=>{\n    return function useSWRArgs(...args) {\n        // Get the default and inherited configuration.\n        const fallbackConfig = useSWRConfig();\n        // Normalize arguments.\n        const [key, fn, _config] = normalize(args);\n        // Merge configurations.\n        const config = mergeConfigs(fallbackConfig, _config);\n        // Apply middleware\n        let next = hook;\n        const { use } = config;\n        const middleware = (use || []).concat(BUILT_IN_MIDDLEWARE);\n        for(let i = middleware.length; i--;){\n            next = middleware[i](next);\n        }\n        return next(key, fn || config.fetcher || null, config);\n    };\n};\n\n// Add a callback function to a list of keyed callback functions and return\n// the unsubscribe function.\nconst subscribeCallback = (key, callbacks, callback)=>{\n    const keyedRevalidators = callbacks[key] || (callbacks[key] = []);\n    keyedRevalidators.push(callback);\n    return ()=>{\n        const index = keyedRevalidators.indexOf(callback);\n        if (index >= 0) {\n            // O(1): faster than splice\n            keyedRevalidators[index] = keyedRevalidators[keyedRevalidators.length - 1];\n            keyedRevalidators.pop();\n        }\n    };\n};\n\n// Create a custom hook with a middleware\nconst withMiddleware = (useSWR, middleware)=>{\n    return (...args)=>{\n        const [key, fn, config] = normalize(args);\n        const uses = (config.use || []).concat(middleware);\n        return useSWR(key, fn, {\n            ...config,\n            use: uses\n        });\n    };\n};\n\nsetupDevTools();\n\nexport { SWRGlobalState, cache, defaultConfig, isFunction, isUndefined, isWindowDefined, mergeConfigs, mergeObjects, normalize, preload, serialize, subscribeCallback, useSWRConfig, withArgs, withMiddleware };\n", "export function combineHeaders(\n  ...headers: Array<Record<string, string | undefined> | undefined>\n): Record<string, string | undefined> {\n  return headers.reduce(\n    (combinedHeaders, currentHeaders) => ({\n      ...combinedHeaders,\n      ...(currentHeaders ?? {}),\n    }),\n    {},\n  ) as Record<string, string | undefined>;\n}\n", "/**\n * Converts an AsyncIterator to a ReadableStream.\n *\n * @template T - The type of elements produced by the AsyncIterator.\n * @param { <T>} iterator - The AsyncIterator to convert.\n * @returns {ReadableStream<T>} - A ReadableStream that provides the same data as the AsyncIterator.\n */\nexport function convertAsyncIteratorToReadableStream<T>(\n  iterator: AsyncIterator<T>,\n): ReadableStream<T> {\n  let cancelled = false;\n\n  return new ReadableStream<T>({\n    /**\n     * Called when the consumer wants to pull more data from the stream.\n     *\n     * @param {ReadableStreamDefaultController<T>} controller - The controller to enqueue data into the stream.\n     * @returns {Promise<void>}\n     */\n    async pull(controller) {\n      if (cancelled) return;\n      try {\n        const { value, done } = await iterator.next();\n        if (done) {\n          controller.close();\n        } else {\n          controller.enqueue(value);\n        }\n      } catch (error) {\n        controller.error(error);\n      }\n    },\n    /**\n     * Called when the consumer cancels the stream.\n     */\n    async cancel(reason?: unknown) {\n      cancelled = true;\n      if (iterator.return) {\n        try {\n          await iterator.return(reason);\n        } catch {\n          // intentionally ignore errors during cancellation\n        }\n      }\n    },\n  });\n}\n", "/**\n * Creates a Promise that resolves after a specified delay\n * @param delayInMs - The delay duration in milliseconds. If null or undefined, resolves immediately.\n * @param signal - Optional AbortSignal to cancel the delay\n * @returns A Promise that resolves after the specified delay\n * @throws {DOMException} When the signal is aborted\n */\nexport async function delay(\n  delayInMs?: number | null,\n  options?: {\n    abortSignal?: AbortSignal;\n  },\n): Promise<void> {\n  if (delayInMs == null) {\n    return Promise.resolve();\n  }\n\n  const signal = options?.abortSignal;\n\n  return new Promise<void>((resolve, reject) => {\n    if (signal?.aborted) {\n      reject(createAbortError());\n      return;\n    }\n\n    const timeoutId = setTimeout(() => {\n      cleanup();\n      resolve();\n    }, delayInMs);\n\n    const cleanup = () => {\n      clearTimeout(timeoutId);\n      signal?.removeEventListener('abort', onAbort);\n    };\n\n    const onAbort = () => {\n      cleanup();\n      reject(createAbortError());\n    };\n\n    signal?.addEventListener('abort', onAbort);\n  });\n}\n\nfunction createAbortError(): DOMException {\n  return new DOMException('Delay was aborted', 'AbortError');\n}\n", "/**\nExtracts the headers from a response object and returns them as a key-value object.\n\n@param response - The response object to extract headers from.\n@returns The headers as a key-value object.\n*/\nexport function extractResponseHeaders(response: Response) {\n  return Object.fromEntries<string>([...response.headers]);\n}\n", "import { InvalidArgumentError } from '@ai-sdk/provider';\n\n/**\nCreates an ID generator.\nThe total length of the ID is the sum of the prefix, separator, and random part length.\nNot cryptographically secure.\n\n@param alphabet - The alphabet to use for the ID. Default: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'.\n@param prefix - The prefix of the ID to generate. Optional.\n@param separator - The separator between the prefix and the random part of the ID. Default: '-'.\n@param size - The size of the random part of the ID to generate. Default: 16.\n */\nexport const createIdGenerator = ({\n  prefix,\n  size = 16,\n  alphabet = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz',\n  separator = '-',\n}: {\n  prefix?: string;\n  separator?: string;\n  size?: number;\n  alphabet?: string;\n} = {}): IdGenerator => {\n  const generator = () => {\n    const alphabetLength = alphabet.length;\n    const chars = new Array(size);\n    for (let i = 0; i < size; i++) {\n      chars[i] = alphabet[(Math.random() * alphabetLength) | 0];\n    }\n    return chars.join('');\n  };\n\n  if (prefix == null) {\n    return generator;\n  }\n\n  // check that the prefix is not part of the alphabet (otherwise prefix checking can fail randomly)\n  if (alphabet.includes(separator)) {\n    throw new InvalidArgumentError({\n      argument: 'separator',\n      message: `The separator \"${separator}\" must not be part of the alphabet \"${alphabet}\".`,\n    });\n  }\n\n  return () => `${prefix}${separator}${generator()}`;\n};\n\n/**\nA function that generates an ID.\n */\nexport type IdGenerator = () => string;\n\n/**\nGenerates a 16-character random string to use for IDs.\nNot cryptographically secure.\n */\nexport const generateId = createIdGenerator();\n", "export function getErrorMessage(error: unknown | undefined) {\n  if (error == null) {\n    return 'unknown error';\n  }\n\n  if (typeof error === 'string') {\n    return error;\n  }\n\n  if (error instanceof Error) {\n    return error.message;\n  }\n\n  return JSON.stringify(error);\n}\n", "import { APICallError } from '@ai-sdk/provider';\nimport { extractResponseHeaders } from './extract-response-headers';\nimport { FetchFunction } from './fetch-function';\nimport { handleFetchError } from './handle-fetch-error';\nimport { isAbortError } from './is-abort-error';\nimport { ResponseHandler } from './response-handler';\nimport { getRuntimeEnvironmentUserAgent } from './get-runtime-environment-user-agent';\nimport { withUserAgentSuffix } from './with-user-agent-suffix';\nimport { VERSION } from './version';\n\n// use function to allow for mocking in tests:\nconst getOriginalFetch = () => globalThis.fetch;\n\nexport const getFromApi = async <T>({\n  url,\n  headers = {},\n  successfulResponseHandler,\n  failedResponseHandler,\n  abortSignal,\n  fetch = getOriginalFetch(),\n}: {\n  url: string;\n  headers?: Record<string, string | undefined>;\n  failedResponseHandler: ResponseHandler<Error>;\n  successfulResponseHandler: ResponseHandler<T>;\n  abortSignal?: AbortSignal;\n  fetch?: FetchFunction;\n}) => {\n  try {\n    const response = await fetch(url, {\n      method: 'GET',\n      headers: withUserAgentSuffix(\n        headers,\n        `ai-sdk/provider-utils/${VERSION}`,\n        getRuntimeEnvironmentUserAgent(),\n      ),\n      signal: abortSignal,\n    });\n\n    const responseHeaders = extractResponseHeaders(response);\n\n    if (!response.ok) {\n      let errorInformation: {\n        value: Error;\n        responseHeaders?: Record<string, string> | undefined;\n      };\n\n      try {\n        errorInformation = await failedResponseHandler({\n          response,\n          url,\n          requestBodyValues: {},\n        });\n      } catch (error) {\n        if (isAbortError(error) || APICallError.isInstance(error)) {\n          throw error;\n        }\n\n        throw new APICallError({\n          message: 'Failed to process error response',\n          cause: error,\n          statusCode: response.status,\n          url,\n          responseHeaders,\n          requestBodyValues: {},\n        });\n      }\n\n      throw errorInformation.value;\n    }\n\n    try {\n      return await successfulResponseHandler({\n        response,\n        url,\n        requestBodyValues: {},\n      });\n    } catch (error) {\n      if (error instanceof Error) {\n        if (isAbortError(error) || APICallError.isInstance(error)) {\n          throw error;\n        }\n      }\n\n      throw new APICallError({\n        message: 'Failed to process successful response',\n        cause: error,\n        statusCode: response.status,\n        url,\n        responseHeaders,\n        requestBodyValues: {},\n      });\n    }\n  } catch (error) {\n    throw handleFetchError({ error, url, requestBodyValues: {} });\n  }\n};\n", "import { APICallError } from '@ai-sdk/provider';\nimport { isAbortError } from './is-abort-error';\n\nconst FETCH_FAILED_ERROR_MESSAGES = ['fetch failed', 'failed to fetch'];\n\nexport function handleFetchError({\n  error,\n  url,\n  requestBodyValues,\n}: {\n  error: unknown;\n  url: string;\n  requestBodyValues: unknown;\n}) {\n  if (isAbortError(error)) {\n    return error;\n  }\n\n  // unwrap original error when fetch failed (for easier debugging):\n  if (\n    error instanceof TypeError &&\n    FETCH_FAILED_ERROR_MESSAGES.includes(error.message.toLowerCase())\n  ) {\n    const cause = (error as any).cause;\n\n    if (cause != null) {\n      // Failed to connect to server:\n      return new APICallError({\n        message: `Cannot connect to API: ${cause.message}`,\n        cause,\n        url,\n        requestBodyValues,\n        isRetryable: true, // retry when network error\n      });\n    }\n  }\n\n  return error;\n}\n", "export function isAbortError(error: unknown): error is Error {\n  return (\n    (error instanceof Error || error instanceof DOMException) &&\n    (error.name === 'AbortError' ||\n      error.name === 'ResponseAborted' || // Next.js\n      error.name === 'TimeoutError')\n  );\n}\n", "export function getRuntimeEnvironmentUserAgent(\n  globalThisAny: any = globalThis as any,\n): string {\n  // Browsers\n  if (globalThisAny.window) {\n    return `runtime/browser`;\n  }\n\n  // Cloudflare Workers / Deno / Bun / Node.js >= 21.1\n  if (globalThisAny.navigator?.userAgent) {\n    return `runtime/${globalThisAny.navigator.userAgent.toLowerCase()}`;\n  }\n\n  // Nodes.js < 21.1\n  if (globalThisAny.process?.versions?.node) {\n    return `runtime/node.js/${globalThisAny.process.version.substring(0)}`;\n  }\n\n  if (globalThisAny.EdgeRuntime) {\n    return `runtime/vercel-edge`;\n  }\n\n  return 'runtime/unknown';\n}\n", "/**\n * Normalizes different header inputs into a plain record with lower-case keys.\n * Entries with `undefined` or `null` values are removed.\n *\n * @param headers - Input headers (`Headers`, tuples array, plain record) to normalize.\n * @returns A record containing the normalized header entries.\n */\nexport function normalizeHeaders(\n  headers:\n    | HeadersInit\n    | Record<string, string | undefined>\n    | Array<[string, string | undefined]>\n    | undefined,\n): Record<string, string> {\n  if (headers == null) {\n    return {};\n  }\n\n  const normalized: Record<string, string> = {};\n\n  if (headers instanceof Headers) {\n    headers.forEach((value, key) => {\n      normalized[key.toLowerCase()] = value;\n    });\n  } else {\n    if (!Array.isArray(headers)) {\n      headers = Object.entries(headers);\n    }\n\n    for (const [key, value] of headers) {\n      if (value != null) {\n        normalized[key.toLowerCase()] = value;\n      }\n    }\n  }\n\n  return normalized;\n}\n", "import { normalizeHeaders } from './normalize-headers';\n\n/**\n * Appends suffix parts to the `user-agent` header.\n * If a `user-agent` header already exists, the suffix parts are appended to it.\n * If no `user-agent` header exists, a new one is created with the suffix parts.\n * Automatically removes undefined entries from the headers.\n *\n * @param headers - The original headers.\n * @param userAgentSuffixParts - The parts to append to the `user-agent` header.\n * @returns The new headers with the `user-agent` header set or updated.\n */\nexport function withUserAgentSuffix(\n  headers: HeadersInit | Record<string, string | undefined> | undefined,\n  ...userAgentSuffixParts: string[]\n): Record<string, string> {\n  const normalizedHeaders = new Headers(normalizeHeaders(headers));\n\n  const currentUserAgentHeader = normalizedHeaders.get('user-agent') || '';\n\n  normalizedHeaders.set(\n    'user-agent',\n    [currentUserAgentHeader, ...userAgentSuffixParts].filter(Boolean).join(' '),\n  );\n\n  return Object.fromEntries(normalizedHeaders.entries());\n}\n", "// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n", "import {\n  JSONSchema7,\n  LanguageModelV2Message,\n  LanguageModelV2Prompt,\n} from '@ai-sdk/provider';\n\nconst DEFAULT_SCHEMA_PREFIX = 'JSON schema:';\nconst DEFAULT_SCHEMA_SUFFIX =\n  'You MUST answer with a JSON object that matches the JSON schema above.';\nconst DEFAULT_GENERIC_SUFFIX = 'You MUST answer with JSON.';\n\nexport function injectJsonInstruction({\n  prompt,\n  schema,\n  schemaPrefix = schema != null ? DEFAULT_SCHEMA_PREFIX : undefined,\n  schemaSuffix = schema != null\n    ? DEFAULT_SCHEMA_SUFFIX\n    : DEFAULT_GENERIC_SUFFIX,\n}: {\n  prompt?: string;\n  schema?: JSONSchema7;\n  schemaPrefix?: string;\n  schemaSuffix?: string;\n}): string {\n  return [\n    prompt != null && prompt.length > 0 ? prompt : undefined,\n    prompt != null && prompt.length > 0 ? '' : undefined, // add a newline if prompt is not null\n    schemaPrefix,\n    schema != null ? JSON.stringify(schema) : undefined,\n    schemaSuffix,\n  ]\n    .filter(line => line != null)\n    .join('\\n');\n}\n\nexport function injectJsonInstructionIntoMessages({\n  messages,\n  schema,\n  schemaPrefix,\n  schemaSuffix,\n}: {\n  messages: LanguageModelV2Prompt;\n  schema?: JSONSchema7;\n  schemaPrefix?: string;\n  schemaSuffix?: string;\n}): LanguageModelV2Prompt {\n  const systemMessage: LanguageModelV2Message =\n    messages[0]?.role === 'system'\n      ? { ...messages[0] }\n      : { role: 'system', content: '' };\n\n  systemMessage.content = injectJsonInstruction({\n    prompt: systemMessage.content,\n    schema,\n    schemaPrefix,\n    schemaSuffix,\n  });\n\n  return [\n    systemMessage,\n    ...(messages[0]?.role === 'system' ? messages.slice(1) : messages),\n  ];\n}\n", "/**\n * Checks if the given URL is supported natively by the model.\n *\n * @param mediaType - The media type of the URL. Case-sensitive.\n * @param url - The URL to check.\n * @param supportedUrls - A record where keys are case-sensitive media types (or '*')\n *                        and values are arrays of RegExp patterns for URLs.\n *\n * @returns `true` if the URL matches a pattern under the specific media type\n *          or the wildcard '*', `false` otherwise.\n */\nexport function isUrlSupported({\n  mediaType,\n  url,\n  supportedUrls,\n}: {\n  mediaType: string;\n  url: string;\n  supportedUrls: Record<string, RegExp[]>;\n}): boolean {\n  // standardize media type and url to lower case\n  url = url.toLowerCase();\n  mediaType = mediaType.toLowerCase();\n\n  return (\n    Object.entries(supportedUrls)\n      // standardize supported url map into lowercase prefixes:\n      .map(([key, value]) => {\n        const mediaType = key.toLowerCase();\n        return mediaType === '*' || mediaType === '*/*'\n          ? { mediaTypePrefix: '', regexes: value }\n          : { mediaTypePrefix: mediaType.replace(/\\*/, ''), regexes: value };\n      })\n      // gather all regexp pattern from matched media type prefixes:\n      .filter(({ mediaTypePrefix }) => mediaType.startsWith(mediaTypePrefix))\n      .flatMap(({ regexes }) => regexes)\n      // check if any pattern matches the url:\n      .some(pattern => pattern.test(url))\n  );\n}\n", "import { LoadAPIKeyError } from '@ai-sdk/provider';\n\nexport function loadApiKey({\n  apiKey,\n  environmentVariableName,\n  apiKeyParameterName = 'apiKey',\n  description,\n}: {\n  apiKey: string | undefined;\n  environmentVariableName: string;\n  apiKeyParameterName?: string;\n  description: string;\n}): string {\n  if (typeof apiKey === 'string') {\n    return apiKey;\n  }\n\n  if (apiKey != null) {\n    throw new LoadAPIKeyError({\n      message: `${description} API key must be a string.`,\n    });\n  }\n\n  if (typeof process === 'undefined') {\n    throw new LoadAPIKeyError({\n      message: `${description} API key is missing. Pass it using the '${apiKeyParameterName}' parameter. Environment variables is not supported in this environment.`,\n    });\n  }\n\n  apiKey = process.env[environmentVariableName];\n\n  if (apiKey == null) {\n    throw new LoadAPIKeyError({\n      message: `${description} API key is missing. Pass it using the '${apiKeyParameterName}' parameter or the ${environmentVariableName} environment variable.`,\n    });\n  }\n\n  if (typeof apiKey !== 'string') {\n    throw new LoadAPIKeyError({\n      message: `${description} API key must be a string. The value of the ${environmentVariableName} environment variable is not a string.`,\n    });\n  }\n\n  return apiKey;\n}\n", "/**\n * Loads an optional `string` setting from the environment or a parameter.\n *\n * @param settingValue - The setting value.\n * @param environmentVariableName - The environment variable name.\n * @returns The setting value.\n */\nexport function loadOptionalSetting({\n  settingValue,\n  environmentVariableName,\n}: {\n  settingValue: string | undefined;\n  environmentVariableName: string;\n}): string | undefined {\n  if (typeof settingValue === 'string') {\n    return settingValue;\n  }\n\n  if (settingValue != null || typeof process === 'undefined') {\n    return undefined;\n  }\n\n  settingValue = process.env[environmentVariableName];\n\n  if (settingValue == null || typeof settingValue !== 'string') {\n    return undefined;\n  }\n\n  return settingValue;\n}\n", "import { LoadSettingError } from '@ai-sdk/provider';\n\n/**\n * Loads a `string` setting from the environment or a parameter.\n *\n * @param settingValue - The setting value.\n * @param environmentVariableName - The environment variable name.\n * @param settingName - The setting name.\n * @param description - The description of the setting.\n * @returns The setting value.\n */\nexport function loadSetting({\n  settingValue,\n  environmentVariableName,\n  settingName,\n  description,\n}: {\n  settingValue: string | undefined;\n  environmentVariableName: string;\n  settingName: string;\n  description: string;\n}): string {\n  if (typeof settingValue === 'string') {\n    return settingValue;\n  }\n\n  if (settingValue != null) {\n    throw new LoadSettingError({\n      message: `${description} setting must be a string.`,\n    });\n  }\n\n  if (typeof process === 'undefined') {\n    throw new LoadSettingError({\n      message:\n        `${description} setting is missing. ` +\n        `Pass it using the '${settingName}' parameter. ` +\n        `Environment variables is not supported in this environment.`,\n    });\n  }\n\n  settingValue = process.env[environmentVariableName];\n\n  if (settingValue == null) {\n    throw new LoadSettingError({\n      message:\n        `${description} setting is missing. ` +\n        `Pass it using the '${settingName}' parameter ` +\n        `or the ${environmentVariableName} environment variable.`,\n    });\n  }\n\n  if (typeof settingValue !== 'string') {\n    throw new LoadSettingError({\n      message:\n        `${description} setting must be a string. ` +\n        `The value of the ${environmentVariableName} environment variable is not a string.`,\n    });\n  }\n\n  return settingValue;\n}\n", "/**\n * Maps a media type to its corresponding file extension.\n * It was originally introduced to set a filename for audio file uploads\n * in https://github.com/vercel/ai/pull/8159.\n *\n * @param mediaType The media type to map.\n * @returns The corresponding file extension\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/MIME_types/Common_types\n */\nexport function mediaTypeToExtension(mediaType: string) {\n  const [_type, subtype = ''] = mediaType.toLowerCase().split('/');\n\n  return (\n    {\n      mpeg: 'mp3',\n      'x-wav': 'wav',\n      opus: 'ogg',\n      mp4: 'm4a',\n      'x-m4a': 'm4a',\n    }[subtype] ?? subtype\n  );\n}\n", "import {\n  JSONParseError,\n  JSONValue,\n  TypeValidationError,\n} from '@ai-sdk/provider';\nimport { secureJsonParse } from './secure-json-parse';\nimport { safeValidateTypes, validateTypes } from './validate-types';\nimport { FlexibleValidator, Validator } from './validator';\n\n/**\n * Parses a JSON string into an unknown object.\n *\n * @param text - The JSON string to parse.\n * @returns {JSONValue} - The parsed JSON object.\n */\nexport async function parseJSON(options: {\n  text: string;\n  schema?: undefined;\n}): Promise<JSONValue>;\n/**\n * Parses a JSON string into a strongly-typed object using the provided schema.\n *\n * @template T - The type of the object to parse the JSON into.\n * @param {string} text - The JSON string to parse.\n * @param {Validator<T>} schema - The schema to use for parsing the JSON.\n * @returns {Promise<T>} - The parsed object.\n */\nexport async function parseJSON<T>(options: {\n  text: string;\n  schema: FlexibleValidator<T>;\n}): Promise<T>;\nexport async function parseJSON<T>({\n  text,\n  schema,\n}: {\n  text: string;\n  schema?: FlexibleValidator<T>;\n}): Promise<T> {\n  try {\n    const value = secureJsonParse(text);\n\n    if (schema == null) {\n      return value;\n    }\n\n    return validateTypes<T>({ value, schema });\n  } catch (error) {\n    if (\n      JSONParseError.isInstance(error) ||\n      TypeValidationError.isInstance(error)\n    ) {\n      throw error;\n    }\n\n    throw new JSONParseError({ text, cause: error });\n  }\n}\n\nexport type ParseResult<T> =\n  | { success: true; value: T; rawValue: unknown }\n  | {\n      success: false;\n      error: JSONParseError | TypeValidationError;\n      rawValue: unknown;\n    };\n\n/**\n * Safely parses a JSON string and returns the result as an object of type `unknown`.\n *\n * @param text - The JSON string to parse.\n * @returns {Promise<object>} Either an object with `success: true` and the parsed data, or an object with `success: false` and the error that occurred.\n */\nexport async function safeParseJSON(options: {\n  text: string;\n  schema?: undefined;\n}): Promise<ParseResult<JSONValue>>;\n/**\n * Safely parses a JSON string into a strongly-typed object, using a provided schema to validate the object.\n *\n * @template T - The type of the object to parse the JSON into.\n * @param {string} text - The JSON string to parse.\n * @param {Validator<T>} schema - The schema to use for parsing the JSON.\n * @returns An object with either a `success` flag and the parsed and typed data, or a `success` flag and an error object.\n */\nexport async function safeParseJSON<T>(options: {\n  text: string;\n  schema: FlexibleValidator<T>;\n}): Promise<ParseResult<T>>;\nexport async function safeParseJSON<T>({\n  text,\n  schema,\n}: {\n  text: string;\n  schema?: FlexibleValidator<T>;\n}): Promise<ParseResult<T>> {\n  try {\n    const value = secureJsonParse(text);\n\n    if (schema == null) {\n      return { success: true, value: value as T, rawValue: value };\n    }\n\n    return await safeValidateTypes<T>({ value, schema });\n  } catch (error) {\n    return {\n      success: false,\n      error: JSONParseError.isInstance(error)\n        ? error\n        : new JSONParseError({ text, cause: error }),\n      rawValue: undefined,\n    };\n  }\n}\n\nexport function isParsableJson(input: string): boolean {\n  try {\n    secureJsonParse(input);\n    return true;\n  } catch {\n    return false;\n  }\n}\n", "// Licensed under BSD-3-Clause (this file only)\n// Code adapted from https://github.com/fastify/secure-json-parse/blob/783fcb1b5434709466759847cec974381939673a/index.js\n//\n// Copyright (c) Vercel, Inc. (https://vercel.com)\n// Copyright (c) 2019 The Fastify Team\n// Copyright (c) 2019, Sideway Inc, and project contributors\n// All rights reserved.\n//\n// The complete list of contributors can be found at:\n// - https://github.com/hapijs/bourne/graphs/contributors\n// - https://github.com/fastify/secure-json-parse/graphs/contributors\n// - https://github.com/vercel/ai/commits/main/packages/provider-utils/src/secure-parse-json.ts\n//\n// Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n//\n// 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n//\n// 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n//\n// 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nconst suspectProtoRx = /\"__proto__\"\\s*:/;\nconst suspectConstructorRx = /\"constructor\"\\s*:/;\n\nfunction _parse(text: string) {\n  // Parse normally\n  const obj = JSON.parse(text);\n\n  // Ignore null and non-objects\n  if (obj === null || typeof obj !== 'object') {\n    return obj;\n  }\n\n  if (\n    suspectProtoRx.test(text) === false &&\n    suspectConstructorRx.test(text) === false\n  ) {\n    return obj;\n  }\n\n  // Scan result for proto keys\n  return filter(obj);\n}\n\nfunction filter(obj: any) {\n  let next = [obj];\n\n  while (next.length) {\n    const nodes = next;\n    next = [];\n\n    for (const node of nodes) {\n      if (Object.prototype.hasOwnProperty.call(node, '__proto__')) {\n        throw new SyntaxError('Object contains forbidden prototype property');\n      }\n\n      if (\n        Object.prototype.hasOwnProperty.call(node, 'constructor') &&\n        Object.prototype.hasOwnProperty.call(node.constructor, 'prototype')\n      ) {\n        throw new SyntaxError('Object contains forbidden prototype property');\n      }\n\n      for (const key in node) {\n        const value = node[key];\n        if (value && typeof value === 'object') {\n          next.push(value);\n        }\n      }\n    }\n  }\n  return obj;\n}\n\nexport function secureJsonParse(text: string) {\n  // Performance optimization, see https://github.com/fastify/secure-json-parse/pull/90\n  const { stackTraceLimit } = Error;\n  Error.stackTraceLimit = 0;\n  try {\n    return _parse(text);\n  } finally {\n    Error.stackTraceLimit = stackTraceLimit;\n  }\n}\n", "import { TypeValidationError } from '@ai-sdk/provider';\nimport { FlexibleValidator, asValidator } from './validator';\n\n/**\n * Validates the types of an unknown object using a schema and\n * return a strongly-typed object.\n *\n * @template T - The type of the object to validate.\n * @param {string} options.value - The object to validate.\n * @param {Validator<T>} options.schema - The schema to use for validating the JSON.\n * @returns {Promise<T>} - The typed object.\n */\nexport async function validateTypes<OBJECT>({\n  value,\n  schema,\n}: {\n  value: unknown;\n  schema: FlexibleValidator<OBJECT>;\n}): Promise<OBJECT> {\n  const result = await safeValidateTypes({ value, schema });\n\n  if (!result.success) {\n    throw TypeValidationError.wrap({ value, cause: result.error });\n  }\n\n  return result.value;\n}\n\n/**\n * Safely validates the types of an unknown object using a schema and\n * return a strongly-typed object.\n *\n * @template T - The type of the object to validate.\n * @param {string} options.value - The JSON object to validate.\n * @param {Validator<T>} options.schema - The schema to use for validating the JSON.\n * @returns An object with either a `success` flag and the parsed and typed data, or a `success` flag and an error object.\n */\nexport async function safeValidateTypes<OBJECT>({\n  value,\n  schema,\n}: {\n  value: unknown;\n  schema: FlexibleValidator<OBJECT>;\n}): Promise<\n  | {\n      success: true;\n      value: OBJECT;\n      rawValue: unknown;\n    }\n  | {\n      success: false;\n      error: TypeValidationError;\n      rawValue: unknown;\n    }\n> {\n  const validator = asValidator(schema);\n\n  try {\n    if (validator.validate == null) {\n      return { success: true, value: value as OBJECT, rawValue: value };\n    }\n\n    const result = await validator.validate(value);\n\n    if (result.success) {\n      return { success: true, value: result.value, rawValue: value };\n    }\n\n    return {\n      success: false,\n      error: TypeValidationError.wrap({ value, cause: result.error }),\n      rawValue: value,\n    };\n  } catch (error) {\n    return {\n      success: false,\n      error: TypeValidationError.wrap({ value, cause: error }),\n      rawValue: value,\n    };\n  }\n}\n", "import { TypeValidationError } from '@ai-sdk/provider';\nimport { StandardSchemaV1 } from '@standard-schema/spec';\n\n/**\n * Used to mark validator functions so we can support both Zod and custom schemas.\n */\nexport const validatorSymbol = Symbol.for('vercel.ai.validator');\n\nexport type ValidationResult<OBJECT> =\n  | { success: true; value: OBJECT }\n  | { success: false; error: Error };\n\nexport type Validator<OBJECT = unknown> = {\n  /**\n   * Used to mark validator functions so we can support both Zod and custom schemas.\n   */\n  [validatorSymbol]: true;\n\n  /**\n   * Optional. Validates that the structure of a value matches this schema,\n   * and returns a typed version of the value if it does.\n   */\n  readonly validate?: (\n    value: unknown,\n  ) => ValidationResult<OBJECT> | PromiseLike<ValidationResult<OBJECT>>;\n};\n\n/**\n * Create a validator.\n *\n * @param validate A validation function for the schema.\n */\nexport function validator<OBJECT>(\n  validate?:\n    | undefined\n    | ((\n        value: unknown,\n      ) => ValidationResult<OBJECT> | PromiseLike<ValidationResult<OBJECT>>),\n): Validator<OBJECT> {\n  return { [validatorSymbol]: true, validate };\n}\n\nexport function isValidator(value: unknown): value is Validator {\n  return (\n    typeof value === 'object' &&\n    value !== null &&\n    validatorSymbol in value &&\n    value[validatorSymbol] === true &&\n    'validate' in value\n  );\n}\n\n/**\n * Creates a validator with deferred creation.\n * This is important to reduce the startup time of the library\n * and to avoid initializing unused validators.\n *\n * @param createValidator A function that creates a validator.\n * @returns A function that returns a validator.\n */\nexport function lazyValidator<OBJECT>(\n  createValidator: () => Validator<OBJECT>,\n): LazyValidator<OBJECT> {\n  // cache the validator to avoid initializing it multiple times\n  let validator: Validator<OBJECT> | undefined;\n  return () => {\n    if (validator == null) {\n      validator = createValidator();\n    }\n    return validator;\n  };\n}\n\nexport type LazyValidator<OBJECT> = () => Validator<OBJECT>;\n\nexport type FlexibleValidator<OBJECT> =\n  | Validator<OBJECT>\n  | LazyValidator<OBJECT>\n  | StandardSchemaV1<unknown, OBJECT>;\n\nexport type InferValidator<SCHEMA> =\n  SCHEMA extends StandardSchemaV1<unknown, infer T>\n    ? T\n    : SCHEMA extends LazyValidator<infer T>\n      ? T\n      : SCHEMA extends Validator<infer T>\n        ? T\n        : never;\n\nexport function asValidator<OBJECT>(\n  value: FlexibleValidator<OBJECT>,\n): Validator<OBJECT> {\n  return isValidator(value)\n    ? value\n    : typeof value === 'function'\n      ? value()\n      : standardSchemaValidator(value);\n}\n\nexport function standardSchemaValidator<OBJECT>(\n  standardSchema: StandardSchemaV1<unknown, OBJECT>,\n): Validator<OBJECT> {\n  return validator(async value => {\n    const result = await standardSchema['~standard'].validate(value);\n\n    return result.issues == null\n      ? { success: true, value: result.value }\n      : {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause: result.issues,\n          }),\n        };\n  });\n}\n", "import {\n  EventSourceMessage,\n  EventSourceParserStream,\n} from 'eventsource-parser/stream';\nimport { ParseResult, safeParseJSON } from './parse-json';\nimport { FlexibleValidator } from './validator';\n\n/**\n * Parses a JSON event stream into a stream of parsed JSON objects.\n */\nexport function parseJsonEventStream<T>({\n  stream,\n  schema,\n}: {\n  stream: ReadableStream<Uint8Array>;\n  schema: FlexibleValidator<T>;\n}): ReadableStream<ParseResult<T>> {\n  return stream\n    .pipeThrough(new TextDecoderStream())\n    .pipeThrough(new EventSourceParserStream())\n    .pipeThrough(\n      new TransformStream<EventSourceMessage, ParseResult<T>>({\n        async transform({ data }, controller) {\n          // ignore the 'DONE' event that e.g. OpenAI sends:\n          if (data === '[DONE]') {\n            return;\n          }\n\n          controller.enqueue(await safeParseJSON({ text: data, schema }));\n        },\n      }),\n    );\n}\n", "import { InvalidArgumentError } from '@ai-sdk/provider';\nimport { safeValidateTypes } from './validate-types';\nimport { FlexibleValidator } from './validator';\n\nexport async function parseProviderOptions<OPTIONS>({\n  provider,\n  providerOptions,\n  schema,\n}: {\n  provider: string;\n  providerOptions: Record<string, unknown> | undefined;\n  schema: FlexibleValidator<OPTIONS>;\n}): Promise<OPTIONS | undefined> {\n  if (providerOptions?.[provider] == null) {\n    return undefined;\n  }\n\n  const parsedProviderOptions = await safeValidateTypes<OPTIONS | undefined>({\n    value: providerOptions[provider],\n    schema,\n  });\n\n  if (!parsedProviderOptions.success) {\n    throw new InvalidArgumentError({\n      argument: 'providerOptions',\n      message: `invalid ${provider} provider options`,\n      cause: parsedProviderOptions.error,\n    });\n  }\n\n  return parsedProviderOptions.value;\n}\n", "import { APICallError } from '@ai-sdk/provider';\nimport { extractResponseHeaders } from './extract-response-headers';\nimport { FetchFunction } from './fetch-function';\nimport { handleFetchError } from './handle-fetch-error';\nimport { isAbortError } from './is-abort-error';\nimport { ResponseHandler } from './response-handler';\nimport { getRuntimeEnvironmentUserAgent } from './get-runtime-environment-user-agent';\nimport { withUserAgentSuffix } from './with-user-agent-suffix';\nimport { VERSION } from './version';\n\n// use function to allow for mocking in tests:\nconst getOriginalFetch = () => globalThis.fetch;\n\nexport const postJsonToApi = async <T>({\n  url,\n  headers,\n  body,\n  failedResponseHandler,\n  successfulResponseHandler,\n  abortSignal,\n  fetch,\n}: {\n  url: string;\n  headers?: Record<string, string | undefined>;\n  body: unknown;\n  failedResponseHandler: ResponseHandler<APICallError>;\n  successfulResponseHandler: ResponseHandler<T>;\n  abortSignal?: AbortSignal;\n  fetch?: FetchFunction;\n}) =>\n  postToApi({\n    url,\n    headers: {\n      'Content-Type': 'application/json',\n      ...headers,\n    },\n    body: {\n      content: JSON.stringify(body),\n      values: body,\n    },\n    failedResponseHandler,\n    successfulResponseHandler,\n    abortSignal,\n    fetch,\n  });\n\nexport const postFormDataToApi = async <T>({\n  url,\n  headers,\n  formData,\n  failedResponseHandler,\n  successfulResponseHandler,\n  abortSignal,\n  fetch,\n}: {\n  url: string;\n  headers?: Record<string, string | undefined>;\n  formData: FormData;\n  failedResponseHandler: ResponseHandler<APICallError>;\n  successfulResponseHandler: ResponseHandler<T>;\n  abortSignal?: AbortSignal;\n  fetch?: FetchFunction;\n}) =>\n  postToApi({\n    url,\n    headers,\n    body: {\n      content: formData,\n      values: Object.fromEntries((formData as any).entries()),\n    },\n    failedResponseHandler,\n    successfulResponseHandler,\n    abortSignal,\n    fetch,\n  });\n\nexport const postToApi = async <T>({\n  url,\n  headers = {},\n  body,\n  successfulResponseHandler,\n  failedResponseHandler,\n  abortSignal,\n  fetch = getOriginalFetch(),\n}: {\n  url: string;\n  headers?: Record<string, string | undefined>;\n  body: {\n    content: string | FormData | Uint8Array;\n    values: unknown;\n  };\n  failedResponseHandler: ResponseHandler<Error>;\n  successfulResponseHandler: ResponseHandler<T>;\n  abortSignal?: AbortSignal;\n  fetch?: FetchFunction;\n}) => {\n  try {\n    const response = await fetch(url, {\n      method: 'POST',\n      headers: withUserAgentSuffix(\n        headers,\n        `ai-sdk/provider-utils/${VERSION}`,\n        getRuntimeEnvironmentUserAgent(),\n      ),\n      body: body.content,\n      signal: abortSignal,\n    });\n\n    const responseHeaders = extractResponseHeaders(response);\n\n    if (!response.ok) {\n      let errorInformation: {\n        value: Error;\n        responseHeaders?: Record<string, string> | undefined;\n      };\n\n      try {\n        errorInformation = await failedResponseHandler({\n          response,\n          url,\n          requestBodyValues: body.values,\n        });\n      } catch (error) {\n        if (isAbortError(error) || APICallError.isInstance(error)) {\n          throw error;\n        }\n\n        throw new APICallError({\n          message: 'Failed to process error response',\n          cause: error,\n          statusCode: response.status,\n          url,\n          responseHeaders,\n          requestBodyValues: body.values,\n        });\n      }\n\n      throw errorInformation.value;\n    }\n\n    try {\n      return await successfulResponseHandler({\n        response,\n        url,\n        requestBodyValues: body.values,\n      });\n    } catch (error) {\n      if (error instanceof Error) {\n        if (isAbortError(error) || APICallError.isInstance(error)) {\n          throw error;\n        }\n      }\n\n      throw new APICallError({\n        message: 'Failed to process successful response',\n        cause: error,\n        statusCode: response.status,\n        url,\n        responseHeaders,\n        requestBodyValues: body.values,\n      });\n    }\n  } catch (error) {\n    throw handleFetchError({ error, url, requestBodyValues: body.values });\n  }\n};\n", "import { JSONValue, LanguageModelV2ToolResultPart } from '@ai-sdk/provider';\nimport { FlexibleSchema } from '../schema';\nimport { ModelMessage } from './model-message';\nimport { ProviderOptions } from './provider-options';\n\n/**\n * Additional options that are sent into each tool call.\n */\n// TODO AI SDK 6: rename to ToolExecutionOptions\nexport interface ToolCallOptions {\n  /**\n   * The ID of the tool call. You can use it e.g. when sending tool-call related information with stream data.\n   */\n  toolCallId: string;\n\n  /**\n   * Messages that were sent to the language model to initiate the response that contained the tool call.\n   * The messages **do not** include the system prompt nor the assistant response that contained the tool call.\n   */\n  messages: ModelMessage[];\n\n  /**\n   * An optional abort signal that indicates that the overall operation should be aborted.\n   */\n  abortSignal?: AbortSignal;\n\n  /**\n   * Additional context.\n   *\n   * Experimental (can break in patch releases).\n   */\n  experimental_context?: unknown;\n}\n\nexport type ToolExecuteFunction<INPUT, OUTPUT> = (\n  input: INPUT,\n  options: ToolCallOptions,\n) => AsyncIterable<OUTPUT> | PromiseLike<OUTPUT> | OUTPUT;\n\n// 0 extends 1 & N checks for any\n// [N] extends [never] checks for never\ntype NeverOptional<N, T> = 0 extends 1 & N\n  ? Partial<T>\n  : [N] extends [never]\n    ? Partial<Record<keyof T, undefined>>\n    : T;\n\ntype ToolOutputProperties<INPUT, OUTPUT> = NeverOptional<\n  OUTPUT,\n  | {\n      /**\nAn async function that is called with the arguments from the tool call and produces a result.\nIf not provided, the tool will not be executed automatically.\n\n@args is the input of the tool call.\n@options.abortSignal is a signal that can be used to abort the tool call.\n    */\n      execute: ToolExecuteFunction<INPUT, OUTPUT>;\n\n      outputSchema?: FlexibleSchema<OUTPUT>;\n    }\n  | {\n      outputSchema: FlexibleSchema<OUTPUT>;\n\n      execute?: never;\n    }\n>;\n\n/**\nA tool contains the description and the schema of the input that the tool expects.\nThis enables the language model to generate the input.\n\nThe tool can also contain an optional execute function for the actual execution function of the tool.\n */\nexport type Tool<\n  INPUT extends JSONValue | unknown | never = any,\n  OUTPUT extends JSONValue | unknown | never = any,\n> = {\n  /**\nAn optional description of what the tool does.\nWill be used by the language model to decide whether to use the tool.\nNot used for provider-defined tools.\n   */\n  description?: string;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n   */\n  providerOptions?: ProviderOptions;\n\n  /**\nThe schema of the input that the tool expects. The language model will use this to generate the input.\nIt is also used to validate the output of the language model.\nUse descriptions to make the input understandable for the language model.\n   */\n  inputSchema: FlexibleSchema<INPUT>;\n\n  /**\n   * Optional function that is called when the argument streaming starts.\n   * Only called when the tool is used in a streaming context.\n   */\n  onInputStart?: (options: ToolCallOptions) => void | PromiseLike<void>;\n\n  /**\n   * Optional function that is called when an argument streaming delta is available.\n   * Only called when the tool is used in a streaming context.\n   */\n  onInputDelta?: (\n    options: { inputTextDelta: string } & ToolCallOptions,\n  ) => void | PromiseLike<void>;\n\n  /**\n   * Optional function that is called when a tool call can be started,\n   * even if the execute function is not provided.\n   */\n  onInputAvailable?: (\n    options: {\n      input: [INPUT] extends [never] ? undefined : INPUT;\n    } & ToolCallOptions,\n  ) => void | PromiseLike<void>;\n} & ToolOutputProperties<INPUT, OUTPUT> & {\n    /**\nOptional conversion function that maps the tool result to an output that can be used by the language model.\n\nIf not provided, the tool result will be sent as a JSON object.\n  */\n    toModelOutput?: (\n      output: 0 extends 1 & OUTPUT\n        ? any\n        : [OUTPUT] extends [never]\n          ? any\n          : NoInfer<OUTPUT>,\n    ) => LanguageModelV2ToolResultPart['output'];\n  } & (\n    | {\n        /**\nTool with user-defined input and output schemas.\n     */\n        type?: undefined | 'function';\n      }\n    | {\n        /**\nTool that is defined at runtime (e.g. an MCP tool).\nThe types of input and output are not known at development time.\n       */\n        type: 'dynamic';\n      }\n    | {\n        /**\nTool with provider-defined input and output schemas.\n     */\n        type: 'provider-defined';\n\n        /**\nThe ID of the tool. Should follow the format `<provider-name>.<unique-tool-name>`.\n   */\n        id: `${string}.${string}`;\n\n        /**\nThe name of the tool that the user must use in the tool set.\n */\n        name: string;\n\n        /**\nThe arguments for configuring the tool. Must match the expected arguments defined by the provider for this tool.\n     */\n        args: Record<string, unknown>;\n      }\n  );\n\n/**\n * Infer the input type of a tool.\n */\nexport type InferToolInput<TOOL extends Tool> =\n  TOOL extends Tool<infer INPUT, any> ? INPUT : never;\n\n/**\n * Infer the output type of a tool.\n */\nexport type InferToolOutput<TOOL extends Tool> =\n  TOOL extends Tool<any, infer OUTPUT> ? OUTPUT : never;\n\n/**\nHelper function for inferring the execute args of a tool.\n */\n// Note: overload order is important for auto-completion\nexport function tool<INPUT, OUTPUT>(\n  tool: Tool<INPUT, OUTPUT>,\n): Tool<INPUT, OUTPUT>;\nexport function tool<INPUT>(tool: Tool<INPUT, never>): Tool<INPUT, never>;\nexport function tool<OUTPUT>(tool: Tool<never, OUTPUT>): Tool<never, OUTPUT>;\nexport function tool(tool: Tool<never, never>): Tool<never, never>;\nexport function tool(tool: any): any {\n  return tool;\n}\n\n/**\nHelper function for defining a dynamic tool.\n */\nexport function dynamicTool(tool: {\n  description?: string;\n  providerOptions?: ProviderOptions;\n  inputSchema: FlexibleSchema<unknown>;\n  execute: ToolExecuteFunction<unknown, unknown>;\n  toModelOutput?: (output: unknown) => LanguageModelV2ToolResultPart['output'];\n}): Tool<unknown, unknown> & {\n  type: 'dynamic';\n} {\n  return { ...tool, type: 'dynamic' };\n}\n", "import { tool, Tool, ToolExecuteFunction } from './types/tool';\nimport { FlexibleSchema } from './schema';\n\nexport type ProviderDefinedToolFactory<INPUT, ARGS extends object> = <OUTPUT>(\n  options: ARGS & {\n    execute?: ToolExecuteFunction<INPUT, OUTPUT>;\n    toModelOutput?: Tool<INPUT, OUTPUT>['toModelOutput'];\n    onInputStart?: Tool<INPUT, OUTPUT>['onInputStart'];\n    onInputDelta?: Tool<INPUT, OUTPUT>['onInputDelta'];\n    onInputAvailable?: Tool<INPUT, OUTPUT>['onInputAvailable'];\n  },\n) => Tool<INPUT, OUTPUT>;\n\nexport function createProviderDefinedToolFactory<INPUT, ARGS extends object>({\n  id,\n  name,\n  inputSchema,\n}: {\n  id: `${string}.${string}`;\n  name: string;\n  inputSchema: FlexibleSchema<INPUT>;\n}): ProviderDefinedToolFactory<INPUT, ARGS> {\n  return <OUTPUT>({\n    execute,\n    outputSchema,\n    toModelOutput,\n    onInputStart,\n    onInputDelta,\n    onInputAvailable,\n    ...args\n  }: ARGS & {\n    execute?: ToolExecuteFunction<INPUT, OUTPUT>;\n    outputSchema?: FlexibleSchema<OUTPUT>;\n    toModelOutput?: Tool<INPUT, OUTPUT>['toModelOutput'];\n    onInputStart?: Tool<INPUT, OUTPUT>['onInputStart'];\n    onInputDelta?: Tool<INPUT, OUTPUT>['onInputDelta'];\n    onInputAvailable?: Tool<INPUT, OUTPUT>['onInputAvailable'];\n  }): Tool<INPUT, OUTPUT> =>\n    tool({\n      type: 'provider-defined',\n      id,\n      name,\n      args,\n      inputSchema,\n      outputSchema,\n      execute,\n      toModelOutput,\n      onInputStart,\n      onInputDelta,\n      onInputAvailable,\n    });\n}\n\nexport type ProviderDefinedToolFactoryWithOutputSchema<\n  INPUT,\n  OUTPUT,\n  ARGS extends object,\n> = (\n  options: ARGS & {\n    execute?: ToolExecuteFunction<INPUT, OUTPUT>;\n    toModelOutput?: Tool<INPUT, OUTPUT>['toModelOutput'];\n    onInputStart?: Tool<INPUT, OUTPUT>['onInputStart'];\n    onInputDelta?: Tool<INPUT, OUTPUT>['onInputDelta'];\n    onInputAvailable?: Tool<INPUT, OUTPUT>['onInputAvailable'];\n  },\n) => Tool<INPUT, OUTPUT>;\n\nexport function createProviderDefinedToolFactoryWithOutputSchema<\n  INPUT,\n  OUTPUT,\n  ARGS extends object,\n>({\n  id,\n  name,\n  inputSchema,\n  outputSchema,\n}: {\n  id: `${string}.${string}`;\n  name: string;\n  inputSchema: FlexibleSchema<INPUT>;\n  outputSchema: FlexibleSchema<OUTPUT>;\n}): ProviderDefinedToolFactoryWithOutputSchema<INPUT, OUTPUT, ARGS> {\n  return ({\n    execute,\n    toModelOutput,\n    onInputStart,\n    onInputDelta,\n    onInputAvailable,\n    ...args\n  }: ARGS & {\n    execute?: ToolExecuteFunction<INPUT, OUTPUT>;\n    toModelOutput?: Tool<INPUT, OUTPUT>['toModelOutput'];\n    onInputStart?: Tool<INPUT, OUTPUT>['onInputStart'];\n    onInputDelta?: Tool<INPUT, OUTPUT>['onInputDelta'];\n    onInputAvailable?: Tool<INPUT, OUTPUT>['onInputAvailable'];\n  }): Tool<INPUT, OUTPUT> =>\n    tool({\n      type: 'provider-defined',\n      id,\n      name,\n      args,\n      inputSchema,\n      outputSchema,\n      execute,\n      toModelOutput,\n      onInputStart,\n      onInputDelta,\n      onInputAvailable,\n    });\n}\n", "/**\n * Removes entries from a record where the value is null or undefined.\n * @param record - The input object whose entries may be null or undefined.\n * @returns A new object containing only entries with non-null and non-undefined values.\n */\nexport function removeUndefinedEntries<T>(\n  record: Record<string, T | undefined>,\n): Record<string, T> {\n  return Object.fromEntries(\n    Object.entries(record).filter(([_key, value]) => value != null),\n  ) as Record<string, T>;\n}\n", "export type Resolvable<T> =\n  | T // Raw value\n  | Promise<T> // Promise of value\n  | (() => T) // Function returning value\n  | (() => Promise<T>); // Function returning promise of value\n\n/**\n * Resolves a value that could be a raw value, a Promise, a function returning a value,\n * or a function returning a Promise.\n */\nexport async function resolve<T>(value: Resolvable<T>): Promise<T> {\n  // If it's a function, call it to get the value/promise\n  if (typeof value === 'function') {\n    value = (value as Function)();\n  }\n\n  // Otherwise just resolve whatever we got (value or promise)\n  return Promise.resolve(value as T);\n}\n", "import { APICallError, EmptyResponseBodyError } from '@ai-sdk/provider';\nimport { ZodType } from 'zod/v4';\nimport { extractResponseHeaders } from './extract-response-headers';\nimport { parseJSON, ParseResult, safeParseJSON } from './parse-json';\nimport { parseJsonEventStream } from './parse-json-event-stream';\nimport { FlexibleValidator } from './validator';\n\nexport type ResponseHandler<RETURN_TYPE> = (options: {\n  url: string;\n  requestBodyValues: unknown;\n  response: Response;\n}) => PromiseLike<{\n  value: RETURN_TYPE;\n  rawValue?: unknown;\n  responseHeaders?: Record<string, string>;\n}>;\n\nexport const createJsonErrorResponseHandler =\n  <T>({\n    errorSchema,\n    errorToMessage,\n    isRetryable,\n  }: {\n    errorSchema: FlexibleValidator<T>;\n    errorToMessage: (error: T) => string;\n    isRetryable?: (response: Response, error?: T) => boolean;\n  }): ResponseHandler<APICallError> =>\n  async ({ response, url, requestBodyValues }) => {\n    const responseBody = await response.text();\n    const responseHeaders = extractResponseHeaders(response);\n\n    // Some providers return an empty response body for some errors:\n    if (responseBody.trim() === '') {\n      return {\n        responseHeaders,\n        value: new APICallError({\n          message: response.statusText,\n          url,\n          requestBodyValues,\n          statusCode: response.status,\n          responseHeaders,\n          responseBody,\n          isRetryable: isRetryable?.(response),\n        }),\n      };\n    }\n\n    // resilient parsing in case the response is not JSON or does not match the schema:\n    try {\n      const parsedError = await parseJSON({\n        text: responseBody,\n        schema: errorSchema,\n      });\n\n      return {\n        responseHeaders,\n        value: new APICallError({\n          message: errorToMessage(parsedError),\n          url,\n          requestBodyValues,\n          statusCode: response.status,\n          responseHeaders,\n          responseBody,\n          data: parsedError,\n          isRetryable: isRetryable?.(response, parsedError),\n        }),\n      };\n    } catch (parseError) {\n      return {\n        responseHeaders,\n        value: new APICallError({\n          message: response.statusText,\n          url,\n          requestBodyValues,\n          statusCode: response.status,\n          responseHeaders,\n          responseBody,\n          isRetryable: isRetryable?.(response),\n        }),\n      };\n    }\n  };\n\nexport const createEventSourceResponseHandler =\n  <T>(\n    chunkSchema: FlexibleValidator<T>,\n  ): ResponseHandler<ReadableStream<ParseResult<T>>> =>\n  async ({ response }: { response: Response }) => {\n    const responseHeaders = extractResponseHeaders(response);\n\n    if (response.body == null) {\n      throw new EmptyResponseBodyError({});\n    }\n\n    return {\n      responseHeaders,\n      value: parseJsonEventStream({\n        stream: response.body,\n        schema: chunkSchema,\n      }),\n    };\n  };\n\nexport const createJsonStreamResponseHandler =\n  <T>(\n    chunkSchema: ZodType<T>,\n  ): ResponseHandler<ReadableStream<ParseResult<T>>> =>\n  async ({ response }: { response: Response }) => {\n    const responseHeaders = extractResponseHeaders(response);\n\n    if (response.body == null) {\n      throw new EmptyResponseBodyError({});\n    }\n\n    let buffer = '';\n\n    return {\n      responseHeaders,\n      value: response.body.pipeThrough(new TextDecoderStream()).pipeThrough(\n        new TransformStream<string, ParseResult<T>>({\n          async transform(chunkText, controller) {\n            if (chunkText.endsWith('\\n')) {\n              controller.enqueue(\n                await safeParseJSON({\n                  text: buffer + chunkText,\n                  schema: chunkSchema,\n                }),\n              );\n              buffer = '';\n            } else {\n              buffer += chunkText;\n            }\n          },\n        }),\n      ),\n    };\n  };\n\nexport const createJsonResponseHandler =\n  <T>(responseSchema: FlexibleValidator<T>): ResponseHandler<T> =>\n  async ({ response, url, requestBodyValues }) => {\n    const responseBody = await response.text();\n\n    const parsedResult = await safeParseJSON({\n      text: responseBody,\n      schema: responseSchema,\n    });\n\n    const responseHeaders = extractResponseHeaders(response);\n\n    if (!parsedResult.success) {\n      throw new APICallError({\n        message: 'Invalid JSON response',\n        cause: parsedResult.error,\n        statusCode: response.status,\n        responseHeaders,\n        responseBody,\n        url,\n        requestBodyValues,\n      });\n    }\n\n    return {\n      responseHeaders,\n      value: parsedResult.value,\n      rawValue: parsedResult.rawValue,\n    };\n  };\n\nexport const createBinaryResponseHandler =\n  (): ResponseHandler<Uint8Array> =>\n  async ({ response, url, requestBodyValues }) => {\n    const responseHeaders = extractResponseHeaders(response);\n\n    if (!response.body) {\n      throw new APICallError({\n        message: 'Response body is empty',\n        url,\n        requestBodyValues,\n        statusCode: response.status,\n        responseHeaders,\n        responseBody: undefined,\n      });\n    }\n\n    try {\n      const buffer = await response.arrayBuffer();\n      return {\n        responseHeaders,\n        value: new Uint8Array(buffer),\n      };\n    } catch (error) {\n      throw new APICallError({\n        message: 'Failed to read response as array buffer',\n        url,\n        requestBodyValues,\n        statusCode: response.status,\n        responseHeaders,\n        responseBody: undefined,\n        cause: error,\n      });\n    }\n  };\n\nexport const createStatusCodeErrorResponseHandler =\n  (): ResponseHandler<APICallError> =>\n  async ({ response, url, requestBodyValues }) => {\n    const responseHeaders = extractResponseHeaders(response);\n    const responseBody = await response.text();\n\n    return {\n      responseHeaders,\n      value: new APICallError({\n        message: response.statusText,\n        url,\n        requestBodyValues: requestBodyValues as Record<string, unknown>,\n        statusCode: response.status,\n        responseHeaders,\n        responseBody,\n      }),\n    };\n  };\n", "import { JSONSchema7 } from '@ai-sdk/provider';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4';\nimport zodToJsonSchema from './zod-to-json-schema';\nimport { jsonSchema, Schema } from './schema';\n\nexport function zod3Schema<OBJECT>(\n  zodSchema: z3.Schema<OBJECT, z3.ZodTypeDef, any>,\n  options?: {\n    /**\n     * Enables support for references in the schema.\n     * This is required for recursive schemas, e.g. with `z.lazy`.\n     * However, not all language models and providers support such references.\n     * Defaults to `false`.\n     */\n    useReferences?: boolean;\n  },\n): Schema<OBJECT> {\n  // default to no references (to support openapi conversion for google)\n  const useReferences = options?.useReferences ?? false;\n\n  return jsonSchema(\n    // defer json schema creation to avoid unnecessary computation when only validation is needed\n    () =>\n      zodToJsonSchema(zodSchema, {\n        $refStrategy: useReferences ? 'root' : 'none',\n      }) as JSONSchema7,\n    {\n      validate: async value => {\n        const result = await zodSchema.safeParseAsync(value);\n        return result.success\n          ? { success: true, value: result.data }\n          : { success: false, error: result.error };\n      },\n    },\n  );\n}\n\nexport function zod4Schema<OBJECT>(\n  zodSchema: z4.core.$ZodType<OBJECT, any>,\n  options?: {\n    /**\n     * Enables support for references in the schema.\n     * This is required for recursive schemas, e.g. with `z.lazy`.\n     * However, not all language models and providers support such references.\n     * Defaults to `false`.\n     */\n    useReferences?: boolean;\n  },\n): Schema<OBJECT> {\n  // default to no references (to support openapi conversion for google)\n  const useReferences = options?.useReferences ?? false;\n\n  return jsonSchema(\n    // defer json schema creation to avoid unnecessary computation when only validation is needed\n    () =>\n      z4.toJSONSchema(zodSchema, {\n        target: 'draft-7',\n        io: 'output',\n        reused: useReferences ? 'ref' : 'inline',\n      }) as JSONSchema7,\n    {\n      validate: async value => {\n        const result = await z4.safeParseAsync(zodSchema, value);\n        return result.success\n          ? { success: true, value: result.data }\n          : { success: false, error: result.error };\n      },\n    },\n  );\n}\n\nexport function isZod4Schema(\n  zodSchema: z4.core.$ZodType<any, any> | z3.Schema<any, z3.ZodTypeDef, any>,\n): zodSchema is z4.core.$ZodType<any, any> {\n  // https://zod.dev/library-authors?id=how-to-support-zod-3-and-zod-4-simultaneously\n  return '_zod' in zodSchema;\n}\n\nexport function zodSchema<OBJECT>(\n  zodSchema:\n    | z4.core.$ZodType<OBJECT, any>\n    | z3.Schema<OBJECT, z3.ZodTypeDef, any>,\n  options?: {\n    /**\n     * Enables support for references in the schema.\n     * This is required for recursive schemas, e.g. with `z.lazy`.\n     * However, not all language models and providers support such references.\n     * Defaults to `false`.\n     */\n    useReferences?: boolean;\n  },\n): Schema<OBJECT> {\n  if (isZod4Schema(zodSchema)) {\n    return zod4Schema(zodSchema, options);\n  } else {\n    return zod3Schema(zodSchema, options);\n  }\n}\n", "export const getRelativePath = (pathA: string[], pathB: string[]) => {\n  let i = 0;\n  for (; i < pathA.length && i < pathB.length; i++) {\n    if (pathA[i] !== pathB[i]) break;\n  }\n  return [(pathA.length - i).toString(), ...pathB.slice(i)].join('/');\n};\n", "import { ZodSchema, ZodTypeDef } from 'zod/v3';\nimport { Refs, Seen } from './refs';\nimport { JsonSchema7Type } from './parse-types';\n\nexport type DateStrategy =\n  | 'format:date-time'\n  | 'format:date'\n  | 'string'\n  | 'integer';\n\nexport const ignoreOverride = Symbol(\n  'Let zodToJsonSchema decide on which parser to use',\n);\n\nexport type OverrideCallback = (\n  def: ZodTypeDef,\n  refs: Refs,\n  seen: Seen | undefined,\n  forceResolution?: boolean,\n) => JsonSchema7Type | undefined | typeof ignoreOverride;\n\nexport type PostProcessCallback = (\n  jsonSchema: JsonSchema7Type | undefined,\n  def: ZodTypeDef,\n  refs: Refs,\n) => JsonSchema7Type | undefined;\n\nexport const jsonDescription: PostProcessCallback = (jsonSchema, def) => {\n  if (def.description) {\n    try {\n      return {\n        ...jsonSchema,\n        ...JSON.parse(def.description),\n      };\n    } catch {}\n  }\n\n  return jsonSchema;\n};\n\nexport type Options = {\n  name: string | undefined;\n  $refStrategy: 'root' | 'relative' | 'none' | 'seen';\n  basePath: string[];\n  effectStrategy: 'input' | 'any';\n  pipeStrategy: 'input' | 'output' | 'all';\n  dateStrategy: DateStrategy | DateStrategy[];\n  mapStrategy: 'entries' | 'record';\n  removeAdditionalStrategy: 'passthrough' | 'strict';\n  allowedAdditionalProperties: true | undefined;\n  rejectedAdditionalProperties: false | undefined;\n  strictUnions: boolean;\n  definitionPath: string;\n  definitions: Record<string, ZodSchema>;\n  errorMessages: boolean;\n  patternStrategy: 'escape' | 'preserve';\n  applyRegexFlags: boolean;\n  emailStrategy: 'format:email' | 'format:idn-email' | 'pattern:zod';\n  base64Strategy: 'format:binary' | 'contentEncoding:base64' | 'pattern:zod';\n  nameStrategy: 'ref' | 'title';\n  override?: OverrideCallback;\n  postProcess?: PostProcessCallback;\n};\n\nexport const defaultOptions: Options = {\n  name: undefined,\n  $refStrategy: 'root',\n  basePath: ['#'],\n  effectStrategy: 'input',\n  pipeStrategy: 'all',\n  dateStrategy: 'format:date-time',\n  mapStrategy: 'entries',\n  removeAdditionalStrategy: 'passthrough',\n  allowedAdditionalProperties: true,\n  rejectedAdditionalProperties: false,\n  definitionPath: 'definitions',\n  strictUnions: false,\n  definitions: {},\n  errorMessages: false,\n  patternStrategy: 'escape',\n  applyRegexFlags: false,\n  emailStrategy: 'format:email',\n  base64Strategy: 'contentEncoding:base64',\n  nameStrategy: 'ref',\n};\n\nexport const getDefaultOptions = (\n  options: Partial<Options> | string | undefined,\n) =>\n  (typeof options === 'string'\n    ? {\n        ...defaultOptions,\n        name: options,\n      }\n    : {\n        ...defaultOptions,\n        ...options,\n      }) as Options;\n", "import { ZodFirstPartyTypeKind } from 'zod/v3';\nimport { parseAnyDef } from './parsers/any';\nimport { parseArrayDef } from './parsers/array';\nimport { parseBigintDef } from './parsers/bigint';\nimport { parseBooleanDef } from './parsers/boolean';\nimport { parseBrandedDef } from './parsers/branded';\nimport { parseCatchDef } from './parsers/catch';\nimport { parseDateDef } from './parsers/date';\nimport { parseDefaultDef } from './parsers/default';\nimport { parseEffectsDef } from './parsers/effects';\nimport { parseEnumDef } from './parsers/enum';\nimport { parseIntersectionDef } from './parsers/intersection';\nimport { parseLiteralDef } from './parsers/literal';\nimport { parseMapDef } from './parsers/map';\nimport { parseNativeEnumDef } from './parsers/native-enum';\nimport { parseNeverDef } from './parsers/never';\nimport { parseNullDef } from './parsers/null';\nimport { parseNullableDef } from './parsers/nullable';\nimport { parseNumberDef } from './parsers/number';\nimport { parseObjectDef } from './parsers/object';\nimport { parseOptionalDef } from './parsers/optional';\nimport { parsePipelineDef } from './parsers/pipeline';\nimport { parsePromiseDef } from './parsers/promise';\nimport { parseRecordDef } from './parsers/record';\nimport { parseSetDef } from './parsers/set';\nimport { parseStringDef } from './parsers/string';\nimport { parseTupleDef } from './parsers/tuple';\nimport { parseUndefinedDef } from './parsers/undefined';\nimport { parseUnionDef } from './parsers/union';\nimport { parseUnknownDef } from './parsers/unknown';\nimport { Refs } from './refs';\nimport { parseReadonlyDef } from './parsers/readonly';\nimport { JsonSchema7Type } from './parse-types';\n\nexport type InnerDefGetter = () => any;\n\nexport const selectParser = (\n  def: any,\n  typeName: ZodFirstPartyTypeKind,\n  refs: Refs,\n): JsonSchema7Type | undefined | InnerDefGetter => {\n  switch (typeName) {\n    case ZodFirstPartyTypeKind.ZodString:\n      return parseStringDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodNumber:\n      return parseNumberDef(def);\n    case ZodFirstPartyTypeKind.ZodObject:\n      return parseObjectDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodBigInt:\n      return parseBigintDef(def);\n    case ZodFirstPartyTypeKind.ZodBoolean:\n      return parseBooleanDef();\n    case ZodFirstPartyTypeKind.ZodDate:\n      return parseDateDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodUndefined:\n      return parseUndefinedDef();\n    case ZodFirstPartyTypeKind.ZodNull:\n      return parseNullDef();\n    case ZodFirstPartyTypeKind.ZodArray:\n      return parseArrayDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodUnion:\n    case ZodFirstPartyTypeKind.ZodDiscriminatedUnion:\n      return parseUnionDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodIntersection:\n      return parseIntersectionDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodTuple:\n      return parseTupleDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodRecord:\n      return parseRecordDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodLiteral:\n      return parseLiteralDef(def);\n    case ZodFirstPartyTypeKind.ZodEnum:\n      return parseEnumDef(def);\n    case ZodFirstPartyTypeKind.ZodNativeEnum:\n      return parseNativeEnumDef(def);\n    case ZodFirstPartyTypeKind.ZodNullable:\n      return parseNullableDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodOptional:\n      return parseOptionalDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodMap:\n      return parseMapDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodSet:\n      return parseSetDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodLazy:\n      return () => (def as any).getter()._def;\n    case ZodFirstPartyTypeKind.ZodPromise:\n      return parsePromiseDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodNaN:\n    case ZodFirstPartyTypeKind.ZodNever:\n      return parseNeverDef();\n    case ZodFirstPartyTypeKind.ZodEffects:\n      return parseEffectsDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodAny:\n      return parseAnyDef();\n    case ZodFirstPartyTypeKind.ZodUnknown:\n      return parseUnknownDef();\n    case ZodFirstPartyTypeKind.ZodDefault:\n      return parseDefaultDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodBranded:\n      return parseBrandedDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodReadonly:\n      return parseReadonlyDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodCatch:\n      return parseCatchDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodPipeline:\n      return parsePipelineDef(def, refs);\n    case ZodFirstPartyTypeKind.ZodFunction:\n    case ZodFirstPartyTypeKind.ZodVoid:\n    case ZodFirstPartyTypeKind.ZodSymbol:\n      return undefined;\n    default:\n      /* c8 ignore next */\n      return ((_: never) => undefined)(typeName);\n  }\n};\n", "export type JsonSchema7AnyType = { $ref?: string };\n\nexport function parseAnyDef(): JsonSchema7AnyType {\n  return {};\n}\n", "import { ZodArrayDef, ZodFirstPartyTypeKind } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\n\nexport type JsonSchema7ArrayType = {\n  type: 'array';\n  items?: JsonSchema7Type;\n  minItems?: number;\n  maxItems?: number;\n};\n\nexport function parseArrayDef(def: ZodArrayDef, refs: Refs) {\n  const res: JsonSchema7ArrayType = {\n    type: 'array',\n  };\n  if (\n    def.type?._def &&\n    def.type?._def?.typeName !== ZodFirstPartyTypeKind.ZodAny\n  ) {\n    res.items = parseDef(def.type._def, {\n      ...refs,\n      currentPath: [...refs.currentPath, 'items'],\n    });\n  }\n\n  if (def.minLength) {\n    res.minItems = def.minLength.value;\n  }\n  if (def.maxLength) {\n    res.maxItems = def.maxLength.value;\n  }\n  if (def.exactLength) {\n    res.minItems = def.exactLength.value;\n    res.maxItems = def.exactLength.value;\n  }\n  return res;\n}\n", "import { ZodBigIntDef } from 'zod/v3';\n\nexport type JsonSchema7BigintType = {\n  type: 'integer';\n  format: 'int64';\n  minimum?: BigInt;\n  exclusiveMinimum?: BigInt;\n  maximum?: BigInt;\n  exclusiveMaximum?: BigInt;\n  multipleOf?: BigInt;\n};\n\nexport function parseBigintDef(def: ZodBigIntDef): JsonSchema7BigintType {\n  const res: JsonSchema7BigintType = {\n    type: 'integer',\n    format: 'int64',\n  };\n\n  if (!def.checks) return res;\n\n  for (const check of def.checks) {\n    switch (check.kind) {\n      case 'min':\n        if (check.inclusive) {\n          res.minimum = check.value;\n        } else {\n          res.exclusiveMinimum = check.value;\n        }\n        break;\n      case 'max':\n        if (check.inclusive) {\n          res.maximum = check.value;\n        } else {\n          res.exclusiveMaximum = check.value;\n        }\n\n        break;\n      case 'multipleOf':\n        res.multipleOf = check.value;\n        break;\n    }\n  }\n  return res;\n}\n", "export type JsonSchema7BooleanType = {\n  type: 'boolean';\n};\n\nexport function parseBooleanDef(): JsonSchema7BooleanType {\n  return { type: 'boolean' };\n}\n", "import { ZodBrandedDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { Refs } from '../refs';\n\nexport function parseBrandedDef(_def: ZodBrandedDef<any>, refs: Refs) {\n  return parseDef(_def.type._def, refs);\n}\n", "import { ZodCatchDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { Refs } from '../refs';\n\nexport const parseCatchDef = (def: ZodCatchDef<any>, refs: Refs) => {\n  return parseDef(def.innerType._def, refs);\n};\n", "import { ZodDateDef } from 'zod/v3';\nimport { Refs } from '../refs';\nimport { DateStrategy } from '../options';\n\nexport type JsonSchema7DateType =\n  | {\n      type: 'integer' | 'string';\n      format: 'unix-time' | 'date-time' | 'date';\n      minimum?: number;\n      maximum?: number;\n    }\n  | {\n      anyOf: JsonSchema7DateType[];\n    };\n\nexport function parseDateDef(\n  def: ZodDateDef,\n  refs: Refs,\n  overrideDateStrategy?: DateStrategy,\n): JsonSchema7DateType {\n  const strategy = overrideDateStrategy ?? refs.dateStrategy;\n\n  if (Array.isArray(strategy)) {\n    return {\n      anyOf: strategy.map((item, i) => parseDateDef(def, refs, item)),\n    };\n  }\n\n  switch (strategy) {\n    case 'string':\n    case 'format:date-time':\n      return {\n        type: 'string',\n        format: 'date-time',\n      };\n    case 'format:date':\n      return {\n        type: 'string',\n        format: 'date',\n      };\n    case 'integer':\n      return integerDateParser(def);\n  }\n}\n\nconst integerDateParser = (def: ZodDateDef) => {\n  const res: JsonSchema7DateType = {\n    type: 'integer',\n    format: 'unix-time',\n  };\n\n  for (const check of def.checks) {\n    switch (check.kind) {\n      case 'min':\n        res.minimum = check.value;\n        break;\n      case 'max':\n        res.maximum = check.value;\n        break;\n    }\n  }\n\n  return res;\n};\n", "import { ZodDefaultDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\n\nexport function parseDefaultDef(\n  _def: ZodDefaultDef,\n  refs: Refs,\n): JsonSchema7Type & { default: any } {\n  return {\n    ...parseDef(_def.innerType._def, refs),\n    default: _def.defaultValue(),\n  };\n}\n", "import { ZodEffectsDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\nimport { parseAnyDef } from './any';\n\nexport function parseEffectsDef(\n  _def: ZodEffectsDef,\n  refs: Refs,\n): JsonSchema7Type | undefined {\n  return refs.effectStrategy === 'input'\n    ? parseDef(_def.schema._def, refs)\n    : parseAnyDef();\n}\n", "import { ZodEnumDef } from 'zod/v3';\n\nexport type JsonSchema7EnumType = {\n  type: 'string';\n  enum: string[];\n};\n\nexport function parseEnumDef(def: ZodEnumDef): JsonSchema7EnumType {\n  return {\n    type: 'string',\n    enum: Array.from(def.values),\n  };\n}\n", "import { ZodIntersectionDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\nimport { JsonSchema7StringType } from './string';\n\nexport type JsonSchema7AllOfType = {\n  allOf: JsonSchema7Type[];\n  unevaluatedProperties?: boolean;\n};\n\nconst isJsonSchema7AllOfType = (\n  type: JsonSchema7Type | JsonSchema7StringType,\n): type is JsonSchema7AllOfType => {\n  if ('type' in type && type.type === 'string') return false;\n  return 'allOf' in type;\n};\n\nexport function parseIntersectionDef(\n  def: ZodIntersectionDef,\n  refs: Refs,\n): JsonSchema7AllOfType | JsonSchema7Type | undefined {\n  const allOf = [\n    parseDef(def.left._def, {\n      ...refs,\n      currentPath: [...refs.currentPath, 'allOf', '0'],\n    }),\n    parseDef(def.right._def, {\n      ...refs,\n      currentPath: [...refs.currentPath, 'allOf', '1'],\n    }),\n  ].filter((x): x is JsonSchema7Type => !!x);\n\n  const mergedAllOf: JsonSchema7Type[] = [];\n  // If either of the schemas is an allOf, merge them into a single allOf\n  allOf.forEach(schema => {\n    if (isJsonSchema7AllOfType(schema)) {\n      mergedAllOf.push(...schema.allOf);\n    } else {\n      let nestedSchema: JsonSchema7Type = schema;\n      if (\n        'additionalProperties' in schema &&\n        schema.additionalProperties === false\n      ) {\n        const { additionalProperties, ...rest } = schema;\n        nestedSchema = rest;\n      }\n      mergedAllOf.push(nestedSchema);\n    }\n  });\n  return mergedAllOf.length ? { allOf: mergedAllOf } : undefined;\n}\n", "import { ZodLiteralDef } from 'zod/v3';\n\nexport type JsonSchema7LiteralType =\n  | {\n      type: 'string' | 'number' | 'integer' | 'boolean';\n      const: string | number | boolean;\n    }\n  | {\n      type: 'object' | 'array';\n    };\n\nexport function parseLiteralDef(def: ZodLiteralDef): JsonSchema7LiteralType {\n  const parsedType = typeof def.value;\n  if (\n    parsedType !== 'bigint' &&\n    parsedType !== 'number' &&\n    parsedType !== 'boolean' &&\n    parsedType !== 'string'\n  ) {\n    return {\n      type: Array.isArray(def.value) ? 'array' : 'object',\n    };\n  }\n\n  return {\n    type: parsedType === 'bigint' ? 'integer' : parsedType,\n    const: def.value,\n  };\n}\n", "import {\n  ZodFirstPartyTypeKind,\n  ZodMapDef,\n  ZodRecordDef,\n  ZodTypeAny,\n} from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\nimport { parseBrandedDef } from './branded';\nimport { JsonSchema7EnumType } from './enum';\nimport { JsonSchema7StringType, parseStringDef } from './string';\n\ntype JsonSchema7RecordPropertyNamesType =\n  | Omit<JsonSchema7StringType, 'type'>\n  | Omit<JsonSchema7EnumType, 'type'>;\n\nexport type JsonSchema7RecordType = {\n  type: 'object';\n  additionalProperties?: JsonSchema7Type | true;\n  propertyNames?: JsonSchema7RecordPropertyNamesType;\n};\n\nexport function parseRecordDef(\n  def: ZodRecordDef<ZodTypeAny, ZodTypeAny> | ZodMapDef,\n  refs: Refs,\n): JsonSchema7RecordType {\n  const schema: JsonSchema7RecordType = {\n    type: 'object',\n    additionalProperties:\n      parseDef(def.valueType._def, {\n        ...refs,\n        currentPath: [...refs.currentPath, 'additionalProperties'],\n      }) ?? refs.allowedAdditionalProperties,\n  };\n\n  if (\n    def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodString &&\n    def.keyType._def.checks?.length\n  ) {\n    const { type, ...keyType } = parseStringDef(def.keyType._def, refs);\n\n    return {\n      ...schema,\n      propertyNames: keyType,\n    };\n  } else if (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodEnum) {\n    return {\n      ...schema,\n      propertyNames: {\n        enum: def.keyType._def.values,\n      },\n    };\n  } else if (\n    def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodBranded &&\n    def.keyType._def.type._def.typeName === ZodFirstPartyTypeKind.ZodString &&\n    def.keyType._def.type._def.checks?.length\n  ) {\n    const { type, ...keyType } = parseBrandedDef(\n      def.keyType._def,\n      refs,\n    ) as JsonSchema7StringType;\n\n    return {\n      ...schema,\n      propertyNames: keyType,\n    };\n  }\n\n  return schema;\n}\n", "import { ZodStringDef } from 'zod/v3';\nimport { Refs } from '../refs';\n\nlet emojiRegex: RegExp | undefined = undefined;\n\n/**\n * Generated from the regular expressions found here as of 2024-05-22:\n * https://github.com/colinhacks/zod/blob/master/src/types.ts.\n *\n * Expressions with /i flag have been changed accordingly.\n */\nexport const zodPatterns = {\n  /**\n   * `c` was changed to `[cC]` to replicate /i flag\n   */\n  cuid: /^[cC][^\\s-]{8,}$/,\n  cuid2: /^[0-9a-z]+$/,\n  ulid: /^[0-9A-HJKMNP-TV-Z]{26}$/,\n  /**\n   * `a-z` was added to replicate /i flag\n   */\n  email:\n    /^(?!\\.)(?!.*\\.\\.)([a-zA-Z0-9_'+\\-\\.]*)[a-zA-Z0-9_+-]@([a-zA-Z0-9][a-zA-Z0-9\\-]*\\.)+[a-zA-Z]{2,}$/,\n  /**\n   * Constructed a valid Unicode RegExp\n   *\n   * Lazily instantiate since this type of regex isn't supported\n   * in all envs (e.g. React Native).\n   *\n   * See:\n   * https://github.com/colinhacks/zod/issues/2433\n   * Fix in Zod:\n   * https://github.com/colinhacks/zod/commit/9340fd51e48576a75adc919bff65dbc4a5d4c99b\n   */\n  emoji: () => {\n    if (emojiRegex === undefined) {\n      emojiRegex = RegExp(\n        '^(\\\\p{Extended_Pictographic}|\\\\p{Emoji_Component})+$',\n        'u',\n      );\n    }\n    return emojiRegex;\n  },\n  /**\n   * Unused\n   */\n  uuid: /^[0-9a-fA-F]{8}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{4}\\b-[0-9a-fA-F]{12}$/,\n  /**\n   * Unused\n   */\n  ipv4: /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])$/,\n  ipv4Cidr:\n    /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\/(3[0-2]|[12]?[0-9])$/,\n  /**\n   * Unused\n   */\n  ipv6: /^(([a-f0-9]{1,4}:){7}|::([a-f0-9]{1,4}:){0,6}|([a-f0-9]{1,4}:){1}:([a-f0-9]{1,4}:){0,5}|([a-f0-9]{1,4}:){2}:([a-f0-9]{1,4}:){0,4}|([a-f0-9]{1,4}:){3}:([a-f0-9]{1,4}:){0,3}|([a-f0-9]{1,4}:){4}:([a-f0-9]{1,4}:){0,2}|([a-f0-9]{1,4}:){5}:([a-f0-9]{1,4}:){0,1})([a-f0-9]{1,4}|(((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\\.){3}((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2})))$/,\n  ipv6Cidr:\n    /^(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\\/(12[0-8]|1[01][0-9]|[1-9]?[0-9])$/,\n  base64: /^([0-9a-zA-Z+/]{4})*(([0-9a-zA-Z+/]{2}==)|([0-9a-zA-Z+/]{3}=))?$/,\n  base64url:\n    /^([0-9a-zA-Z-_]{4})*(([0-9a-zA-Z-_]{2}(==)?)|([0-9a-zA-Z-_]{3}(=)?))?$/,\n  nanoid: /^[a-zA-Z0-9_-]{21}$/,\n  jwt: /^[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]*$/,\n} as const;\n\nexport type JsonSchema7StringType = {\n  type: 'string';\n  minLength?: number;\n  maxLength?: number;\n  format?:\n    | 'email'\n    | 'idn-email'\n    | 'uri'\n    | 'uuid'\n    | 'date-time'\n    | 'ipv4'\n    | 'ipv6'\n    | 'date'\n    | 'time'\n    | 'duration';\n  pattern?: string;\n  allOf?: {\n    pattern: string;\n  }[];\n  anyOf?: {\n    format: string;\n  }[];\n  contentEncoding?: string;\n};\n\nexport function parseStringDef(\n  def: ZodStringDef,\n  refs: Refs,\n): JsonSchema7StringType {\n  const res: JsonSchema7StringType = {\n    type: 'string',\n  };\n\n  if (def.checks) {\n    for (const check of def.checks) {\n      switch (check.kind) {\n        case 'min':\n          res.minLength =\n            typeof res.minLength === 'number'\n              ? Math.max(res.minLength, check.value)\n              : check.value;\n          break;\n        case 'max':\n          res.maxLength =\n            typeof res.maxLength === 'number'\n              ? Math.min(res.maxLength, check.value)\n              : check.value;\n\n          break;\n        case 'email':\n          switch (refs.emailStrategy) {\n            case 'format:email':\n              addFormat(res, 'email', check.message, refs);\n              break;\n            case 'format:idn-email':\n              addFormat(res, 'idn-email', check.message, refs);\n              break;\n            case 'pattern:zod':\n              addPattern(res, zodPatterns.email, check.message, refs);\n              break;\n          }\n\n          break;\n        case 'url':\n          addFormat(res, 'uri', check.message, refs);\n          break;\n        case 'uuid':\n          addFormat(res, 'uuid', check.message, refs);\n          break;\n        case 'regex':\n          addPattern(res, check.regex, check.message, refs);\n          break;\n        case 'cuid':\n          addPattern(res, zodPatterns.cuid, check.message, refs);\n          break;\n        case 'cuid2':\n          addPattern(res, zodPatterns.cuid2, check.message, refs);\n          break;\n        case 'startsWith':\n          addPattern(\n            res,\n            RegExp(`^${escapeLiteralCheckValue(check.value, refs)}`),\n            check.message,\n            refs,\n          );\n          break;\n        case 'endsWith':\n          addPattern(\n            res,\n            RegExp(`${escapeLiteralCheckValue(check.value, refs)}$`),\n            check.message,\n            refs,\n          );\n          break;\n        case 'datetime':\n          addFormat(res, 'date-time', check.message, refs);\n          break;\n        case 'date':\n          addFormat(res, 'date', check.message, refs);\n          break;\n        case 'time':\n          addFormat(res, 'time', check.message, refs);\n          break;\n        case 'duration':\n          addFormat(res, 'duration', check.message, refs);\n          break;\n        case 'length':\n          res.minLength =\n            typeof res.minLength === 'number'\n              ? Math.max(res.minLength, check.value)\n              : check.value;\n          res.maxLength =\n            typeof res.maxLength === 'number'\n              ? Math.min(res.maxLength, check.value)\n              : check.value;\n          break;\n        case 'includes': {\n          addPattern(\n            res,\n            RegExp(escapeLiteralCheckValue(check.value, refs)),\n            check.message,\n            refs,\n          );\n          break;\n        }\n        case 'ip': {\n          if (check.version !== 'v6') {\n            addFormat(res, 'ipv4', check.message, refs);\n          }\n          if (check.version !== 'v4') {\n            addFormat(res, 'ipv6', check.message, refs);\n          }\n          break;\n        }\n        case 'base64url':\n          addPattern(res, zodPatterns.base64url, check.message, refs);\n          break;\n        case 'jwt':\n          addPattern(res, zodPatterns.jwt, check.message, refs);\n          break;\n        case 'cidr': {\n          if (check.version !== 'v6') {\n            addPattern(res, zodPatterns.ipv4Cidr, check.message, refs);\n          }\n          if (check.version !== 'v4') {\n            addPattern(res, zodPatterns.ipv6Cidr, check.message, refs);\n          }\n          break;\n        }\n        case 'emoji':\n          addPattern(res, zodPatterns.emoji(), check.message, refs);\n          break;\n        case 'ulid': {\n          addPattern(res, zodPatterns.ulid, check.message, refs);\n          break;\n        }\n        case 'base64': {\n          switch (refs.base64Strategy) {\n            case 'format:binary': {\n              addFormat(res, 'binary' as any, check.message, refs);\n              break;\n            }\n\n            case 'contentEncoding:base64': {\n              res.contentEncoding = 'base64';\n              break;\n            }\n\n            case 'pattern:zod': {\n              addPattern(res, zodPatterns.base64, check.message, refs);\n              break;\n            }\n          }\n          break;\n        }\n        case 'nanoid': {\n          addPattern(res, zodPatterns.nanoid, check.message, refs);\n        }\n        case 'toLowerCase':\n        case 'toUpperCase':\n        case 'trim':\n          break;\n        default:\n          /* c8 ignore next */\n          ((_: never) => {})(check);\n      }\n    }\n  }\n\n  return res;\n}\n\nfunction escapeLiteralCheckValue(literal: string, refs: Refs): string {\n  return refs.patternStrategy === 'escape'\n    ? escapeNonAlphaNumeric(literal)\n    : literal;\n}\n\nconst ALPHA_NUMERIC = new Set(\n  'ABCDEFGHIJKLMNOPQRSTUVXYZabcdefghijklmnopqrstuvxyz0123456789',\n);\n\nfunction escapeNonAlphaNumeric(source: string) {\n  let result = '';\n\n  for (let i = 0; i < source.length; i++) {\n    if (!ALPHA_NUMERIC.has(source[i])) {\n      result += '\\\\';\n    }\n\n    result += source[i];\n  }\n\n  return result;\n}\n\n// Adds a \"format\" keyword to the schema. If a format exists, both formats will be joined in an allOf-node, along with subsequent ones.\nfunction addFormat(\n  schema: JsonSchema7StringType,\n  value: Required<JsonSchema7StringType>['format'],\n  message: string | undefined,\n  refs: Refs,\n) {\n  if (schema.format || schema.anyOf?.some(x => x.format)) {\n    if (!schema.anyOf) {\n      schema.anyOf = [];\n    }\n\n    if (schema.format) {\n      schema.anyOf!.push({\n        format: schema.format,\n      });\n      delete schema.format;\n    }\n\n    schema.anyOf!.push({\n      format: value,\n      ...(message &&\n        refs.errorMessages && { errorMessage: { format: message } }),\n    });\n  } else {\n    schema.format = value;\n  }\n}\n\n// Adds a \"pattern\" keyword to the schema. If a pattern exists, both patterns will be joined in an allOf-node, along with subsequent ones.\nfunction addPattern(\n  schema: JsonSchema7StringType,\n  regex: RegExp,\n  message: string | undefined,\n  refs: Refs,\n) {\n  if (schema.pattern || schema.allOf?.some(x => x.pattern)) {\n    if (!schema.allOf) {\n      schema.allOf = [];\n    }\n\n    if (schema.pattern) {\n      schema.allOf!.push({\n        pattern: schema.pattern,\n      });\n      delete schema.pattern;\n    }\n\n    schema.allOf!.push({\n      pattern: stringifyRegExpWithFlags(regex, refs),\n      ...(message &&\n        refs.errorMessages && { errorMessage: { pattern: message } }),\n    });\n  } else {\n    schema.pattern = stringifyRegExpWithFlags(regex, refs);\n  }\n}\n\n// Mutate z.string.regex() in a best attempt to accommodate for regex flags when applyRegexFlags is true\nfunction stringifyRegExpWithFlags(regex: RegExp, refs: Refs): string {\n  if (!refs.applyRegexFlags || !regex.flags) {\n    return regex.source;\n  }\n\n  // Currently handled flags\n  const flags = {\n    i: regex.flags.includes('i'), // Case-insensitive\n    m: regex.flags.includes('m'), // `^` and `$` matches adjacent to newline characters\n    s: regex.flags.includes('s'), // `.` matches newlines\n  };\n\n  // The general principle here is to step through each character, one at a time, applying mutations as flags require. We keep track when the current character is escaped, and when it's inside a group /like [this]/ or (also) a range like /[a-z]/. The following is fairly brittle imperative code; edit at your peril!\n  const source = flags.i ? regex.source.toLowerCase() : regex.source;\n  let pattern = '';\n  let isEscaped = false;\n  let inCharGroup = false;\n  let inCharRange = false;\n\n  for (let i = 0; i < source.length; i++) {\n    if (isEscaped) {\n      pattern += source[i];\n      isEscaped = false;\n      continue;\n    }\n\n    if (flags.i) {\n      if (inCharGroup) {\n        if (source[i].match(/[a-z]/)) {\n          if (inCharRange) {\n            pattern += source[i];\n            pattern += `${source[i - 2]}-${source[i]}`.toUpperCase();\n            inCharRange = false;\n          } else if (source[i + 1] === '-' && source[i + 2]?.match(/[a-z]/)) {\n            pattern += source[i];\n            inCharRange = true;\n          } else {\n            pattern += `${source[i]}${source[i].toUpperCase()}`;\n          }\n          continue;\n        }\n      } else if (source[i].match(/[a-z]/)) {\n        pattern += `[${source[i]}${source[i].toUpperCase()}]`;\n        continue;\n      }\n    }\n\n    if (flags.m) {\n      if (source[i] === '^') {\n        pattern += `(^|(?<=[\\r\\n]))`;\n        continue;\n      } else if (source[i] === '$') {\n        pattern += `($|(?=[\\r\\n]))`;\n        continue;\n      }\n    }\n\n    if (flags.s && source[i] === '.') {\n      pattern += inCharGroup ? `${source[i]}\\r\\n` : `[${source[i]}\\r\\n]`;\n      continue;\n    }\n\n    pattern += source[i];\n    if (source[i] === '\\\\') {\n      isEscaped = true;\n    } else if (inCharGroup && source[i] === ']') {\n      inCharGroup = false;\n    } else if (!inCharGroup && source[i] === '[') {\n      inCharGroup = true;\n    }\n  }\n\n  try {\n    new RegExp(pattern);\n  } catch {\n    console.warn(\n      `Could not convert regex pattern at ${refs.currentPath.join(\n        '/',\n      )} to a flag-independent form! Falling back to the flag-ignorant source`,\n    );\n    return regex.source;\n  }\n\n  return pattern;\n}\n", "import { ZodMapDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\nimport { parseAnyDef } from './any';\nimport { JsonSchema7RecordType, parseRecordDef } from './record';\n\nexport type JsonSchema7MapType = {\n  type: 'array';\n  maxItems: 125;\n  items: {\n    type: 'array';\n    items: [JsonSchema7Type, JsonSchema7Type];\n    minItems: 2;\n    maxItems: 2;\n  };\n};\n\nexport function parseMapDef(\n  def: ZodMapDef,\n  refs: Refs,\n): JsonSchema7MapType | JsonSchema7RecordType {\n  if (refs.mapStrategy === 'record') {\n    return parseRecordDef(def, refs);\n  }\n\n  const keys =\n    parseDef(def.keyType._def, {\n      ...refs,\n      currentPath: [...refs.currentPath, 'items', 'items', '0'],\n    }) || parseAnyDef();\n  const values =\n    parseDef(def.valueType._def, {\n      ...refs,\n      currentPath: [...refs.currentPath, 'items', 'items', '1'],\n    }) || parseAnyDef();\n  return {\n    type: 'array',\n    maxItems: 125,\n    items: {\n      type: 'array',\n      items: [keys, values],\n      minItems: 2,\n      maxItems: 2,\n    },\n  };\n}\n", "import { ZodNativeEnumDef } from 'zod/v3';\n\nexport type JsonSchema7NativeEnumType = {\n  type: 'string' | 'number' | ['string', 'number'];\n  enum: (string | number)[];\n};\n\nexport function parseNativeEnumDef(\n  def: ZodNativeEnumDef,\n): JsonSchema7NativeEnumType {\n  const object = def.values;\n  const actualKeys = Object.keys(def.values).filter((key: string) => {\n    return typeof object[object[key]] !== 'number';\n  });\n\n  const actualValues = actualKeys.map((key: string) => object[key]);\n\n  const parsedTypes = Array.from(\n    new Set(actualValues.map((values: string | number) => typeof values)),\n  );\n\n  return {\n    type:\n      parsedTypes.length === 1\n        ? parsedTypes[0] === 'string'\n          ? 'string'\n          : 'number'\n        : ['string', 'number'],\n    enum: actualValues,\n  };\n}\n", "import { JsonSchema7AnyType, parseAnyDef } from './any';\n\nexport type JsonSchema7NeverType = {\n  not: JsonSchema7AnyType;\n};\n\nexport function parseNeverDef(): JsonSchema7NeverType | undefined {\n  return { not: parseAnyDef() };\n}\n", "export type JsonSchema7NullType = {\n  type: 'null';\n};\n\nexport function parseNullDef(): JsonSchema7NullType {\n  return {\n    type: 'null',\n  };\n}\n", "import {\n  ZodDiscriminatedUnionDef,\n  ZodLiteralDef,\n  ZodTypeAny,\n  ZodUnionDef,\n} from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\n\nexport const primitiveMappings = {\n  ZodString: 'string',\n  ZodNumber: 'number',\n  ZodBigInt: 'integer',\n  ZodBoolean: 'boolean',\n  ZodNull: 'null',\n} as const;\ntype ZodPrimitive = keyof typeof primitiveMappings;\ntype JsonSchema7Primitive =\n  (typeof primitiveMappings)[keyof typeof primitiveMappings];\n\nexport type JsonSchema7UnionType =\n  | JsonSchema7PrimitiveUnionType\n  | JsonSchema7AnyOfType;\n\ntype JsonSchema7PrimitiveUnionType =\n  | {\n      type: JsonSchema7Primitive | JsonSchema7Primitive[];\n    }\n  | {\n      type: JsonSchema7Primitive | JsonSchema7Primitive[];\n      enum: (string | number | bigint | boolean | null)[];\n    };\n\ntype JsonSchema7AnyOfType = {\n  anyOf: JsonSchema7Type[];\n};\n\nexport function parseUnionDef(\n  def: ZodUnionDef | ZodDiscriminatedUnionDef<any, any>,\n  refs: Refs,\n): JsonSchema7PrimitiveUnionType | JsonSchema7AnyOfType | undefined {\n  const options: readonly ZodTypeAny[] =\n    def.options instanceof Map ? Array.from(def.options.values()) : def.options;\n\n  // This blocks tries to look ahead a bit to produce nicer looking schemas with type array instead of anyOf.\n  if (\n    options.every(\n      x =>\n        x._def.typeName in primitiveMappings &&\n        (!x._def.checks || !x._def.checks.length),\n    )\n  ) {\n    // all types in union are primitive and lack checks, so might as well squash into {type: [...]}\n\n    const types = options.reduce((types: JsonSchema7Primitive[], x) => {\n      const type = primitiveMappings[x._def.typeName as ZodPrimitive]; //Can be safely casted due to row 43\n      return type && !types.includes(type) ? [...types, type] : types;\n    }, []);\n\n    return {\n      type: types.length > 1 ? types : types[0],\n    };\n  } else if (\n    options.every(x => x._def.typeName === 'ZodLiteral' && !x.description)\n  ) {\n    // all options literals\n\n    const types = options.reduce(\n      (acc: JsonSchema7Primitive[], x: { _def: ZodLiteralDef }) => {\n        const type = typeof x._def.value;\n        switch (type) {\n          case 'string':\n          case 'number':\n          case 'boolean':\n            return [...acc, type];\n          case 'bigint':\n            return [...acc, 'integer' as const];\n          case 'object':\n            if (x._def.value === null) return [...acc, 'null' as const];\n          case 'symbol':\n          case 'undefined':\n          case 'function':\n          default:\n            return acc;\n        }\n      },\n      [],\n    );\n\n    if (types.length === options.length) {\n      // all the literals are primitive, as far as null can be considered primitive\n\n      const uniqueTypes = types.filter((x, i, a) => a.indexOf(x) === i);\n      return {\n        type: uniqueTypes.length > 1 ? uniqueTypes : uniqueTypes[0],\n        enum: options.reduce(\n          (acc, x) => {\n            return acc.includes(x._def.value) ? acc : [...acc, x._def.value];\n          },\n          [] as (string | number | bigint | boolean | null)[],\n        ),\n      };\n    }\n  } else if (options.every(x => x._def.typeName === 'ZodEnum')) {\n    return {\n      type: 'string',\n      enum: options.reduce(\n        (acc: string[], x) => [\n          ...acc,\n          ...x._def.values.filter((x: string) => !acc.includes(x)),\n        ],\n        [],\n      ),\n    };\n  }\n\n  return asAnyOf(def, refs);\n}\n\nconst asAnyOf = (\n  def: ZodUnionDef | ZodDiscriminatedUnionDef<any, any>,\n  refs: Refs,\n): JsonSchema7PrimitiveUnionType | JsonSchema7AnyOfType | undefined => {\n  const anyOf = (\n    (def.options instanceof Map\n      ? Array.from(def.options.values())\n      : def.options) as any[]\n  )\n    .map((x, i) =>\n      parseDef(x._def, {\n        ...refs,\n        currentPath: [...refs.currentPath, 'anyOf', `${i}`],\n      }),\n    )\n    .filter(\n      (x): x is JsonSchema7Type =>\n        !!x &&\n        (!refs.strictUnions ||\n          (typeof x === 'object' && Object.keys(x).length > 0)),\n    );\n\n  return anyOf.length ? { anyOf } : undefined;\n};\n", "import { ZodNullableDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\nimport { JsonSchema7NullType } from './null';\nimport { primitiveMappings } from './union';\n\nexport type JsonSchema7NullableType =\n  | {\n      anyOf: [JsonSchema7Type, JsonSchema7NullType];\n    }\n  | {\n      type: [string, 'null'];\n    };\n\nexport function parseNullableDef(\n  def: ZodNullableDef,\n  refs: Refs,\n): JsonSchema7NullableType | undefined {\n  if (\n    ['ZodString', 'ZodNumber', 'ZodBigInt', 'ZodBoolean', 'ZodNull'].includes(\n      def.innerType._def.typeName,\n    ) &&\n    (!def.innerType._def.checks || !def.innerType._def.checks.length)\n  ) {\n    return {\n      type: [\n        primitiveMappings[\n          def.innerType._def.typeName as keyof typeof primitiveMappings\n        ],\n        'null',\n      ],\n    };\n  }\n\n  const base = parseDef(def.innerType._def, {\n    ...refs,\n    currentPath: [...refs.currentPath, 'anyOf', '0'],\n  });\n\n  return base && { anyOf: [base, { type: 'null' }] };\n}\n", "import { ZodNumberDef } from 'zod/v3';\n\nexport type JsonSchema7NumberType = {\n  type: 'number' | 'integer';\n  minimum?: number;\n  exclusiveMinimum?: number;\n  maximum?: number;\n  exclusiveMaximum?: number;\n  multipleOf?: number;\n};\n\nexport function parseNumberDef(def: ZodNumberDef): JsonSchema7NumberType {\n  const res: JsonSchema7NumberType = {\n    type: 'number',\n  };\n\n  if (!def.checks) return res;\n\n  for (const check of def.checks) {\n    switch (check.kind) {\n      case 'int':\n        res.type = 'integer';\n        break;\n      case 'min':\n        if (check.inclusive) {\n          res.minimum = check.value;\n        } else {\n          res.exclusiveMinimum = check.value;\n        }\n        break;\n      case 'max':\n        if (check.inclusive) {\n          res.maximum = check.value;\n        } else {\n          res.exclusiveMaximum = check.value;\n        }\n        break;\n      case 'multipleOf':\n        res.multipleOf = check.value;\n        break;\n    }\n  }\n  return res;\n}\n", "import { ZodObjectDef, ZodTypeAny } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\n\nexport type JsonSchema7ObjectType = {\n  type: 'object';\n  properties: Record<string, JsonSchema7Type>;\n  additionalProperties?: boolean | JsonSchema7Type;\n  required?: string[];\n};\n\nexport function parseObjectDef(def: ZodObjectDef, refs: Refs) {\n  const result: JsonSchema7ObjectType = {\n    type: 'object',\n    properties: {},\n  };\n\n  const required: string[] = [];\n\n  const shape = def.shape();\n\n  for (const propName in shape) {\n    let propDef = shape[propName];\n\n    if (propDef === undefined || propDef._def === undefined) {\n      continue;\n    }\n\n    const propOptional = safeIsOptional(propDef);\n\n    const parsedDef = parseDef(propDef._def, {\n      ...refs,\n      currentPath: [...refs.currentPath, 'properties', propName],\n      propertyPath: [...refs.currentPath, 'properties', propName],\n    });\n\n    if (parsedDef === undefined) {\n      continue;\n    }\n\n    result.properties[propName] = parsedDef;\n\n    if (!propOptional) {\n      required.push(propName);\n    }\n  }\n\n  if (required.length) {\n    result.required = required;\n  }\n\n  const additionalProperties = decideAdditionalProperties(def, refs);\n\n  if (additionalProperties !== undefined) {\n    result.additionalProperties = additionalProperties;\n  }\n\n  return result;\n}\n\nfunction decideAdditionalProperties(def: ZodObjectDef, refs: Refs) {\n  if (def.catchall._def.typeName !== 'ZodNever') {\n    return parseDef(def.catchall._def, {\n      ...refs,\n      currentPath: [...refs.currentPath, 'additionalProperties'],\n    });\n  }\n\n  switch (def.unknownKeys) {\n    case 'passthrough':\n      return refs.allowedAdditionalProperties;\n    case 'strict':\n      return refs.rejectedAdditionalProperties;\n    case 'strip':\n      return refs.removeAdditionalStrategy === 'strict'\n        ? refs.allowedAdditionalProperties\n        : refs.rejectedAdditionalProperties;\n  }\n}\n\nfunction safeIsOptional(schema: ZodTypeAny): boolean {\n  try {\n    return schema.isOptional();\n  } catch {\n    return true;\n  }\n}\n", "import { ZodOptionalDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\nimport { parseAnyDef } from './any';\n\nexport const parseOptionalDef = (\n  def: ZodOptionalDef,\n  refs: Refs,\n): JsonSchema7Type | undefined => {\n  if (refs.currentPath.toString() === refs.propertyPath?.toString()) {\n    return parseDef(def.innerType._def, refs);\n  }\n\n  const innerSchema = parseDef(def.innerType._def, {\n    ...refs,\n    currentPath: [...refs.currentPath, 'anyOf', '1'],\n  });\n\n  return innerSchema\n    ? { anyOf: [{ not: parseAnyDef() }, innerSchema] }\n    : parseAnyDef();\n};\n", "import { ZodPipelineDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\nimport { JsonSchema7AllOfType } from './intersection';\n\nexport const parsePipelineDef = (\n  def: ZodPipelineDef<any, any>,\n  refs: Refs,\n): JsonSchema7AllOfType | JsonSchema7Type | undefined => {\n  if (refs.pipeStrategy === 'input') {\n    return parseDef(def.in._def, refs);\n  } else if (refs.pipeStrategy === 'output') {\n    return parseDef(def.out._def, refs);\n  }\n\n  const a = parseDef(def.in._def, {\n    ...refs,\n    currentPath: [...refs.currentPath, 'allOf', '0'],\n  });\n  const b = parseDef(def.out._def, {\n    ...refs,\n    currentPath: [...refs.currentPath, 'allOf', a ? '1' : '0'],\n  });\n\n  return {\n    allOf: [a, b].filter((x): x is JsonSchema7Type => x !== undefined),\n  };\n};\n", "import { ZodPromiseDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\n\nexport function parsePromiseDef(\n  def: ZodPromiseDef,\n  refs: Refs,\n): JsonSchema7Type | undefined {\n  return parseDef(def.type._def, refs);\n}\n", "import { ZodSetDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\n\nexport type JsonSchema7SetType = {\n  type: 'array';\n  uniqueItems: true;\n  items?: JsonSchema7Type;\n  minItems?: number;\n  maxItems?: number;\n};\n\nexport function parseSetDef(def: ZodSetDef, refs: Refs): JsonSchema7SetType {\n  const items = parseDef(def.valueType._def, {\n    ...refs,\n    currentPath: [...refs.currentPath, 'items'],\n  });\n\n  const schema: JsonSchema7SetType = {\n    type: 'array',\n    uniqueItems: true,\n    items,\n  };\n\n  if (def.minSize) {\n    schema.minItems = def.minSize.value;\n  }\n\n  if (def.maxSize) {\n    schema.maxItems = def.maxSize.value;\n  }\n\n  return schema;\n}\n", "import { ZodTupleDef, ZodTupleItems, ZodTypeAny } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { JsonSchema7Type } from '../parse-types';\nimport { Refs } from '../refs';\n\nexport type JsonSchema7TupleType = {\n  type: 'array';\n  minItems: number;\n  items: JsonSchema7Type[];\n} & (\n  | {\n      maxItems: number;\n    }\n  | {\n      additionalItems?: JsonSchema7Type;\n    }\n);\n\nexport function parseTupleDef(\n  def: ZodTupleDef<ZodTupleItems | [], ZodTypeAny | null>,\n  refs: Refs,\n): JsonSchema7TupleType {\n  if (def.rest) {\n    return {\n      type: 'array',\n      minItems: def.items.length,\n      items: def.items\n        .map((x, i) =>\n          parseDef(x._def, {\n            ...refs,\n            currentPath: [...refs.currentPath, 'items', `${i}`],\n          }),\n        )\n        .reduce(\n          (acc: JsonSchema7Type[], x) => (x === undefined ? acc : [...acc, x]),\n          [],\n        ),\n      additionalItems: parseDef(def.rest._def, {\n        ...refs,\n        currentPath: [...refs.currentPath, 'additionalItems'],\n      }),\n    };\n  } else {\n    return {\n      type: 'array',\n      minItems: def.items.length,\n      maxItems: def.items.length,\n      items: def.items\n        .map((x, i) =>\n          parseDef(x._def, {\n            ...refs,\n            currentPath: [...refs.currentPath, 'items', `${i}`],\n          }),\n        )\n        .reduce(\n          (acc: JsonSchema7Type[], x) => (x === undefined ? acc : [...acc, x]),\n          [],\n        ),\n    };\n  }\n}\n", "import { JsonSchema7AnyType, parseAnyDef } from './any';\n\nexport type JsonSchema7UndefinedType = {\n  not: JsonSchema7AnyType;\n};\n\nexport function parseUndefinedDef(): JsonSchema7UndefinedType {\n  return {\n    not: parseAnyDef(),\n  };\n}\n", "import { JsonSchema7AnyType, parseAnyDef } from './any';\n\nexport type JsonSchema7UnknownType = JsonSchema7AnyType;\n\nexport function parseUnknownDef(): JsonSchema7UnknownType {\n  return parseAnyDef();\n}\n", "import { ZodReadonlyDef } from 'zod/v3';\nimport { parseDef } from '../parse-def';\nimport { Refs } from '../refs';\n\nexport const parseReadonlyDef = (def: ZodReadonlyDef<any>, refs: Refs) => {\n  return parseDef(def.innerType._def, refs);\n};\n", "import { ZodTypeDef } from 'zod/v3';\nimport { Refs, Seen } from './refs';\nimport { ignoreOverride } from './options';\nimport { JsonSchema7Type } from './parse-types';\nimport { selectParser } from './select-parser';\nimport { getRelativePath } from './get-relative-path';\nimport { parseAnyDef } from './parsers/any';\n\nexport function parseDef(\n  def: ZodTypeDef,\n  refs: Refs,\n  forceResolution = false, // Forces a new schema to be instantiated even though its def has been seen. Used for improving refs in definitions. See https://github.com/StefanTerdell/zod-to-json-schema/pull/61.\n): JsonSchema7Type | undefined {\n  const seenItem = refs.seen.get(def);\n\n  if (refs.override) {\n    const overrideResult = refs.override?.(\n      def,\n      refs,\n      seenItem,\n      forceResolution,\n    );\n\n    if (overrideResult !== ignoreOverride) {\n      return overrideResult;\n    }\n  }\n\n  if (seenItem && !forceResolution) {\n    const seenSchema = get$ref(seenItem, refs);\n\n    if (seenSchema !== undefined) {\n      return seenSchema;\n    }\n  }\n\n  const newItem: Seen = { def, path: refs.currentPath, jsonSchema: undefined };\n\n  refs.seen.set(def, newItem);\n\n  const jsonSchemaOrGetter = selectParser(def, (def as any).typeName, refs);\n\n  // If the return was a function, then the inner definition needs to be extracted before a call to parseDef (recursive)\n  const jsonSchema =\n    typeof jsonSchemaOrGetter === 'function'\n      ? parseDef(jsonSchemaOrGetter(), refs)\n      : jsonSchemaOrGetter;\n\n  if (jsonSchema) {\n    addMeta(def, refs, jsonSchema);\n  }\n\n  if (refs.postProcess) {\n    const postProcessResult = refs.postProcess(jsonSchema, def, refs);\n\n    newItem.jsonSchema = jsonSchema;\n\n    return postProcessResult;\n  }\n\n  newItem.jsonSchema = jsonSchema;\n\n  return jsonSchema;\n}\n\nconst get$ref = (\n  item: Seen,\n  refs: Refs,\n):\n  | {\n      $ref: string;\n    }\n  | {}\n  | undefined => {\n  switch (refs.$refStrategy) {\n    case 'root':\n      return { $ref: item.path.join('/') };\n    case 'relative':\n      return { $ref: getRelativePath(refs.currentPath, item.path) };\n    case 'none':\n    case 'seen': {\n      if (\n        item.path.length < refs.currentPath.length &&\n        item.path.every((value, index) => refs.currentPath[index] === value)\n      ) {\n        console.warn(\n          `Recursive reference detected at ${refs.currentPath.join(\n            '/',\n          )}! Defaulting to any`,\n        );\n\n        return parseAnyDef();\n      }\n\n      return refs.$refStrategy === 'seen' ? parseAnyDef() : undefined;\n    }\n  }\n};\n\nconst addMeta = (\n  def: ZodTypeDef,\n  refs: Refs,\n  jsonSchema: JsonSchema7Type,\n): JsonSchema7Type => {\n  if (def.description) {\n    jsonSchema.description = def.description;\n  }\n  return jsonSchema;\n};\n", "import { ZodTypeDef } from 'zod/v3';\nimport { getDefaultOptions, Options } from './options';\nimport { JsonSchema7Type } from './parse-types';\n\nexport type Refs = {\n  seen: Map<ZodTypeDef, Seen>;\n  currentPath: string[];\n  propertyPath: string[] | undefined;\n} & Options;\n\nexport type Seen = {\n  def: ZodTypeDef;\n  path: string[];\n  jsonSchema: JsonSchema7Type | undefined;\n};\n\nexport const getRefs = (options?: string | Partial<Options>): Refs => {\n  const _options = getDefaultOptions(options);\n  const currentPath =\n    _options.name !== undefined\n      ? [..._options.basePath, _options.definitionPath, _options.name]\n      : _options.basePath;\n  return {\n    ..._options,\n    currentPath: currentPath,\n    propertyPath: undefined,\n    seen: new Map(\n      Object.entries(_options.definitions).map(([name, def]) => [\n        def._def,\n        {\n          def: def._def,\n          path: [..._options.basePath, _options.definitionPath, name],\n          // Resolution of references will be forced even though seen, so it's ok that the schema is undefined here for now.\n          jsonSchema: undefined,\n        },\n      ]),\n    ),\n  };\n};\n", "import { ZodSchema } from 'zod/v3';\nimport { Options } from './options';\nimport { parseDef } from './parse-def';\nimport { JsonSchema7Type } from './parse-types';\nimport { getRefs } from './refs';\nimport { parseAnyDef } from './parsers/any';\n\nconst zodToJsonSchema = (\n  schema: ZodSchema<any>,\n  options?: Partial<Options> | string,\n): JsonSchema7Type & {\n  $schema?: string;\n  definitions?: {\n    [key: string]: JsonSchema7Type;\n  };\n} => {\n  const refs = getRefs(options);\n\n  let definitions =\n    typeof options === 'object' && options.definitions\n      ? Object.entries(options.definitions).reduce(\n          (acc: { [key: string]: JsonSchema7Type }, [name, schema]) => ({\n            ...acc,\n            [name]:\n              parseDef(\n                schema._def,\n                {\n                  ...refs,\n                  currentPath: [...refs.basePath, refs.definitionPath, name],\n                },\n                true,\n              ) ?? parseAnyDef(),\n          }),\n          {},\n        )\n      : undefined;\n\n  const name =\n    typeof options === 'string'\n      ? options\n      : options?.nameStrategy === 'title'\n        ? undefined\n        : options?.name;\n\n  const main =\n    parseDef(\n      schema._def,\n      name === undefined\n        ? refs\n        : {\n            ...refs,\n            currentPath: [...refs.basePath, refs.definitionPath, name],\n          },\n      false,\n    ) ?? (parseAnyDef() as JsonSchema7Type);\n\n  const title =\n    typeof options === 'object' &&\n    options.name !== undefined &&\n    options.nameStrategy === 'title'\n      ? options.name\n      : undefined;\n\n  if (title !== undefined) {\n    main.title = title;\n  }\n\n  const combined: ReturnType<typeof zodToJsonSchema> =\n    name === undefined\n      ? definitions\n        ? {\n            ...main,\n            [refs.definitionPath]: definitions,\n          }\n        : main\n      : {\n          $ref: [\n            ...(refs.$refStrategy === 'relative' ? [] : refs.basePath),\n            refs.definitionPath,\n            name,\n          ].join('/'),\n          [refs.definitionPath]: {\n            ...definitions,\n            [name]: main,\n          },\n        };\n\n  combined.$schema = 'http://json-schema.org/draft-07/schema#';\n\n  return combined;\n};\n\nexport { zodToJsonSchema };\n", "export * from './get-relative-path';\nexport * from './options';\nexport * from './parse-def';\nexport * from './parse-types';\nexport * from './parsers/any';\nexport * from './parsers/array';\nexport * from './parsers/bigint';\nexport * from './parsers/boolean';\nexport * from './parsers/branded';\nexport * from './parsers/catch';\nexport * from './parsers/date';\nexport * from './parsers/default';\nexport * from './parsers/effects';\nexport * from './parsers/enum';\nexport * from './parsers/intersection';\nexport * from './parsers/literal';\nexport * from './parsers/map';\nexport * from './parsers/native-enum';\nexport * from './parsers/never';\nexport * from './parsers/null';\nexport * from './parsers/nullable';\nexport * from './parsers/number';\nexport * from './parsers/object';\nexport * from './parsers/optional';\nexport * from './parsers/pipeline';\nexport * from './parsers/promise';\nexport * from './parsers/readonly';\nexport * from './parsers/record';\nexport * from './parsers/set';\nexport * from './parsers/string';\nexport * from './parsers/tuple';\nexport * from './parsers/undefined';\nexport * from './parsers/union';\nexport * from './parsers/unknown';\nexport * from './refs';\nexport * from './select-parser';\nexport * from './zod-to-json-schema';\nimport { zodToJsonSchema } from './zod-to-json-schema';\nexport default zodToJsonSchema;\n", "import { JSONSchema7 } from '@ai-sdk/provider';\nimport * as z3 from 'zod/v3';\nimport * as z4 from 'zod/v4';\nimport { Validator, validatorSymbol, type ValidationResult } from './validator';\nimport { zodSchema } from './zod-schema';\n\n/**\n * Used to mark schemas so we can support both Zod and custom schemas.\n */\nconst schemaSymbol = Symbol.for('vercel.ai.schema');\n\nexport type Schema<OBJECT = unknown> = Validator<OBJECT> & {\n  /**\n   * Used to mark schemas so we can support both Zod and custom schemas.\n   */\n  [schemaSymbol]: true;\n\n  /**\n   * Schema type for inference.\n   */\n  _type: OBJECT;\n\n  /**\n   * The JSON Schema for the schema. It is passed to the providers.\n   */\n  readonly jsonSchema: JSONSchema7;\n};\n\n/**\n * Creates a schema with deferred creation.\n * This is important to reduce the startup time of the library\n * and to avoid initializing unused validators.\n *\n * @param createValidator A function that creates a schema.\n * @returns A function that returns a schema.\n */\nexport function lazySchema<SCHEMA>(\n  createSchema: () => Schema<SCHEMA>,\n): LazySchema<SCHEMA> {\n  // cache the validator to avoid initializing it multiple times\n  let schema: Schema<SCHEMA> | undefined;\n  return () => {\n    if (schema == null) {\n      schema = createSchema();\n    }\n    return schema;\n  };\n}\n\nexport type LazySchema<SCHEMA> = () => Schema<SCHEMA>;\n\n// Note: Zod types here exactly match the types in zod-schema.ts\n// to prevent type errors when using zod schemas with flexible schemas.\nexport type FlexibleSchema<SCHEMA> =\n  | z4.core.$ZodType<SCHEMA, any>\n  | z3.Schema<SCHEMA, z3.ZodTypeDef, any>\n  | Schema<SCHEMA>\n  | LazySchema<SCHEMA>;\n\nexport type InferSchema<SCHEMA> = SCHEMA extends z3.Schema\n  ? z3.infer<SCHEMA>\n  : SCHEMA extends z4.core.$ZodType\n    ? z4.infer<SCHEMA>\n    : SCHEMA extends LazySchema<infer T>\n      ? T\n      : SCHEMA extends Schema<infer T>\n        ? T\n        : never;\n\n/**\n * Create a schema using a JSON Schema.\n *\n * @param jsonSchema The JSON Schema for the schema.\n * @param options.validate Optional. A validation function for the schema.\n */\nexport function jsonSchema<OBJECT = unknown>(\n  jsonSchema: JSONSchema7 | (() => JSONSchema7),\n  {\n    validate,\n  }: {\n    validate?: (\n      value: unknown,\n    ) => ValidationResult<OBJECT> | PromiseLike<ValidationResult<OBJECT>>;\n  } = {},\n): Schema<OBJECT> {\n  return {\n    [schemaSymbol]: true,\n    _type: undefined as OBJECT, // should never be used directly\n    [validatorSymbol]: true,\n    get jsonSchema() {\n      if (typeof jsonSchema === 'function') {\n        jsonSchema = jsonSchema(); // cache the function results\n      }\n      return jsonSchema;\n    },\n    validate,\n  };\n}\n\nfunction isSchema(value: unknown): value is Schema {\n  return (\n    typeof value === 'object' &&\n    value !== null &&\n    schemaSymbol in value &&\n    value[schemaSymbol] === true &&\n    'jsonSchema' in value &&\n    'validate' in value\n  );\n}\n\nexport function asSchema<OBJECT>(\n  schema: FlexibleSchema<OBJECT> | undefined,\n): Schema<OBJECT> {\n  return schema == null\n    ? jsonSchema({\n        properties: {},\n        additionalProperties: false,\n      })\n    : isSchema(schema)\n      ? schema\n      : typeof schema === 'function'\n        ? schema()\n        : zodSchema(schema);\n}\n", "// btoa and atob need to be invoked as a function call, not as a method call.\n// Otherwise CloudFlare will throw a\n// \"TypeError: Illegal invocation: function called with incorrect this reference\"\nconst { btoa, atob } = globalThis;\n\nexport function convertBase64ToUint8Array(base64String: string) {\n  const base64Url = base64String.replace(/-/g, '+').replace(/_/g, '/');\n  const latin1string = atob(base64Url);\n  return Uint8Array.from(latin1string, byte => byte.codePointAt(0)!);\n}\n\nexport function convertUint8ArrayToBase64(array: Uint8Array): string {\n  let latin1string = '';\n\n  // Note: regular for loop to support older JavaScript versions that\n  // do not support for..of on Uint8Array\n  for (let i = 0; i < array.length; i++) {\n    latin1string += String.fromCodePoint(array[i]);\n  }\n\n  return btoa(latin1string);\n}\n\nexport function convertToBase64(value: string | Uint8Array): string {\n  return value instanceof Uint8Array ? convertUint8ArrayToBase64(value) : value;\n}\n", "export function withoutTrailingSlash(url: string | undefined) {\n  return url?.replace(/\\/$/, '');\n}\n", "export function isAsyncIterable<T = any>(obj: any): obj is AsyncIterable<T> {\n  return obj != null && typeof obj[Symbol.asyncIterator] === 'function';\n}\n", "import { Tool, ToolCallOptions, ToolExecuteFunction } from './tool';\nimport { isAsyncIterable } from '../is-async-iterable';\n\nexport async function* executeTool<INPUT, OUTPUT>({\n  execute,\n  input,\n  options,\n}: {\n  execute: ToolExecuteFunction<INPUT, OUTPUT>;\n  input: INPUT;\n  options: ToolCallOptions;\n}): AsyncGenerator<\n  { type: 'preliminary'; output: OUTPUT } | { type: 'final'; output: OUTPUT }\n> {\n  const result = execute(input, options);\n\n  if (isAsyncIterable(result)) {\n    let lastOutput: OUTPUT | undefined;\n    for await (const output of result) {\n      lastOutput = output;\n      yield { type: 'preliminary', output };\n    }\n    yield { type: 'final', output: lastOutput! };\n  } else {\n    yield { type: 'final', output: await result };\n  }\n}\n", "export * from './combine-headers';\nexport { convertAsyncIteratorToReadableStream } from './convert-async-iterator-to-readable-stream';\nexport * from './delay';\nexport * from './extract-response-headers';\nexport * from './fetch-function';\nexport { createIdGenerator, generateId, type IdGenerator } from './generate-id';\nexport * from './get-error-message';\nexport * from './get-from-api';\nexport { getRuntimeEnvironmentUserAgent } from './get-runtime-environment-user-agent';\nexport { injectJsonInstructionIntoMessages } from './inject-json-instruction';\nexport * from './is-abort-error';\nexport { isUrlSupported } from './is-url-supported';\nexport * from './load-api-key';\nexport { loadOptionalSetting } from './load-optional-setting';\nexport { loadSetting } from './load-setting';\nexport { mediaTypeToExtension } from './media-type-to-extension';\nexport { normalizeHeaders } from './normalize-headers';\nexport * from './parse-json';\nexport { parseJsonEventStream } from './parse-json-event-stream';\nexport { parseProviderOptions } from './parse-provider-options';\nexport * from './post-to-api';\nexport {\n  createProviderDefinedToolFactory,\n  createProviderDefinedToolFactoryWithOutputSchema,\n  type ProviderDefinedToolFactory,\n  type ProviderDefinedToolFactoryWithOutputSchema,\n} from './provider-defined-tool-factory';\nexport * from './remove-undefined-entries';\nexport * from './resolve';\nexport * from './response-handler';\nexport {\n  asSchema,\n  jsonSchema,\n  lazySchema,\n  type FlexibleSchema,\n  type InferSchema,\n  type LazySchema,\n  type Schema,\n} from './schema';\nexport * from './uint8-utils';\nexport * from './validate-types';\nexport {\n  asValidator,\n  isValidator,\n  lazyValidator,\n  standardSchemaValidator,\n  validator,\n  type FlexibleValidator,\n  type InferValidator,\n  type LazyValidator,\n  type ValidationResult,\n  type Validator,\n} from './validator';\nexport { VERSION } from './version';\nexport { withUserAgentSuffix } from './with-user-agent-suffix';\nexport * from './without-trailing-slash';\nexport { zodSchema } from './zod-schema';\n\n// folder re-exports\nexport * from './types';\n\n// external re-exports\nexport * from '@standard-schema/spec';\nexport {\n  EventSourceParserStream,\n  type EventSourceMessage,\n} from 'eventsource-parser/stream';\n", "import { NoSuchModelError } from '@ai-sdk/provider';\nimport {\n  loadOptionalSetting,\n  withoutTrailingSlash,\n  type FetchFunction,\n} from '@ai-sdk/provider-utils';\nimport { asGatewayError, GatewayAuthenticationError } from './errors';\nimport {\n  GATEWAY_AUTH_METHOD_HEADER,\n  parseAuthMethod,\n} from './errors/parse-auth-method';\nimport {\n  GatewayFetchMetadata,\n  type GatewayFetchMetadataResponse,\n  type GatewayCreditsResponse,\n} from './gateway-fetch-metadata';\nimport { GatewayLanguageModel } from './gateway-language-model';\nimport { GatewayEmbeddingModel } from './gateway-embedding-model';\nimport type { GatewayEmbeddingModelId } from './gateway-embedding-model-settings';\nimport { getVercelOidcToken, getVercelRequestId } from './vercel-environment';\nimport type { GatewayModelId } from './gateway-language-model-settings';\nimport type {\n  LanguageModelV2,\n  EmbeddingModelV2,\n  ProviderV2,\n} from '@ai-sdk/provider';\nimport { withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { VERSION } from './version';\n\nexport interface GatewayProvider extends ProviderV2 {\n  (modelId: GatewayModelId): LanguageModelV2;\n\n  /**\nCreates a model for text generation.\n*/\n  languageModel(modelId: GatewayModelId): LanguageModelV2;\n\n  /**\nReturns available providers and models for use with the remote provider.\n */\n  getAvailableModels(): Promise<GatewayFetchMetadataResponse>;\n\n  /**\nReturns credit information for the authenticated user.\n */\n  getCredits(): Promise<GatewayCreditsResponse>;\n\n  /**\nCreates a model for generating text embeddings.\n*/\n  textEmbeddingModel(\n    modelId: GatewayEmbeddingModelId,\n  ): EmbeddingModelV2<string>;\n}\n\nexport interface GatewayProviderSettings {\n  /**\nThe base URL prefix for API calls. Defaults to `https://ai-gateway.vercel.sh/v1/ai`.\n   */\n  baseURL?: string;\n\n  /**\nAPI key that is being sent using the `Authorization` header.\n   */\n  apiKey?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string>;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n\n  /**\nHow frequently to refresh the metadata cache in milliseconds.\n   */\n  metadataCacheRefreshMillis?: number;\n\n  /**\n   * @internal For testing purposes only\n   */\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nconst AI_GATEWAY_PROTOCOL_VERSION = '0.0.1';\n\n/**\nCreate a remote provider instance.\n */\nexport function createGatewayProvider(\n  options: GatewayProviderSettings = {},\n): GatewayProvider {\n  let pendingMetadata: Promise<GatewayFetchMetadataResponse> | null = null;\n  let metadataCache: GatewayFetchMetadataResponse | null = null;\n  const cacheRefreshMillis =\n    options.metadataCacheRefreshMillis ?? 1000 * 60 * 5;\n  let lastFetchTime = 0;\n\n  const baseURL =\n    withoutTrailingSlash(options.baseURL) ??\n    'https://ai-gateway.vercel.sh/v1/ai';\n\n  const getHeaders = async () => {\n    const auth = await getGatewayAuthToken(options);\n    if (auth) {\n      return withUserAgentSuffix(\n        {\n          Authorization: `Bearer ${auth.token}`,\n          'ai-gateway-protocol-version': AI_GATEWAY_PROTOCOL_VERSION,\n          [GATEWAY_AUTH_METHOD_HEADER]: auth.authMethod,\n          ...options.headers,\n        },\n        `ai-sdk/gateway/${VERSION}`,\n      );\n    }\n\n    throw GatewayAuthenticationError.createContextualError({\n      apiKeyProvided: false,\n      oidcTokenProvided: false,\n      statusCode: 401,\n    });\n  };\n\n  const createO11yHeaders = () => {\n    const deploymentId = loadOptionalSetting({\n      settingValue: undefined,\n      environmentVariableName: 'VERCEL_DEPLOYMENT_ID',\n    });\n    const environment = loadOptionalSetting({\n      settingValue: undefined,\n      environmentVariableName: 'VERCEL_ENV',\n    });\n    const region = loadOptionalSetting({\n      settingValue: undefined,\n      environmentVariableName: 'VERCEL_REGION',\n    });\n\n    return async () => {\n      const requestId = await getVercelRequestId();\n      return {\n        ...(deploymentId && { 'ai-o11y-deployment-id': deploymentId }),\n        ...(environment && { 'ai-o11y-environment': environment }),\n        ...(region && { 'ai-o11y-region': region }),\n        ...(requestId && { 'ai-o11y-request-id': requestId }),\n      };\n    };\n  };\n\n  const createLanguageModel = (modelId: GatewayModelId) => {\n    return new GatewayLanguageModel(modelId, {\n      provider: 'gateway',\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n      o11yHeaders: createO11yHeaders(),\n    });\n  };\n\n  const getAvailableModels = async () => {\n    const now = options._internal?.currentDate?.().getTime() ?? Date.now();\n    if (!pendingMetadata || now - lastFetchTime > cacheRefreshMillis) {\n      lastFetchTime = now;\n\n      pendingMetadata = new GatewayFetchMetadata({\n        baseURL,\n        headers: getHeaders,\n        fetch: options.fetch,\n      })\n        .getAvailableModels()\n        .then(metadata => {\n          metadataCache = metadata;\n          return metadata;\n        })\n        .catch(async (error: unknown) => {\n          throw await asGatewayError(\n            error,\n            await parseAuthMethod(await getHeaders()),\n          );\n        });\n    }\n\n    return metadataCache ? Promise.resolve(metadataCache) : pendingMetadata;\n  };\n\n  const getCredits = async () => {\n    return new GatewayFetchMetadata({\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n    })\n      .getCredits()\n      .catch(async (error: unknown) => {\n        throw await asGatewayError(\n          error,\n          await parseAuthMethod(await getHeaders()),\n        );\n      });\n  };\n\n  const provider = function (modelId: GatewayModelId) {\n    if (new.target) {\n      throw new Error(\n        'The Gateway Provider model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createLanguageModel(modelId);\n  };\n\n  provider.getAvailableModels = getAvailableModels;\n  provider.getCredits = getCredits;\n  provider.imageModel = (modelId: string) => {\n    throw new NoSuchModelError({ modelId, modelType: 'imageModel' });\n  };\n  provider.languageModel = createLanguageModel;\n  provider.textEmbeddingModel = (modelId: GatewayEmbeddingModelId) => {\n    return new GatewayEmbeddingModel(modelId, {\n      provider: 'gateway',\n      baseURL,\n      headers: getHeaders,\n      fetch: options.fetch,\n      o11yHeaders: createO11yHeaders(),\n    });\n  };\n\n  return provider;\n}\n\nexport const gateway = createGatewayProvider();\n\nexport async function getGatewayAuthToken(\n  options: GatewayProviderSettings,\n): Promise<{\n  token: string;\n  authMethod: 'api-key' | 'oidc';\n} | null> {\n  const apiKey = loadOptionalSetting({\n    settingValue: options.apiKey,\n    environmentVariableName: 'AI_GATEWAY_API_KEY',\n  });\n\n  if (apiKey) {\n    return {\n      token: apiKey,\n      authMethod: 'api-key',\n    };\n  }\n\n  try {\n    const oidcToken = await getVercelOidcToken();\n    return {\n      token: oidcToken,\n      authMethod: 'oidc',\n    };\n  } catch {\n    return null;\n  }\n}\n", "import { APICallError } from '@ai-sdk/provider';\nimport { extractApiCallResponse, GatewayError } from '.';\nimport { createGatewayErrorFromResponse } from './create-gateway-error';\n\nexport function asGatewayError(\n  error: unknown,\n  authMethod?: 'api-key' | 'oidc',\n) {\n  if (GatewayError.isInstance(error)) {\n    return error;\n  }\n\n  if (APICallError.isInstance(error)) {\n    return createGatewayErrorFromResponse({\n      response: extractApiCallResponse(error),\n      statusCode: error.statusCode ?? 500,\n      defaultMessage: 'Gateway request failed',\n      cause: error,\n      authMethod,\n    });\n  }\n\n  return createGatewayErrorFromResponse({\n    response: {},\n    statusCode: 500,\n    defaultMessage:\n      error instanceof Error\n        ? `Gateway request failed: ${error.message}`\n        : 'Unknown Gateway error',\n    cause: error,\n    authMethod,\n  });\n}\n", "import { z } from 'zod/v4';\nimport type { GatewayError } from './gateway-error';\nimport { GatewayAuthenticationError } from './gateway-authentication-error';\nimport { GatewayInvalidRequestError } from './gateway-invalid-request-error';\nimport { GatewayRateLimitError } from './gateway-rate-limit-error';\nimport {\n  GatewayModelNotFoundError,\n  modelNotFoundParamSchema,\n} from './gateway-model-not-found-error';\nimport { GatewayInternalServerError } from './gateway-internal-server-error';\nimport { GatewayResponseError } from './gateway-response-error';\nimport {\n  InferValidator,\n  lazyValidator,\n  safeValidateTypes,\n  validateTypes,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\n\nexport async function createGatewayErrorFromResponse({\n  response,\n  statusCode,\n  defaultMessage = 'Gateway request failed',\n  cause,\n  authMethod,\n}: {\n  response: unknown;\n  statusCode: number;\n  defaultMessage?: string;\n  cause?: unknown;\n  authMethod?: 'api-key' | 'oidc';\n}): Promise<GatewayError> {\n  const parseResult = await safeValidateTypes({\n    value: response,\n    schema: gatewayErrorResponseSchema,\n  });\n\n  if (!parseResult.success) {\n    return new GatewayResponseError({\n      message: `Invalid error response format: ${defaultMessage}`,\n      statusCode,\n      response,\n      validationError: parseResult.error,\n      cause,\n    });\n  }\n\n  const validatedResponse: GatewayErrorResponse = parseResult.value;\n  const errorType = validatedResponse.error.type;\n  const message = validatedResponse.error.message;\n\n  switch (errorType) {\n    case 'authentication_error':\n      return GatewayAuthenticationError.createContextualError({\n        apiKeyProvided: authMethod === 'api-key',\n        oidcTokenProvided: authMethod === 'oidc',\n        statusCode,\n        cause,\n      });\n    case 'invalid_request_error':\n      return new GatewayInvalidRequestError({ message, statusCode, cause });\n    case 'rate_limit_exceeded':\n      return new GatewayRateLimitError({ message, statusCode, cause });\n    case 'model_not_found': {\n      const modelResult = await safeValidateTypes({\n        value: validatedResponse.error.param,\n        schema: modelNotFoundParamSchema,\n      });\n\n      return new GatewayModelNotFoundError({\n        message,\n        statusCode,\n        modelId: modelResult.success ? modelResult.value.modelId : undefined,\n        cause,\n      });\n    }\n    case 'internal_server_error':\n      return new GatewayInternalServerError({ message, statusCode, cause });\n    default:\n      return new GatewayInternalServerError({ message, statusCode, cause });\n  }\n}\n\nconst gatewayErrorResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      error: z.object({\n        message: z.string(),\n        type: z.string().nullish(),\n        param: z.unknown().nullish(),\n        code: z.union([z.string(), z.number()]).nullish(),\n      }),\n    }),\n  ),\n);\n\nexport type GatewayErrorResponse = InferValidator<\n  typeof gatewayErrorResponseSchema\n>;\n", "const marker = 'vercel.ai.gateway.error';\nconst symbol = Symbol.for(marker);\n\nexport abstract class GatewayError extends Error {\n  private readonly [symbol] = true; // used in isInstance\n\n  abstract readonly name: string;\n  abstract readonly type: string;\n  readonly statusCode: number;\n  readonly cause?: unknown;\n\n  constructor({\n    message,\n    statusCode = 500,\n    cause,\n  }: {\n    message: string;\n    statusCode?: number;\n    cause?: unknown;\n  }) {\n    super(message);\n    this.statusCode = statusCode;\n    this.cause = cause;\n  }\n\n  /**\n   * Checks if the given error is a Gateway Error.\n   * @param {unknown} error - The error to check.\n   * @returns {boolean} True if the error is a Gateway Error, false otherwise.\n   */\n  static isInstance(error: unknown): error is GatewayError {\n    return GatewayError.hasMarker(error);\n  }\n\n  static hasMarker(error: unknown): error is GatewayError {\n    return (\n      typeof error === 'object' &&\n      error !== null &&\n      symbol in error &&\n      (error as any)[symbol] === true\n    );\n  }\n}\n", "import { GatewayError } from './gateway-error';\n\nconst name = 'GatewayAuthenticationError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Authentication failed - invalid API key or OIDC token\n */\nexport class GatewayAuthenticationError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'authentication_error';\n\n  constructor({\n    message = 'Authentication failed',\n    statusCode = 401,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n  }\n\n  static isInstance(error: unknown): error is GatewayAuthenticationError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n\n  /**\n   * Creates a contextual error message when authentication fails\n   */\n  static createContextualError({\n    apiKeyProvided,\n    oidcTokenProvided,\n    message = 'Authentication failed',\n    statusCode = 401,\n    cause,\n  }: {\n    apiKeyProvided: boolean;\n    oidcTokenProvided: boolean;\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  }): GatewayAuthenticationError {\n    let contextualMessage: string;\n\n    if (apiKeyProvided) {\n      contextualMessage = `AI Gateway authentication failed: Invalid API key.\n\nCreate a new API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys\n\nProvide via 'apiKey' option or 'AI_GATEWAY_API_KEY' environment variable.`;\n    } else if (oidcTokenProvided) {\n      contextualMessage = `AI Gateway authentication failed: Invalid OIDC token.\n\nRun 'npx vercel link' to link your project, then 'vc env pull' to fetch the token.\n\nAlternatively, use an API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys`;\n    } else {\n      contextualMessage = `AI Gateway authentication failed: No authentication provided.\n\nOption 1 - API key:\nCreate an API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys\nProvide via 'apiKey' option or 'AI_GATEWAY_API_KEY' environment variable.\n\nOption 2 - OIDC token:\nRun 'npx vercel link' to link your project, then 'vc env pull' to fetch the token.`;\n    }\n\n    return new GatewayAuthenticationError({\n      message: contextualMessage,\n      statusCode,\n      cause,\n    });\n  }\n}\n", "import { GatewayError } from './gateway-error';\n\nconst name = 'GatewayInvalidRequestError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Invalid request - missing headers, malformed data, etc.\n */\nexport class GatewayInvalidRequestError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'invalid_request_error';\n\n  constructor({\n    message = 'Invalid request',\n    statusCode = 400,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n  }\n\n  static isInstance(error: unknown): error is GatewayInvalidRequestError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n", "import { GatewayError } from './gateway-error';\n\nconst name = 'GatewayRateLimitError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Rate limit exceeded.\n */\nexport class GatewayRateLimitError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'rate_limit_exceeded';\n\n  constructor({\n    message = 'Rate limit exceeded',\n    statusCode = 429,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n  }\n\n  static isInstance(error: unknown): error is GatewayRateLimitError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n", "import { z } from 'zod/v4';\nimport { GatewayError } from './gateway-error';\nimport { lazyValidator, zodSchema } from '@ai-sdk/provider-utils';\n\nconst name = 'GatewayModelNotFoundError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport const modelNotFoundParamSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      modelId: z.string(),\n    }),\n  ),\n);\n\n/**\n * Model not found or not available\n */\nexport class GatewayModelNotFoundError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'model_not_found';\n  readonly modelId?: string;\n\n  constructor({\n    message = 'Model not found',\n    statusCode = 404,\n    modelId,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    modelId?: string;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n    this.modelId = modelId;\n  }\n\n  static isInstance(error: unknown): error is GatewayModelNotFoundError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n", "import { GatewayError } from './gateway-error';\n\nconst name = 'GatewayInternalServerError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Internal server error from the Gateway\n */\nexport class GatewayInternalServerError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'internal_server_error';\n\n  constructor({\n    message = 'Internal server error',\n    statusCode = 500,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n  }\n\n  static isInstance(error: unknown): error is GatewayInternalServerError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n", "import { TypeValidationError } from '@ai-sdk/provider';\nimport { GatewayError } from './gateway-error';\n\nconst name = 'GatewayResponseError';\nconst marker = `vercel.ai.gateway.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\n * Gateway response parsing error\n */\nexport class GatewayResponseError extends GatewayError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly name = name;\n  readonly type = 'response_error';\n  readonly response?: unknown;\n  readonly validationError?: TypeValidationError;\n\n  constructor({\n    message = 'Invalid response from Gateway',\n    statusCode = 502,\n    response,\n    validationError,\n    cause,\n  }: {\n    message?: string;\n    statusCode?: number;\n    response?: unknown;\n    validationError?: TypeValidationError;\n    cause?: unknown;\n  } = {}) {\n    super({ message, statusCode, cause });\n    this.response = response;\n    this.validationError = validationError;\n  }\n\n  static isInstance(error: unknown): error is GatewayResponseError {\n    return GatewayError.hasMarker(error) && symbol in error;\n  }\n}\n", "import type { APICallError } from '@ai-sdk/provider';\n\nexport function extractApiCallResponse(error: APICallError): unknown {\n  if (error.data !== undefined) {\n    return error.data;\n  }\n  if (error.responseBody != null) {\n    try {\n      return JSON.parse(error.responseBody);\n    } catch {\n      return error.responseBody;\n    }\n  }\n  return {};\n}\n", "import { z } from 'zod/v4';\nimport {\n  lazyValidator,\n  safeValidateTypes,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\n\nexport const GATEWAY_AUTH_METHOD_HEADER = 'ai-gateway-auth-method' as const;\n\nexport async function parseAuthMethod(\n  headers: Record<string, string | undefined>,\n) {\n  const result = await safeValidateTypes({\n    value: headers[GATEWAY_AUTH_METHOD_HEADER],\n    schema: gatewayAuthMethodSchema,\n  });\n\n  return result.success ? result.value : undefined;\n}\n\nconst gatewayAuthMethodSchema = lazyValidator(() =>\n  zodSchema(z.union([z.literal('api-key'), z.literal('oidc')])),\n);\n", "import {\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  getFromApi,\n  lazyValidator,\n  resolve,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { asGatewayError } from './errors';\nimport type { GatewayConfig } from './gateway-config';\nimport type { GatewayLanguageModelEntry } from './gateway-model-entry';\n\ntype GatewayFetchMetadataConfig = GatewayConfig;\n\nexport interface GatewayFetchMetadataResponse {\n  models: GatewayLanguageModelEntry[];\n}\n\nexport interface GatewayCreditsResponse {\n  /** The remaining gateway credit balance available for API usage */\n  balance: string;\n  /** The total amount of gateway credits that have been consumed */\n  totalUsed: string;\n}\n\nexport class GatewayFetchMetadata {\n  constructor(private readonly config: GatewayFetchMetadataConfig) {}\n\n  async getAvailableModels(): Promise<GatewayFetchMetadataResponse> {\n    try {\n      const { value } = await getFromApi({\n        url: `${this.config.baseURL}/config`,\n        headers: await resolve(this.config.headers()),\n        successfulResponseHandler: createJsonResponseHandler(\n          gatewayAvailableModelsResponseSchema,\n        ),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        fetch: this.config.fetch,\n      });\n\n      return value;\n    } catch (error) {\n      throw await asGatewayError(error);\n    }\n  }\n\n  async getCredits(): Promise<GatewayCreditsResponse> {\n    try {\n      const baseUrl = new URL(this.config.baseURL);\n\n      const { value } = await getFromApi({\n        url: `${baseUrl.origin}/v1/credits`,\n        headers: await resolve(this.config.headers()),\n        successfulResponseHandler: createJsonResponseHandler(\n          gatewayCreditsResponseSchema,\n        ),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        fetch: this.config.fetch,\n      });\n\n      return value;\n    } catch (error) {\n      throw await asGatewayError(error);\n    }\n  }\n}\n\nconst gatewayAvailableModelsResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      models: z.array(\n        z.object({\n          id: z.string(),\n          name: z.string(),\n          description: z.string().nullish(),\n          pricing: z\n            .object({\n              input: z.string(),\n              output: z.string(),\n              input_cache_read: z.string().nullish(),\n              input_cache_write: z.string().nullish(),\n            })\n            .transform(\n              ({ input, output, input_cache_read, input_cache_write }) => ({\n                input,\n                output,\n                ...(input_cache_read\n                  ? { cachedInputTokens: input_cache_read }\n                  : {}),\n                ...(input_cache_write\n                  ? { cacheCreationInputTokens: input_cache_write }\n                  : {}),\n              }),\n            )\n            .nullish(),\n          specification: z.object({\n            specificationVersion: z.literal('v2'),\n            provider: z.string(),\n            modelId: z.string(),\n          }),\n          modelType: z.enum(['language', 'embedding', 'image']).nullish(),\n        }),\n      ),\n    }),\n  ),\n);\n\nconst gatewayCreditsResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z\n      .object({\n        balance: z.string(),\n        total_used: z.string(),\n      })\n      .transform(({ balance, total_used }) => ({\n        balance,\n        totalUsed: total_used,\n      })),\n  ),\n);\n", "import type {\n  LanguageModelV2,\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  LanguageModelV2FilePart,\n  LanguageModelV2StreamPart,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  postJsonToApi,\n  resolve,\n  type ParseResult,\n  type Resolvable,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport type { GatewayConfig } from './gateway-config';\nimport type { GatewayModelId } from './gateway-language-model-settings';\nimport { asGatewayError } from './errors';\nimport { parseAuthMethod } from './errors/parse-auth-method';\n\ntype GatewayChatConfig = GatewayConfig & {\n  provider: string;\n  o11yHeaders: Resolvable<Record<string, string>>;\n};\n\nexport class GatewayLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n  readonly supportedUrls = { '*/*': [/.*/] };\n\n  constructor(\n    readonly modelId: GatewayModelId,\n    private readonly config: GatewayChatConfig,\n  ) {}\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs(options: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const { abortSignal: _abortSignal, ...optionsWithoutSignal } = options;\n\n    return {\n      args: this.maybeEncodeFileParts(optionsWithoutSignal),\n      warnings: [],\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args, warnings } = await this.getArgs(options);\n    const { abortSignal } = options;\n\n    const resolvedHeaders = await resolve(this.config.headers());\n\n    try {\n      const {\n        responseHeaders,\n        value: responseBody,\n        rawValue: rawResponse,\n      } = await postJsonToApi({\n        url: this.getUrl(),\n        headers: combineHeaders(\n          resolvedHeaders,\n          options.headers,\n          this.getModelConfigHeaders(this.modelId, false),\n          await resolve(this.config.o11yHeaders),\n        ),\n        body: args,\n        successfulResponseHandler: createJsonResponseHandler(z.any()),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        ...(abortSignal && { abortSignal }),\n        fetch: this.config.fetch,\n      });\n\n      return {\n        ...responseBody,\n        request: { body: args },\n        response: { headers: responseHeaders, body: rawResponse },\n        warnings,\n      };\n    } catch (error) {\n      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));\n    }\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n    const { abortSignal } = options;\n\n    const resolvedHeaders = await resolve(this.config.headers());\n\n    try {\n      const { value: response, responseHeaders } = await postJsonToApi({\n        url: this.getUrl(),\n        headers: combineHeaders(\n          resolvedHeaders,\n          options.headers,\n          this.getModelConfigHeaders(this.modelId, true),\n          await resolve(this.config.o11yHeaders),\n        ),\n        body: args,\n        successfulResponseHandler: createEventSourceResponseHandler(z.any()),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        ...(abortSignal && { abortSignal }),\n        fetch: this.config.fetch,\n      });\n\n      return {\n        stream: response.pipeThrough(\n          new TransformStream<\n            ParseResult<LanguageModelV2StreamPart>,\n            LanguageModelV2StreamPart\n          >({\n            start(controller) {\n              if (warnings.length > 0) {\n                controller.enqueue({ type: 'stream-start', warnings });\n              }\n            },\n            transform(chunk, controller) {\n              if (chunk.success) {\n                const streamPart = chunk.value;\n\n                // Handle raw chunks: if this is a raw chunk from the gateway API,\n                // only emit it if includeRawChunks is true\n                if (streamPart.type === 'raw' && !options.includeRawChunks) {\n                  return; // Skip raw chunks if not requested\n                }\n\n                if (\n                  streamPart.type === 'response-metadata' &&\n                  streamPart.timestamp &&\n                  typeof streamPart.timestamp === 'string'\n                ) {\n                  streamPart.timestamp = new Date(streamPart.timestamp);\n                }\n\n                controller.enqueue(streamPart);\n              } else {\n                controller.error(\n                  (chunk as { success: false; error: unknown }).error,\n                );\n              }\n            },\n          }),\n        ),\n        request: { body: args },\n        response: { headers: responseHeaders },\n      };\n    } catch (error) {\n      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));\n    }\n  }\n\n  private isFilePart(part: unknown) {\n    return (\n      part && typeof part === 'object' && 'type' in part && part.type === 'file'\n    );\n  }\n\n  /**\n   * Encodes file parts in the prompt to base64. Mutates the passed options\n   * instance directly to avoid copying the file data.\n   * @param options - The options to encode.\n   * @returns The options with the file parts encoded.\n   */\n  private maybeEncodeFileParts(options: LanguageModelV2CallOptions) {\n    for (const message of options.prompt) {\n      for (const part of message.content) {\n        if (this.isFilePart(part)) {\n          const filePart = part as LanguageModelV2FilePart;\n          // If the file part is a URL it will get cleanly converted to a string.\n          // If it's a binary file attachment we convert it to a data url.\n          // In either case, server-side we should only ever see URLs as strings.\n          if (filePart.data instanceof Uint8Array) {\n            const buffer = Uint8Array.from(filePart.data);\n            const base64Data = Buffer.from(buffer).toString('base64');\n            filePart.data = new URL(\n              `data:${filePart.mediaType || 'application/octet-stream'};base64,${base64Data}`,\n            );\n          }\n        }\n      }\n    }\n    return options;\n  }\n\n  private getUrl() {\n    return `${this.config.baseURL}/language-model`;\n  }\n\n  private getModelConfigHeaders(modelId: string, streaming: boolean) {\n    return {\n      'ai-language-model-specification-version': '2',\n      'ai-language-model-id': modelId,\n      'ai-language-model-streaming': String(streaming),\n    };\n  }\n}\n", "import type {\n  EmbeddingModelV2,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  lazyValidator,\n  postJsonToApi,\n  resolve,\n  zodSchema,\n  type Resolvable,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { asGatewayError } from './errors';\nimport { parseAuthMethod } from './errors/parse-auth-method';\nimport type { GatewayConfig } from './gateway-config';\n\nexport class GatewayEmbeddingModel implements EmbeddingModelV2<string> {\n  readonly specificationVersion = 'v2';\n  readonly maxEmbeddingsPerCall = 2048;\n  readonly supportsParallelCalls = true;\n\n  constructor(\n    readonly modelId: string,\n    private readonly config: GatewayConfig & {\n      provider: string;\n      o11yHeaders: Resolvable<Record<string, string>>;\n    },\n  ) {}\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n    providerOptions,\n  }: Parameters<EmbeddingModelV2<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV2<string>['doEmbed']>>\n  > {\n    const resolvedHeaders = await resolve(this.config.headers());\n    try {\n      const {\n        responseHeaders,\n        value: responseBody,\n        rawValue,\n      } = await postJsonToApi({\n        url: this.getUrl(),\n        headers: combineHeaders(\n          resolvedHeaders,\n          headers ?? {},\n          this.getModelConfigHeaders(),\n          await resolve(this.config.o11yHeaders),\n        ),\n        body: {\n          input: values.length === 1 ? values[0] : values,\n          ...(providerOptions ? { providerOptions } : {}),\n        },\n        successfulResponseHandler: createJsonResponseHandler(\n          gatewayEmbeddingResponseSchema,\n        ),\n        failedResponseHandler: createJsonErrorResponseHandler({\n          errorSchema: z.any(),\n          errorToMessage: data => data,\n        }),\n        ...(abortSignal && { abortSignal }),\n        fetch: this.config.fetch,\n      });\n\n      return {\n        embeddings: responseBody.embeddings,\n        usage: responseBody.usage ?? undefined,\n        providerMetadata:\n          responseBody.providerMetadata as unknown as SharedV2ProviderMetadata,\n        response: { headers: responseHeaders, body: rawValue },\n      };\n    } catch (error) {\n      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));\n    }\n  }\n\n  private getUrl() {\n    return `${this.config.baseURL}/embedding-model`;\n  }\n\n  private getModelConfigHeaders() {\n    return {\n      'ai-embedding-model-specification-version': '2',\n      'ai-model-id': this.modelId,\n    };\n  }\n}\n\nconst gatewayEmbeddingResponseSchema = lazyValidator(() =>\n  zodSchema(\n    z.object({\n      embeddings: z.array(z.array(z.number())),\n      usage: z.object({ tokens: z.number() }).nullish(),\n      providerMetadata: z\n        .record(z.string(), z.record(z.string(), z.unknown()))\n        .optional(),\n    }),\n  ),\n);\n", "import { getContext } from '@vercel/oidc';\nexport { getVercelOidcToken } from '@vercel/oidc';\n\nexport async function getVercelRequestId(): Promise<string | undefined> {\n  return getContext().headers?.['x-vercel-id'];\n}\n", "// Version string of this package injected at build time.\ndeclare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n", "// re-exports:\nexport { gateway, createGateway } from '@ai-sdk/gateway';\nexport {\n  asSchema,\n  createIdGenerator,\n  dynamicTool,\n  generateId,\n  jsonSchema,\n  parseJsonEventStream,\n  tool,\n  zodSchema,\n  type IdGenerator,\n  type InferToolInput,\n  type InferToolOutput,\n  type Schema,\n  type Tool,\n  type ToolCallOptions,\n  type ToolExecuteFunction,\n} from '@ai-sdk/provider-utils';\n\n// directory exports\nexport * from './agent';\nexport * from './embed';\nexport * from './error';\nexport * from './generate-image';\nexport * from './generate-object';\nexport * from './generate-speech';\nexport * from './generate-text';\nexport * from './logger';\nexport * from './middleware';\nexport * from './prompt';\nexport * from './registry';\nexport * from './text-stream';\nexport * from './transcribe';\nexport * from './types';\nexport * from './ui';\nexport * from './ui-message-stream';\nexport * from './util';\n\n// telemetry types:\nexport type { TelemetrySettings } from './telemetry/telemetry-settings';\n\n// import globals\nimport './global';\n", "import {\n  LanguageModelV2,\n  LanguageModelV2Content,\n  LanguageModelV2ToolCall,\n} from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  executeTool,\n  getErrorMessage,\n  IdGenerator,\n  ProviderOptions,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { Tracer } from '@opentelemetry/api';\nimport { NoOutputSpecifiedError } from '../error/no-output-specified-error';\nimport { logWarnings } from '../logger/log-warnings';\nimport { resolveLanguageModel } from '../model/resolve-model';\nimport { ModelMessage } from '../prompt';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { prepareToolsAndToolChoice } from '../prompt/prepare-tools-and-tool-choice';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordErrorOnSpan, recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { LanguageModel, ToolChoice } from '../types';\nimport { addLanguageModelUsage, LanguageModelUsage } from '../types/usage';\nimport { asArray } from '../util/as-array';\nimport { DownloadFunction } from '../util/download/download-function';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { ContentPart } from './content-part';\nimport { extractTextContent } from './extract-text-content';\nimport { GenerateTextResult } from './generate-text-result';\nimport { DefaultGeneratedFile } from './generated-file';\nimport { Output } from './output';\nimport { parseToolCall } from './parse-tool-call';\nimport { PrepareStepFunction } from './prepare-step';\nimport { ResponseMessage } from './response-message';\nimport { DefaultStepResult, StepResult } from './step-result';\nimport {\n  isStopConditionMet,\n  stepCountIs,\n  StopCondition,\n} from './stop-condition';\nimport { toResponseMessages } from './to-response-messages';\nimport { TypedToolCall } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair-function';\nimport { TypedToolError } from './tool-error';\nimport { ToolOutput } from './tool-output';\nimport { TypedToolResult } from './tool-result';\nimport { ToolSet } from './tool-set';\nimport { VERSION } from '../version';\n\nconst originalGenerateId = createIdGenerator({\n  prefix: 'aitxt',\n  size: 24,\n});\n\n/**\nCallback that is set using the `onStepFinish` option.\n\n@param stepResult - The result of the step.\n */\nexport type GenerateTextOnStepFinishCallback<TOOLS extends ToolSet> = (\n  stepResult: StepResult<TOOLS>,\n) => Promise<void> | void;\n\n/**\nGenerate a text and call tools for a given prompt using a language model.\n\nThis function does not stream the output. If you want to stream the output, use `streamText` instead.\n\n@param model - The language model to use.\n\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n@param toolChoice - The tool choice strategy. Default: 'auto'.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param experimental_generateMessageId - Generate a unique ID for each message.\n\n@param onStepFinish - Callback that is called when each step (LLM call) is finished, including intermediate steps.\n\n@returns\nA result object that contains the generated text, the results of the tool calls, and additional information.\n */\nexport async function generateText<\n  TOOLS extends ToolSet,\n  OUTPUT = never,\n  OUTPUT_PARTIAL = never,\n>({\n  model: modelArg,\n  tools,\n  toolChoice,\n  system,\n  prompt,\n  messages,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n  stopWhen = stepCountIs(1),\n  experimental_output: output,\n  experimental_telemetry: telemetry,\n  providerOptions,\n  experimental_activeTools,\n  activeTools = experimental_activeTools,\n  experimental_prepareStep,\n  prepareStep = experimental_prepareStep,\n  experimental_repairToolCall: repairToolCall,\n  experimental_download: download,\n  experimental_context,\n  _internal: {\n    generateId = originalGenerateId,\n    currentDate = () => new Date(),\n  } = {},\n  onStepFinish,\n  ...settings\n}: CallSettings &\n  Prompt & {\n    /**\nThe language model to use.\n     */\n    model: LanguageModel;\n\n    /**\nThe tools that the model can call. The model needs to support calling tools.\n*/\n    tools?: TOOLS;\n\n    /**\nThe tool choice strategy. Default: 'auto'.\n     */\n    toolChoice?: ToolChoice<NoInfer<TOOLS>>;\n\n    /**\nCondition for stopping the generation when there are tool results in the last step.\nWhen the condition is an array, any of the conditions can be met to stop the generation.\n\n@default stepCountIs(1)\n     */\n    stopWhen?:\n      | StopCondition<NoInfer<TOOLS>>\n      | Array<StopCondition<NoInfer<TOOLS>>>;\n\n    /**\nOptional telemetry configuration (experimental).\n     */\n    experimental_telemetry?: TelemetrySettings;\n\n    /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n    providerOptions?: ProviderOptions;\n\n    /**\n     * @deprecated Use `activeTools` instead.\n     */\n    experimental_activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nLimits the tools that are available for the model to call without\nchanging the tool call and result types in the result.\n     */\n    activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nOptional specification for parsing structured outputs from the LLM response.\n     */\n    experimental_output?: Output<OUTPUT, OUTPUT_PARTIAL>;\n\n    /**\nCustom download function to use for URLs.\n\nBy default, files are downloaded if the model does not support the URL for the given media type.\n     */\n    experimental_download?: DownloadFunction | undefined;\n\n    /**\n     * @deprecated Use `prepareStep` instead.\n     */\n    experimental_prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nOptional function that you can use to provide different settings for a step.\n    */\n    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nA function that attempts to repair a tool call that failed to parse.\n     */\n    experimental_repairToolCall?: ToolCallRepairFunction<NoInfer<TOOLS>>;\n\n    /**\n    Callback that is called when each step (LLM call) is finished, including intermediate steps.\n    */\n    onStepFinish?: GenerateTextOnStepFinishCallback<NoInfer<TOOLS>>;\n\n    /**\n     * Context that is passed into tool execution.\n     *\n     * Experimental (can break in patch releases).\n     *\n     * @default undefined\n     */\n    experimental_context?: unknown;\n\n    /**\n     * Internal. For test use only. May change without notice.\n     */\n    _internal?: {\n      generateId?: IdGenerator;\n      currentDate?: () => Date;\n    };\n  }): Promise<GenerateTextResult<TOOLS, OUTPUT>> {\n  const model = resolveLanguageModel(modelArg);\n  const stopConditions = asArray(stopWhen);\n  const { maxRetries, retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const callSettings = prepareCallSettings(settings);\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers: headersWithUserAgent,\n    settings: { ...callSettings, maxRetries },\n  });\n\n  const initialPrompt = await standardizePrompt({\n    system,\n    prompt,\n    messages,\n  } as Prompt);\n\n  const tracer = getTracer(telemetry);\n\n  try {\n    return await recordSpan({\n      name: 'ai.generateText',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.generateText',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // model:\n          'ai.model.provider': model.provider,\n          'ai.model.id': model.modelId,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n        },\n      }),\n      tracer,\n      fn: async span => {\n        const callSettings = prepareCallSettings(settings);\n\n        let currentModelResponse: Awaited<\n          ReturnType<LanguageModelV2['doGenerate']>\n        > & { response: { id: string; timestamp: Date; modelId: string } };\n        let clientToolCalls: Array<TypedToolCall<TOOLS>> = [];\n        let clientToolOutputs: Array<ToolOutput<TOOLS>> = [];\n        const responseMessages: Array<ResponseMessage> = [];\n        const steps: GenerateTextResult<TOOLS, OUTPUT>['steps'] = [];\n\n        do {\n          const stepInputMessages = [\n            ...initialPrompt.messages,\n            ...responseMessages,\n          ];\n\n          const prepareStepResult = await prepareStep?.({\n            model,\n            steps,\n            stepNumber: steps.length,\n            messages: stepInputMessages,\n          });\n\n          const stepModel = resolveLanguageModel(\n            prepareStepResult?.model ?? model,\n          );\n\n          const promptMessages = await convertToLanguageModelPrompt({\n            prompt: {\n              system: prepareStepResult?.system ?? initialPrompt.system,\n              messages: prepareStepResult?.messages ?? stepInputMessages,\n            },\n            supportedUrls: await stepModel.supportedUrls,\n            download,\n          });\n\n          const { toolChoice: stepToolChoice, tools: stepTools } =\n            prepareToolsAndToolChoice({\n              tools,\n              toolChoice: prepareStepResult?.toolChoice ?? toolChoice,\n              activeTools: prepareStepResult?.activeTools ?? activeTools,\n            });\n\n          currentModelResponse = await retry(() =>\n            recordSpan({\n              name: 'ai.generateText.doGenerate',\n              attributes: selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  ...assembleOperationName({\n                    operationId: 'ai.generateText.doGenerate',\n                    telemetry,\n                  }),\n                  ...baseTelemetryAttributes,\n                  // model:\n                  'ai.model.provider': stepModel.provider,\n                  'ai.model.id': stepModel.modelId,\n                  // prompt:\n                  'ai.prompt.messages': {\n                    input: () => stringifyForTelemetry(promptMessages),\n                  },\n                  'ai.prompt.tools': {\n                    // convert the language model level tools:\n                    input: () => stepTools?.map(tool => JSON.stringify(tool)),\n                  },\n                  'ai.prompt.toolChoice': {\n                    input: () =>\n                      stepToolChoice != null\n                        ? JSON.stringify(stepToolChoice)\n                        : undefined,\n                  },\n\n                  // standardized gen-ai llm span attributes:\n                  'gen_ai.system': stepModel.provider,\n                  'gen_ai.request.model': stepModel.modelId,\n                  'gen_ai.request.frequency_penalty': settings.frequencyPenalty,\n                  'gen_ai.request.max_tokens': settings.maxOutputTokens,\n                  'gen_ai.request.presence_penalty': settings.presencePenalty,\n                  'gen_ai.request.stop_sequences': settings.stopSequences,\n                  'gen_ai.request.temperature':\n                    settings.temperature ?? undefined,\n                  'gen_ai.request.top_k': settings.topK,\n                  'gen_ai.request.top_p': settings.topP,\n                },\n              }),\n              tracer,\n              fn: async span => {\n                const result = await stepModel.doGenerate({\n                  ...callSettings,\n                  tools: stepTools,\n                  toolChoice: stepToolChoice,\n                  responseFormat: output?.responseFormat,\n                  prompt: promptMessages,\n                  providerOptions,\n                  abortSignal,\n                  headers: headersWithUserAgent,\n                });\n\n                // Fill in default values:\n                const responseData = {\n                  id: result.response?.id ?? generateId(),\n                  timestamp: result.response?.timestamp ?? currentDate(),\n                  modelId: result.response?.modelId ?? stepModel.modelId,\n                  headers: result.response?.headers,\n                  body: result.response?.body,\n                };\n\n                // Add response information to the span:\n                span.setAttributes(\n                  selectTelemetryAttributes({\n                    telemetry,\n                    attributes: {\n                      'ai.response.finishReason': result.finishReason,\n                      'ai.response.text': {\n                        output: () => extractTextContent(result.content),\n                      },\n                      'ai.response.toolCalls': {\n                        output: () => {\n                          const toolCalls = asToolCalls(result.content);\n                          return toolCalls == null\n                            ? undefined\n                            : JSON.stringify(toolCalls);\n                        },\n                      },\n                      'ai.response.id': responseData.id,\n                      'ai.response.model': responseData.modelId,\n                      'ai.response.timestamp':\n                        responseData.timestamp.toISOString(),\n                      'ai.response.providerMetadata': JSON.stringify(\n                        result.providerMetadata,\n                      ),\n\n                      // TODO rename telemetry attributes to inputTokens and outputTokens\n                      'ai.usage.promptTokens': result.usage.inputTokens,\n                      'ai.usage.completionTokens': result.usage.outputTokens,\n\n                      // standardized gen-ai llm span attributes:\n                      'gen_ai.response.finish_reasons': [result.finishReason],\n                      'gen_ai.response.id': responseData.id,\n                      'gen_ai.response.model': responseData.modelId,\n                      'gen_ai.usage.input_tokens': result.usage.inputTokens,\n                      'gen_ai.usage.output_tokens': result.usage.outputTokens,\n                    },\n                  }),\n                );\n\n                return { ...result, response: responseData };\n              },\n            }),\n          );\n\n          // parse tool calls:\n          const stepToolCalls: TypedToolCall<TOOLS>[] = await Promise.all(\n            currentModelResponse.content\n              .filter(\n                (part): part is LanguageModelV2ToolCall =>\n                  part.type === 'tool-call',\n              )\n              .map(toolCall =>\n                parseToolCall({\n                  toolCall,\n                  tools,\n                  repairToolCall,\n                  system,\n                  messages: stepInputMessages,\n                }),\n              ),\n          );\n\n          // notify the tools that the tool calls are available:\n          for (const toolCall of stepToolCalls) {\n            if (toolCall.invalid) {\n              continue; // ignore invalid tool calls\n            }\n\n            const tool = tools![toolCall.toolName];\n            if (tool?.onInputAvailable != null) {\n              await tool.onInputAvailable({\n                input: toolCall.input,\n                toolCallId: toolCall.toolCallId,\n                messages: stepInputMessages,\n                abortSignal,\n                experimental_context,\n              });\n            }\n          }\n\n          // insert error tool outputs for invalid tool calls:\n          // TODO AI SDK 6: invalid inputs should not require output parts\n          const invalidToolCalls = stepToolCalls.filter(\n            toolCall => toolCall.invalid && toolCall.dynamic,\n          );\n\n          clientToolOutputs = [];\n\n          for (const toolCall of invalidToolCalls) {\n            clientToolOutputs.push({\n              type: 'tool-error',\n              toolCallId: toolCall.toolCallId,\n              toolName: toolCall.toolName,\n              input: toolCall.input,\n              error: getErrorMessage(toolCall.error!),\n              dynamic: true,\n            });\n          }\n\n          // execute client tool calls:\n          clientToolCalls = stepToolCalls.filter(\n            toolCall => !toolCall.providerExecuted,\n          );\n\n          if (tools != null) {\n            clientToolOutputs.push(\n              ...(await executeTools({\n                toolCalls: clientToolCalls.filter(\n                  toolCall => !toolCall.invalid,\n                ),\n                tools,\n                tracer,\n                telemetry,\n                messages: stepInputMessages,\n                abortSignal,\n                experimental_context,\n              })),\n            );\n          }\n\n          // content:\n          const stepContent = asContent({\n            content: currentModelResponse.content,\n            toolCalls: stepToolCalls,\n            toolOutputs: clientToolOutputs,\n          });\n\n          // append to messages for potential next step:\n          responseMessages.push(\n            ...toResponseMessages({\n              content: stepContent,\n              tools,\n            }),\n          );\n\n          // Add step information (after response messages are updated):\n          const currentStepResult: StepResult<TOOLS> = new DefaultStepResult({\n            content: stepContent,\n            finishReason: currentModelResponse.finishReason,\n            usage: currentModelResponse.usage,\n            warnings: currentModelResponse.warnings,\n            providerMetadata: currentModelResponse.providerMetadata,\n            request: currentModelResponse.request ?? {},\n            response: {\n              ...currentModelResponse.response,\n              // deep clone msgs to avoid mutating past messages in multi-step:\n              messages: structuredClone(responseMessages),\n            },\n          });\n\n          logWarnings(currentModelResponse.warnings ?? []);\n\n          steps.push(currentStepResult);\n          await onStepFinish?.(currentStepResult);\n        } while (\n          // there are tool calls:\n          clientToolCalls.length > 0 &&\n          // all current tool calls have outputs (incl. execution errors):\n          clientToolOutputs.length === clientToolCalls.length &&\n          // continue until a stop condition is met:\n          !(await isStopConditionMet({ stopConditions, steps }))\n        );\n\n        // Add response information to the span:\n        span.setAttributes(\n          selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              'ai.response.finishReason': currentModelResponse.finishReason,\n              'ai.response.text': {\n                output: () => extractTextContent(currentModelResponse.content),\n              },\n              'ai.response.toolCalls': {\n                output: () => {\n                  const toolCalls = asToolCalls(currentModelResponse.content);\n                  return toolCalls == null\n                    ? undefined\n                    : JSON.stringify(toolCalls);\n                },\n              },\n              'ai.response.providerMetadata': JSON.stringify(\n                currentModelResponse.providerMetadata,\n              ),\n\n              // TODO rename telemetry attributes to inputTokens and outputTokens\n              'ai.usage.promptTokens': currentModelResponse.usage.inputTokens,\n              'ai.usage.completionTokens':\n                currentModelResponse.usage.outputTokens,\n            },\n          }),\n        );\n\n        const lastStep = steps[steps.length - 1];\n\n        // parse output only if the last step was finished with \"stop\":\n        let resolvedOutput;\n        if (lastStep.finishReason === 'stop') {\n          resolvedOutput = await output?.parseOutput(\n            { text: lastStep.text },\n            {\n              response: lastStep.response,\n              usage: lastStep.usage,\n              finishReason: lastStep.finishReason,\n            },\n          );\n        }\n\n        return new DefaultGenerateTextResult({\n          steps,\n          resolvedOutput,\n        });\n      },\n    });\n  } catch (error) {\n    throw wrapGatewayError(error);\n  }\n}\n\nasync function executeTools<TOOLS extends ToolSet>({\n  toolCalls,\n  tools,\n  tracer,\n  telemetry,\n  messages,\n  abortSignal,\n  experimental_context,\n}: {\n  toolCalls: Array<TypedToolCall<TOOLS>>;\n  tools: TOOLS;\n  tracer: Tracer;\n  telemetry: TelemetrySettings | undefined;\n  messages: ModelMessage[];\n  abortSignal: AbortSignal | undefined;\n  experimental_context: unknown;\n}): Promise<Array<ToolOutput<TOOLS>>> {\n  const toolOutputs = await Promise.all(\n    toolCalls.map(async ({ toolCallId, toolName, input }) => {\n      const tool = tools[toolName];\n\n      if (tool?.execute == null) {\n        return undefined;\n      }\n\n      return recordSpan({\n        name: 'ai.toolCall',\n        attributes: selectTelemetryAttributes({\n          telemetry,\n          attributes: {\n            ...assembleOperationName({\n              operationId: 'ai.toolCall',\n              telemetry,\n            }),\n            'ai.toolCall.name': toolName,\n            'ai.toolCall.id': toolCallId,\n            'ai.toolCall.args': {\n              output: () => JSON.stringify(input),\n            },\n          },\n        }),\n        tracer,\n        fn: async span => {\n          try {\n            const stream = executeTool({\n              execute: tool.execute!.bind(tool),\n              input,\n              options: {\n                toolCallId,\n                messages,\n                abortSignal,\n                experimental_context,\n              },\n            });\n\n            let output: unknown;\n            for await (const part of stream) {\n              if (part.type === 'final') {\n                output = part.output;\n              }\n            }\n            try {\n              span.setAttributes(\n                selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    'ai.toolCall.result': {\n                      output: () => JSON.stringify(output),\n                    },\n                  },\n                }),\n              );\n            } catch (ignored) {\n              // JSON stringify might fail if the result is not serializable,\n              // in which case we just ignore it. In the future we might want to\n              // add an optional serialize method to the tool interface and warn\n              // if the result is not serializable.\n            }\n\n            return {\n              type: 'tool-result',\n              toolCallId,\n              toolName,\n              input,\n              output,\n              dynamic: tool.type === 'dynamic',\n            } as TypedToolResult<TOOLS>;\n          } catch (error) {\n            recordErrorOnSpan(span, error);\n            return {\n              type: 'tool-error',\n              toolCallId,\n              toolName,\n              input,\n              error,\n              dynamic: tool.type === 'dynamic',\n            } as TypedToolError<TOOLS>;\n          }\n        },\n      });\n    }),\n  );\n\n  return toolOutputs.filter(\n    (output): output is NonNullable<typeof output> => output != null,\n  );\n}\n\nclass DefaultGenerateTextResult<TOOLS extends ToolSet, OUTPUT>\n  implements GenerateTextResult<TOOLS, OUTPUT>\n{\n  readonly steps: GenerateTextResult<TOOLS, OUTPUT>['steps'];\n\n  private readonly resolvedOutput: OUTPUT;\n\n  constructor(options: {\n    steps: GenerateTextResult<TOOLS, OUTPUT>['steps'];\n    resolvedOutput: OUTPUT;\n  }) {\n    this.steps = options.steps;\n    this.resolvedOutput = options.resolvedOutput;\n  }\n\n  private get finalStep() {\n    return this.steps[this.steps.length - 1];\n  }\n\n  get content() {\n    return this.finalStep.content;\n  }\n\n  get text() {\n    return this.finalStep.text;\n  }\n\n  get files() {\n    return this.finalStep.files;\n  }\n\n  get reasoningText() {\n    return this.finalStep.reasoningText;\n  }\n\n  get reasoning() {\n    return this.finalStep.reasoning;\n  }\n\n  get toolCalls() {\n    return this.finalStep.toolCalls;\n  }\n\n  get staticToolCalls() {\n    return this.finalStep.staticToolCalls;\n  }\n\n  get dynamicToolCalls() {\n    return this.finalStep.dynamicToolCalls;\n  }\n\n  get toolResults() {\n    return this.finalStep.toolResults;\n  }\n\n  get staticToolResults() {\n    return this.finalStep.staticToolResults;\n  }\n\n  get dynamicToolResults() {\n    return this.finalStep.dynamicToolResults;\n  }\n\n  get sources() {\n    return this.finalStep.sources;\n  }\n\n  get finishReason() {\n    return this.finalStep.finishReason;\n  }\n\n  get warnings() {\n    return this.finalStep.warnings;\n  }\n\n  get providerMetadata() {\n    return this.finalStep.providerMetadata;\n  }\n\n  get response() {\n    return this.finalStep.response;\n  }\n\n  get request() {\n    return this.finalStep.request;\n  }\n\n  get usage() {\n    return this.finalStep.usage;\n  }\n\n  get totalUsage() {\n    return this.steps.reduce(\n      (totalUsage, step) => {\n        return addLanguageModelUsage(totalUsage, step.usage);\n      },\n      {\n        inputTokens: undefined,\n        outputTokens: undefined,\n        totalTokens: undefined,\n        reasoningTokens: undefined,\n        cachedInputTokens: undefined,\n      } as LanguageModelUsage,\n    );\n  }\n\n  get experimental_output() {\n    if (this.resolvedOutput == null) {\n      throw new NoOutputSpecifiedError();\n    }\n\n    return this.resolvedOutput;\n  }\n}\n\nfunction asToolCalls(content: Array<LanguageModelV2Content>) {\n  const parts = content.filter(\n    (part): part is LanguageModelV2ToolCall => part.type === 'tool-call',\n  );\n\n  if (parts.length === 0) {\n    return undefined;\n  }\n\n  return parts.map(toolCall => ({\n    toolCallId: toolCall.toolCallId,\n    toolName: toolCall.toolName,\n    input: toolCall.input,\n  }));\n}\n\nfunction asContent<TOOLS extends ToolSet>({\n  content,\n  toolCalls,\n  toolOutputs,\n}: {\n  content: Array<LanguageModelV2Content>;\n  toolCalls: Array<TypedToolCall<TOOLS>>;\n  toolOutputs: Array<ToolOutput<TOOLS>>;\n}): Array<ContentPart<TOOLS>> {\n  return [\n    ...content.map(part => {\n      switch (part.type) {\n        case 'text':\n        case 'reasoning':\n        case 'source':\n          return part;\n\n        case 'file': {\n          return {\n            type: 'file' as const,\n            file: new DefaultGeneratedFile(part),\n          };\n        }\n\n        case 'tool-call': {\n          return toolCalls.find(\n            toolCall => toolCall.toolCallId === part.toolCallId,\n          )!;\n        }\n\n        case 'tool-result': {\n          const toolCall = toolCalls.find(\n            toolCall => toolCall.toolCallId === part.toolCallId,\n          )!;\n\n          if (toolCall == null) {\n            throw new Error(`Tool call ${part.toolCallId} not found.`);\n          }\n\n          if (part.isError) {\n            return {\n              type: 'tool-error' as const,\n              toolCallId: part.toolCallId,\n              toolName: part.toolName as keyof TOOLS & string,\n              input: toolCall.input,\n              error: part.result,\n              providerExecuted: true,\n              dynamic: toolCall.dynamic,\n            } as TypedToolError<TOOLS>;\n          }\n\n          return {\n            type: 'tool-result' as const,\n            toolCallId: part.toolCallId,\n            toolName: part.toolName as keyof TOOLS & string,\n            input: toolCall.input,\n            output: part.result,\n            providerExecuted: true,\n            dynamic: toolCall.dynamic,\n          } as TypedToolResult<TOOLS>;\n        }\n      }\n    }),\n    ...toolOutputs,\n  ];\n}\n", "import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_NoOutputSpecifiedError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\nThrown when no output type is specified and output-related methods are called.\n */\nexport class NoOutputSpecifiedError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  constructor({ message = 'No output specified.' }: { message?: string } = {}) {\n    super({ name, message });\n  }\n\n  static isInstance(error: unknown): error is NoOutputSpecifiedError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import {\n  ImageModelV2CallWarning,\n  LanguageModelV2CallWarning,\n  SpeechModelV2CallWarning,\n  TranscriptionModelV2CallWarning,\n} from '@ai-sdk/provider';\n\nexport type Warning =\n  | LanguageModelV2CallWarning\n  | ImageModelV2CallWarning\n  | SpeechModelV2CallWarning\n  | TranscriptionModelV2CallWarning;\n\nexport type LogWarningsFunction = (warnings: Warning[]) => void;\n\n/**\n * Formats a warning object into a human-readable string with clear AI SDK branding\n */\nfunction formatWarning(warning: Warning): string {\n  const prefix = 'AI SDK Warning:';\n\n  switch (warning.type) {\n    case 'unsupported-setting': {\n      let message = `${prefix} The \"${warning.setting}\" setting is not supported by this model`;\n      if (warning.details) {\n        message += ` - ${warning.details}`;\n      }\n      return message;\n    }\n\n    case 'unsupported-tool': {\n      const toolName =\n        'name' in warning.tool ? warning.tool.name : 'unknown tool';\n      let message = `${prefix} The tool \"${toolName}\" is not supported by this model`;\n      if (warning.details) {\n        message += ` - ${warning.details}`;\n      }\n      return message;\n    }\n\n    case 'other': {\n      return `${prefix} ${warning.message}`;\n    }\n\n    default: {\n      // Fallback for any unknown warning types\n      return `${prefix} ${JSON.stringify(warning, null, 2)}`;\n    }\n  }\n}\n\nexport const FIRST_WARNING_INFO_MESSAGE =\n  'AI SDK Warning System: To turn off warning logging, set the AI_SDK_LOG_WARNINGS global to false.';\n\nlet hasLoggedBefore = false;\n\nexport const logWarnings: LogWarningsFunction = warnings => {\n  // if the warnings array is empty, do nothing\n  if (warnings.length === 0) {\n    return;\n  }\n\n  const logger = globalThis.AI_SDK_LOG_WARNINGS;\n\n  // if the logger is set to false, do nothing\n  if (logger === false) {\n    return;\n  }\n\n  // use the provided logger if it is a function\n  if (typeof logger === 'function') {\n    logger(warnings);\n    return;\n  }\n\n  // display information note on first call\n  if (!hasLoggedBefore) {\n    hasLoggedBefore = true;\n    console.info(FIRST_WARNING_INFO_MESSAGE);\n  }\n\n  // default behavior: log warnings to the console\n  for (const warning of warnings) {\n    console.warn(formatWarning(warning));\n  }\n};\n\n// Reset function for testing purposes\nexport const resetLogWarningsState = () => {\n  hasLoggedBefore = false;\n};\n", "import { gateway } from '@ai-sdk/gateway';\nimport {\n  EmbeddingModelV2,\n  LanguageModelV2,\n  ProviderV2,\n} from '@ai-sdk/provider';\nimport { UnsupportedModelVersionError } from '../error';\nimport { EmbeddingModel } from '../types/embedding-model';\nimport { LanguageModel } from '../types/language-model';\n\nexport function resolveLanguageModel(model: LanguageModel): LanguageModelV2 {\n  if (typeof model !== 'string') {\n    if (model.specificationVersion !== 'v2') {\n      throw new UnsupportedModelVersionError({\n        version: model.specificationVersion,\n        provider: model.provider,\n        modelId: model.modelId,\n      });\n    }\n\n    return model;\n  }\n\n  return getGlobalProvider().languageModel(model);\n}\n\nexport function resolveEmbeddingModel<VALUE = string>(\n  model: EmbeddingModel<VALUE>,\n): EmbeddingModelV2<VALUE> {\n  if (typeof model !== 'string') {\n    if (model.specificationVersion !== 'v2') {\n      throw new UnsupportedModelVersionError({\n        version: model.specificationVersion,\n        provider: model.provider,\n        modelId: model.modelId,\n      });\n    }\n\n    return model;\n  }\n\n  // TODO AI SDK 6: figure out how to cleanly support different generic types\n  return getGlobalProvider().textEmbeddingModel(\n    model,\n  ) as EmbeddingModelV2<VALUE>;\n}\n\nfunction getGlobalProvider(): ProviderV2 {\n  return globalThis.AI_SDK_DEFAULT_PROVIDER ?? gateway;\n}\n", "export {\n  AISDKError,\n  APICallError,\n  EmptyResponseBodyError,\n  InvalidPromptError,\n  InvalidResponseDataError,\n  JSONParseError,\n  LoadAPIKeyError,\n  LoadSettingError,\n  NoContentGeneratedError,\n  NoSuchModelError,\n  TooManyEmbeddingValuesForCallError,\n  TypeValidationError,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport { InvalidArgumentError } from './invalid-argument-error';\nexport { InvalidStreamPartError } from './invalid-stream-part-error';\nexport { InvalidToolInputError } from './invalid-tool-input-error';\nexport { NoImageGeneratedError } from './no-image-generated-error';\nexport { NoObjectGeneratedError } from './no-object-generated-error';\nexport { NoOutputGeneratedError } from './no-output-generated-error';\nexport { NoOutputSpecifiedError } from './no-output-specified-error';\nexport { NoSpeechGeneratedError } from './no-speech-generated-error';\nexport { NoSuchToolError } from './no-such-tool-error';\nexport { ToolCallRepairError } from './tool-call-repair-error';\nexport { UnsupportedModelVersionError } from './unsupported-model-version-error';\n\nexport { InvalidDataContentError } from '../prompt/invalid-data-content-error';\nexport { InvalidMessageRoleError } from '../prompt/invalid-message-role-error';\nexport { MessageConversionError } from '../prompt/message-conversion-error';\nexport { DownloadError } from '../util/download/download-error';\nexport { RetryError } from '../util/retry-error';\n", "import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidArgumentError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidArgumentError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly parameter: string;\n  readonly value: unknown;\n\n  constructor({\n    parameter,\n    value,\n    message,\n  }: {\n    parameter: string;\n    value: unknown;\n    message: string;\n  }) {\n    super({\n      name,\n      message: `Invalid argument for parameter ${parameter}: ${message}`,\n    });\n\n    this.parameter = parameter;\n    this.value = value;\n  }\n\n  static isInstance(error: unknown): error is InvalidArgumentError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\nimport { SingleRequestTextStreamPart } from '../generate-text/run-tools-transformation';\n\nconst name = 'AI_InvalidStreamPartError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidStreamPartError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly chunk: SingleRequestTextStreamPart<any>;\n\n  constructor({\n    chunk,\n    message,\n  }: {\n    chunk: SingleRequestTextStreamPart<any>;\n    message: string;\n  }) {\n    super({ name, message });\n\n    this.chunk = chunk;\n  }\n\n  static isInstance(error: unknown): error is InvalidStreamPartError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError, getErrorMessage } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidToolInputError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidToolInputError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly toolName: string;\n  readonly toolInput: string;\n\n  constructor({\n    toolInput,\n    toolName,\n    cause,\n    message = `Invalid input for tool ${toolName}: ${getErrorMessage(cause)}`,\n  }: {\n    message?: string;\n    toolInput: string;\n    toolName: string;\n    cause: unknown;\n  }) {\n    super({ name, message, cause });\n\n    this.toolInput = toolInput;\n    this.toolName = toolName;\n  }\n\n  static isInstance(error: unknown): error is InvalidToolInputError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\nimport { ImageModelResponseMetadata } from '../types/image-model-response-metadata';\n\nconst name = 'AI_NoImageGeneratedError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\nThrown when no image could be generated. This can have multiple causes:\n\n- The model failed to generate a response.\n- The model generated a response that could not be parsed.\n */\nexport class NoImageGeneratedError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  /**\nThe response metadata for each call.\n   */\n  readonly responses: Array<ImageModelResponseMetadata> | undefined;\n\n  constructor({\n    message = 'No image generated.',\n    cause,\n    responses,\n  }: {\n    message?: string;\n    cause?: Error;\n    responses?: Array<ImageModelResponseMetadata>;\n  }) {\n    super({ name, message, cause });\n\n    this.responses = responses;\n  }\n\n  static isInstance(error: unknown): error is NoImageGeneratedError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\nimport { FinishReason } from '../types/language-model';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { LanguageModelUsage } from '../types/usage';\n\nconst name = 'AI_NoObjectGeneratedError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\nThrown when no object could be generated. This can have several causes:\n\n- The model failed to generate a response.\n- The model generated a response that could not be parsed.\n- The model generated a response that could not be validated against the schema.\n\nThe error contains the following properties:\n\n- `text`: The text that was generated by the model. This can be the raw text or the tool call text, depending on the model.\n */\nexport class NoObjectGeneratedError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  /**\n  The text that was generated by the model. This can be the raw text or the tool call text, depending on the model.\n   */\n  readonly text: string | undefined;\n\n  /**\n  The response metadata.\n   */\n  readonly response: LanguageModelResponseMetadata | undefined;\n\n  /**\n  The usage of the model.\n   */\n  readonly usage: LanguageModelUsage | undefined;\n\n  /**\n  Reason why the model finished generating a response.\n   */\n  readonly finishReason: FinishReason | undefined;\n\n  constructor({\n    message = 'No object generated.',\n    cause,\n    text,\n    response,\n    usage,\n    finishReason,\n  }: {\n    message?: string;\n    cause?: Error;\n    text?: string;\n    response: LanguageModelResponseMetadata;\n    usage: LanguageModelUsage;\n    finishReason: FinishReason;\n  }) {\n    super({ name, message, cause });\n\n    this.text = text;\n    this.response = response;\n    this.usage = usage;\n    this.finishReason = finishReason;\n  }\n\n  static isInstance(error: unknown): error is NoObjectGeneratedError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_NoOutputGeneratedError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\n/**\nThrown when no LLM output was generated, e.g. because of errors.\n */\nexport class NoOutputGeneratedError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  constructor({\n    message = 'No output generated.',\n    cause,\n  }: {\n    message?: string;\n    cause?: Error;\n  } = {}) {\n    super({ name, message, cause });\n  }\n\n  static isInstance(error: unknown): error is NoOutputGeneratedError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\nimport { SpeechModelResponseMetadata } from '../types/speech-model-response-metadata';\n\n/**\nError that is thrown when no speech audio was generated.\n */\nexport class NoSpeechGeneratedError extends AISDKError {\n  readonly responses: Array<SpeechModelResponseMetadata>;\n\n  constructor(options: { responses: Array<SpeechModelResponseMetadata> }) {\n    super({\n      name: 'AI_NoSpeechGeneratedError',\n      message: 'No speech audio generated.',\n    });\n\n    this.responses = options.responses;\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_NoSuchToolError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class NoSuchToolError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly toolName: string;\n  readonly availableTools: string[] | undefined;\n\n  constructor({\n    toolName,\n    availableTools = undefined,\n    message = `Model tried to call unavailable tool '${toolName}'. ${\n      availableTools === undefined\n        ? 'No tools are available.'\n        : `Available tools: ${availableTools.join(', ')}.`\n    }`,\n  }: {\n    toolName: string;\n    availableTools?: string[] | undefined;\n    message?: string;\n  }) {\n    super({ name, message });\n\n    this.toolName = toolName;\n    this.availableTools = availableTools;\n  }\n\n  static isInstance(error: unknown): error is NoSuchToolError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError, getErrorMessage } from '@ai-sdk/provider';\nimport { InvalidToolInputError } from './invalid-tool-input-error';\nimport { NoSuchToolError } from './no-such-tool-error';\n\nconst name = 'AI_ToolCallRepairError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class ToolCallRepairError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly originalError: NoSuchToolError | InvalidToolInputError;\n\n  constructor({\n    cause,\n    originalError,\n    message = `Error repairing tool call: ${getErrorMessage(cause)}`,\n  }: {\n    message?: string;\n    cause: unknown;\n    originalError: NoSuchToolError | InvalidToolInputError;\n  }) {\n    super({ name, message, cause });\n    this.originalError = originalError;\n  }\n\n  static isInstance(error: unknown): error is ToolCallRepairError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\n\n/**\nError that is thrown when a model with an unsupported version is used.\n */\nexport class UnsupportedModelVersionError extends AISDKError {\n  readonly version: string;\n  readonly provider: string;\n  readonly modelId: string;\n\n  constructor(options: { version: string; provider: string; modelId: string }) {\n    super({\n      name: 'AI_UnsupportedModelVersionError',\n      message:\n        `Unsupported model version ${options.version} for provider \"${options.provider}\" and model \"${options.modelId}\". ` +\n        `AI SDK 5 only supports models that implement specification version \"v2\".`,\n    });\n\n    this.version = options.version;\n    this.provider = options.provider;\n    this.modelId = options.modelId;\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidDataContentError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidDataContentError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly content: unknown;\n\n  constructor({\n    content,\n    cause,\n    message = `Invalid data content. Expected a base64 string, Uint8Array, ArrayBuffer, or Buffer, but got ${typeof content}.`,\n  }: {\n    content: unknown;\n    cause?: unknown;\n    message?: string;\n  }) {\n    super({ name, message, cause });\n\n    this.content = content;\n  }\n\n  static isInstance(error: unknown): error is InvalidDataContentError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_InvalidMessageRoleError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class InvalidMessageRoleError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly role: string;\n\n  constructor({\n    role,\n    message = `Invalid message role: '${role}'. Must be one of: \"system\", \"user\", \"assistant\", \"tool\".`,\n  }: {\n    role: string;\n    message?: string;\n  }) {\n    super({ name, message });\n\n    this.role = role;\n  }\n\n  static isInstance(error: unknown): error is InvalidMessageRoleError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\nimport { UIMessage } from '../ui/ui-messages';\n\nconst name = 'AI_MessageConversionError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class MessageConversionError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly originalMessage: Omit<UIMessage, 'id'>;\n\n  constructor({\n    originalMessage,\n    message,\n  }: {\n    originalMessage: Omit<UIMessage, 'id'>;\n    message: string;\n  }) {\n    super({ name, message });\n\n    this.originalMessage = originalMessage;\n  }\n\n  static isInstance(error: unknown): error is MessageConversionError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_DownloadError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class DownloadError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly url: string;\n  readonly statusCode?: number;\n  readonly statusText?: string;\n\n  constructor({\n    url,\n    statusCode,\n    statusText,\n    cause,\n    message = cause == null\n      ? `Failed to download ${url}: ${statusCode} ${statusText}`\n      : `Failed to download ${url}: ${cause}`,\n  }: {\n    url: string;\n    statusCode?: number;\n    statusText?: string;\n    message?: string;\n    cause?: unknown;\n  }) {\n    super({ name, message, cause });\n\n    this.url = url;\n    this.statusCode = statusCode;\n    this.statusText = statusText;\n  }\n\n  static isInstance(error: unknown): error is DownloadError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\n\nconst name = 'AI_RetryError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport type RetryErrorReason =\n  | 'maxRetriesExceeded'\n  | 'errorNotRetryable'\n  | 'abort';\n\nexport class RetryError extends AISDKError {\n  private readonly [symbol] = true; // used in isInstance\n\n  // note: property order determines debugging output\n  readonly reason: RetryErrorReason;\n  readonly lastError: unknown;\n  readonly errors: Array<unknown>;\n\n  constructor({\n    message,\n    reason,\n    errors,\n  }: {\n    message: string;\n    reason: RetryErrorReason;\n    errors: Array<unknown>;\n  }) {\n    super({ name, message });\n\n    this.reason = reason;\n    this.errors = errors;\n\n    // separate our last error to make debugging via log easier:\n    this.lastError = errors[errors.length - 1];\n  }\n\n  static isInstance(error: unknown): error is RetryError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import {\n  LanguageModelV2FilePart,\n  LanguageModelV2Message,\n  LanguageModelV2Prompt,\n  LanguageModelV2TextPart,\n} from '@ai-sdk/provider';\nimport {\n  DataContent,\n  FilePart,\n  ImagePart,\n  isUrlSupported,\n  ModelMessage,\n  TextPart,\n} from '@ai-sdk/provider-utils';\nimport {\n  detectMediaType,\n  imageMediaTypeSignatures,\n} from '../util/detect-media-type';\nimport {\n  createDefaultDownloadFunction,\n  DownloadFunction,\n} from '../util/download/download-function';\nimport { convertToLanguageModelV2DataContent } from './data-content';\nimport { InvalidMessageRoleError } from './invalid-message-role-error';\nimport { StandardizedPrompt } from './standardize-prompt';\n\nexport async function convertToLanguageModelPrompt({\n  prompt,\n  supportedUrls,\n  download = createDefaultDownloadFunction(),\n}: {\n  prompt: StandardizedPrompt;\n  supportedUrls: Record<string, RegExp[]>;\n  download: DownloadFunction | undefined;\n}): Promise<LanguageModelV2Prompt> {\n  const downloadedAssets = await downloadAssets(\n    prompt.messages,\n    download,\n    supportedUrls,\n  );\n\n  return [\n    ...(prompt.system != null\n      ? [{ role: 'system' as const, content: prompt.system }]\n      : []),\n    ...prompt.messages.map(message =>\n      convertToLanguageModelMessage({ message, downloadedAssets }),\n    ),\n  ];\n}\n\n/**\n * Convert a ModelMessage to a LanguageModelV2Message.\n *\n * @param message The ModelMessage to convert.\n * @param downloadedAssets A map of URLs to their downloaded data. Only\n *   available if the model does not support URLs, null otherwise.\n */\nexport function convertToLanguageModelMessage({\n  message,\n  downloadedAssets,\n}: {\n  message: ModelMessage;\n  downloadedAssets: Record<\n    string,\n    { mediaType: string | undefined; data: Uint8Array }\n  >;\n}): LanguageModelV2Message {\n  const role = message.role;\n  switch (role) {\n    case 'system': {\n      return {\n        role: 'system',\n        content: message.content,\n        providerOptions: message.providerOptions,\n      };\n    }\n\n    case 'user': {\n      if (typeof message.content === 'string') {\n        return {\n          role: 'user',\n          content: [{ type: 'text', text: message.content }],\n          providerOptions: message.providerOptions,\n        };\n      }\n\n      return {\n        role: 'user',\n        content: message.content\n          .map(part => convertPartToLanguageModelPart(part, downloadedAssets))\n          // remove empty text parts:\n          .filter(part => part.type !== 'text' || part.text !== ''),\n        providerOptions: message.providerOptions,\n      };\n    }\n\n    case 'assistant': {\n      if (typeof message.content === 'string') {\n        return {\n          role: 'assistant',\n          content: [{ type: 'text', text: message.content }],\n          providerOptions: message.providerOptions,\n        };\n      }\n\n      return {\n        role: 'assistant',\n        content: message.content\n          .filter(\n            // remove empty text parts (no text, and no provider options):\n            part =>\n              part.type !== 'text' ||\n              part.text !== '' ||\n              part.providerOptions != null,\n          )\n          .map(part => {\n            const providerOptions = part.providerOptions;\n\n            switch (part.type) {\n              case 'file': {\n                const { data, mediaType } = convertToLanguageModelV2DataContent(\n                  part.data,\n                );\n                return {\n                  type: 'file',\n                  data,\n                  filename: part.filename,\n                  mediaType: mediaType ?? part.mediaType,\n                  providerOptions,\n                };\n              }\n              case 'reasoning': {\n                return {\n                  type: 'reasoning',\n                  text: part.text,\n                  providerOptions,\n                };\n              }\n              case 'text': {\n                return {\n                  type: 'text' as const,\n                  text: part.text,\n                  providerOptions,\n                };\n              }\n              case 'tool-call': {\n                return {\n                  type: 'tool-call' as const,\n                  toolCallId: part.toolCallId,\n                  toolName: part.toolName,\n                  input: part.input,\n                  providerExecuted: part.providerExecuted,\n                  providerOptions,\n                };\n              }\n              case 'tool-result': {\n                return {\n                  type: 'tool-result' as const,\n                  toolCallId: part.toolCallId,\n                  toolName: part.toolName,\n                  output: part.output,\n                  providerOptions,\n                };\n              }\n            }\n          }),\n        providerOptions: message.providerOptions,\n      };\n    }\n\n    case 'tool': {\n      return {\n        role: 'tool',\n        content: message.content.map(part => ({\n          type: 'tool-result' as const,\n          toolCallId: part.toolCallId,\n          toolName: part.toolName,\n          output: part.output,\n          providerOptions: part.providerOptions,\n        })),\n        providerOptions: message.providerOptions,\n      };\n    }\n\n    default: {\n      const _exhaustiveCheck: never = role;\n      throw new InvalidMessageRoleError({ role: _exhaustiveCheck });\n    }\n  }\n}\n\n/**\n * Downloads images and files from URLs in the messages.\n */\nasync function downloadAssets(\n  messages: ModelMessage[],\n  download: DownloadFunction,\n  supportedUrls: Record<string, RegExp[]>,\n): Promise<\n  Record<string, { mediaType: string | undefined; data: Uint8Array }>\n> {\n  const plannedDownloads = messages\n    .filter(message => message.role === 'user')\n    .map(message => message.content)\n    .filter((content): content is Array<TextPart | ImagePart | FilePart> =>\n      Array.isArray(content),\n    )\n    .flat()\n    .filter(\n      (part): part is ImagePart | FilePart =>\n        part.type === 'image' || part.type === 'file',\n    )\n    .map(part => {\n      const mediaType =\n        part.mediaType ?? (part.type === 'image' ? 'image/*' : undefined);\n\n      let data = part.type === 'image' ? part.image : part.data;\n      if (typeof data === 'string') {\n        try {\n          data = new URL(data);\n        } catch (ignored) {}\n      }\n\n      return { mediaType, data };\n    })\n\n    .filter(\n      (part): part is { mediaType: string | undefined; data: URL } =>\n        part.data instanceof URL,\n    )\n    .map(part => ({\n      url: part.data,\n      isUrlSupportedByModel:\n        part.mediaType != null &&\n        isUrlSupported({\n          url: part.data.toString(),\n          mediaType: part.mediaType,\n          supportedUrls,\n        }),\n    }));\n\n  // download in parallel:\n  const downloadedFiles = await download(plannedDownloads);\n\n  return Object.fromEntries(\n    downloadedFiles\n      .map((file, index) =>\n        file == null\n          ? null\n          : [\n              plannedDownloads[index].url.toString(),\n              { data: file.data, mediaType: file.mediaType },\n            ],\n      )\n      .filter(file => file != null),\n  );\n}\n\n/**\n * Convert part of a message to a LanguageModelV2Part.\n * @param part The part to convert.\n * @param downloadedAssets A map of URLs to their downloaded data. Only\n *  available if the model does not support URLs, null otherwise.\n *\n * @returns The converted part.\n */\nfunction convertPartToLanguageModelPart(\n  part: TextPart | ImagePart | FilePart,\n  downloadedAssets: Record<\n    string,\n    { mediaType: string | undefined; data: Uint8Array }\n  >,\n): LanguageModelV2TextPart | LanguageModelV2FilePart {\n  if (part.type === 'text') {\n    return {\n      type: 'text',\n      text: part.text,\n      providerOptions: part.providerOptions,\n    };\n  }\n\n  let originalData: DataContent | URL;\n  const type = part.type;\n  switch (type) {\n    case 'image':\n      originalData = part.image;\n      break;\n    case 'file':\n      originalData = part.data;\n\n      break;\n    default:\n      throw new Error(`Unsupported part type: ${type}`);\n  }\n\n  const { data: convertedData, mediaType: convertedMediaType } =\n    convertToLanguageModelV2DataContent(originalData);\n\n  let mediaType: string | undefined = convertedMediaType ?? part.mediaType;\n  let data: Uint8Array | string | URL = convertedData; // binary | base64 | url\n\n  // If the content is a URL, we check if it was downloaded:\n  if (data instanceof URL) {\n    const downloadedFile = downloadedAssets[data.toString()];\n    if (downloadedFile) {\n      data = downloadedFile.data;\n      mediaType ??= downloadedFile.mediaType;\n    }\n  }\n\n  // Now that we have the normalized data either as a URL or a Uint8Array,\n  // we can create the LanguageModelV2Part.\n  switch (type) {\n    case 'image': {\n      // When possible, try to detect the media type automatically\n      // to deal with incorrect media type inputs.\n      // When detection fails, use provided media type.\n      if (data instanceof Uint8Array || typeof data === 'string') {\n        mediaType =\n          detectMediaType({ data, signatures: imageMediaTypeSignatures }) ??\n          mediaType;\n      }\n\n      return {\n        type: 'file',\n        mediaType: mediaType ?? 'image/*', // any image\n        filename: undefined,\n        data,\n        providerOptions: part.providerOptions,\n      };\n    }\n\n    case 'file': {\n      // We must have a mediaType for files, if not, throw an error.\n      if (mediaType == null) {\n        throw new Error(`Media type is missing for file part`);\n      }\n\n      return {\n        type: 'file',\n        mediaType,\n        filename: part.filename,\n        data,\n        providerOptions: part.providerOptions,\n      };\n    }\n  }\n}\n", "import { convertBase64ToUint8Array } from '@ai-sdk/provider-utils';\n\nexport const imageMediaTypeSignatures = [\n  {\n    mediaType: 'image/gif' as const,\n    bytesPrefix: [0x47, 0x49, 0x46], // GIF\n  },\n  {\n    mediaType: 'image/png' as const,\n    bytesPrefix: [0x89, 0x50, 0x4e, 0x47], // PNG\n  },\n  {\n    mediaType: 'image/jpeg' as const,\n    bytesPrefix: [0xff, 0xd8], // JPEG\n  },\n  {\n    mediaType: 'image/webp' as const,\n    bytesPrefix: [\n      0x52,\n      0x49,\n      0x46,\n      0x46, // \"RIFF\"\n      null,\n      null,\n      null,\n      null, // file size (variable)\n      0x57,\n      0x45,\n      0x42,\n      0x50, // \"WEBP\"\n    ],\n  },\n  {\n    mediaType: 'image/bmp' as const,\n    bytesPrefix: [0x42, 0x4d],\n  },\n  {\n    mediaType: 'image/tiff' as const,\n    bytesPrefix: [0x49, 0x49, 0x2a, 0x00],\n  },\n  {\n    mediaType: 'image/tiff' as const,\n    bytesPrefix: [0x4d, 0x4d, 0x00, 0x2a],\n  },\n  {\n    mediaType: 'image/avif' as const,\n    bytesPrefix: [\n      0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70, 0x61, 0x76, 0x69, 0x66,\n    ],\n  },\n  {\n    mediaType: 'image/heic' as const,\n    bytesPrefix: [\n      0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70, 0x68, 0x65, 0x69, 0x63,\n    ],\n  },\n] as const;\n\nexport const audioMediaTypeSignatures = [\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xfb],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xfa],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xf3],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xf2],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xe3],\n  },\n  {\n    mediaType: 'audio/mpeg' as const,\n    bytesPrefix: [0xff, 0xe2],\n  },\n  {\n    mediaType: 'audio/wav' as const,\n    bytesPrefix: [\n      0x52, // R\n      0x49, // I\n      0x46, // F\n      0x46, // F\n      null,\n      null,\n      null,\n      null,\n      0x57, // W\n      0x41, // A\n      0x56, // V\n      0x45, // E\n    ],\n  },\n  {\n    mediaType: 'audio/ogg' as const,\n    bytesPrefix: [0x4f, 0x67, 0x67, 0x53],\n  },\n  {\n    mediaType: 'audio/flac' as const,\n    bytesPrefix: [0x66, 0x4c, 0x61, 0x43],\n  },\n  {\n    mediaType: 'audio/aac' as const,\n    bytesPrefix: [0x40, 0x15, 0x00, 0x00],\n  },\n  {\n    mediaType: 'audio/mp4' as const,\n    bytesPrefix: [0x66, 0x74, 0x79, 0x70],\n  },\n  {\n    mediaType: 'audio/webm',\n    bytesPrefix: [0x1a, 0x45, 0xdf, 0xa3],\n  },\n] as const;\n\nconst stripID3 = (data: Uint8Array | string) => {\n  const bytes =\n    typeof data === 'string' ? convertBase64ToUint8Array(data) : data;\n  const id3Size =\n    ((bytes[6] & 0x7f) << 21) |\n    ((bytes[7] & 0x7f) << 14) |\n    ((bytes[8] & 0x7f) << 7) |\n    (bytes[9] & 0x7f);\n\n  // The raw MP3 starts here\n  return bytes.slice(id3Size + 10);\n};\n\nfunction stripID3TagsIfPresent(data: Uint8Array | string): Uint8Array | string {\n  const hasId3 =\n    (typeof data === 'string' && data.startsWith('SUQz')) ||\n    (typeof data !== 'string' &&\n      data.length > 10 &&\n      data[0] === 0x49 && // 'I'\n      data[1] === 0x44 && // 'D'\n      data[2] === 0x33); // '3'\n\n  return hasId3 ? stripID3(data) : data;\n}\n\n/**\n * Detect the media IANA media type of a file using a list of signatures.\n *\n * @param data - The file data.\n * @param signatures - The signatures to use for detection.\n * @returns The media type of the file.\n */\nexport function detectMediaType({\n  data,\n  signatures,\n}: {\n  data: Uint8Array | string;\n  signatures: typeof audioMediaTypeSignatures | typeof imageMediaTypeSignatures;\n}): (typeof signatures)[number]['mediaType'] | undefined {\n  const processedData = stripID3TagsIfPresent(data);\n\n  // Convert the first ~18 bytes (24 base64 chars) for consistent detection logic:\n  const bytes =\n    typeof processedData === 'string'\n      ? convertBase64ToUint8Array(\n          processedData.substring(0, Math.min(processedData.length, 24)),\n        )\n      : processedData;\n\n  for (const signature of signatures) {\n    if (\n      bytes.length >= signature.bytesPrefix.length &&\n      signature.bytesPrefix.every(\n        (byte, index) => byte === null || bytes[index] === byte,\n      )\n    ) {\n      return signature.mediaType;\n    }\n  }\n\n  return undefined;\n}\n", "import { DownloadError } from './download-error';\nimport {\n  withUserAgentSuffix,\n  getRuntimeEnvironmentUserAgent,\n} from '@ai-sdk/provider-utils';\nimport { VERSION } from '../../version';\n\n/**\n * Download a file from a URL.\n *\n * @param url - The URL to download from.\n * @returns The downloaded data and media type.\n *\n * @throws DownloadError if the download fails.\n */\nexport const download = async ({ url }: { url: URL }) => {\n  const urlText = url.toString();\n  try {\n    const response = await fetch(urlText, {\n      headers: withUserAgentSuffix(\n        {},\n        `ai-sdk/${VERSION}`,\n        getRuntimeEnvironmentUserAgent(),\n      ),\n    });\n\n    if (!response.ok) {\n      throw new DownloadError({\n        url: urlText,\n        statusCode: response.status,\n        statusText: response.statusText,\n      });\n    }\n\n    return {\n      data: new Uint8Array(await response.arrayBuffer()),\n      mediaType: response.headers.get('content-type') ?? undefined,\n    };\n  } catch (error) {\n    if (DownloadError.isInstance(error)) {\n      throw error;\n    }\n\n    throw new DownloadError({ url: urlText, cause: error });\n  }\n};\n", "declare const __PACKAGE_VERSION__: string | undefined;\nexport const VERSION: string =\n  typeof __PACKAGE_VERSION__ !== 'undefined'\n    ? __PACKAGE_VERSION__\n    : '0.0.0-test';\n", "import { download as originalDownload } from './download';\n\n/**\n * Experimental. Can change in patch versions without warning.\n *\n * Download function. Called with the array of URLs and a boolean indicating\n * whether the URL is supported by the model.\n *\n * The download function can decide for each URL:\n * - to return null (which means that the URL should be passed to the model)\n * - to download the asset and return the data (incl. retries, authentication, etc.)\n *\n * Should throw DownloadError if the download fails.\n *\n * Should return an array of objects sorted by the order of the requested downloads.\n * For each object, the data should be a Uint8Array if the URL was downloaded.\n * For each object, the mediaType should be the media type of the downloaded asset.\n * For each object, the data should be null if the URL should be passed through as is.\n */\nexport type DownloadFunction = (\n  options: Array<{\n    url: URL;\n    isUrlSupportedByModel: boolean;\n  }>,\n) => PromiseLike<\n  Array<{\n    data: Uint8Array;\n    mediaType: string | undefined;\n  } | null>\n>;\n\n/**\n * Default download function.\n * Downloads the file if it is not supported by the model.\n */\nexport const createDefaultDownloadFunction =\n  (download: typeof originalDownload = originalDownload): DownloadFunction =>\n  requestedDownloads =>\n    Promise.all(\n      requestedDownloads.map(async requestedDownload =>\n        requestedDownload.isUrlSupportedByModel\n          ? null\n          : download(requestedDownload),\n      ),\n    );\n", "import { AISDKError, LanguageModelV2DataContent } from '@ai-sdk/provider';\nimport {\n  convertBase64ToUint8Array,\n  convertUint8ArrayToBase64,\n  DataContent,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { InvalidDataContentError } from './invalid-data-content-error';\nimport { splitDataUrl } from './split-data-url';\n\n/**\n@internal\n */\nexport const dataContentSchema: z.ZodType<DataContent> = z.union([\n  z.string(),\n  z.instanceof(Uint8Array),\n  z.instanceof(ArrayBuffer),\n  z.custom<Buffer>(\n    // Buffer might not be available in some environments such as CloudFlare:\n    (value: unknown): value is Buffer =>\n      globalThis.Buffer?.isBuffer(value) ?? false,\n    { message: 'Must be a Buffer' },\n  ),\n]);\n\nexport function convertToLanguageModelV2DataContent(\n  content: DataContent | URL,\n): {\n  data: LanguageModelV2DataContent;\n  mediaType: string | undefined;\n} {\n  // Buffer & Uint8Array:\n  if (content instanceof Uint8Array) {\n    return { data: content, mediaType: undefined };\n  }\n\n  // ArrayBuffer needs conversion to Uint8Array (lightweight):\n  if (content instanceof ArrayBuffer) {\n    return { data: new Uint8Array(content), mediaType: undefined };\n  }\n\n  // Attempt to create a URL from the data. If it fails, we can assume the data\n  // is not a URL and likely some other sort of data.\n  if (typeof content === 'string') {\n    try {\n      content = new URL(content);\n    } catch (error) {\n      // ignored\n    }\n  }\n\n  // Extract data from data URL:\n  if (content instanceof URL && content.protocol === 'data:') {\n    const { mediaType: dataUrlMediaType, base64Content } = splitDataUrl(\n      content.toString(),\n    );\n\n    if (dataUrlMediaType == null || base64Content == null) {\n      throw new AISDKError({\n        name: 'InvalidDataContentError',\n        message: `Invalid data URL format in content ${content.toString()}`,\n      });\n    }\n\n    return { data: base64Content, mediaType: dataUrlMediaType };\n  }\n\n  return { data: content, mediaType: undefined };\n}\n\n/**\nConverts data content to a base64-encoded string.\n\n@param content - Data content to convert.\n@returns Base64-encoded string.\n*/\nexport function convertDataContentToBase64String(content: DataContent): string {\n  if (typeof content === 'string') {\n    return content;\n  }\n\n  if (content instanceof ArrayBuffer) {\n    return convertUint8ArrayToBase64(new Uint8Array(content));\n  }\n\n  return convertUint8ArrayToBase64(content);\n}\n\n/**\nConverts data content to a Uint8Array.\n\n@param content - Data content to convert.\n@returns Uint8Array.\n */\nexport function convertDataContentToUint8Array(\n  content: DataContent,\n): Uint8Array {\n  if (content instanceof Uint8Array) {\n    return content;\n  }\n\n  if (typeof content === 'string') {\n    try {\n      return convertBase64ToUint8Array(content);\n    } catch (error) {\n      throw new InvalidDataContentError({\n        message:\n          'Invalid data content. Content string is not a base64-encoded media.',\n        content,\n        cause: error,\n      });\n    }\n  }\n\n  if (content instanceof ArrayBuffer) {\n    return new Uint8Array(content);\n  }\n\n  throw new InvalidDataContentError({ content });\n}\n\n/**\n * Converts a Uint8Array to a string of text.\n *\n * @param uint8Array - The Uint8Array to convert.\n * @returns The converted string.\n */\nexport function convertUint8ArrayToText(uint8Array: Uint8Array): string {\n  try {\n    return new TextDecoder().decode(uint8Array);\n  } catch (error) {\n    throw new Error('Error decoding Uint8Array to text');\n  }\n}\n", "export function splitDataUrl(dataUrl: string): {\n  mediaType: string | undefined;\n  base64Content: string | undefined;\n} {\n  try {\n    const [header, base64Content] = dataUrl.split(',');\n    return {\n      mediaType: header.split(';')[0].split(':')[1],\n      base64Content,\n    };\n  } catch (error) {\n    return {\n      mediaType: undefined,\n      base64Content: undefined,\n    };\n  }\n}\n", "import { InvalidArgumentError } from '../error/invalid-argument-error';\nimport { CallSettings } from './call-settings';\n\n/**\n * Validates call settings and returns a new object with limited values.\n */\nexport function prepareCallSettings({\n  maxOutputTokens,\n  temperature,\n  topP,\n  topK,\n  presencePenalty,\n  frequencyPenalty,\n  seed,\n  stopSequences,\n}: Omit<CallSettings, 'abortSignal' | 'headers' | 'maxRetries'>): Omit<\n  CallSettings,\n  'abortSignal' | 'headers' | 'maxRetries'\n> {\n  if (maxOutputTokens != null) {\n    if (!Number.isInteger(maxOutputTokens)) {\n      throw new InvalidArgumentError({\n        parameter: 'maxOutputTokens',\n        value: maxOutputTokens,\n        message: 'maxOutputTokens must be an integer',\n      });\n    }\n\n    if (maxOutputTokens < 1) {\n      throw new InvalidArgumentError({\n        parameter: 'maxOutputTokens',\n        value: maxOutputTokens,\n        message: 'maxOutputTokens must be >= 1',\n      });\n    }\n  }\n\n  if (temperature != null) {\n    if (typeof temperature !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'temperature',\n        value: temperature,\n        message: 'temperature must be a number',\n      });\n    }\n  }\n\n  if (topP != null) {\n    if (typeof topP !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'topP',\n        value: topP,\n        message: 'topP must be a number',\n      });\n    }\n  }\n\n  if (topK != null) {\n    if (typeof topK !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'topK',\n        value: topK,\n        message: 'topK must be a number',\n      });\n    }\n  }\n\n  if (presencePenalty != null) {\n    if (typeof presencePenalty !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'presencePenalty',\n        value: presencePenalty,\n        message: 'presencePenalty must be a number',\n      });\n    }\n  }\n\n  if (frequencyPenalty != null) {\n    if (typeof frequencyPenalty !== 'number') {\n      throw new InvalidArgumentError({\n        parameter: 'frequencyPenalty',\n        value: frequencyPenalty,\n        message: 'frequencyPenalty must be a number',\n      });\n    }\n  }\n\n  if (seed != null) {\n    if (!Number.isInteger(seed)) {\n      throw new InvalidArgumentError({\n        parameter: 'seed',\n        value: seed,\n        message: 'seed must be an integer',\n      });\n    }\n  }\n\n  return {\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    presencePenalty,\n    frequencyPenalty,\n    stopSequences,\n    seed,\n  };\n}\n", "import {\n  LanguageModelV2FunctionTool,\n  LanguageModelV2ProviderDefinedTool,\n  LanguageModelV2ToolChoice,\n} from '@ai-sdk/provider';\nimport { asSchema } from '@ai-sdk/provider-utils';\nimport { isNonEmptyObject } from '../util/is-non-empty-object';\nimport { ToolSet } from '../generate-text';\nimport { ToolChoice } from '../types/language-model';\n\nexport function prepareToolsAndToolChoice<TOOLS extends ToolSet>({\n  tools,\n  toolChoice,\n  activeTools,\n}: {\n  tools: TOOLS | undefined;\n  toolChoice: ToolChoice<TOOLS> | undefined;\n  activeTools: Array<keyof TOOLS> | undefined;\n}): {\n  tools:\n    | Array<LanguageModelV2FunctionTool | LanguageModelV2ProviderDefinedTool>\n    | undefined;\n  toolChoice: LanguageModelV2ToolChoice | undefined;\n} {\n  if (!isNonEmptyObject(tools)) {\n    return {\n      tools: undefined,\n      toolChoice: undefined,\n    };\n  }\n\n  // when activeTools is provided, we only include the tools that are in the list:\n  const filteredTools =\n    activeTools != null\n      ? Object.entries(tools).filter(([name]) =>\n          activeTools.includes(name as keyof TOOLS),\n        )\n      : Object.entries(tools);\n\n  return {\n    tools: filteredTools.map(([name, tool]) => {\n      const toolType = tool.type;\n      switch (toolType) {\n        case undefined:\n        case 'dynamic':\n        case 'function':\n          return {\n            type: 'function' as const,\n            name,\n            description: tool.description,\n            inputSchema: asSchema(tool.inputSchema).jsonSchema,\n            providerOptions: tool.providerOptions,\n          };\n        case 'provider-defined':\n          return {\n            type: 'provider-defined' as const,\n            name,\n            id: tool.id,\n            args: tool.args,\n          };\n        default: {\n          const exhaustiveCheck: never = toolType;\n          throw new Error(`Unsupported tool type: ${exhaustiveCheck}`);\n        }\n      }\n    }),\n    toolChoice:\n      toolChoice == null\n        ? { type: 'auto' }\n        : typeof toolChoice === 'string'\n          ? { type: toolChoice }\n          : { type: 'tool' as const, toolName: toolChoice.toolName as string },\n  };\n}\n", "export function isNonEmptyObject(\n  object: Record<string, unknown> | undefined | null,\n): object is Record<string, unknown> {\n  return object != null && Object.keys(object).length > 0;\n}\n", "import { InvalidPromptError } from '@ai-sdk/provider';\nimport { ModelMessage, safeValidateTypes } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { modelMessageSchema } from './message';\nimport { Prompt } from './prompt';\n\nexport type StandardizedPrompt = {\n  /**\n   * System message.\n   */\n  system?: string;\n\n  /**\n   * Messages.\n   */\n  messages: ModelMessage[];\n};\n\nexport async function standardizePrompt(\n  prompt: Prompt,\n): Promise<StandardizedPrompt> {\n  if (prompt.prompt == null && prompt.messages == null) {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'prompt or messages must be defined',\n    });\n  }\n\n  if (prompt.prompt != null && prompt.messages != null) {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'prompt and messages cannot be defined at the same time',\n    });\n  }\n\n  // validate that system is a string\n  if (prompt.system != null && typeof prompt.system !== 'string') {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'system must be a string',\n    });\n  }\n\n  let messages: ModelMessage[];\n\n  if (prompt.prompt != null && typeof prompt.prompt === 'string') {\n    messages = [{ role: 'user', content: prompt.prompt }];\n  } else if (prompt.prompt != null && Array.isArray(prompt.prompt)) {\n    messages = prompt.prompt;\n  } else if (prompt.messages != null) {\n    messages = prompt.messages;\n  } else {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'prompt or messages must be defined',\n    });\n  }\n\n  if (messages.length === 0) {\n    throw new InvalidPromptError({\n      prompt,\n      message: 'messages must not be empty',\n    });\n  }\n\n  const validationResult = await safeValidateTypes({\n    value: messages,\n    schema: z.array(modelMessageSchema),\n  });\n\n  if (!validationResult.success) {\n    throw new InvalidPromptError({\n      prompt,\n      message:\n        'The messages must be a ModelMessage[]. ' +\n        'If you have passed a UIMessage[], you can use convertToModelMessages to convert them.',\n      cause: validationResult.error,\n    });\n  }\n\n  return {\n    messages,\n    system: prompt.system,\n  };\n}\n", "import {\n  AssistantModelMessage,\n  ModelMessage,\n  SystemModelMessage,\n  ToolModelMessage,\n  UserModelMessage,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { providerMetadataSchema } from '../types/provider-metadata';\nimport {\n  filePartSchema,\n  imagePartSchema,\n  reasoningPartSchema,\n  textPartSchema,\n  toolCallPartSchema,\n  toolResultPartSchema,\n} from './content-part';\n\n/**\n@deprecated Use `SystemModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreSystemMessage = SystemModelMessage;\n\nexport const systemModelMessageSchema: z.ZodType<SystemModelMessage> = z.object(\n  {\n    role: z.literal('system'),\n    content: z.string(),\n    providerOptions: providerMetadataSchema.optional(),\n  },\n);\n\n/**\n@deprecated Use `systemModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreSystemMessageSchema = systemModelMessageSchema;\n\n/**\n@deprecated Use `UserModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreUserMessage = UserModelMessage;\n\nexport const userModelMessageSchema: z.ZodType<UserModelMessage> = z.object({\n  role: z.literal('user'),\n  content: z.union([\n    z.string(),\n    z.array(z.union([textPartSchema, imagePartSchema, filePartSchema])),\n  ]),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@deprecated Use `userModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreUserMessageSchema = userModelMessageSchema;\n\n/**\n@deprecated Use `AssistantModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreAssistantMessage = AssistantModelMessage;\n\nexport const assistantModelMessageSchema: z.ZodType<AssistantModelMessage> =\n  z.object({\n    role: z.literal('assistant'),\n    content: z.union([\n      z.string(),\n      z.array(\n        z.union([\n          textPartSchema,\n          filePartSchema,\n          reasoningPartSchema,\n          toolCallPartSchema,\n          toolResultPartSchema,\n        ]),\n      ),\n    ]),\n    providerOptions: providerMetadataSchema.optional(),\n  });\n\n/**\n@deprecated Use `assistantModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreAssistantMessageSchema = assistantModelMessageSchema;\n\n/**\n@deprecated Use `ToolModelMessage` instead.\n */\n// TODO remove in AI SDK 6\nexport type CoreToolMessage = ToolModelMessage;\n\nexport const toolModelMessageSchema: z.ZodType<ToolModelMessage> = z.object({\n  role: z.literal('tool'),\n  content: z.array(toolResultPartSchema),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@deprecated Use `toolModelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreToolMessageSchema = toolModelMessageSchema;\n\n/**\n@deprecated Use `ModelMessage` instead.\n   */\n// TODO remove in AI SDK 6\nexport type CoreMessage = ModelMessage;\n\nexport const modelMessageSchema: z.ZodType<ModelMessage> = z.union([\n  systemModelMessageSchema,\n  userModelMessageSchema,\n  assistantModelMessageSchema,\n  toolModelMessageSchema,\n]);\n\n/**\n@deprecated Use `modelMessageSchema` instead.\n */\n// TODO remove in AI SDK 6\nexport const coreMessageSchema: z.ZodType<CoreMessage> = modelMessageSchema;\n", "import { SharedV2ProviderMetadata } from '@ai-sdk/provider';\nimport { z } from 'zod/v4';\nimport { jsonValueSchema } from './json-value';\n\n/**\nAdditional provider-specific metadata that is returned from the provider.\n\nThis is needed to enable provider-specific functionality that can be\nfully encapsulated in the provider.\n */\nexport type ProviderMetadata = SharedV2ProviderMetadata;\n\nexport const providerMetadataSchema: z.ZodType<ProviderMetadata> = z.record(\n  z.string(),\n  z.record(z.string(), jsonValueSchema),\n);\n", "import { JSONValue as OriginalJSONValue } from '@ai-sdk/provider';\nimport { z } from 'zod/v4';\n\nexport const jsonValueSchema: z.ZodType<JSONValue> = z.lazy(() =>\n  z.union([\n    z.null(),\n    z.string(),\n    z.number(),\n    z.boolean(),\n    z.record(z.string(), jsonValueSchema),\n    z.array(jsonValueSchema),\n  ]),\n);\n\nexport type JSONValue = OriginalJSONValue;\n", "import { LanguageModelV2ToolResultOutput } from '@ai-sdk/provider';\nimport {\n  FilePart,\n  ImagePart,\n  ProviderOptions,\n  ReasoningPart,\n  TextPart,\n  ToolResultPart,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { jsonValueSchema } from '../types/json-value';\nimport { providerMetadataSchema } from '../types/provider-metadata';\nimport { dataContentSchema } from './data-content';\n\n/**\n@internal\n */\nexport const textPartSchema: z.ZodType<TextPart> = z.object({\n  type: z.literal('text'),\n  text: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@internal\n */\nexport const imagePartSchema: z.ZodType<ImagePart> = z.object({\n  type: z.literal('image'),\n  image: z.union([dataContentSchema, z.instanceof(URL)]),\n  mediaType: z.string().optional(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@internal\n */\nexport const filePartSchema: z.ZodType<FilePart> = z.object({\n  type: z.literal('file'),\n  data: z.union([dataContentSchema, z.instanceof(URL)]),\n  filename: z.string().optional(),\n  mediaType: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\n@internal\n */\nexport const reasoningPartSchema: z.ZodType<ReasoningPart> = z.object({\n  type: z.literal('reasoning'),\n  text: z.string(),\n  providerOptions: providerMetadataSchema.optional(),\n});\n\n/**\nTool call content part of a prompt. It contains a tool call (usually generated by the AI model).\n */\nexport interface ToolCallPart {\n  type: 'tool-call';\n\n  /**\nID of the tool call. This ID is used to match the tool call with the tool result.\n */\n  toolCallId: string;\n\n  /**\nName of the tool that is being called.\n */\n  toolName: string;\n\n  /**\nArguments of the tool call. This is a JSON-serializable object that matches the tool's input schema.\n   */\n  input: unknown;\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n  providerOptions?: ProviderOptions;\n}\n\n/**\n@internal\n */\nexport const toolCallPartSchema: z.ZodType<ToolCallPart> = z.object({\n  type: z.literal('tool-call'),\n  toolCallId: z.string(),\n  toolName: z.string(),\n  input: z.unknown(),\n  providerOptions: providerMetadataSchema.optional(),\n  providerExecuted: z.boolean().optional(),\n}) as z.ZodType<ToolCallPart>; // necessary bc input is optional on Zod type\n\n/**\n@internal\n */\nexport const outputSchema: z.ZodType<LanguageModelV2ToolResultOutput> =\n  z.discriminatedUnion('type', [\n    z.object({\n      type: z.literal('text'),\n      value: z.string(),\n    }),\n    z.object({\n      type: z.literal('json'),\n      value: jsonValueSchema,\n    }),\n    z.object({\n      type: z.literal('error-text'),\n      value: z.string(),\n    }),\n    z.object({\n      type: z.literal('error-json'),\n      value: jsonValueSchema,\n    }),\n    z.object({\n      type: z.literal('content'),\n      value: z.array(\n        z.union([\n          z.object({\n            type: z.literal('text'),\n            text: z.string(),\n          }),\n          z.object({\n            type: z.literal('media'),\n            data: z.string(),\n            mediaType: z.string(),\n          }),\n        ]),\n      ),\n    }),\n  ]);\n\n/**\n@internal\n */\nexport const toolResultPartSchema: z.ZodType<ToolResultPart> = z.object({\n  type: z.literal('tool-result'),\n  toolCallId: z.string(),\n  toolName: z.string(),\n  output: outputSchema,\n  providerOptions: providerMetadataSchema.optional(),\n}) as z.ZodType<ToolResultPart>; // necessary bc result is optional on Zod type\n", "import {\n  GatewayAuthenticationError,\n  GatewayModelNotFoundError,\n} from '@ai-sdk/gateway';\nimport { AISDKError } from '@ai-sdk/provider';\n\nexport function wrapGatewayError(error: unknown): unknown {\n  if (\n    GatewayAuthenticationError.isInstance(error) ||\n    GatewayModelNotFoundError.isInstance(error)\n  ) {\n    return new AISDKError({\n      name: 'GatewayError',\n      message:\n        'Vercel AI Gateway access failed. ' +\n        'If you want to use AI SDK providers directly, use the providers, e.g. @ai-sdk/openai, ' +\n        'or register a different global default provider.',\n      cause: error,\n    });\n  }\n\n  return error;\n}\n", "import { TelemetrySettings } from './telemetry-settings';\n\nexport function assembleOperationName({\n  operationId,\n  telemetry,\n}: {\n  operationId: string;\n  telemetry?: TelemetrySettings;\n}) {\n  return {\n    // standardized operation and resource name:\n    'operation.name': `${operationId}${\n      telemetry?.functionId != null ? ` ${telemetry.functionId}` : ''\n    }`,\n    'resource.name': telemetry?.functionId,\n\n    // detailed, AI SDK specific data:\n    'ai.operationId': operationId,\n    'ai.telemetry.functionId': telemetry?.functionId,\n  };\n}\n", "import { Attributes } from '@opentelemetry/api';\nimport { CallSettings } from '../prompt/call-settings';\nimport { TelemetrySettings } from './telemetry-settings';\n\nexport function getBaseTelemetryAttributes({\n  model,\n  settings,\n  telemetry,\n  headers,\n}: {\n  model: { modelId: string; provider: string };\n  settings: Omit<CallSettings, 'abortSignal' | 'headers' | 'temperature'>;\n  telemetry: TelemetrySettings | undefined;\n  headers: Record<string, string | undefined> | undefined;\n}): Attributes {\n  return {\n    'ai.model.provider': model.provider,\n    'ai.model.id': model.modelId,\n\n    // settings:\n    ...Object.entries(settings).reduce((attributes, [key, value]) => {\n      attributes[`ai.settings.${key}`] = value;\n      return attributes;\n    }, {} as Attributes),\n\n    // add metadata as attributes:\n    ...Object.entries(telemetry?.metadata ?? {}).reduce(\n      (attributes, [key, value]) => {\n        attributes[`ai.telemetry.metadata.${key}`] = value;\n        return attributes;\n      },\n      {} as Attributes,\n    ),\n\n    // request headers\n    ...Object.entries(headers ?? {}).reduce((attributes, [key, value]) => {\n      if (value !== undefined) {\n        attributes[`ai.request.headers.${key}`] = value;\n      }\n      return attributes;\n    }, {} as Attributes),\n  };\n}\n", "import { Tracer, trace } from '@opentelemetry/api';\nimport { noopTracer } from './noop-tracer';\n\nexport function getTracer({\n  isEnabled = false,\n  tracer,\n}: {\n  isEnabled?: boolean;\n  tracer?: Tracer;\n} = {}): Tracer {\n  if (!isEnabled) {\n    return noopTracer;\n  }\n\n  if (tracer) {\n    return tracer;\n  }\n\n  return trace.getTracer('ai');\n}\n", "import { Span, SpanContext, Tracer } from '@opentelemetry/api';\n\n/**\n * Tracer implementation that does nothing (null object).\n */\nexport const noopTracer: Tracer = {\n  startSpan(): Span {\n    return noopSpan;\n  },\n\n  startActiveSpan<F extends (span: Span) => unknown>(\n    name: unknown,\n    arg1: unknown,\n    arg2?: unknown,\n    arg3?: F,\n  ): ReturnType<any> {\n    if (typeof arg1 === 'function') {\n      return arg1(noopSpan);\n    }\n    if (typeof arg2 === 'function') {\n      return arg2(noopSpan);\n    }\n    if (typeof arg3 === 'function') {\n      return arg3(noopSpan);\n    }\n  },\n};\n\nconst noopSpan: Span = {\n  spanContext() {\n    return noopSpanContext;\n  },\n  setAttribute() {\n    return this;\n  },\n  setAttributes() {\n    return this;\n  },\n  addEvent() {\n    return this;\n  },\n  addLink() {\n    return this;\n  },\n  addLinks() {\n    return this;\n  },\n  setStatus() {\n    return this;\n  },\n  updateName() {\n    return this;\n  },\n  end() {\n    return this;\n  },\n  isRecording() {\n    return false;\n  },\n  recordException() {\n    return this;\n  },\n};\n\nconst noopSpanContext: SpanContext = {\n  traceId: '',\n  spanId: '',\n  traceFlags: 0,\n};\n", "import { Attributes, Span, Tracer, SpanStatusCode } from '@opentelemetry/api';\n\nexport function recordSpan<T>({\n  name,\n  tracer,\n  attributes,\n  fn,\n  endWhenDone = true,\n}: {\n  name: string;\n  tracer: Tracer;\n  attributes: Attributes;\n  fn: (span: Span) => Promise<T>;\n  endWhenDone?: boolean;\n}) {\n  return tracer.startActiveSpan(name, { attributes }, async span => {\n    try {\n      const result = await fn(span);\n\n      if (endWhenDone) {\n        span.end();\n      }\n\n      return result;\n    } catch (error) {\n      try {\n        recordErrorOnSpan(span, error);\n      } finally {\n        // always stop the span when there is an error:\n        span.end();\n      }\n\n      throw error;\n    }\n  });\n}\n\n/**\n * Record an error on a span. If the error is an instance of Error, an exception event will be recorded on the span, otherwise\n * the span will be set to an error status.\n *\n * @param span - The span to record the error on.\n * @param error - The error to record on the span.\n */\nexport function recordErrorOnSpan(span: Span, error: unknown) {\n  if (error instanceof Error) {\n    span.recordException({\n      name: error.name,\n      message: error.message,\n      stack: error.stack,\n    });\n    span.setStatus({\n      code: SpanStatusCode.ERROR,\n      message: error.message,\n    });\n  } else {\n    span.setStatus({ code: SpanStatusCode.ERROR });\n  }\n}\n", "import type { Attributes, AttributeValue } from '@opentelemetry/api';\nimport type { TelemetrySettings } from './telemetry-settings';\n\nexport function selectTelemetryAttributes({\n  telemetry,\n  attributes,\n}: {\n  telemetry?: TelemetrySettings;\n  attributes: {\n    [attributeKey: string]:\n      | AttributeValue\n      | { input: () => AttributeValue | undefined }\n      | { output: () => AttributeValue | undefined }\n      | undefined;\n  };\n}): Attributes {\n  // when telemetry is disabled, return an empty object to avoid serialization overhead:\n  if (telemetry?.isEnabled !== true) {\n    return {};\n  }\n\n  return Object.entries(attributes).reduce((attributes, [key, value]) => {\n    if (value == null) {\n      return attributes;\n    }\n\n    // input value, check if it should be recorded:\n    if (\n      typeof value === 'object' &&\n      'input' in value &&\n      typeof value.input === 'function'\n    ) {\n      // default to true:\n      if (telemetry?.recordInputs === false) {\n        return attributes;\n      }\n\n      const result = value.input();\n\n      return result == null ? attributes : { ...attributes, [key]: result };\n    }\n\n    // output value, check if it should be recorded:\n    if (\n      typeof value === 'object' &&\n      'output' in value &&\n      typeof value.output === 'function'\n    ) {\n      // default to true:\n      if (telemetry?.recordOutputs === false) {\n        return attributes;\n      }\n\n      const result = value.output();\n\n      return result == null ? attributes : { ...attributes, [key]: result };\n    }\n\n    // value is an attribute value already:\n    return { ...attributes, [key]: value };\n  }, {});\n}\n", "import {\n  LanguageModelV2Message,\n  LanguageModelV2Prompt,\n} from '@ai-sdk/provider';\nimport { convertDataContentToBase64String } from '../prompt/data-content';\n\n/**\n * Helper utility to serialize prompt content for OpenTelemetry tracing.\n * It is initially created because normalized LanguageModelV1Prompt carries\n * images as Uint8Arrays, on which JSON.stringify acts weirdly, converting\n * them to objects with stringified indices as keys, e.g. {\"0\": 42, \"1\": 69 }.\n */\nexport function stringifyForTelemetry(prompt: LanguageModelV2Prompt): string {\n  return JSON.stringify(\n    prompt.map((message: LanguageModelV2Message) => ({\n      ...message,\n      content:\n        typeof message.content === 'string'\n          ? message.content\n          : message.content.map(part =>\n              part.type === 'file'\n                ? {\n                    ...part,\n                    data:\n                      part.data instanceof Uint8Array\n                        ? convertDataContentToBase64String(part.data)\n                        : part.data,\n                  }\n                : part,\n            ),\n    })),\n  );\n}\n", "import { LanguageModelV2Usage } from '@ai-sdk/provider';\n\n/**\nRepresents the number of tokens used in a prompt and completion.\n */\nexport type LanguageModelUsage = LanguageModelV2Usage;\n\n/**\nRepresents the number of tokens used in an embedding.\n */\n// TODO replace with EmbeddingModelV2Usage\nexport type EmbeddingModelUsage = {\n  /**\nThe number of tokens used in the embedding.\n   */\n  tokens: number;\n};\n\nexport function addLanguageModelUsage(\n  usage1: LanguageModelUsage,\n  usage2: LanguageModelUsage,\n): LanguageModelUsage {\n  return {\n    inputTokens: addTokenCounts(usage1.inputTokens, usage2.inputTokens),\n    outputTokens: addTokenCounts(usage1.outputTokens, usage2.outputTokens),\n    totalTokens: addTokenCounts(usage1.totalTokens, usage2.totalTokens),\n    reasoningTokens: addTokenCounts(\n      usage1.reasoningTokens,\n      usage2.reasoningTokens,\n    ),\n    cachedInputTokens: addTokenCounts(\n      usage1.cachedInputTokens,\n      usage2.cachedInputTokens,\n    ),\n  };\n}\n\nfunction addTokenCounts(\n  tokenCount1: number | undefined,\n  tokenCount2: number | undefined,\n): number | undefined {\n  return tokenCount1 == null && tokenCount2 == null\n    ? undefined\n    : (tokenCount1 ?? 0) + (tokenCount2 ?? 0);\n}\n", "export function asArray<T>(value: T | T[] | undefined): T[] {\n  return value === undefined ? [] : Array.isArray(value) ? value : [value];\n}\n", "import { APICallError } from '@ai-sdk/provider';\nimport { delay, getErrorMessage, isAbortError } from '@ai-sdk/provider-utils';\nimport { RetryError } from './retry-error';\n\nexport type RetryFunction = <OUTPUT>(\n  fn: () => PromiseLike<OUTPUT>,\n) => PromiseLike<OUTPUT>;\n\nfunction getRetryDelayInMs({\n  error,\n  exponentialBackoffDelay,\n}: {\n  error: APICallError;\n  exponentialBackoffDelay: number;\n}): number {\n  const headers = error.responseHeaders;\n\n  if (!headers) return exponentialBackoffDelay;\n\n  let ms: number | undefined;\n\n  // retry-ms is more precise than retry-after and used by e.g. OpenAI\n  const retryAfterMs = headers['retry-after-ms'];\n  if (retryAfterMs) {\n    const timeoutMs = parseFloat(retryAfterMs);\n    if (!Number.isNaN(timeoutMs)) {\n      ms = timeoutMs;\n    }\n  }\n\n  // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n  const retryAfter = headers['retry-after'];\n  if (retryAfter && ms === undefined) {\n    const timeoutSeconds = parseFloat(retryAfter);\n    if (!Number.isNaN(timeoutSeconds)) {\n      ms = timeoutSeconds * 1000;\n    } else {\n      ms = Date.parse(retryAfter) - Date.now();\n    }\n  }\n\n  // check that the delay is reasonable:\n  if (\n    ms != null &&\n    !Number.isNaN(ms) &&\n    0 <= ms &&\n    (ms < 60 * 1000 || ms < exponentialBackoffDelay)\n  ) {\n    return ms;\n  }\n\n  return exponentialBackoffDelay;\n}\n\n/**\nThe `retryWithExponentialBackoffRespectingRetryHeaders` strategy retries a failed API call with an exponential backoff,\nwhile respecting rate limit headers (retry-after-ms and retry-after) if they are provided and reasonable (0-60 seconds).\nYou can configure the maximum number of retries, the initial delay, and the backoff factor.\n */\nexport const retryWithExponentialBackoffRespectingRetryHeaders =\n  ({\n    maxRetries = 2,\n    initialDelayInMs = 2000,\n    backoffFactor = 2,\n    abortSignal,\n  }: {\n    maxRetries?: number;\n    initialDelayInMs?: number;\n    backoffFactor?: number;\n    abortSignal?: AbortSignal;\n  } = {}): RetryFunction =>\n  async <OUTPUT>(f: () => PromiseLike<OUTPUT>) =>\n    _retryWithExponentialBackoff(f, {\n      maxRetries,\n      delayInMs: initialDelayInMs,\n      backoffFactor,\n      abortSignal,\n    });\n\nasync function _retryWithExponentialBackoff<OUTPUT>(\n  f: () => PromiseLike<OUTPUT>,\n  {\n    maxRetries,\n    delayInMs,\n    backoffFactor,\n    abortSignal,\n  }: {\n    maxRetries: number;\n    delayInMs: number;\n    backoffFactor: number;\n    abortSignal: AbortSignal | undefined;\n  },\n  errors: unknown[] = [],\n): Promise<OUTPUT> {\n  try {\n    return await f();\n  } catch (error) {\n    if (isAbortError(error)) {\n      throw error; // don't retry when the request was aborted\n    }\n\n    if (maxRetries === 0) {\n      throw error; // don't wrap the error when retries are disabled\n    }\n\n    const errorMessage = getErrorMessage(error);\n    const newErrors = [...errors, error];\n    const tryNumber = newErrors.length;\n\n    if (tryNumber > maxRetries) {\n      throw new RetryError({\n        message: `Failed after ${tryNumber} attempts. Last error: ${errorMessage}`,\n        reason: 'maxRetriesExceeded',\n        errors: newErrors,\n      });\n    }\n\n    if (\n      error instanceof Error &&\n      APICallError.isInstance(error) &&\n      error.isRetryable === true &&\n      tryNumber <= maxRetries\n    ) {\n      await delay(\n        getRetryDelayInMs({\n          error,\n          exponentialBackoffDelay: delayInMs,\n        }),\n        { abortSignal },\n      );\n\n      return _retryWithExponentialBackoff(\n        f,\n        {\n          maxRetries,\n          delayInMs: backoffFactor * delayInMs,\n          backoffFactor,\n          abortSignal,\n        },\n        newErrors,\n      );\n    }\n\n    if (tryNumber === 1) {\n      throw error; // don't wrap the error when a non-retryable error occurs on the first try\n    }\n\n    throw new RetryError({\n      message: `Failed after ${tryNumber} attempts with non-retryable error: '${errorMessage}'`,\n      reason: 'errorNotRetryable',\n      errors: newErrors,\n    });\n  }\n}\n", "import { InvalidArgumentError } from '../error/invalid-argument-error';\nimport {\n  RetryFunction,\n  retryWithExponentialBackoffRespectingRetryHeaders,\n} from '../util/retry-with-exponential-backoff';\n\n/**\n * Validate and prepare retries.\n */\nexport function prepareRetries({\n  maxRetries,\n  abortSignal,\n}: {\n  maxRetries: number | undefined;\n  abortSignal: AbortSignal | undefined;\n}): {\n  maxRetries: number;\n  retry: RetryFunction;\n} {\n  if (maxRetries != null) {\n    if (!Number.isInteger(maxRetries)) {\n      throw new InvalidArgumentError({\n        parameter: 'maxRetries',\n        value: maxRetries,\n        message: 'maxRetries must be an integer',\n      });\n    }\n\n    if (maxRetries < 0) {\n      throw new InvalidArgumentError({\n        parameter: 'maxRetries',\n        value: maxRetries,\n        message: 'maxRetries must be >= 0',\n      });\n    }\n  }\n\n  const maxRetriesResult = maxRetries ?? 2;\n\n  return {\n    maxRetries: maxRetriesResult,\n    retry: retryWithExponentialBackoffRespectingRetryHeaders({\n      maxRetries: maxRetriesResult,\n      abortSignal,\n    }),\n  };\n}\n", "import { LanguageModelV2Content, LanguageModelV2Text } from '@ai-sdk/provider';\n\nexport function extractTextContent(\n  content: LanguageModelV2Content[],\n): string | undefined {\n  const parts = content.filter(\n    (content): content is LanguageModelV2Text => content.type === 'text',\n  );\n\n  if (parts.length === 0) {\n    return undefined;\n  }\n\n  return parts.map(content => content.text).join('');\n}\n", "import {\n  convertBase64ToUint8Array,\n  convertUint8ArrayToBase64,\n} from '@ai-sdk/provider-utils';\n\n/**\n * A generated file.\n */\nexport interface GeneratedFile {\n  /**\nFile as a base64 encoded string.\n     */\n  readonly base64: string;\n\n  /**\nFile as a Uint8Array.\n     */\n  readonly uint8Array: Uint8Array;\n\n  /**\nThe IANA media type of the file.\n\n@see https://www.iana.org/assignments/media-types/media-types.xhtml\n   */\n  readonly mediaType: string;\n}\n\nexport class DefaultGeneratedFile implements GeneratedFile {\n  private base64Data: string | undefined;\n  private uint8ArrayData: Uint8Array | undefined;\n\n  readonly mediaType: string;\n\n  constructor({\n    data,\n    mediaType,\n  }: {\n    data: string | Uint8Array;\n    mediaType: string;\n  }) {\n    const isUint8Array = data instanceof Uint8Array;\n    this.base64Data = isUint8Array ? undefined : data;\n    this.uint8ArrayData = isUint8Array ? data : undefined;\n    this.mediaType = mediaType;\n  }\n\n  // lazy conversion with caching to avoid unnecessary conversion overhead:\n  get base64() {\n    if (this.base64Data == null) {\n      this.base64Data = convertUint8ArrayToBase64(this.uint8ArrayData!);\n    }\n    return this.base64Data;\n  }\n\n  // lazy conversion with caching to avoid unnecessary conversion overhead:\n  get uint8Array() {\n    if (this.uint8ArrayData == null) {\n      this.uint8ArrayData = convertBase64ToUint8Array(this.base64Data!);\n    }\n    return this.uint8ArrayData;\n  }\n}\n\nexport class DefaultGeneratedFileWithType extends DefaultGeneratedFile {\n  readonly type = 'file';\n\n  constructor(options: { data: string | Uint8Array; mediaType: string }) {\n    super(options);\n  }\n}\n", "import { LanguageModelV2ToolCall } from '@ai-sdk/provider';\nimport {\n  asSchema,\n  ModelMessage,\n  safeParseJSON,\n  safeValidateTypes,\n} from '@ai-sdk/provider-utils';\nimport { InvalidToolInputError } from '../error/invalid-tool-input-error';\nimport { NoSuchToolError } from '../error/no-such-tool-error';\nimport { ToolCallRepairError } from '../error/tool-call-repair-error';\nimport { TypedToolCall } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair-function';\nimport { ToolSet } from './tool-set';\n\nexport async function parseToolCall<TOOLS extends ToolSet>({\n  toolCall,\n  tools,\n  repairToolCall,\n  system,\n  messages,\n}: {\n  toolCall: LanguageModelV2ToolCall;\n  tools: TOOLS | undefined;\n  repairToolCall: ToolCallRepairFunction<TOOLS> | undefined;\n  system: string | undefined;\n  messages: ModelMessage[];\n}): Promise<TypedToolCall<TOOLS>> {\n  try {\n    if (tools == null) {\n      throw new NoSuchToolError({ toolName: toolCall.toolName });\n    }\n\n    try {\n      return await doParseToolCall({ toolCall, tools });\n    } catch (error) {\n      if (\n        repairToolCall == null ||\n        !(\n          NoSuchToolError.isInstance(error) ||\n          InvalidToolInputError.isInstance(error)\n        )\n      ) {\n        throw error;\n      }\n\n      let repairedToolCall: LanguageModelV2ToolCall | null = null;\n\n      try {\n        repairedToolCall = await repairToolCall({\n          toolCall,\n          tools,\n          inputSchema: ({ toolName }) => {\n            const { inputSchema } = tools[toolName];\n            return asSchema(inputSchema).jsonSchema;\n          },\n          system,\n          messages,\n          error,\n        });\n      } catch (repairError) {\n        throw new ToolCallRepairError({\n          cause: repairError,\n          originalError: error,\n        });\n      }\n\n      // no repaired tool call returned\n      if (repairedToolCall == null) {\n        throw error;\n      }\n\n      return await doParseToolCall({ toolCall: repairedToolCall, tools });\n    }\n  } catch (error) {\n    // use parsed input when possible\n    const parsedInput = await safeParseJSON({ text: toolCall.input });\n    const input = parsedInput.success ? parsedInput.value : toolCall.input;\n\n    // TODO AI SDK 6: special invalid tool call parts\n    return {\n      type: 'tool-call',\n      toolCallId: toolCall.toolCallId,\n      toolName: toolCall.toolName,\n      input,\n      dynamic: true,\n      invalid: true,\n      error,\n    };\n  }\n}\n\nasync function doParseToolCall<TOOLS extends ToolSet>({\n  toolCall,\n  tools,\n}: {\n  toolCall: LanguageModelV2ToolCall;\n  tools: TOOLS;\n}): Promise<TypedToolCall<TOOLS>> {\n  const toolName = toolCall.toolName as keyof TOOLS & string;\n\n  const tool = tools[toolName];\n\n  if (tool == null) {\n    throw new NoSuchToolError({\n      toolName: toolCall.toolName,\n      availableTools: Object.keys(tools),\n    });\n  }\n\n  const schema = asSchema(tool.inputSchema);\n\n  // when the tool call has no arguments, we try passing an empty object to the schema\n  // (many LLMs generate empty strings for tool calls with no arguments)\n  const parseResult =\n    toolCall.input.trim() === ''\n      ? await safeValidateTypes({ value: {}, schema })\n      : await safeParseJSON({ text: toolCall.input, schema });\n\n  if (parseResult.success === false) {\n    throw new InvalidToolInputError({\n      toolName,\n      toolInput: toolCall.input,\n      cause: parseResult.error,\n    });\n  }\n\n  return tool.type === 'dynamic'\n    ? {\n        type: 'tool-call',\n        toolCallId: toolCall.toolCallId,\n        toolName: toolCall.toolName,\n        input: parseResult.value,\n        providerExecuted: toolCall.providerExecuted,\n        providerMetadata: toolCall.providerMetadata,\n        dynamic: true,\n      }\n    : {\n        type: 'tool-call',\n        toolCallId: toolCall.toolCallId,\n        toolName,\n        input: parseResult.value,\n        providerExecuted: toolCall.providerExecuted,\n        providerMetadata: toolCall.providerMetadata,\n      };\n}\n", "import { ReasoningPart } from '@ai-sdk/provider-utils';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModelRequestMetadata,\n  LanguageModelResponseMetadata,\n  ProviderMetadata,\n} from '../types';\nimport { Source } from '../types/language-model';\nimport { LanguageModelUsage } from '../types/usage';\nimport { ContentPart } from './content-part';\nimport { GeneratedFile } from './generated-file';\nimport { ResponseMessage } from './response-message';\nimport { DynamicToolCall, StaticToolCall, TypedToolCall } from './tool-call';\nimport {\n  DynamicToolResult,\n  StaticToolResult,\n  TypedToolResult,\n} from './tool-result';\nimport { ToolSet } from './tool-set';\n\n/**\n * The result of a single step in the generation process.\n */\nexport type StepResult<TOOLS extends ToolSet> = {\n  /**\nThe content that was generated in the last step.\n   */\n  readonly content: Array<ContentPart<TOOLS>>;\n\n  /**\nThe generated text.\n*/\n  readonly text: string;\n\n  /**\nThe reasoning that was generated during the generation.\n*/\n  readonly reasoning: Array<ReasoningPart>;\n\n  /**\nThe reasoning text that was generated during the generation.\n*/\n  readonly reasoningText: string | undefined;\n\n  /**\nThe files that were generated during the generation.\n*/\n  readonly files: Array<GeneratedFile>;\n\n  /**\nThe sources that were used to generate the text.\n*/\n  readonly sources: Array<Source>;\n\n  /**\nThe tool calls that were made during the generation.\n*/\n  readonly toolCalls: Array<TypedToolCall<TOOLS>>;\n\n  /**\nThe static tool calls that were made in the last step.\n*/\n  readonly staticToolCalls: Array<StaticToolCall<TOOLS>>;\n\n  /**\nThe dynamic tool calls that were made in the last step.\n*/\n  readonly dynamicToolCalls: Array<DynamicToolCall>;\n\n  /**\nThe results of the tool calls.\n*/\n  readonly toolResults: Array<TypedToolResult<TOOLS>>;\n\n  /**\nThe static tool results that were made in the last step.\n*/\n  readonly staticToolResults: Array<StaticToolResult<TOOLS>>;\n\n  /**\nThe dynamic tool results that were made in the last step.\n*/\n  readonly dynamicToolResults: Array<DynamicToolResult>;\n\n  /**\nThe reason why the generation finished.\n*/\n  readonly finishReason: FinishReason;\n\n  /**\nThe token usage of the generated text.\n*/\n  readonly usage: LanguageModelUsage;\n\n  /**\nWarnings from the model provider (e.g. unsupported settings).\n*/\n  readonly warnings: CallWarning[] | undefined;\n\n  /**\nAdditional request information.\n   */\n  readonly request: LanguageModelRequestMetadata;\n\n  /**\nAdditional response information.\n*/\n  readonly response: LanguageModelResponseMetadata & {\n    /**\nThe response messages that were generated during the call.\nResponse messages can be either assistant messages or tool messages.\nThey contain a generated id.\n*/\n    readonly messages: Array<ResponseMessage>;\n\n    /**\nResponse body (available only for providers that use HTTP requests).\n     */\n    body?: unknown;\n  };\n\n  /**\nAdditional provider-specific metadata. They are passed through\nfrom the provider to the AI SDK and enable provider-specific\nresults that can be fully encapsulated in the provider.\n   */\n  readonly providerMetadata: ProviderMetadata | undefined;\n};\n\nexport class DefaultStepResult<TOOLS extends ToolSet>\n  implements StepResult<TOOLS>\n{\n  readonly content: StepResult<TOOLS>['content'];\n  readonly finishReason: StepResult<TOOLS>['finishReason'];\n  readonly usage: StepResult<TOOLS>['usage'];\n  readonly warnings: StepResult<TOOLS>['warnings'];\n  readonly request: StepResult<TOOLS>['request'];\n  readonly response: StepResult<TOOLS>['response'];\n  readonly providerMetadata: StepResult<TOOLS>['providerMetadata'];\n\n  constructor({\n    content,\n    finishReason,\n    usage,\n    warnings,\n    request,\n    response,\n    providerMetadata,\n  }: {\n    content: StepResult<TOOLS>['content'];\n    finishReason: StepResult<TOOLS>['finishReason'];\n    usage: StepResult<TOOLS>['usage'];\n    warnings: StepResult<TOOLS>['warnings'];\n    request: StepResult<TOOLS>['request'];\n    response: StepResult<TOOLS>['response'];\n    providerMetadata: StepResult<TOOLS>['providerMetadata'];\n  }) {\n    this.content = content;\n    this.finishReason = finishReason;\n    this.usage = usage;\n    this.warnings = warnings;\n    this.request = request;\n    this.response = response;\n    this.providerMetadata = providerMetadata;\n  }\n\n  get text() {\n    return this.content\n      .filter(part => part.type === 'text')\n      .map(part => part.text)\n      .join('');\n  }\n\n  get reasoning() {\n    return this.content.filter(part => part.type === 'reasoning');\n  }\n\n  get reasoningText() {\n    return this.reasoning.length === 0\n      ? undefined\n      : this.reasoning.map(part => part.text).join('');\n  }\n\n  get files() {\n    return this.content\n      .filter(part => part.type === 'file')\n      .map(part => part.file);\n  }\n\n  get sources() {\n    return this.content.filter(part => part.type === 'source');\n  }\n\n  get toolCalls() {\n    return this.content.filter(part => part.type === 'tool-call');\n  }\n\n  get staticToolCalls() {\n    return this.toolCalls.filter(\n      (toolCall): toolCall is StaticToolCall<TOOLS> =>\n        toolCall.dynamic !== true,\n    );\n  }\n\n  get dynamicToolCalls() {\n    return this.toolCalls.filter(\n      (toolCall): toolCall is DynamicToolCall => toolCall.dynamic === true,\n    );\n  }\n\n  get toolResults() {\n    return this.content.filter(part => part.type === 'tool-result');\n  }\n\n  get staticToolResults() {\n    return this.toolResults.filter(\n      (toolResult): toolResult is StaticToolResult<TOOLS> =>\n        toolResult.dynamic !== true,\n    );\n  }\n\n  get dynamicToolResults() {\n    return this.toolResults.filter(\n      (toolResult): toolResult is DynamicToolResult =>\n        toolResult.dynamic === true,\n    );\n  }\n}\n", "import { StepResult } from './step-result';\nimport { ToolSet } from './tool-set';\n\nexport type StopCondition<TOOLS extends ToolSet> = (options: {\n  steps: Array<StepResult<TOOLS>>;\n}) => PromiseLike<boolean> | boolean;\n\nexport function stepCountIs(stepCount: number): StopCondition<any> {\n  return ({ steps }) => steps.length === stepCount;\n}\n\nexport function hasToolCall(toolName: string): StopCondition<any> {\n  return ({ steps }) =>\n    steps[steps.length - 1]?.toolCalls?.some(\n      toolCall => toolCall.toolName === toolName,\n    ) ?? false;\n}\n\nexport async function isStopConditionMet<TOOLS extends ToolSet>({\n  stopConditions,\n  steps,\n}: {\n  stopConditions: Array<StopCondition<TOOLS>>;\n  steps: Array<StepResult<TOOLS>>;\n}): Promise<boolean> {\n  return (\n    await Promise.all(stopConditions.map(condition => condition({ steps })))\n  ).some(result => result);\n}\n", "import {\n  getErrorMessage,\n  JSONValue,\n  LanguageModelV2ToolResultOutput,\n} from '@ai-sdk/provider';\nimport { Tool } from '@ai-sdk/provider-utils';\n\nexport function createToolModelOutput({\n  output,\n  tool,\n  errorMode,\n}: {\n  output: unknown;\n  tool: Tool | undefined;\n  errorMode: 'none' | 'text' | 'json';\n}): LanguageModelV2ToolResultOutput {\n  if (errorMode === 'text') {\n    return { type: 'error-text', value: getErrorMessage(output) };\n  } else if (errorMode === 'json') {\n    return { type: 'error-json', value: toJSONValue(output) };\n  }\n\n  if (tool?.toModelOutput) {\n    return tool.toModelOutput(output);\n  }\n\n  return typeof output === 'string'\n    ? { type: 'text', value: output }\n    : { type: 'json', value: toJSONValue(output) };\n}\n\nfunction toJSONValue(value: unknown): JSONValue {\n  return value === undefined ? null : (value as JSONValue);\n}\n", "import {\n  AssistantContent,\n  AssistantModelMessage,\n  ToolContent,\n  ToolModelMessage,\n} from '../prompt';\nimport { createToolModelOutput } from '../prompt/create-tool-model-output';\nimport { ContentPart } from './content-part';\nimport { ToolSet } from './tool-set';\n\n/**\nConverts the result of a `generateText` or `streamText` call to a list of response messages.\n */\nexport function toResponseMessages<TOOLS extends ToolSet>({\n  content: inputContent,\n  tools,\n}: {\n  content: Array<ContentPart<TOOLS>>;\n  tools: TOOLS | undefined;\n}): Array<AssistantModelMessage | ToolModelMessage> {\n  const responseMessages: Array<AssistantModelMessage | ToolModelMessage> = [];\n\n  const content: AssistantContent = inputContent\n    .filter(part => part.type !== 'source')\n    .filter(\n      part =>\n        (part.type !== 'tool-result' || part.providerExecuted) &&\n        (part.type !== 'tool-error' || part.providerExecuted),\n    )\n    .filter(part => part.type !== 'text' || part.text.length > 0)\n    .map(part => {\n      switch (part.type) {\n        case 'text':\n          return {\n            type: 'text',\n            text: part.text,\n            providerOptions: part.providerMetadata,\n          };\n        case 'reasoning':\n          return {\n            type: 'reasoning',\n            text: part.text,\n            providerOptions: part.providerMetadata,\n          };\n        case 'file':\n          return {\n            type: 'file',\n            data: part.file.base64,\n            mediaType: part.file.mediaType,\n            providerOptions: part.providerMetadata,\n          };\n        case 'tool-call':\n          return {\n            type: 'tool-call',\n            toolCallId: part.toolCallId,\n            toolName: part.toolName,\n            input: part.input,\n            providerExecuted: part.providerExecuted,\n            providerOptions: part.providerMetadata,\n          };\n        case 'tool-result':\n          return {\n            type: 'tool-result',\n            toolCallId: part.toolCallId,\n            toolName: part.toolName,\n            output: createToolModelOutput({\n              tool: tools?.[part.toolName],\n              output: part.output,\n              errorMode: 'none',\n            }),\n            providerExecuted: true,\n            providerOptions: part.providerMetadata,\n          };\n        case 'tool-error':\n          return {\n            type: 'tool-result',\n            toolCallId: part.toolCallId,\n            toolName: part.toolName,\n            output: createToolModelOutput({\n              tool: tools?.[part.toolName],\n              output: part.error,\n              errorMode: 'json',\n            }),\n            providerOptions: part.providerMetadata,\n          };\n      }\n    });\n\n  if (content.length > 0) {\n    responseMessages.push({\n      role: 'assistant',\n      content,\n    });\n  }\n\n  const toolResultContent: ToolContent = inputContent\n    .filter(part => part.type === 'tool-result' || part.type === 'tool-error')\n    .filter(part => !part.providerExecuted)\n    .map(toolResult => ({\n      type: 'tool-result',\n      toolCallId: toolResult.toolCallId,\n      toolName: toolResult.toolName,\n      output: createToolModelOutput({\n        tool: tools?.[toolResult.toolName],\n        output:\n          toolResult.type === 'tool-result'\n            ? toolResult.output\n            : toolResult.error,\n        errorMode: toolResult.type === 'tool-error' ? 'text' : 'none',\n      }),\n    }));\n\n  if (toolResultContent.length > 0) {\n    responseMessages.push({\n      role: 'tool',\n      content: toolResultContent,\n    });\n  }\n\n  return responseMessages;\n}\n", "import {\n  getErrorMessage,\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n} from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  IdGenerator,\n  isAbortError,\n  ProviderOptions,\n} from '@ai-sdk/provider-utils';\nimport { Span } from '@opentelemetry/api';\nimport { ServerResponse } from 'node:http';\nimport { NoOutputGeneratedError } from '../error';\nimport { NoOutputSpecifiedError } from '../error/no-output-specified-error';\nimport { logWarnings } from '../logger/log-warnings';\nimport { resolveLanguageModel } from '../model/resolve-model';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { prepareToolsAndToolChoice } from '../prompt/prepare-tools-and-tool-choice';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { createTextStreamResponse } from '../text-stream/create-text-stream-response';\nimport { pipeTextStreamToResponse } from '../text-stream/pipe-text-stream-to-response';\nimport { LanguageModelRequestMetadata } from '../types';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModel,\n  ToolChoice,\n} from '../types/language-model';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { addLanguageModelUsage, LanguageModelUsage } from '../types/usage';\nimport { UIMessage } from '../ui';\nimport { createUIMessageStreamResponse } from '../ui-message-stream/create-ui-message-stream-response';\nimport { getResponseUIMessageId } from '../ui-message-stream/get-response-ui-message-id';\nimport { handleUIMessageStreamFinish } from '../ui-message-stream/handle-ui-message-stream-finish';\nimport { pipeUIMessageStreamToResponse } from '../ui-message-stream/pipe-ui-message-stream-to-response';\nimport {\n  InferUIMessageChunk,\n  UIMessageChunk,\n} from '../ui-message-stream/ui-message-chunks';\nimport { UIMessageStreamResponseInit } from '../ui-message-stream/ui-message-stream-response-init';\nimport { InferUIMessageData, InferUIMessageMetadata } from '../ui/ui-messages';\nimport { asArray } from '../util/as-array';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../util/async-iterable-stream';\nimport { consumeStream } from '../util/consume-stream';\nimport { createStitchableStream } from '../util/create-stitchable-stream';\nimport { DelayedPromise } from '../util/delayed-promise';\nimport { DownloadFunction } from '../util/download/download-function';\nimport { now as originalNow } from '../util/now';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { ContentPart } from './content-part';\nimport { Output } from './output';\nimport { PrepareStepFunction } from './prepare-step';\nimport { ResponseMessage } from './response-message';\nimport {\n  runToolsTransformation,\n  SingleRequestTextStreamPart,\n} from './run-tools-transformation';\nimport { DefaultStepResult, StepResult } from './step-result';\nimport {\n  isStopConditionMet,\n  stepCountIs,\n  StopCondition,\n} from './stop-condition';\nimport {\n  ConsumeStreamOptions,\n  StreamTextResult,\n  TextStreamPart,\n  UIMessageStreamOptions,\n} from './stream-text-result';\nimport { toResponseMessages } from './to-response-messages';\nimport { TypedToolCall } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair-function';\nimport { ToolOutput } from './tool-output';\nimport { ToolSet } from './tool-set';\n\nconst originalGenerateId = createIdGenerator({\n  prefix: 'aitxt',\n  size: 24,\n});\n\n/**\nA transformation that is applied to the stream.\n\n@param stopStream - A function that stops the source stream.\n@param tools - The tools that are accessible to and can be called by the model. The model needs to support calling tools.\n */\nexport type StreamTextTransform<TOOLS extends ToolSet> = (options: {\n  tools: TOOLS; // for type inference\n  stopStream: () => void;\n}) => TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>;\n\n/**\nCallback that is set using the `onError` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnErrorCallback = (event: {\n  error: unknown;\n}) => PromiseLike<void> | void;\n\n/**\nCallback that is set using the `onStepFinish` option.\n\n@param stepResult - The result of the step.\n */\nexport type StreamTextOnStepFinishCallback<TOOLS extends ToolSet> = (\n  stepResult: StepResult<TOOLS>,\n) => PromiseLike<void> | void;\n\n/**\nCallback that is set using the `onChunk` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnChunkCallback<TOOLS extends ToolSet> = (event: {\n  chunk: Extract<\n    TextStreamPart<TOOLS>,\n    {\n      type:\n        | 'text-delta'\n        | 'reasoning-delta'\n        | 'source'\n        | 'tool-call'\n        | 'tool-input-start'\n        | 'tool-input-delta'\n        | 'tool-result'\n        | 'raw';\n    }\n  >;\n}) => PromiseLike<void> | void;\n\n/**\nCallback that is set using the `onFinish` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnFinishCallback<TOOLS extends ToolSet> = (\n  event: StepResult<TOOLS> & {\n    /**\nDetails for all steps.\n   */\n    readonly steps: StepResult<TOOLS>[];\n\n    /**\nTotal usage for all steps. This is the sum of the usage of all steps.\n     */\n    readonly totalUsage: LanguageModelUsage;\n  },\n) => PromiseLike<void> | void;\n\n/**\nCallback that is set using the `onAbort` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamTextOnAbortCallback<TOOLS extends ToolSet> = (event: {\n  /**\nDetails for all previously finished steps.\n   */\n  readonly steps: StepResult<TOOLS>[];\n}) => PromiseLike<void> | void;\n\n/**\nGenerate a text and call tools for a given prompt using a language model.\n\nThis function streams the output. If you do not want to stream the output, use `generateText` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param maxSteps - Maximum number of sequential LLM calls (steps), e.g. when you use tool calls.\n\n@param onChunk - Callback that is called for each chunk of the stream. The stream processing will pause until the callback promise is resolved.\n@param onError - Callback that is called when an error occurs during streaming. You can use it to log errors.\n@param onStepFinish - Callback that is called when each step (LLM call) is finished, including intermediate steps.\n@param onFinish - Callback that is called when the LLM response and all request tool executions\n(for tools that have an `execute` function) are finished.\n\n@return\nA result object for accessing different stream types and additional information.\n */\nexport function streamText<\n  TOOLS extends ToolSet,\n  OUTPUT = never,\n  PARTIAL_OUTPUT = never,\n>({\n  model,\n  tools,\n  toolChoice,\n  system,\n  prompt,\n  messages,\n  maxRetries,\n  abortSignal,\n  headers,\n  stopWhen = stepCountIs(1),\n  experimental_output: output,\n  experimental_telemetry: telemetry,\n  prepareStep,\n  providerOptions,\n  experimental_activeTools,\n  activeTools = experimental_activeTools,\n  experimental_repairToolCall: repairToolCall,\n  experimental_transform: transform,\n  experimental_download: download,\n  includeRawChunks = false,\n  onChunk,\n  onError = ({ error }) => {\n    console.error(error);\n  },\n  onFinish,\n  onAbort,\n  onStepFinish,\n  experimental_context,\n  _internal: {\n    now = originalNow,\n    generateId = originalGenerateId,\n    currentDate = () => new Date(),\n  } = {},\n  ...settings\n}: CallSettings &\n  Prompt & {\n    /**\nThe language model to use.\n     */\n    model: LanguageModel;\n\n    /**\nThe tools that the model can call. The model needs to support calling tools.\n    */\n    tools?: TOOLS;\n\n    /**\nThe tool choice strategy. Default: 'auto'.\n     */\n    toolChoice?: ToolChoice<TOOLS>;\n\n    /**\nCondition for stopping the generation when there are tool results in the last step.\nWhen the condition is an array, any of the conditions can be met to stop the generation.\n\n@default stepCountIs(1)\n     */\n    stopWhen?:\n      | StopCondition<NoInfer<TOOLS>>\n      | Array<StopCondition<NoInfer<TOOLS>>>;\n\n    /**\nOptional telemetry configuration (experimental).\n     */\n    experimental_telemetry?: TelemetrySettings;\n\n    /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n    providerOptions?: ProviderOptions;\n\n    /**\n     * @deprecated Use `activeTools` instead.\n     */\n    experimental_activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\n   Limits the tools that are available for the model to call without\n   changing the tool call and result types in the result.\n        */\n    activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n    /**\nOptional specification for parsing structured outputs from the LLM response.\n     */\n    experimental_output?: Output<OUTPUT, PARTIAL_OUTPUT>;\n\n    /**\nOptional function that you can use to provide different settings for a step.\n\n@param options - The options for the step.\n@param options.steps - The steps that have been executed so far.\n@param options.stepNumber - The number of the step that is being executed.\n@param options.model - The model that is being used.\n\n@returns An object that contains the settings for the step.\nIf you return undefined (or for undefined settings), the settings from the outer level will be used.\n    */\n    prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n    /**\nA function that attempts to repair a tool call that failed to parse.\n     */\n    experimental_repairToolCall?: ToolCallRepairFunction<TOOLS>;\n\n    /**\nOptional stream transformations.\nThey are applied in the order they are provided.\nThe stream transformations must maintain the stream structure for streamText to work correctly.\n     */\n    experimental_transform?:\n      | StreamTextTransform<TOOLS>\n      | Array<StreamTextTransform<TOOLS>>;\n\n    /**\nCustom download function to use for URLs.\n\nBy default, files are downloaded if the model does not support the URL for the given media type.\n     */\n    experimental_download?: DownloadFunction | undefined;\n\n    /**\nWhether to include raw chunks from the provider in the stream.\nWhen enabled, you will receive raw chunks with type 'raw' that contain the unprocessed data from the provider.\nThis allows access to cutting-edge provider features not yet wrapped by the AI SDK.\nDefaults to false.\n     */\n    includeRawChunks?: boolean;\n\n    /**\nCallback that is called for each chunk of the stream.\nThe stream processing will pause until the callback promise is resolved.\n     */\n    onChunk?: StreamTextOnChunkCallback<TOOLS>;\n\n    /**\nCallback that is invoked when an error occurs during streaming.\nYou can use it to log errors.\nThe stream processing will pause until the callback promise is resolved.\n     */\n    onError?: StreamTextOnErrorCallback;\n\n    /**\nCallback that is called when the LLM response and all request tool executions\n(for tools that have an `execute` function) are finished.\n\nThe usage is the combined usage of all steps.\n     */\n    onFinish?: StreamTextOnFinishCallback<TOOLS>;\n\n    onAbort?: StreamTextOnAbortCallback<TOOLS>;\n\n    /**\nCallback that is called when each step (LLM call) is finished, including intermediate steps.\n    */\n    onStepFinish?: StreamTextOnStepFinishCallback<TOOLS>;\n\n    /**\n     * Context that is passed into tool execution.\n     *\n     * Experimental (can break in patch releases).\n     *\n     * @default undefined\n     */\n    experimental_context?: unknown;\n\n    /**\nInternal. For test use only. May change without notice.\n     */\n    _internal?: {\n      now?: () => number;\n      generateId?: IdGenerator;\n      currentDate?: () => Date;\n    };\n  }): StreamTextResult<TOOLS, PARTIAL_OUTPUT> {\n  return new DefaultStreamTextResult<TOOLS, OUTPUT, PARTIAL_OUTPUT>({\n    model: resolveLanguageModel(model),\n    telemetry,\n    headers,\n    settings,\n    maxRetries,\n    abortSignal,\n    system,\n    prompt,\n    messages,\n    tools,\n    toolChoice,\n    transforms: asArray(transform),\n    activeTools,\n    repairToolCall,\n    stopConditions: asArray(stopWhen),\n    output,\n    providerOptions,\n    prepareStep,\n    includeRawChunks,\n    onChunk,\n    onError,\n    onFinish,\n    onAbort,\n    onStepFinish,\n    now,\n    currentDate,\n    generateId,\n    experimental_context,\n    download,\n  });\n}\n\ntype EnrichedStreamPart<TOOLS extends ToolSet, PARTIAL_OUTPUT> = {\n  part: TextStreamPart<TOOLS>;\n  partialOutput: PARTIAL_OUTPUT | undefined;\n};\n\nfunction createOutputTransformStream<\n  TOOLS extends ToolSet,\n  OUTPUT,\n  PARTIAL_OUTPUT,\n>(\n  output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined,\n): TransformStream<\n  TextStreamPart<TOOLS>,\n  EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n> {\n  if (!output) {\n    return new TransformStream<\n      TextStreamPart<TOOLS>,\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >({\n      transform(chunk, controller) {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n      },\n    });\n  }\n\n  let firstTextChunkId: string | undefined = undefined;\n  let text = '';\n  let textChunk = '';\n  let lastPublishedJson = '';\n\n  function publishTextChunk({\n    controller,\n    partialOutput = undefined,\n  }: {\n    controller: TransformStreamDefaultController<\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >;\n    partialOutput?: PARTIAL_OUTPUT;\n  }) {\n    controller.enqueue({\n      part: {\n        type: 'text-delta',\n        id: firstTextChunkId!,\n        text: textChunk,\n      },\n      partialOutput,\n    });\n    textChunk = '';\n  }\n\n  return new TransformStream<\n    TextStreamPart<TOOLS>,\n    EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n  >({\n    async transform(chunk, controller) {\n      // ensure that we publish the last text chunk before the step finish:\n      if (chunk.type === 'finish-step' && textChunk.length > 0) {\n        publishTextChunk({ controller });\n      }\n\n      if (\n        chunk.type !== 'text-delta' &&\n        chunk.type !== 'text-start' &&\n        chunk.type !== 'text-end'\n      ) {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      // we have to pick a text chunk which contains the json text\n      // since we are streaming, we have to pick the first text chunk\n      if (firstTextChunkId == null) {\n        firstTextChunkId = chunk.id;\n      } else if (chunk.id !== firstTextChunkId) {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      if (chunk.type === 'text-start') {\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      if (chunk.type === 'text-end') {\n        if (textChunk.length > 0) {\n          publishTextChunk({ controller });\n        }\n        controller.enqueue({ part: chunk, partialOutput: undefined });\n        return;\n      }\n\n      text += chunk.text;\n      textChunk += chunk.text;\n\n      // only publish if partial json can be parsed:\n      const result = await output.parsePartial({ text });\n      if (result != null) {\n        // only send new json if it has changed:\n        const currentJson = JSON.stringify(result.partial);\n        if (currentJson !== lastPublishedJson) {\n          publishTextChunk({ controller, partialOutput: result.partial });\n          lastPublishedJson = currentJson;\n        }\n      }\n    },\n  });\n}\n\nclass DefaultStreamTextResult<TOOLS extends ToolSet, OUTPUT, PARTIAL_OUTPUT>\n  implements StreamTextResult<TOOLS, PARTIAL_OUTPUT>\n{\n  private readonly _totalUsage = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['usage']>\n  >();\n  private readonly _finishReason = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['finishReason']>\n  >();\n  private readonly _steps = new DelayedPromise<\n    Awaited<StreamTextResult<TOOLS, PARTIAL_OUTPUT>['steps']>\n  >();\n\n  private readonly addStream: (\n    stream: ReadableStream<TextStreamPart<TOOLS>>,\n  ) => void;\n\n  private readonly closeStream: () => void;\n\n  private baseStream: ReadableStream<EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>>;\n\n  private output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined;\n\n  private includeRawChunks: boolean;\n\n  private tools: TOOLS | undefined;\n\n  constructor({\n    model,\n    telemetry,\n    headers,\n    settings,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    system,\n    prompt,\n    messages,\n    tools,\n    toolChoice,\n    transforms,\n    activeTools,\n    repairToolCall,\n    stopConditions,\n    output,\n    providerOptions,\n    prepareStep,\n    includeRawChunks,\n    now,\n    currentDate,\n    generateId,\n    onChunk,\n    onError,\n    onFinish,\n    onAbort,\n    onStepFinish,\n    experimental_context,\n    download,\n  }: {\n    model: LanguageModelV2;\n    telemetry: TelemetrySettings | undefined;\n    headers: Record<string, string | undefined> | undefined;\n    settings: Omit<CallSettings, 'abortSignal' | 'headers'>;\n    maxRetries: number | undefined;\n    abortSignal: AbortSignal | undefined;\n    system: Prompt['system'];\n    prompt: Prompt['prompt'];\n    messages: Prompt['messages'];\n    tools: TOOLS | undefined;\n    toolChoice: ToolChoice<TOOLS> | undefined;\n    transforms: Array<StreamTextTransform<TOOLS>>;\n    activeTools: Array<keyof TOOLS> | undefined;\n    repairToolCall: ToolCallRepairFunction<TOOLS> | undefined;\n    stopConditions: Array<StopCondition<NoInfer<TOOLS>>>;\n    output: Output<OUTPUT, PARTIAL_OUTPUT> | undefined;\n    providerOptions: ProviderOptions | undefined;\n    prepareStep: PrepareStepFunction<NoInfer<TOOLS>> | undefined;\n    includeRawChunks: boolean;\n    now: () => number;\n    currentDate: () => Date;\n    generateId: () => string;\n    experimental_context: unknown;\n    download: DownloadFunction | undefined;\n\n    // callbacks:\n    onChunk: undefined | StreamTextOnChunkCallback<TOOLS>;\n    onError: StreamTextOnErrorCallback;\n    onFinish: undefined | StreamTextOnFinishCallback<TOOLS>;\n    onAbort: undefined | StreamTextOnAbortCallback<TOOLS>;\n    onStepFinish: undefined | StreamTextOnStepFinishCallback<TOOLS>;\n  }) {\n    this.output = output;\n    this.includeRawChunks = includeRawChunks;\n    this.tools = tools;\n\n    // promise to ensure that the step has been fully processed by the event processor\n    // before a new step is started. This is required because the continuation condition\n    // needs the updated steps to determine if another step is needed.\n    let stepFinish!: DelayedPromise<void>;\n\n    let recordedContent: Array<ContentPart<TOOLS>> = [];\n    const recordedResponseMessages: Array<ResponseMessage> = [];\n    let recordedFinishReason: FinishReason | undefined = undefined;\n    let recordedTotalUsage: LanguageModelUsage | undefined = undefined;\n    let recordedRequest: LanguageModelRequestMetadata = {};\n    let recordedWarnings: Array<CallWarning> = [];\n    const recordedSteps: StepResult<TOOLS>[] = [];\n\n    let rootSpan!: Span;\n\n    let activeTextContent: Record<\n      string,\n      {\n        type: 'text';\n        text: string;\n        providerMetadata: ProviderMetadata | undefined;\n      }\n    > = {};\n\n    let activeReasoningContent: Record<\n      string,\n      {\n        type: 'reasoning';\n        text: string;\n        providerMetadata: ProviderMetadata | undefined;\n      }\n    > = {};\n\n    const eventProcessor = new TransformStream<\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n      EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>\n    >({\n      async transform(chunk, controller) {\n        controller.enqueue(chunk); // forward the chunk to the next stream\n\n        const { part } = chunk;\n\n        if (\n          part.type === 'text-delta' ||\n          part.type === 'reasoning-delta' ||\n          part.type === 'source' ||\n          part.type === 'tool-call' ||\n          part.type === 'tool-result' ||\n          part.type === 'tool-input-start' ||\n          part.type === 'tool-input-delta' ||\n          part.type === 'raw'\n        ) {\n          await onChunk?.({ chunk: part });\n        }\n\n        if (part.type === 'error') {\n          await onError({ error: wrapGatewayError(part.error) });\n        }\n\n        if (part.type === 'text-start') {\n          activeTextContent[part.id] = {\n            type: 'text',\n            text: '',\n            providerMetadata: part.providerMetadata,\n          };\n\n          recordedContent.push(activeTextContent[part.id]);\n        }\n\n        if (part.type === 'text-delta') {\n          const activeText = activeTextContent[part.id];\n\n          if (activeText == null) {\n            controller.enqueue({\n              part: {\n                type: 'error',\n                error: `text part ${part.id} not found`,\n              },\n              partialOutput: undefined,\n            });\n            return;\n          }\n\n          activeText.text += part.text;\n          activeText.providerMetadata =\n            part.providerMetadata ?? activeText.providerMetadata;\n        }\n\n        if (part.type === 'text-end') {\n          const activeText = activeTextContent[part.id];\n\n          if (activeText == null) {\n            controller.enqueue({\n              part: {\n                type: 'error',\n                error: `text part ${part.id} not found`,\n              },\n              partialOutput: undefined,\n            });\n            return;\n          }\n\n          activeText.providerMetadata =\n            part.providerMetadata ?? activeText.providerMetadata;\n\n          delete activeTextContent[part.id];\n        }\n\n        if (part.type === 'reasoning-start') {\n          activeReasoningContent[part.id] = {\n            type: 'reasoning',\n            text: '',\n            providerMetadata: part.providerMetadata,\n          };\n\n          recordedContent.push(activeReasoningContent[part.id]);\n        }\n\n        if (part.type === 'reasoning-delta') {\n          const activeReasoning = activeReasoningContent[part.id];\n\n          if (activeReasoning == null) {\n            controller.enqueue({\n              part: {\n                type: 'error',\n                error: `reasoning part ${part.id} not found`,\n              },\n              partialOutput: undefined,\n            });\n            return;\n          }\n\n          activeReasoning.text += part.text;\n          activeReasoning.providerMetadata =\n            part.providerMetadata ?? activeReasoning.providerMetadata;\n        }\n\n        if (part.type === 'reasoning-end') {\n          const activeReasoning = activeReasoningContent[part.id];\n\n          if (activeReasoning == null) {\n            controller.enqueue({\n              part: {\n                type: 'error',\n                error: `reasoning part ${part.id} not found`,\n              },\n              partialOutput: undefined,\n            });\n            return;\n          }\n\n          activeReasoning.providerMetadata =\n            part.providerMetadata ?? activeReasoning.providerMetadata;\n\n          delete activeReasoningContent[part.id];\n        }\n\n        if (part.type === 'file') {\n          recordedContent.push({ type: 'file', file: part.file });\n        }\n\n        if (part.type === 'source') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'tool-call') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'tool-result' && !part.preliminary) {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'tool-error') {\n          recordedContent.push(part);\n        }\n\n        if (part.type === 'start-step') {\n          recordedRequest = part.request;\n          recordedWarnings = part.warnings;\n        }\n\n        if (part.type === 'finish-step') {\n          const stepMessages = toResponseMessages({\n            content: recordedContent,\n            tools,\n          });\n\n          // Add step information (after response messages are updated):\n          const currentStepResult: StepResult<TOOLS> = new DefaultStepResult({\n            content: recordedContent,\n            finishReason: part.finishReason,\n            usage: part.usage,\n            warnings: recordedWarnings,\n            request: recordedRequest,\n            response: {\n              ...part.response,\n              messages: [...recordedResponseMessages, ...stepMessages],\n            },\n            providerMetadata: part.providerMetadata,\n          });\n\n          await onStepFinish?.(currentStepResult);\n\n          logWarnings(recordedWarnings);\n\n          recordedSteps.push(currentStepResult);\n\n          recordedContent = [];\n          activeReasoningContent = {};\n          activeTextContent = {};\n\n          recordedResponseMessages.push(...stepMessages);\n\n          // resolve the promise to signal that the step has been fully processed\n          // by the event processor:\n          stepFinish.resolve();\n        }\n\n        if (part.type === 'finish') {\n          recordedTotalUsage = part.totalUsage;\n          recordedFinishReason = part.finishReason;\n        }\n      },\n\n      async flush(controller) {\n        try {\n          if (recordedSteps.length === 0) {\n            const error = new NoOutputGeneratedError({\n              message: 'No output generated. Check the stream for errors.',\n            });\n\n            self._finishReason.reject(error);\n            self._totalUsage.reject(error);\n            self._steps.reject(error);\n\n            return; // no steps recorded (e.g. in error scenario)\n          }\n\n          // derived:\n          const finishReason = recordedFinishReason ?? 'unknown';\n          const totalUsage = recordedTotalUsage ?? {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          };\n\n          // from finish:\n          self._finishReason.resolve(finishReason);\n          self._totalUsage.resolve(totalUsage);\n\n          // aggregate results:\n          self._steps.resolve(recordedSteps);\n\n          // call onFinish callback:\n          const finalStep = recordedSteps[recordedSteps.length - 1];\n          await onFinish?.({\n            finishReason,\n            totalUsage,\n            usage: finalStep.usage,\n            content: finalStep.content,\n            text: finalStep.text,\n            reasoningText: finalStep.reasoningText,\n            reasoning: finalStep.reasoning,\n            files: finalStep.files,\n            sources: finalStep.sources,\n            toolCalls: finalStep.toolCalls,\n            staticToolCalls: finalStep.staticToolCalls,\n            dynamicToolCalls: finalStep.dynamicToolCalls,\n            toolResults: finalStep.toolResults,\n            staticToolResults: finalStep.staticToolResults,\n            dynamicToolResults: finalStep.dynamicToolResults,\n            request: finalStep.request,\n            response: finalStep.response,\n            warnings: finalStep.warnings,\n            providerMetadata: finalStep.providerMetadata,\n            steps: recordedSteps,\n          });\n\n          // Add response information to the root span:\n          rootSpan.setAttributes(\n            selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                'ai.response.finishReason': finishReason,\n                'ai.response.text': { output: () => finalStep.text },\n                'ai.response.toolCalls': {\n                  output: () =>\n                    finalStep.toolCalls?.length\n                      ? JSON.stringify(finalStep.toolCalls)\n                      : undefined,\n                },\n                'ai.response.providerMetadata': JSON.stringify(\n                  finalStep.providerMetadata,\n                ),\n\n                'ai.usage.inputTokens': totalUsage.inputTokens,\n                'ai.usage.outputTokens': totalUsage.outputTokens,\n                'ai.usage.totalTokens': totalUsage.totalTokens,\n                'ai.usage.reasoningTokens': totalUsage.reasoningTokens,\n                'ai.usage.cachedInputTokens': totalUsage.cachedInputTokens,\n              },\n            }),\n          );\n        } catch (error) {\n          controller.error(error);\n        } finally {\n          rootSpan.end();\n        }\n      },\n    });\n\n    // initialize the stitchable stream and the transformed stream:\n    const stitchableStream = createStitchableStream<TextStreamPart<TOOLS>>();\n    this.addStream = stitchableStream.addStream;\n    this.closeStream = stitchableStream.close;\n\n    // resilient stream that handles abort signals and errors:\n    const reader = stitchableStream.stream.getReader();\n    let stream = new ReadableStream<TextStreamPart<TOOLS>>({\n      async start(controller) {\n        // send start event:\n        controller.enqueue({ type: 'start' });\n      },\n\n      async pull(controller) {\n        // abort handling:\n        function abort() {\n          onAbort?.({ steps: recordedSteps });\n          controller.enqueue({ type: 'abort' });\n          controller.close();\n        }\n\n        try {\n          const { done, value } = await reader.read();\n\n          if (done) {\n            controller.close();\n            return;\n          }\n\n          if (abortSignal?.aborted) {\n            abort();\n            return;\n          }\n\n          controller.enqueue(value);\n        } catch (error) {\n          if (isAbortError(error) && abortSignal?.aborted) {\n            abort();\n          } else {\n            controller.error(error);\n          }\n        }\n      },\n\n      cancel(reason) {\n        return stitchableStream.stream.cancel(reason);\n      },\n    });\n\n    // transform the stream before output parsing\n    // to enable replacement of stream segments:\n    for (const transform of transforms) {\n      stream = stream.pipeThrough(\n        transform({\n          tools: tools as TOOLS,\n          stopStream() {\n            stitchableStream.terminate();\n          },\n        }),\n      );\n    }\n\n    this.baseStream = stream\n      .pipeThrough(createOutputTransformStream(output))\n      .pipeThrough(eventProcessor);\n\n    const { maxRetries, retry } = prepareRetries({\n      maxRetries: maxRetriesArg,\n      abortSignal,\n    });\n\n    const tracer = getTracer(telemetry);\n\n    const callSettings = prepareCallSettings(settings);\n\n    const baseTelemetryAttributes = getBaseTelemetryAttributes({\n      model,\n      telemetry,\n      headers,\n      settings: { ...callSettings, maxRetries },\n    });\n\n    const self = this;\n\n    recordSpan({\n      name: 'ai.streamText',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({ operationId: 'ai.streamText', telemetry }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n        },\n      }),\n      tracer,\n      endWhenDone: false,\n      fn: async rootSpanArg => {\n        rootSpan = rootSpanArg;\n\n        async function streamStep({\n          currentStep,\n          responseMessages,\n          usage,\n        }: {\n          currentStep: number;\n          responseMessages: Array<ResponseMessage>;\n          usage: LanguageModelUsage;\n        }) {\n          const includeRawChunks = self.includeRawChunks;\n\n          stepFinish = new DelayedPromise<void>();\n\n          const initialPrompt = await standardizePrompt({\n            system,\n            prompt,\n            messages,\n          } as Prompt);\n\n          const stepInputMessages = [\n            ...initialPrompt.messages,\n            ...responseMessages,\n          ];\n\n          const prepareStepResult = await prepareStep?.({\n            model,\n            steps: recordedSteps,\n            stepNumber: recordedSteps.length,\n            messages: stepInputMessages,\n          });\n\n          const stepModel = resolveLanguageModel(\n            prepareStepResult?.model ?? model,\n          );\n\n          const promptMessages = await convertToLanguageModelPrompt({\n            prompt: {\n              system: prepareStepResult?.system ?? initialPrompt.system,\n              messages: prepareStepResult?.messages ?? stepInputMessages,\n            },\n            supportedUrls: await stepModel.supportedUrls,\n            download,\n          });\n\n          const { toolChoice: stepToolChoice, tools: stepTools } =\n            prepareToolsAndToolChoice({\n              tools,\n              toolChoice: prepareStepResult?.toolChoice ?? toolChoice,\n              activeTools: prepareStepResult?.activeTools ?? activeTools,\n            });\n\n          const {\n            result: { stream, response, request },\n            doStreamSpan,\n            startTimestampMs,\n          } = await retry(() =>\n            recordSpan({\n              name: 'ai.streamText.doStream',\n              attributes: selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  ...assembleOperationName({\n                    operationId: 'ai.streamText.doStream',\n                    telemetry,\n                  }),\n                  ...baseTelemetryAttributes,\n                  // model:\n                  'ai.model.provider': stepModel.provider,\n                  'ai.model.id': stepModel.modelId,\n                  // prompt:\n                  'ai.prompt.messages': {\n                    input: () => stringifyForTelemetry(promptMessages),\n                  },\n                  'ai.prompt.tools': {\n                    // convert the language model level tools:\n                    input: () => stepTools?.map(tool => JSON.stringify(tool)),\n                  },\n                  'ai.prompt.toolChoice': {\n                    input: () =>\n                      stepToolChoice != null\n                        ? JSON.stringify(stepToolChoice)\n                        : undefined,\n                  },\n\n                  // standardized gen-ai llm span attributes:\n                  'gen_ai.system': stepModel.provider,\n                  'gen_ai.request.model': stepModel.modelId,\n                  'gen_ai.request.frequency_penalty':\n                    callSettings.frequencyPenalty,\n                  'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                  'gen_ai.request.presence_penalty':\n                    callSettings.presencePenalty,\n                  'gen_ai.request.stop_sequences': callSettings.stopSequences,\n                  'gen_ai.request.temperature': callSettings.temperature,\n                  'gen_ai.request.top_k': callSettings.topK,\n                  'gen_ai.request.top_p': callSettings.topP,\n                },\n              }),\n              tracer,\n              endWhenDone: false,\n              fn: async doStreamSpan => {\n                return {\n                  startTimestampMs: now(), // get before the call\n                  doStreamSpan,\n                  result: await stepModel.doStream({\n                    ...callSettings,\n                    tools: stepTools,\n                    toolChoice: stepToolChoice,\n                    responseFormat: output?.responseFormat,\n                    prompt: promptMessages,\n                    providerOptions,\n                    abortSignal,\n                    headers,\n                    includeRawChunks,\n                  }),\n                };\n              },\n            }),\n          );\n\n          const streamWithToolResults = runToolsTransformation({\n            tools,\n            generatorStream: stream,\n            tracer,\n            telemetry,\n            system,\n            messages: stepInputMessages,\n            repairToolCall,\n            abortSignal,\n            experimental_context,\n          });\n\n          const stepRequest = request ?? {};\n          const stepToolCalls: TypedToolCall<TOOLS>[] = [];\n          const stepToolOutputs: ToolOutput<TOOLS>[] = [];\n          let warnings: LanguageModelV2CallWarning[] | undefined;\n\n          const activeToolCallToolNames: Record<string, string> = {};\n\n          let stepFinishReason: FinishReason = 'unknown';\n          let stepUsage: LanguageModelUsage = {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          };\n          let stepProviderMetadata: ProviderMetadata | undefined;\n          let stepFirstChunk = true;\n          let stepResponse: { id: string; timestamp: Date; modelId: string } = {\n            id: generateId(),\n            timestamp: currentDate(),\n            modelId: model.modelId,\n          };\n\n          // raw text as it comes from the provider. recorded for telemetry.\n          let activeText = '';\n\n          self.addStream(\n            streamWithToolResults.pipeThrough(\n              new TransformStream<\n                SingleRequestTextStreamPart<TOOLS>,\n                TextStreamPart<TOOLS>\n              >({\n                async transform(chunk, controller): Promise<void> {\n                  if (chunk.type === 'stream-start') {\n                    warnings = chunk.warnings;\n                    return; // stream start chunks are sent immediately and do not count as first chunk\n                  }\n\n                  if (stepFirstChunk) {\n                    // Telemetry for first chunk:\n                    const msToFirstChunk = now() - startTimestampMs;\n\n                    stepFirstChunk = false;\n\n                    doStreamSpan.addEvent('ai.stream.firstChunk', {\n                      'ai.response.msToFirstChunk': msToFirstChunk,\n                    });\n\n                    doStreamSpan.setAttributes({\n                      'ai.response.msToFirstChunk': msToFirstChunk,\n                    });\n\n                    // Step start:\n                    controller.enqueue({\n                      type: 'start-step',\n                      request: stepRequest,\n                      warnings: warnings ?? [],\n                    });\n                  }\n\n                  const chunkType = chunk.type;\n                  switch (chunkType) {\n                    case 'text-start':\n                    case 'text-end': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'text-delta': {\n                      if (chunk.delta.length > 0) {\n                        controller.enqueue({\n                          type: 'text-delta',\n                          id: chunk.id,\n                          text: chunk.delta,\n                          providerMetadata: chunk.providerMetadata,\n                        });\n                        activeText += chunk.delta;\n                      }\n                      break;\n                    }\n\n                    case 'reasoning-start':\n                    case 'reasoning-end': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'reasoning-delta': {\n                      controller.enqueue({\n                        type: 'reasoning-delta',\n                        id: chunk.id,\n                        text: chunk.delta,\n                        providerMetadata: chunk.providerMetadata,\n                      });\n                      break;\n                    }\n\n                    case 'tool-call': {\n                      controller.enqueue(chunk);\n                      // store tool calls for onFinish callback and toolCalls promise:\n                      stepToolCalls.push(chunk);\n                      break;\n                    }\n\n                    case 'tool-result': {\n                      controller.enqueue(chunk);\n\n                      if (!chunk.preliminary) {\n                        stepToolOutputs.push(chunk);\n                      }\n\n                      break;\n                    }\n\n                    case 'tool-error': {\n                      controller.enqueue(chunk);\n                      stepToolOutputs.push(chunk);\n                      break;\n                    }\n\n                    case 'response-metadata': {\n                      stepResponse = {\n                        id: chunk.id ?? stepResponse.id,\n                        timestamp: chunk.timestamp ?? stepResponse.timestamp,\n                        modelId: chunk.modelId ?? stepResponse.modelId,\n                      };\n                      break;\n                    }\n\n                    case 'finish': {\n                      // Note: tool executions might not be finished yet when the finish event is emitted.\n                      // store usage and finish reason for promises and onFinish callback:\n                      stepUsage = chunk.usage;\n                      stepFinishReason = chunk.finishReason;\n                      stepProviderMetadata = chunk.providerMetadata;\n\n                      // Telemetry for finish event timing\n                      // (since tool executions can take longer and distort calculations)\n                      const msToFinish = now() - startTimestampMs;\n                      doStreamSpan.addEvent('ai.stream.finish');\n                      doStreamSpan.setAttributes({\n                        'ai.response.msToFinish': msToFinish,\n                        'ai.response.avgOutputTokensPerSecond':\n                          (1000 * (stepUsage.outputTokens ?? 0)) / msToFinish,\n                      });\n\n                      break;\n                    }\n\n                    case 'file': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'source': {\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'tool-input-start': {\n                      activeToolCallToolNames[chunk.id] = chunk.toolName;\n\n                      const tool = tools?.[chunk.toolName];\n                      if (tool?.onInputStart != null) {\n                        await tool.onInputStart({\n                          toolCallId: chunk.id,\n                          messages: stepInputMessages,\n                          abortSignal,\n                          experimental_context,\n                        });\n                      }\n\n                      controller.enqueue({\n                        ...chunk,\n                        dynamic: tool?.type === 'dynamic',\n                      });\n                      break;\n                    }\n\n                    case 'tool-input-end': {\n                      delete activeToolCallToolNames[chunk.id];\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'tool-input-delta': {\n                      const toolName = activeToolCallToolNames[chunk.id];\n                      const tool = tools?.[toolName];\n\n                      if (tool?.onInputDelta != null) {\n                        await tool.onInputDelta({\n                          inputTextDelta: chunk.delta,\n                          toolCallId: chunk.id,\n                          messages: stepInputMessages,\n                          abortSignal,\n                          experimental_context,\n                        });\n                      }\n\n                      controller.enqueue(chunk);\n                      break;\n                    }\n\n                    case 'error': {\n                      controller.enqueue(chunk);\n                      stepFinishReason = 'error';\n                      break;\n                    }\n\n                    case 'raw': {\n                      if (includeRawChunks) {\n                        controller.enqueue(chunk);\n                      }\n                      break;\n                    }\n\n                    default: {\n                      const exhaustiveCheck: never = chunkType;\n                      throw new Error(`Unknown chunk type: ${exhaustiveCheck}`);\n                    }\n                  }\n                },\n\n                // invoke onFinish callback and resolve toolResults promise when the stream is about to close:\n                async flush(controller) {\n                  const stepToolCallsJson =\n                    stepToolCalls.length > 0\n                      ? JSON.stringify(stepToolCalls)\n                      : undefined;\n\n                  // record telemetry information first to ensure best effort timing\n                  try {\n                    doStreamSpan.setAttributes(\n                      selectTelemetryAttributes({\n                        telemetry,\n                        attributes: {\n                          'ai.response.finishReason': stepFinishReason,\n                          'ai.response.text': {\n                            output: () => activeText,\n                          },\n                          'ai.response.toolCalls': {\n                            output: () => stepToolCallsJson,\n                          },\n                          'ai.response.id': stepResponse.id,\n                          'ai.response.model': stepResponse.modelId,\n                          'ai.response.timestamp':\n                            stepResponse.timestamp.toISOString(),\n                          'ai.response.providerMetadata':\n                            JSON.stringify(stepProviderMetadata),\n\n                          'ai.usage.inputTokens': stepUsage.inputTokens,\n                          'ai.usage.outputTokens': stepUsage.outputTokens,\n                          'ai.usage.totalTokens': stepUsage.totalTokens,\n                          'ai.usage.reasoningTokens': stepUsage.reasoningTokens,\n                          'ai.usage.cachedInputTokens':\n                            stepUsage.cachedInputTokens,\n\n                          // standardized gen-ai llm span attributes:\n                          'gen_ai.response.finish_reasons': [stepFinishReason],\n                          'gen_ai.response.id': stepResponse.id,\n                          'gen_ai.response.model': stepResponse.modelId,\n                          'gen_ai.usage.input_tokens': stepUsage.inputTokens,\n                          'gen_ai.usage.output_tokens': stepUsage.outputTokens,\n                        },\n                      }),\n                    );\n                  } catch (error) {\n                    // ignore error setting telemetry attributes\n                  } finally {\n                    // finish doStreamSpan before other operations for correct timing:\n                    doStreamSpan.end();\n                  }\n\n                  controller.enqueue({\n                    type: 'finish-step',\n                    finishReason: stepFinishReason,\n                    usage: stepUsage,\n                    providerMetadata: stepProviderMetadata,\n                    response: {\n                      ...stepResponse,\n                      headers: response?.headers,\n                    },\n                  });\n\n                  const combinedUsage = addLanguageModelUsage(usage, stepUsage);\n\n                  // wait for the step to be fully processed by the event processor\n                  // to ensure that the recorded steps are complete:\n                  await stepFinish.promise;\n\n                  const clientToolCalls = stepToolCalls.filter(\n                    toolCall => toolCall.providerExecuted !== true,\n                  );\n                  const clientToolOutputs = stepToolOutputs.filter(\n                    toolOutput => toolOutput.providerExecuted !== true,\n                  );\n\n                  if (\n                    clientToolCalls.length > 0 &&\n                    // all current tool calls have outputs (incl. execution errors):\n                    clientToolOutputs.length === clientToolCalls.length &&\n                    // continue until a stop condition is met:\n                    !(await isStopConditionMet({\n                      stopConditions,\n                      steps: recordedSteps,\n                    }))\n                  ) {\n                    // append to messages for the next step:\n                    responseMessages.push(\n                      ...toResponseMessages({\n                        content:\n                          // use transformed content to create the messages for the next step:\n                          recordedSteps[recordedSteps.length - 1].content,\n                        tools,\n                      }),\n                    );\n\n                    try {\n                      await streamStep({\n                        currentStep: currentStep + 1,\n                        responseMessages,\n                        usage: combinedUsage,\n                      });\n                    } catch (error) {\n                      controller.enqueue({\n                        type: 'error',\n                        error,\n                      });\n\n                      self.closeStream();\n                    }\n                  } else {\n                    controller.enqueue({\n                      type: 'finish',\n                      finishReason: stepFinishReason,\n                      totalUsage: combinedUsage,\n                    });\n\n                    self.closeStream(); // close the stitchable stream\n                  }\n                },\n              }),\n            ),\n          );\n        }\n\n        // add the initial stream to the stitchable stream\n        await streamStep({\n          currentStep: 0,\n          responseMessages: [],\n          usage: {\n            inputTokens: undefined,\n            outputTokens: undefined,\n            totalTokens: undefined,\n          },\n        });\n      },\n    }).catch(error => {\n      // add an error stream part and close the streams:\n      self.addStream(\n        new ReadableStream({\n          start(controller) {\n            controller.enqueue({ type: 'error', error });\n            controller.close();\n          },\n        }),\n      );\n      self.closeStream();\n    });\n  }\n\n  get steps() {\n    // when any of the promises are accessed, the stream is consumed\n    // so it resolves without needing to consume the stream separately\n    this.consumeStream();\n\n    return this._steps.promise;\n  }\n\n  private get finalStep() {\n    return this.steps.then(steps => steps[steps.length - 1]);\n  }\n\n  get content() {\n    return this.finalStep.then(step => step.content);\n  }\n\n  get warnings() {\n    return this.finalStep.then(step => step.warnings);\n  }\n\n  get providerMetadata() {\n    return this.finalStep.then(step => step.providerMetadata);\n  }\n\n  get text() {\n    return this.finalStep.then(step => step.text);\n  }\n\n  get reasoningText() {\n    return this.finalStep.then(step => step.reasoningText);\n  }\n\n  get reasoning() {\n    return this.finalStep.then(step => step.reasoning);\n  }\n\n  get sources() {\n    return this.finalStep.then(step => step.sources);\n  }\n\n  get files() {\n    return this.finalStep.then(step => step.files);\n  }\n\n  get toolCalls() {\n    return this.finalStep.then(step => step.toolCalls);\n  }\n\n  get staticToolCalls() {\n    return this.finalStep.then(step => step.staticToolCalls);\n  }\n\n  get dynamicToolCalls() {\n    return this.finalStep.then(step => step.dynamicToolCalls);\n  }\n\n  get toolResults() {\n    return this.finalStep.then(step => step.toolResults);\n  }\n\n  get staticToolResults() {\n    return this.finalStep.then(step => step.staticToolResults);\n  }\n\n  get dynamicToolResults() {\n    return this.finalStep.then(step => step.dynamicToolResults);\n  }\n\n  get usage() {\n    return this.finalStep.then(step => step.usage);\n  }\n\n  get request() {\n    return this.finalStep.then(step => step.request);\n  }\n\n  get response() {\n    return this.finalStep.then(step => step.response);\n  }\n\n  get totalUsage() {\n    // when any of the promises are accessed, the stream is consumed\n    // so it resolves without needing to consume the stream separately\n    this.consumeStream();\n\n    return this._totalUsage.promise;\n  }\n\n  get finishReason() {\n    // when any of the promises are accessed, the stream is consumed\n    // so it resolves without needing to consume the stream separately\n    this.consumeStream();\n\n    return this._finishReason.promise;\n  }\n\n  /**\nSplit out a new stream from the original stream.\nThe original stream is replaced to allow for further splitting,\nsince we do not know how many times the stream will be split.\n\nNote: this leads to buffering the stream content on the server.\nHowever, the LLM results are expected to be small enough to not cause issues.\n   */\n  private teeStream() {\n    const [stream1, stream2] = this.baseStream.tee();\n    this.baseStream = stream2;\n    return stream1;\n  }\n\n  get textStream(): AsyncIterableStream<string> {\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>, string>({\n          transform({ part }, controller) {\n            if (part.type === 'text-delta') {\n              controller.enqueue(part.text);\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get fullStream(): AsyncIterableStream<TextStreamPart<TOOLS>> {\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<\n          EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n          TextStreamPart<TOOLS>\n        >({\n          transform({ part }, controller) {\n            controller.enqueue(part);\n          },\n        }),\n      ),\n    );\n  }\n\n  async consumeStream(options?: ConsumeStreamOptions): Promise<void> {\n    try {\n      await consumeStream({\n        stream: this.fullStream,\n        onError: options?.onError,\n      });\n    } catch (error) {\n      options?.onError?.(error);\n    }\n  }\n\n  get experimental_partialOutputStream(): AsyncIterableStream<PARTIAL_OUTPUT> {\n    if (this.output == null) {\n      throw new NoOutputSpecifiedError();\n    }\n\n    return createAsyncIterableStream(\n      this.teeStream().pipeThrough(\n        new TransformStream<\n          EnrichedStreamPart<TOOLS, PARTIAL_OUTPUT>,\n          PARTIAL_OUTPUT\n        >({\n          transform({ partialOutput }, controller) {\n            if (partialOutput != null) {\n              controller.enqueue(partialOutput);\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  toUIMessageStream<UI_MESSAGE extends UIMessage>({\n    originalMessages,\n    generateMessageId,\n    onFinish,\n    messageMetadata,\n    sendReasoning = true,\n    sendSources = false,\n    sendStart = true,\n    sendFinish = true,\n    onError = getErrorMessage,\n  }: UIMessageStreamOptions<UI_MESSAGE> = {}): AsyncIterableStream<\n    InferUIMessageChunk<UI_MESSAGE>\n  > {\n    const responseMessageId =\n      generateMessageId != null\n        ? getResponseUIMessageId({\n            originalMessages,\n            responseMessageId: generateMessageId,\n          })\n        : undefined;\n\n    const toolNamesByCallId: Record<string, string> = {};\n\n    const isDynamic = (toolCallId: string) => {\n      const toolName = toolNamesByCallId[toolCallId];\n      const dynamic = this.tools?.[toolName]?.type === 'dynamic';\n      return dynamic ? true : undefined; // only send when dynamic to reduce data transfer\n    };\n\n    const baseStream = this.fullStream.pipeThrough(\n      new TransformStream<\n        TextStreamPart<TOOLS>,\n        UIMessageChunk<\n          InferUIMessageMetadata<UI_MESSAGE>,\n          InferUIMessageData<UI_MESSAGE>\n        >\n      >({\n        transform: async (part, controller) => {\n          const messageMetadataValue = messageMetadata?.({ part });\n\n          const partType = part.type;\n          switch (partType) {\n            case 'text-start': {\n              controller.enqueue({\n                type: 'text-start',\n                id: part.id,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'text-delta': {\n              controller.enqueue({\n                type: 'text-delta',\n                id: part.id,\n                delta: part.text,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'text-end': {\n              controller.enqueue({\n                type: 'text-end',\n                id: part.id,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'reasoning-start': {\n              controller.enqueue({\n                type: 'reasoning-start',\n                id: part.id,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'reasoning-delta': {\n              if (sendReasoning) {\n                controller.enqueue({\n                  type: 'reasoning-delta',\n                  id: part.id,\n                  delta: part.text,\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                });\n              }\n              break;\n            }\n\n            case 'reasoning-end': {\n              controller.enqueue({\n                type: 'reasoning-end',\n                id: part.id,\n                ...(part.providerMetadata != null\n                  ? { providerMetadata: part.providerMetadata }\n                  : {}),\n              });\n              break;\n            }\n\n            case 'file': {\n              controller.enqueue({\n                type: 'file',\n                mediaType: part.file.mediaType,\n                url: `data:${part.file.mediaType};base64,${part.file.base64}`,\n              });\n              break;\n            }\n\n            case 'source': {\n              if (sendSources && part.sourceType === 'url') {\n                controller.enqueue({\n                  type: 'source-url',\n                  sourceId: part.id,\n                  url: part.url,\n                  title: part.title,\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                });\n              }\n\n              if (sendSources && part.sourceType === 'document') {\n                controller.enqueue({\n                  type: 'source-document',\n                  sourceId: part.id,\n                  mediaType: part.mediaType,\n                  title: part.title,\n                  filename: part.filename,\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                });\n              }\n              break;\n            }\n\n            case 'tool-input-start': {\n              toolNamesByCallId[part.id] = part.toolName;\n              const dynamic = isDynamic(part.id);\n\n              controller.enqueue({\n                type: 'tool-input-start',\n                toolCallId: part.id,\n                toolName: part.toolName,\n                ...(part.providerExecuted != null\n                  ? { providerExecuted: part.providerExecuted }\n                  : {}),\n                ...(dynamic != null ? { dynamic } : {}),\n              });\n              break;\n            }\n\n            case 'tool-input-delta': {\n              controller.enqueue({\n                type: 'tool-input-delta',\n                toolCallId: part.id,\n                inputTextDelta: part.delta,\n              });\n              break;\n            }\n\n            case 'tool-call': {\n              toolNamesByCallId[part.toolCallId] = part.toolName;\n              const dynamic = isDynamic(part.toolCallId);\n\n              if (part.invalid) {\n                controller.enqueue({\n                  type: 'tool-input-error',\n                  toolCallId: part.toolCallId,\n                  toolName: part.toolName,\n                  input: part.input,\n                  ...(part.providerExecuted != null\n                    ? { providerExecuted: part.providerExecuted }\n                    : {}),\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                  ...(dynamic != null ? { dynamic } : {}),\n                  errorText: onError(part.error),\n                });\n              } else {\n                controller.enqueue({\n                  type: 'tool-input-available',\n                  toolCallId: part.toolCallId,\n                  toolName: part.toolName,\n                  input: part.input,\n                  ...(part.providerExecuted != null\n                    ? { providerExecuted: part.providerExecuted }\n                    : {}),\n                  ...(part.providerMetadata != null\n                    ? { providerMetadata: part.providerMetadata }\n                    : {}),\n                  ...(dynamic != null ? { dynamic } : {}),\n                });\n              }\n\n              break;\n            }\n\n            case 'tool-result': {\n              const dynamic = isDynamic(part.toolCallId);\n\n              controller.enqueue({\n                type: 'tool-output-available',\n                toolCallId: part.toolCallId,\n                output: part.output,\n                ...(part.providerExecuted != null\n                  ? { providerExecuted: part.providerExecuted }\n                  : {}),\n                ...(part.preliminary != null\n                  ? { preliminary: part.preliminary }\n                  : {}),\n                ...(dynamic != null ? { dynamic } : {}),\n              });\n              break;\n            }\n\n            case 'tool-error': {\n              const dynamic = isDynamic(part.toolCallId);\n\n              controller.enqueue({\n                type: 'tool-output-error',\n                toolCallId: part.toolCallId,\n                errorText: onError(part.error),\n                ...(part.providerExecuted != null\n                  ? { providerExecuted: part.providerExecuted }\n                  : {}),\n                ...(dynamic != null ? { dynamic } : {}),\n              });\n              break;\n            }\n\n            case 'error': {\n              controller.enqueue({\n                type: 'error',\n                errorText: onError(part.error),\n              });\n              break;\n            }\n\n            case 'start-step': {\n              controller.enqueue({ type: 'start-step' });\n              break;\n            }\n\n            case 'finish-step': {\n              controller.enqueue({ type: 'finish-step' });\n              break;\n            }\n\n            case 'start': {\n              if (sendStart) {\n                controller.enqueue({\n                  type: 'start',\n                  ...(messageMetadataValue != null\n                    ? { messageMetadata: messageMetadataValue }\n                    : {}),\n                  ...(responseMessageId != null\n                    ? { messageId: responseMessageId }\n                    : {}),\n                });\n              }\n              break;\n            }\n\n            case 'finish': {\n              if (sendFinish) {\n                controller.enqueue({\n                  type: 'finish',\n                  ...(messageMetadataValue != null\n                    ? { messageMetadata: messageMetadataValue }\n                    : {}),\n                });\n              }\n              break;\n            }\n\n            case 'abort': {\n              controller.enqueue(part);\n              break;\n            }\n\n            case 'tool-input-end': {\n              break;\n            }\n\n            case 'raw': {\n              // Raw chunks are not included in UI message streams\n              // as they contain provider-specific data for developer use\n              break;\n            }\n\n            default: {\n              const exhaustiveCheck: never = partType;\n              throw new Error(`Unknown chunk type: ${exhaustiveCheck}`);\n            }\n          }\n\n          // start and finish events already have metadata\n          // so we only need to send metadata for other parts\n          if (\n            messageMetadataValue != null &&\n            partType !== 'start' &&\n            partType !== 'finish'\n          ) {\n            controller.enqueue({\n              type: 'message-metadata',\n              messageMetadata: messageMetadataValue,\n            });\n          }\n        },\n      }),\n    );\n\n    return createAsyncIterableStream(\n      handleUIMessageStreamFinish<UI_MESSAGE>({\n        stream: baseStream,\n        messageId: responseMessageId ?? generateMessageId?.(),\n        originalMessages,\n        onFinish,\n        onError,\n      }),\n    );\n  }\n\n  pipeUIMessageStreamToResponse<UI_MESSAGE extends UIMessage>(\n    response: ServerResponse,\n    {\n      originalMessages,\n      generateMessageId,\n      onFinish,\n      messageMetadata,\n      sendReasoning,\n      sendSources,\n      sendFinish,\n      sendStart,\n      onError,\n      ...init\n    }: UIMessageStreamResponseInit & UIMessageStreamOptions<UI_MESSAGE> = {},\n  ) {\n    pipeUIMessageStreamToResponse({\n      response,\n      stream: this.toUIMessageStream({\n        originalMessages,\n        generateMessageId,\n        onFinish,\n        messageMetadata,\n        sendReasoning,\n        sendSources,\n        sendFinish,\n        sendStart,\n        onError,\n      }),\n      ...init,\n    });\n  }\n\n  pipeTextStreamToResponse(response: ServerResponse, init?: ResponseInit) {\n    pipeTextStreamToResponse({\n      response,\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n\n  toUIMessageStreamResponse<UI_MESSAGE extends UIMessage>({\n    originalMessages,\n    generateMessageId,\n    onFinish,\n    messageMetadata,\n    sendReasoning,\n    sendSources,\n    sendFinish,\n    sendStart,\n    onError,\n    ...init\n  }: UIMessageStreamResponseInit &\n    UIMessageStreamOptions<UI_MESSAGE> = {}): Response {\n    return createUIMessageStreamResponse({\n      stream: this.toUIMessageStream({\n        originalMessages,\n        generateMessageId,\n        onFinish,\n        messageMetadata,\n        sendReasoning,\n        sendSources,\n        sendFinish,\n        sendStart,\n        onError,\n      }),\n      ...init,\n    });\n  }\n\n  toTextStreamResponse(init?: ResponseInit): Response {\n    return createTextStreamResponse({\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n}\n", "export function prepareHeaders(\n  headers: HeadersInit | undefined,\n  defaultHeaders: Record<string, string>,\n): Headers {\n  const responseHeaders = new Headers(headers ?? {});\n\n  for (const [key, value] of Object.entries(defaultHeaders)) {\n    if (!responseHeaders.has(key)) {\n      responseHeaders.set(key, value);\n    }\n  }\n\n  return responseHeaders;\n}\n", "import { prepareHeaders } from '../util/prepare-headers';\n\nexport function createTextStreamResponse({\n  status,\n  statusText,\n  headers,\n  textStream,\n}: ResponseInit & {\n  textStream: ReadableStream<string>;\n}): Response {\n  return new Response(textStream.pipeThrough(new TextEncoderStream()), {\n    status: status ?? 200,\n    statusText,\n    headers: prepareHeaders(headers, {\n      'content-type': 'text/plain; charset=utf-8',\n    }),\n  });\n}\n", "import { ServerResponse } from 'node:http';\n\n/**\n * Writes the content of a stream to a server response.\n */\nexport function writeToServerResponse({\n  response,\n  status,\n  statusText,\n  headers,\n  stream,\n}: {\n  response: ServerResponse;\n  status?: number;\n  statusText?: string;\n  headers?: Record<string, string | number | string[]>;\n  stream: ReadableStream<Uint8Array>;\n}): void {\n  response.writeHead(status ?? 200, statusText, headers);\n\n  const reader = stream.getReader();\n  const read = async () => {\n    try {\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n\n        // Respect backpressure: if write() returns false, wait for 'drain' event\n        const canContinue = response.write(value);\n        if (!canContinue) {\n          await new Promise<void>(resolve => {\n            response.once('drain', resolve);\n          });\n        }\n      }\n    } catch (error) {\n      throw error;\n    } finally {\n      response.end();\n    }\n  };\n\n  read();\n}\n", "import { ServerResponse } from 'node:http';\nimport { prepareHeaders } from '../util/prepare-headers';\nimport { writeToServerResponse } from '../util/write-to-server-response';\n\nexport function pipeTextStreamToResponse({\n  response,\n  status,\n  statusText,\n  headers,\n  textStream,\n}: {\n  response: ServerResponse;\n  textStream: ReadableStream<string>;\n} & ResponseInit): void {\n  writeToServerResponse({\n    response,\n    status,\n    statusText,\n    headers: Object.fromEntries(\n      prepareHeaders(headers, {\n        'content-type': 'text/plain; charset=utf-8',\n      }).entries(),\n    ),\n    stream: textStream.pipeThrough(new TextEncoderStream()),\n  });\n}\n", "export class JsonToSseTransformStream extends TransformStream<unknown, string> {\n  constructor() {\n    super({\n      transform(part, controller) {\n        controller.enqueue(`data: ${JSON.stringify(part)}\\n\\n`);\n      },\n      flush(controller) {\n        controller.enqueue('data: [DONE]\\n\\n');\n      },\n    });\n  }\n}\n", "export const UI_MESSAGE_STREAM_HEADERS = {\n  'content-type': 'text/event-stream',\n  'cache-control': 'no-cache',\n  connection: 'keep-alive',\n  'x-vercel-ai-ui-message-stream': 'v1',\n  'x-accel-buffering': 'no', // disable nginx buffering\n};\n", "import { prepareHeaders } from '../util/prepare-headers';\nimport { JsonToSseTransformStream } from './json-to-sse-transform-stream';\nimport { UI_MESSAGE_STREAM_HEADERS } from './ui-message-stream-headers';\nimport { UIMessageChunk } from './ui-message-chunks';\nimport { UIMessageStreamResponseInit } from './ui-message-stream-response-init';\n\nexport function createUIMessageStreamResponse({\n  status,\n  statusText,\n  headers,\n  stream,\n  consumeSseStream,\n}: UIMessageStreamResponseInit & {\n  stream: ReadableStream<UIMessageChunk>;\n}): Response {\n  let sseStream = stream.pipeThrough(new JsonToSseTransformStream());\n\n  // when the consumeSseStream is provided, we need to tee the stream\n  // and send the second part to the consumeSseStream function\n  // so that it can be consumed by the client independently\n  if (consumeSseStream) {\n    const [stream1, stream2] = sseStream.tee();\n    sseStream = stream1;\n    consumeSseStream({ stream: stream2 }); // no await (do not block the response)\n  }\n\n  return new Response(sseStream.pipeThrough(new TextEncoderStream()), {\n    status,\n    statusText,\n    headers: prepareHeaders(headers, UI_MESSAGE_STREAM_HEADERS),\n  });\n}\n", "import { IdGenerator } from '@ai-sdk/provider-utils';\nimport { UIMessage } from '../ui/ui-messages';\n\nexport function getResponseUIMessageId({\n  originalMessages,\n  responseMessageId,\n}: {\n  originalMessages: UIMessage[] | undefined;\n  responseMessageId: string | IdGenerator;\n}) {\n  // when there are no original messages (i.e. no persistence),\n  // the assistant message id generation is handled on the client side.\n  if (originalMessages == null) {\n    return undefined;\n  }\n\n  const lastMessage = originalMessages[originalMessages.length - 1];\n\n  return lastMessage?.role === 'assistant'\n    ? lastMessage.id\n    : typeof responseMessageId === 'function'\n      ? responseMessageId()\n      : responseMessageId;\n}\n", "import {\n  StandardSchemaV1,\n  validateTypes,\n  Validator,\n} from '@ai-sdk/provider-utils';\nimport { ProviderMetadata } from '../types';\nimport {\n  DataUIMessageChunk,\n  InferUIMessageChunk,\n  isDataUIMessageChunk,\n  UIMessageChunk,\n} from '../ui-message-stream/ui-message-chunks';\nimport { ErrorHandler } from '../util/error-handler';\nimport { mergeObjects } from '../util/merge-objects';\nimport { parsePartialJson } from '../util/parse-partial-json';\nimport { UIDataTypesToSchemas } from './chat';\nimport {\n  DataUIPart,\n  DynamicToolUIPart,\n  getToolName,\n  InferUIMessageData,\n  InferUIMessageMetadata,\n  InferUIMessageToolCall,\n  InferUIMessageTools,\n  isToolUIPart,\n  ReasoningUIPart,\n  TextUIPart,\n  ToolUIPart,\n  UIMessage,\n  UIMessagePart,\n} from './ui-messages';\n\nexport type StreamingUIMessageState<UI_MESSAGE extends UIMessage> = {\n  message: UI_MESSAGE;\n  activeTextParts: Record<string, TextUIPart>;\n  activeReasoningParts: Record<string, ReasoningUIPart>;\n  partialToolCalls: Record<\n    string,\n    { text: string; index: number; toolName: string; dynamic?: boolean }\n  >;\n};\n\nexport function createStreamingUIMessageState<UI_MESSAGE extends UIMessage>({\n  lastMessage,\n  messageId,\n}: {\n  lastMessage: UI_MESSAGE | undefined;\n  messageId: string;\n}): StreamingUIMessageState<UI_MESSAGE> {\n  return {\n    message:\n      lastMessage?.role === 'assistant'\n        ? lastMessage\n        : ({\n            id: messageId,\n            metadata: undefined,\n            role: 'assistant',\n            parts: [] as UIMessagePart<\n              InferUIMessageData<UI_MESSAGE>,\n              InferUIMessageTools<UI_MESSAGE>\n            >[],\n          } as UI_MESSAGE),\n    activeTextParts: {},\n    activeReasoningParts: {},\n    partialToolCalls: {},\n  };\n}\n\nexport function processUIMessageStream<UI_MESSAGE extends UIMessage>({\n  stream,\n  messageMetadataSchema,\n  dataPartSchemas,\n  runUpdateMessageJob,\n  onError,\n  onToolCall,\n  onData,\n}: {\n  // input stream is not fully typed yet:\n  stream: ReadableStream<UIMessageChunk>;\n  messageMetadataSchema?:\n    | Validator<InferUIMessageMetadata<UI_MESSAGE>>\n    | StandardSchemaV1<InferUIMessageMetadata<UI_MESSAGE>>;\n  dataPartSchemas?: UIDataTypesToSchemas<InferUIMessageData<UI_MESSAGE>>;\n  onToolCall?: (options: {\n    toolCall: InferUIMessageToolCall<UI_MESSAGE>;\n  }) => void | PromiseLike<void>;\n  onData?: (dataPart: DataUIPart<InferUIMessageData<UI_MESSAGE>>) => void;\n  runUpdateMessageJob: (\n    job: (options: {\n      state: StreamingUIMessageState<UI_MESSAGE>;\n      write: () => void;\n    }) => Promise<void>,\n  ) => Promise<void>;\n  onError: ErrorHandler;\n}): ReadableStream<InferUIMessageChunk<UI_MESSAGE>> {\n  return stream.pipeThrough(\n    new TransformStream<UIMessageChunk, InferUIMessageChunk<UI_MESSAGE>>({\n      async transform(chunk, controller) {\n        await runUpdateMessageJob(async ({ state, write }) => {\n          function getToolInvocation(toolCallId: string) {\n            const toolInvocations = state.message.parts.filter(isToolUIPart);\n\n            const toolInvocation = toolInvocations.find(\n              invocation => invocation.toolCallId === toolCallId,\n            );\n\n            if (toolInvocation == null) {\n              throw new Error(\n                'tool-output-error must be preceded by a tool-input-available',\n              );\n            }\n\n            return toolInvocation;\n          }\n\n          function getDynamicToolInvocation(toolCallId: string) {\n            const toolInvocations = state.message.parts.filter(\n              part => part.type === 'dynamic-tool',\n            ) as DynamicToolUIPart[];\n\n            const toolInvocation = toolInvocations.find(\n              invocation => invocation.toolCallId === toolCallId,\n            );\n\n            if (toolInvocation == null) {\n              throw new Error(\n                'tool-output-error must be preceded by a tool-input-available',\n              );\n            }\n\n            return toolInvocation;\n          }\n\n          function updateToolPart(\n            options: {\n              toolName: keyof InferUIMessageTools<UI_MESSAGE> & string;\n              toolCallId: string;\n              providerExecuted?: boolean;\n            } & (\n              | {\n                  state: 'input-streaming';\n                  input: unknown;\n                  providerExecuted?: boolean;\n                }\n              | {\n                  state: 'input-available';\n                  input: unknown;\n                  providerExecuted?: boolean;\n                  providerMetadata?: ProviderMetadata;\n                }\n              | {\n                  state: 'output-available';\n                  input: unknown;\n                  output: unknown;\n                  providerExecuted?: boolean;\n                  preliminary?: boolean;\n                }\n              | {\n                  state: 'output-error';\n                  input: unknown;\n                  rawInput?: unknown;\n                  errorText: string;\n                  providerExecuted?: boolean;\n                  providerMetadata?: ProviderMetadata;\n                }\n            ),\n          ) {\n            const part = state.message.parts.find(\n              part =>\n                isToolUIPart(part) && part.toolCallId === options.toolCallId,\n            ) as ToolUIPart<InferUIMessageTools<UI_MESSAGE>> | undefined;\n\n            const anyOptions = options as any;\n            const anyPart = part as any;\n\n            if (part != null) {\n              part.state = options.state;\n              anyPart.input = anyOptions.input;\n              anyPart.output = anyOptions.output;\n              anyPart.errorText = anyOptions.errorText;\n              anyPart.rawInput = anyOptions.rawInput;\n              anyPart.preliminary = anyOptions.preliminary;\n\n              // once providerExecuted is set, it stays for streaming\n              anyPart.providerExecuted =\n                anyOptions.providerExecuted ?? part.providerExecuted;\n\n              if (\n                anyOptions.providerMetadata != null &&\n                part.state === 'input-available'\n              ) {\n                part.callProviderMetadata = anyOptions.providerMetadata;\n              }\n            } else {\n              state.message.parts.push({\n                type: `tool-${options.toolName}`,\n                toolCallId: options.toolCallId,\n                state: options.state,\n                input: anyOptions.input,\n                output: anyOptions.output,\n                rawInput: anyOptions.rawInput,\n                errorText: anyOptions.errorText,\n                providerExecuted: anyOptions.providerExecuted,\n                preliminary: anyOptions.preliminary,\n                ...(anyOptions.providerMetadata != null\n                  ? { callProviderMetadata: anyOptions.providerMetadata }\n                  : {}),\n              } as ToolUIPart<InferUIMessageTools<UI_MESSAGE>>);\n            }\n          }\n\n          function updateDynamicToolPart(\n            options: {\n              toolName: keyof InferUIMessageTools<UI_MESSAGE> & string;\n              toolCallId: string;\n              providerExecuted?: boolean;\n            } & (\n              | {\n                  state: 'input-streaming';\n                  input: unknown;\n                }\n              | {\n                  state: 'input-available';\n                  input: unknown;\n                  providerMetadata?: ProviderMetadata;\n                }\n              | {\n                  state: 'output-available';\n                  input: unknown;\n                  output: unknown;\n                  preliminary: boolean | undefined;\n                }\n              | {\n                  state: 'output-error';\n                  input: unknown;\n                  errorText: string;\n                  providerMetadata?: ProviderMetadata;\n                }\n            ),\n          ) {\n            const part = state.message.parts.find(\n              part =>\n                part.type === 'dynamic-tool' &&\n                part.toolCallId === options.toolCallId,\n            ) as DynamicToolUIPart | undefined;\n\n            const anyOptions = options as any;\n            const anyPart = part as any;\n\n            if (part != null) {\n              part.state = options.state;\n              anyPart.toolName = options.toolName;\n              anyPart.input = anyOptions.input;\n              anyPart.output = anyOptions.output;\n              anyPart.errorText = anyOptions.errorText;\n              anyPart.rawInput = anyOptions.rawInput ?? anyPart.rawInput;\n              anyPart.preliminary = anyOptions.preliminary;\n\n              // once providerExecuted is set, it stays for streaming\n              anyPart.providerExecuted =\n                anyOptions.providerExecuted ?? part.providerExecuted;\n\n              if (\n                anyOptions.providerMetadata != null &&\n                part.state === 'input-available'\n              ) {\n                part.callProviderMetadata = anyOptions.providerMetadata;\n              }\n            } else {\n              state.message.parts.push({\n                type: 'dynamic-tool',\n                toolName: options.toolName,\n                toolCallId: options.toolCallId,\n                state: options.state,\n                input: anyOptions.input,\n                output: anyOptions.output,\n                errorText: anyOptions.errorText,\n                preliminary: anyOptions.preliminary,\n                providerExecuted: anyOptions.providerExecuted,\n                ...(anyOptions.providerMetadata != null\n                  ? { callProviderMetadata: anyOptions.providerMetadata }\n                  : {}),\n              } as DynamicToolUIPart);\n            }\n          }\n\n          async function updateMessageMetadata(metadata: unknown) {\n            if (metadata != null) {\n              const mergedMetadata =\n                state.message.metadata != null\n                  ? mergeObjects(state.message.metadata, metadata)\n                  : metadata;\n\n              if (messageMetadataSchema != null) {\n                await validateTypes({\n                  value: mergedMetadata,\n                  schema: messageMetadataSchema,\n                });\n              }\n\n              state.message.metadata =\n                mergedMetadata as InferUIMessageMetadata<UI_MESSAGE>;\n            }\n          }\n\n          switch (chunk.type) {\n            case 'text-start': {\n              const textPart: TextUIPart = {\n                type: 'text',\n                text: '',\n                providerMetadata: chunk.providerMetadata,\n                state: 'streaming',\n              };\n              state.activeTextParts[chunk.id] = textPart;\n              state.message.parts.push(textPart);\n              write();\n              break;\n            }\n\n            case 'text-delta': {\n              const textPart = state.activeTextParts[chunk.id];\n              textPart.text += chunk.delta;\n              textPart.providerMetadata =\n                chunk.providerMetadata ?? textPart.providerMetadata;\n              write();\n              break;\n            }\n\n            case 'text-end': {\n              const textPart = state.activeTextParts[chunk.id];\n              textPart.state = 'done';\n              textPart.providerMetadata =\n                chunk.providerMetadata ?? textPart.providerMetadata;\n              delete state.activeTextParts[chunk.id];\n              write();\n              break;\n            }\n\n            case 'reasoning-start': {\n              const reasoningPart: ReasoningUIPart = {\n                type: 'reasoning',\n                text: '',\n                providerMetadata: chunk.providerMetadata,\n                state: 'streaming',\n              };\n              state.activeReasoningParts[chunk.id] = reasoningPart;\n              state.message.parts.push(reasoningPart);\n              write();\n              break;\n            }\n\n            case 'reasoning-delta': {\n              const reasoningPart = state.activeReasoningParts[chunk.id];\n              reasoningPart.text += chunk.delta;\n              reasoningPart.providerMetadata =\n                chunk.providerMetadata ?? reasoningPart.providerMetadata;\n              write();\n              break;\n            }\n\n            case 'reasoning-end': {\n              const reasoningPart = state.activeReasoningParts[chunk.id];\n              reasoningPart.providerMetadata =\n                chunk.providerMetadata ?? reasoningPart.providerMetadata;\n              reasoningPart.state = 'done';\n              delete state.activeReasoningParts[chunk.id];\n\n              write();\n              break;\n            }\n\n            case 'file': {\n              state.message.parts.push({\n                type: 'file',\n                mediaType: chunk.mediaType,\n                url: chunk.url,\n              });\n\n              write();\n              break;\n            }\n\n            case 'source-url': {\n              state.message.parts.push({\n                type: 'source-url',\n                sourceId: chunk.sourceId,\n                url: chunk.url,\n                title: chunk.title,\n                providerMetadata: chunk.providerMetadata,\n              });\n\n              write();\n              break;\n            }\n\n            case 'source-document': {\n              state.message.parts.push({\n                type: 'source-document',\n                sourceId: chunk.sourceId,\n                mediaType: chunk.mediaType,\n                title: chunk.title,\n                filename: chunk.filename,\n                providerMetadata: chunk.providerMetadata,\n              });\n\n              write();\n              break;\n            }\n\n            case 'tool-input-start': {\n              const toolInvocations = state.message.parts.filter(isToolUIPart);\n\n              // add the partial tool call to the map\n              state.partialToolCalls[chunk.toolCallId] = {\n                text: '',\n                toolName: chunk.toolName,\n                index: toolInvocations.length,\n                dynamic: chunk.dynamic,\n              };\n\n              if (chunk.dynamic) {\n                updateDynamicToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: chunk.toolName,\n                  state: 'input-streaming',\n                  input: undefined,\n                  providerExecuted: chunk.providerExecuted,\n                });\n              } else {\n                updateToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: chunk.toolName,\n                  state: 'input-streaming',\n                  input: undefined,\n                  providerExecuted: chunk.providerExecuted,\n                });\n              }\n\n              write();\n              break;\n            }\n\n            case 'tool-input-delta': {\n              const partialToolCall = state.partialToolCalls[chunk.toolCallId];\n\n              partialToolCall.text += chunk.inputTextDelta;\n\n              const { value: partialArgs } = await parsePartialJson(\n                partialToolCall.text,\n              );\n\n              if (partialToolCall.dynamic) {\n                updateDynamicToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: partialToolCall.toolName,\n                  state: 'input-streaming',\n                  input: partialArgs,\n                });\n              } else {\n                updateToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: partialToolCall.toolName,\n                  state: 'input-streaming',\n                  input: partialArgs,\n                });\n              }\n\n              write();\n              break;\n            }\n\n            case 'tool-input-available': {\n              if (chunk.dynamic) {\n                updateDynamicToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: chunk.toolName,\n                  state: 'input-available',\n                  input: chunk.input,\n                  providerExecuted: chunk.providerExecuted,\n                  providerMetadata: chunk.providerMetadata,\n                });\n              } else {\n                updateToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: chunk.toolName,\n                  state: 'input-available',\n                  input: chunk.input,\n                  providerExecuted: chunk.providerExecuted,\n                  providerMetadata: chunk.providerMetadata,\n                });\n              }\n\n              write();\n\n              // invoke the onToolCall callback if it exists. This is blocking.\n              // In the future we should make this non-blocking, which\n              // requires additional state management for error handling etc.\n              // Skip calling onToolCall for provider-executed tools since they are already executed\n              if (onToolCall && !chunk.providerExecuted) {\n                await onToolCall({\n                  toolCall: chunk as InferUIMessageToolCall<UI_MESSAGE>,\n                });\n              }\n              break;\n            }\n\n            case 'tool-input-error': {\n              if (chunk.dynamic) {\n                updateDynamicToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: chunk.toolName,\n                  state: 'output-error',\n                  input: chunk.input,\n                  errorText: chunk.errorText,\n                  providerExecuted: chunk.providerExecuted,\n                  providerMetadata: chunk.providerMetadata,\n                });\n              } else {\n                updateToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: chunk.toolName,\n                  state: 'output-error',\n                  input: undefined,\n                  rawInput: chunk.input,\n                  errorText: chunk.errorText,\n                  providerExecuted: chunk.providerExecuted,\n                  providerMetadata: chunk.providerMetadata,\n                });\n              }\n\n              write();\n              break;\n            }\n\n            case 'tool-output-available': {\n              if (chunk.dynamic) {\n                const toolInvocation = getDynamicToolInvocation(\n                  chunk.toolCallId,\n                );\n\n                updateDynamicToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: toolInvocation.toolName,\n                  state: 'output-available',\n                  input: (toolInvocation as any).input,\n                  output: chunk.output,\n                  preliminary: chunk.preliminary,\n                });\n              } else {\n                const toolInvocation = getToolInvocation(chunk.toolCallId);\n\n                updateToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: getToolName(toolInvocation),\n                  state: 'output-available',\n                  input: (toolInvocation as any).input,\n                  output: chunk.output,\n                  providerExecuted: chunk.providerExecuted,\n                  preliminary: chunk.preliminary,\n                });\n              }\n\n              write();\n              break;\n            }\n\n            case 'tool-output-error': {\n              if (chunk.dynamic) {\n                const toolInvocation = getDynamicToolInvocation(\n                  chunk.toolCallId,\n                );\n\n                updateDynamicToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: toolInvocation.toolName,\n                  state: 'output-error',\n                  input: (toolInvocation as any).input,\n                  errorText: chunk.errorText,\n                  providerExecuted: chunk.providerExecuted,\n                });\n              } else {\n                const toolInvocation = getToolInvocation(chunk.toolCallId);\n\n                updateToolPart({\n                  toolCallId: chunk.toolCallId,\n                  toolName: getToolName(toolInvocation),\n                  state: 'output-error',\n                  input: (toolInvocation as any).input,\n                  rawInput: (toolInvocation as any).rawInput,\n                  errorText: chunk.errorText,\n                  providerExecuted: chunk.providerExecuted,\n                });\n              }\n\n              write();\n              break;\n            }\n\n            case 'start-step': {\n              // add a step boundary part to the message\n              state.message.parts.push({ type: 'step-start' });\n              break;\n            }\n\n            case 'finish-step': {\n              // reset the current text and reasoning parts\n              state.activeTextParts = {};\n              state.activeReasoningParts = {};\n              break;\n            }\n\n            case 'start': {\n              if (chunk.messageId != null) {\n                state.message.id = chunk.messageId;\n              }\n\n              await updateMessageMetadata(chunk.messageMetadata);\n\n              if (chunk.messageId != null || chunk.messageMetadata != null) {\n                write();\n              }\n              break;\n            }\n\n            case 'finish': {\n              await updateMessageMetadata(chunk.messageMetadata);\n              if (chunk.messageMetadata != null) {\n                write();\n              }\n              break;\n            }\n\n            case 'message-metadata': {\n              await updateMessageMetadata(chunk.messageMetadata);\n              if (chunk.messageMetadata != null) {\n                write();\n              }\n              break;\n            }\n\n            case 'error': {\n              onError?.(new Error(chunk.errorText));\n              break;\n            }\n\n            default: {\n              if (isDataUIMessageChunk(chunk)) {\n                // validate data chunk if dataPartSchemas is provided\n                if (dataPartSchemas?.[chunk.type] != null) {\n                  await validateTypes({\n                    value: chunk.data,\n                    schema: dataPartSchemas[chunk.type],\n                  });\n                }\n\n                // cast, validation is done above\n                const dataChunk = chunk as DataUIMessageChunk<\n                  InferUIMessageData<UI_MESSAGE>\n                >;\n\n                // transient parts are not added to the message state\n                if (dataChunk.transient) {\n                  onData?.(dataChunk);\n                  break;\n                }\n\n                const existingUIPart =\n                  dataChunk.id != null\n                    ? (state.message.parts.find(\n                        chunkArg =>\n                          dataChunk.type === chunkArg.type &&\n                          dataChunk.id === chunkArg.id,\n                      ) as\n                        | DataUIPart<InferUIMessageData<UI_MESSAGE>>\n                        | undefined)\n                    : undefined;\n\n                if (existingUIPart != null) {\n                  existingUIPart.data = dataChunk.data;\n                } else {\n                  state.message.parts.push(dataChunk);\n                }\n\n                onData?.(dataChunk);\n\n                write();\n              }\n            }\n          }\n\n          controller.enqueue(chunk as InferUIMessageChunk<UI_MESSAGE>);\n        });\n      },\n    }),\n  );\n}\n", "import { z } from 'zod/v4';\nimport {\n  ProviderMetadata,\n  providerMetadataSchema,\n} from '../types/provider-metadata';\nimport {\n  InferUIMessageData,\n  InferUIMessageMetadata,\n  UIDataTypes,\n  UIMessage,\n} from '../ui/ui-messages';\nimport { ValueOf } from '../util/value-of';\nimport { lazyValidator, zodSchema } from '@ai-sdk/provider-utils';\n\nexport const uiMessageChunkSchema = lazyValidator(() =>\n  zodSchema(\n    z.union([\n      z.strictObject({\n        type: z.literal('text-start'),\n        id: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('text-delta'),\n        id: z.string(),\n        delta: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('text-end'),\n        id: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('error'),\n        errorText: z.string(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-input-start'),\n        toolCallId: z.string(),\n        toolName: z.string(),\n        providerExecuted: z.boolean().optional(),\n        dynamic: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-input-delta'),\n        toolCallId: z.string(),\n        inputTextDelta: z.string(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-input-available'),\n        toolCallId: z.string(),\n        toolName: z.string(),\n        input: z.unknown(),\n        providerExecuted: z.boolean().optional(),\n        providerMetadata: providerMetadataSchema.optional(),\n        dynamic: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-input-error'),\n        toolCallId: z.string(),\n        toolName: z.string(),\n        input: z.unknown(),\n        providerExecuted: z.boolean().optional(),\n        providerMetadata: providerMetadataSchema.optional(),\n        dynamic: z.boolean().optional(),\n        errorText: z.string(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-output-available'),\n        toolCallId: z.string(),\n        output: z.unknown(),\n        providerExecuted: z.boolean().optional(),\n        dynamic: z.boolean().optional(),\n        preliminary: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('tool-output-error'),\n        toolCallId: z.string(),\n        errorText: z.string(),\n        providerExecuted: z.boolean().optional(),\n        dynamic: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('reasoning-start'),\n        id: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('reasoning-delta'),\n        id: z.string(),\n        delta: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('reasoning-end'),\n        id: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('source-url'),\n        sourceId: z.string(),\n        url: z.string(),\n        title: z.string().optional(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('source-document'),\n        sourceId: z.string(),\n        mediaType: z.string(),\n        title: z.string(),\n        filename: z.string().optional(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.literal('file'),\n        url: z.string(),\n        mediaType: z.string(),\n        providerMetadata: providerMetadataSchema.optional(),\n      }),\n      z.strictObject({\n        type: z.custom<`data-${string}`>(\n          (value): value is `data-${string}` =>\n            typeof value === 'string' && value.startsWith('data-'),\n          { message: 'Type must start with \"data-\"' },\n        ),\n        id: z.string().optional(),\n        data: z.unknown(),\n        transient: z.boolean().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('start-step'),\n      }),\n      z.strictObject({\n        type: z.literal('finish-step'),\n      }),\n      z.strictObject({\n        type: z.literal('start'),\n        messageId: z.string().optional(),\n        messageMetadata: z.unknown().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('finish'),\n        messageMetadata: z.unknown().optional(),\n      }),\n      z.strictObject({\n        type: z.literal('abort'),\n      }),\n      z.strictObject({\n        type: z.literal('message-metadata'),\n        messageMetadata: z.unknown(),\n      }),\n    ]),\n  ),\n);\n\nexport type DataUIMessageChunk<DATA_TYPES extends UIDataTypes> = ValueOf<{\n  [NAME in keyof DATA_TYPES & string]: {\n    type: `data-${NAME}`;\n    id?: string;\n    data: DATA_TYPES[NAME];\n    transient?: boolean;\n  };\n}>;\n\nexport type UIMessageChunk<\n  METADATA = unknown,\n  DATA_TYPES extends UIDataTypes = UIDataTypes,\n> =\n  | {\n      type: 'text-start';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'text-delta';\n      delta: string;\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'text-end';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'reasoning-start';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'reasoning-delta';\n      id: string;\n      delta: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'reasoning-end';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'error';\n      errorText: string;\n    }\n  | {\n      type: 'tool-input-available';\n      toolCallId: string;\n      toolName: string;\n      input: unknown;\n      providerExecuted?: boolean;\n      providerMetadata?: ProviderMetadata;\n      dynamic?: boolean;\n    }\n  | {\n      type: 'tool-input-error';\n      toolCallId: string;\n      toolName: string;\n      input: unknown;\n      providerExecuted?: boolean;\n      providerMetadata?: ProviderMetadata;\n      dynamic?: boolean;\n      errorText: string;\n    }\n  | {\n      type: 'tool-output-available';\n      toolCallId: string;\n      output: unknown;\n      providerExecuted?: boolean;\n      dynamic?: boolean;\n      preliminary?: boolean;\n    }\n  | {\n      type: 'tool-output-error';\n      toolCallId: string;\n      errorText: string;\n      providerExecuted?: boolean;\n      dynamic?: boolean;\n    }\n  | {\n      type: 'tool-input-start';\n      toolCallId: string;\n      toolName: string;\n      providerExecuted?: boolean;\n      dynamic?: boolean;\n    }\n  | {\n      type: 'tool-input-delta';\n      toolCallId: string;\n      inputTextDelta: string;\n    }\n  | {\n      type: 'source-url';\n      sourceId: string;\n      url: string;\n      title?: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'source-document';\n      sourceId: string;\n      mediaType: string;\n      title: string;\n      filename?: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'file';\n      url: string;\n      mediaType: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | DataUIMessageChunk<DATA_TYPES>\n  | {\n      type: 'start-step';\n    }\n  | {\n      type: 'finish-step';\n    }\n  | {\n      type: 'start';\n      messageId?: string;\n      messageMetadata?: METADATA;\n    }\n  | {\n      type: 'finish';\n      messageMetadata?: METADATA;\n    }\n  | {\n      type: 'abort';\n    }\n  | {\n      type: 'message-metadata';\n      messageMetadata: METADATA;\n    };\n\nexport function isDataUIMessageChunk(\n  chunk: UIMessageChunk,\n): chunk is DataUIMessageChunk<UIDataTypes> {\n  return chunk.type.startsWith('data-');\n}\n\nexport type InferUIMessageChunk<T extends UIMessage> = UIMessageChunk<\n  InferUIMessageMetadata<T>,\n  InferUIMessageData<T>\n>;\n", "/**\n * Deeply merges two objects together.\n * - Properties from the `overrides` object override those in the `base` object with the same key.\n * - For nested objects, the merge is performed recursively (deep merge).\n * - Arrays are replaced, not merged.\n * - Primitive values are replaced.\n * - If both `base` and `overrides` are undefined, returns undefined.\n * - If one of `base` or `overrides` is undefined, returns the other.\n *\n * @param base The target object to merge into\n * @param overrides The source object to merge from\n * @returns A new object with the merged properties, or undefined if both inputs are undefined\n */\nexport function mergeObjects<T extends object, U extends object>(\n  base: T | undefined,\n  overrides: U | undefined,\n): (T & U) | T | U | undefined {\n  // If both inputs are undefined, return undefined\n  if (base === undefined && overrides === undefined) {\n    return undefined;\n  }\n\n  // If target is undefined, return source\n  if (base === undefined) {\n    return overrides;\n  }\n\n  // If source is undefined, return target\n  if (overrides === undefined) {\n    return base;\n  }\n\n  // Create a new object to avoid mutating the inputs\n  const result = { ...base } as T & U;\n\n  // Iterate through all keys in the source object\n  for (const key in overrides) {\n    if (Object.prototype.hasOwnProperty.call(overrides, key)) {\n      const overridesValue = overrides[key];\n\n      // Skip if the overrides value is undefined\n      if (overridesValue === undefined) continue;\n\n      // Get the base value if it exists\n      const baseValue =\n        key in base ? base[key as unknown as keyof T] : undefined;\n\n      // Check if both values are objects that can be deeply merged\n      const isSourceObject =\n        overridesValue !== null &&\n        typeof overridesValue === 'object' &&\n        !Array.isArray(overridesValue) &&\n        !(overridesValue instanceof Date) &&\n        !(overridesValue instanceof RegExp);\n\n      const isTargetObject =\n        baseValue !== null &&\n        baseValue !== undefined &&\n        typeof baseValue === 'object' &&\n        !Array.isArray(baseValue) &&\n        !(baseValue instanceof Date) &&\n        !(baseValue instanceof RegExp);\n\n      // If both values are mergeable objects, merge them recursively\n      if (isSourceObject && isTargetObject) {\n        result[key as keyof (T & U)] = mergeObjects(\n          baseValue as object,\n          overridesValue as object,\n        ) as any;\n      } else {\n        // For primitives, arrays, or when one value is not a mergeable object,\n        // simply override with the source value\n        result[key as keyof (T & U)] = overridesValue as any;\n      }\n    }\n  }\n\n  return result;\n}\n", "import { JSONValue } from '@ai-sdk/provider';\nimport { safeParseJSON } from '@ai-sdk/provider-utils';\nimport { fixJson } from './fix-json';\n\nexport async function parsePartialJson(jsonText: string | undefined): Promise<{\n  value: JSONValue | undefined;\n  state:\n    | 'undefined-input'\n    | 'successful-parse'\n    | 'repaired-parse'\n    | 'failed-parse';\n}> {\n  if (jsonText === undefined) {\n    return { value: undefined, state: 'undefined-input' };\n  }\n\n  let result = await safeParseJSON({ text: jsonText });\n\n  if (result.success) {\n    return { value: result.value, state: 'successful-parse' };\n  }\n\n  result = await safeParseJSON({ text: fixJson(jsonText) });\n\n  if (result.success) {\n    return { value: result.value, state: 'repaired-parse' };\n  }\n\n  return { value: undefined, state: 'failed-parse' };\n}\n", "type State =\n  | 'ROOT'\n  | 'FINISH'\n  | 'INSIDE_STRING'\n  | 'INSIDE_STRING_ESCAPE'\n  | 'INSIDE_LITERAL'\n  | 'INSIDE_NUMBER'\n  | 'INSIDE_OBJECT_START'\n  | 'INSIDE_OBJECT_KEY'\n  | 'INSIDE_OBJECT_AFTER_KEY'\n  | 'INSIDE_OBJECT_BEFORE_VALUE'\n  | 'INSIDE_OBJECT_AFTER_VALUE'\n  | 'INSIDE_OBJECT_AFTER_COMMA'\n  | 'INSIDE_ARRAY_START'\n  | 'INSIDE_ARRAY_AFTER_VALUE'\n  | 'INSIDE_ARRAY_AFTER_COMMA';\n\n// Implemented as a scanner with additional fixing\n// that performs a single linear time scan pass over the partial JSON.\n//\n// The states should ideally match relevant states from the JSON spec:\n// https://www.json.org/json-en.html\n//\n// Please note that invalid JSON is not considered/covered, because it\n// is assumed that the resulting JSON will be processed by a standard\n// JSON parser that will detect any invalid JSON.\nexport function fixJson(input: string): string {\n  const stack: State[] = ['ROOT'];\n  let lastValidIndex = -1;\n  let literalStart: number | null = null;\n\n  function processValueStart(char: string, i: number, swapState: State) {\n    {\n      switch (char) {\n        case '\"': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_STRING');\n          break;\n        }\n\n        case 'f':\n        case 't':\n        case 'n': {\n          lastValidIndex = i;\n          literalStart = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_LITERAL');\n          break;\n        }\n\n        case '-': {\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_NUMBER');\n          break;\n        }\n        case '0':\n        case '1':\n        case '2':\n        case '3':\n        case '4':\n        case '5':\n        case '6':\n        case '7':\n        case '8':\n        case '9': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_NUMBER');\n          break;\n        }\n\n        case '{': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_OBJECT_START');\n          break;\n        }\n\n        case '[': {\n          lastValidIndex = i;\n          stack.pop();\n          stack.push(swapState);\n          stack.push('INSIDE_ARRAY_START');\n          break;\n        }\n      }\n    }\n  }\n\n  function processAfterObjectValue(char: string, i: number) {\n    switch (char) {\n      case ',': {\n        stack.pop();\n        stack.push('INSIDE_OBJECT_AFTER_COMMA');\n        break;\n      }\n      case '}': {\n        lastValidIndex = i;\n        stack.pop();\n        break;\n      }\n    }\n  }\n\n  function processAfterArrayValue(char: string, i: number) {\n    switch (char) {\n      case ',': {\n        stack.pop();\n        stack.push('INSIDE_ARRAY_AFTER_COMMA');\n        break;\n      }\n      case ']': {\n        lastValidIndex = i;\n        stack.pop();\n        break;\n      }\n    }\n  }\n\n  for (let i = 0; i < input.length; i++) {\n    const char = input[i];\n    const currentState = stack[stack.length - 1];\n\n    switch (currentState) {\n      case 'ROOT':\n        processValueStart(char, i, 'FINISH');\n        break;\n\n      case 'INSIDE_OBJECT_START': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_KEY');\n            break;\n          }\n          case '}': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_COMMA': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_KEY');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_KEY': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_AFTER_KEY');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_KEY': {\n        switch (char) {\n          case ':': {\n            stack.pop();\n            stack.push('INSIDE_OBJECT_BEFORE_VALUE');\n\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_OBJECT_BEFORE_VALUE': {\n        processValueStart(char, i, 'INSIDE_OBJECT_AFTER_VALUE');\n        break;\n      }\n\n      case 'INSIDE_OBJECT_AFTER_VALUE': {\n        processAfterObjectValue(char, i);\n        break;\n      }\n\n      case 'INSIDE_STRING': {\n        switch (char) {\n          case '\"': {\n            stack.pop();\n            lastValidIndex = i;\n            break;\n          }\n\n          case '\\\\': {\n            stack.push('INSIDE_STRING_ESCAPE');\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_ARRAY_START': {\n        switch (char) {\n          case ']': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n            processValueStart(char, i, 'INSIDE_ARRAY_AFTER_VALUE');\n            break;\n          }\n        }\n        break;\n      }\n\n      case 'INSIDE_ARRAY_AFTER_VALUE': {\n        switch (char) {\n          case ',': {\n            stack.pop();\n            stack.push('INSIDE_ARRAY_AFTER_COMMA');\n            break;\n          }\n\n          case ']': {\n            lastValidIndex = i;\n            stack.pop();\n            break;\n          }\n\n          default: {\n            lastValidIndex = i;\n            break;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_ARRAY_AFTER_COMMA': {\n        processValueStart(char, i, 'INSIDE_ARRAY_AFTER_VALUE');\n        break;\n      }\n\n      case 'INSIDE_STRING_ESCAPE': {\n        stack.pop();\n        lastValidIndex = i;\n\n        break;\n      }\n\n      case 'INSIDE_NUMBER': {\n        switch (char) {\n          case '0':\n          case '1':\n          case '2':\n          case '3':\n          case '4':\n          case '5':\n          case '6':\n          case '7':\n          case '8':\n          case '9': {\n            lastValidIndex = i;\n            break;\n          }\n\n          case 'e':\n          case 'E':\n          case '-':\n          case '.': {\n            break;\n          }\n\n          case ',': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n              processAfterArrayValue(char, i);\n            }\n\n            if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n              processAfterObjectValue(char, i);\n            }\n\n            break;\n          }\n\n          case '}': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n              processAfterObjectValue(char, i);\n            }\n\n            break;\n          }\n\n          case ']': {\n            stack.pop();\n\n            if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n              processAfterArrayValue(char, i);\n            }\n\n            break;\n          }\n\n          default: {\n            stack.pop();\n            break;\n          }\n        }\n\n        break;\n      }\n\n      case 'INSIDE_LITERAL': {\n        const partialLiteral = input.substring(literalStart!, i + 1);\n\n        if (\n          !'false'.startsWith(partialLiteral) &&\n          !'true'.startsWith(partialLiteral) &&\n          !'null'.startsWith(partialLiteral)\n        ) {\n          stack.pop();\n\n          if (stack[stack.length - 1] === 'INSIDE_OBJECT_AFTER_VALUE') {\n            processAfterObjectValue(char, i);\n          } else if (stack[stack.length - 1] === 'INSIDE_ARRAY_AFTER_VALUE') {\n            processAfterArrayValue(char, i);\n          }\n        } else {\n          lastValidIndex = i;\n        }\n\n        break;\n      }\n    }\n  }\n\n  let result = input.slice(0, lastValidIndex + 1);\n\n  for (let i = stack.length - 1; i >= 0; i--) {\n    const state = stack[i];\n\n    switch (state) {\n      case 'INSIDE_STRING': {\n        result += '\"';\n        break;\n      }\n\n      case 'INSIDE_OBJECT_KEY':\n      case 'INSIDE_OBJECT_AFTER_KEY':\n      case 'INSIDE_OBJECT_AFTER_COMMA':\n      case 'INSIDE_OBJECT_START':\n      case 'INSIDE_OBJECT_BEFORE_VALUE':\n      case 'INSIDE_OBJECT_AFTER_VALUE': {\n        result += '}';\n        break;\n      }\n\n      case 'INSIDE_ARRAY_START':\n      case 'INSIDE_ARRAY_AFTER_COMMA':\n      case 'INSIDE_ARRAY_AFTER_VALUE': {\n        result += ']';\n        break;\n      }\n\n      case 'INSIDE_LITERAL': {\n        const partialLiteral = input.substring(literalStart!, input.length);\n\n        if ('true'.startsWith(partialLiteral)) {\n          result += 'true'.slice(partialLiteral.length);\n        } else if ('false'.startsWith(partialLiteral)) {\n          result += 'false'.slice(partialLiteral.length);\n        } else if ('null'.startsWith(partialLiteral)) {\n          result += 'null'.slice(partialLiteral.length);\n        }\n      }\n    }\n  }\n\n  return result;\n}\n", "import {\n  InferToolInput,\n  InferToolOutput,\n  Tool,\n  ToolCall,\n} from '@ai-sdk/provider-utils';\nimport { ToolSet } from '../generate-text';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { DeepPartial } from '../util/deep-partial';\nimport { ValueOf } from '../util/value-of';\n\n/**\nThe data types that can be used in the UI message for the UI message data parts.\n */\nexport type UIDataTypes = Record<string, unknown>;\n\nexport type UITool = {\n  input: unknown;\n  output: unknown | undefined;\n};\n\n/**\n * Infer the input and output types of a tool so it can be used as a UI tool.\n */\nexport type InferUITool<TOOL extends Tool> = {\n  input: InferToolInput<TOOL>;\n  output: InferToolOutput<TOOL>;\n};\n\n/**\n * Infer the input and output types of a tool set so it can be used as a UI tool set.\n */\nexport type InferUITools<TOOLS extends ToolSet> = {\n  [NAME in keyof TOOLS & string]: InferUITool<TOOLS[NAME]>;\n};\n\nexport type UITools = Record<string, UITool>;\n\n/**\nAI SDK UI Messages. They are used in the client and to communicate between the frontend and the API routes.\n */\nexport interface UIMessage<\n  METADATA = unknown,\n  DATA_PARTS extends UIDataTypes = UIDataTypes,\n  TOOLS extends UITools = UITools,\n> {\n  /**\nA unique identifier for the message.\n   */\n  id: string;\n\n  /**\nThe role of the message.\n   */\n  role: 'system' | 'user' | 'assistant';\n\n  /**\nThe metadata of the message.\n   */\n  metadata?: METADATA;\n\n  /**\nThe parts of the message. Use this for rendering the message in the UI.\n\nSystem messages should be avoided (set the system prompt on the server instead).\nThey can have text parts.\n\nUser messages can have text parts and file parts.\n\nAssistant messages can have text, reasoning, tool invocation, and file parts.\n   */\n  parts: Array<UIMessagePart<DATA_PARTS, TOOLS>>;\n}\n\nexport type UIMessagePart<\n  DATA_TYPES extends UIDataTypes,\n  TOOLS extends UITools,\n> =\n  | TextUIPart\n  | ReasoningUIPart\n  | ToolUIPart<TOOLS>\n  | DynamicToolUIPart\n  | SourceUrlUIPart\n  | SourceDocumentUIPart\n  | FileUIPart\n  | DataUIPart<DATA_TYPES>\n  | StepStartUIPart;\n\n/**\n * A text part of a message.\n */\nexport type TextUIPart = {\n  type: 'text';\n\n  /**\n   * The text content.\n   */\n  text: string;\n\n  /**\n   * The state of the text part.\n   */\n  state?: 'streaming' | 'done';\n\n  /**\n   * The provider metadata.\n   */\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A reasoning part of a message.\n */\nexport type ReasoningUIPart = {\n  type: 'reasoning';\n\n  /**\n   * The reasoning text.\n   */\n  text: string;\n\n  /**\n   * The state of the reasoning part.\n   */\n  state?: 'streaming' | 'done';\n\n  /**\n   * The provider metadata.\n   */\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A source part of a message.\n */\nexport type SourceUrlUIPart = {\n  type: 'source-url';\n  sourceId: string;\n  url: string;\n  title?: string;\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A document source part of a message.\n */\nexport type SourceDocumentUIPart = {\n  type: 'source-document';\n  sourceId: string;\n  mediaType: string;\n  title: string;\n  filename?: string;\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A file part of a message.\n */\nexport type FileUIPart = {\n  type: 'file';\n\n  /**\n   * IANA media type of the file.\n   *\n   * @see https://www.iana.org/assignments/media-types/media-types.xhtml\n   */\n  mediaType: string;\n\n  /**\n   * Optional filename of the file.\n   */\n  filename?: string;\n\n  /**\n   * The URL of the file.\n   * It can either be a URL to a hosted file or a [Data URL](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs).\n   */\n  url: string;\n\n  /**\n   * The provider metadata.\n   */\n  providerMetadata?: ProviderMetadata;\n};\n\n/**\n * A step boundary part of a message.\n */\nexport type StepStartUIPart = {\n  type: 'step-start';\n};\n\nexport type DataUIPart<DATA_TYPES extends UIDataTypes> = ValueOf<{\n  [NAME in keyof DATA_TYPES & string]: {\n    type: `data-${NAME}`;\n    id?: string;\n    data: DATA_TYPES[NAME];\n  };\n}>;\n\ntype asUITool<TOOL extends UITool | Tool> = TOOL extends Tool\n  ? InferUITool<TOOL>\n  : TOOL;\n\n/**\n * Check if a message part is a data part.\n */\nexport function isDataUIPart<DATA_TYPES extends UIDataTypes>(\n  part: UIMessagePart<DATA_TYPES, UITools>,\n): part is DataUIPart<DATA_TYPES> {\n  return part.type.startsWith('data-');\n}\n\n/**\n * A UI tool invocation contains all the information needed to render a tool invocation in the UI.\n * It can be derived from a tool without knowing the tool name, and can be used to define\n * UI components for the tool.\n */\nexport type UIToolInvocation<TOOL extends UITool | Tool> = {\n  /**\n   * ID of the tool call.\n   */\n  toolCallId: string;\n\n  /**\n   * Whether the tool call was executed by the provider.\n   */\n  providerExecuted?: boolean;\n} & (\n  | {\n      state: 'input-streaming';\n      input: DeepPartial<asUITool<TOOL>['input']> | undefined;\n      providerExecuted?: boolean;\n      output?: never;\n      errorText?: never;\n    }\n  | {\n      state: 'input-available';\n      input: asUITool<TOOL>['input'];\n      providerExecuted?: boolean;\n      output?: never;\n      errorText?: never;\n      callProviderMetadata?: ProviderMetadata;\n    }\n  | {\n      state: 'output-available';\n      input: asUITool<TOOL>['input'];\n      output: asUITool<TOOL>['output'];\n      errorText?: never;\n      providerExecuted?: boolean;\n      callProviderMetadata?: ProviderMetadata;\n      preliminary?: boolean;\n    }\n  | {\n      state: 'output-error'; // TODO AI SDK 6: change to 'error' state\n      input: asUITool<TOOL>['input'] | undefined;\n      rawInput?: unknown; // TODO AI SDK 6: remove this field, input should be unknown\n      output?: never;\n      errorText: string;\n      providerExecuted?: boolean;\n      callProviderMetadata?: ProviderMetadata;\n    }\n);\n\nexport type ToolUIPart<TOOLS extends UITools = UITools> = ValueOf<{\n  [NAME in keyof TOOLS & string]: {\n    type: `tool-${NAME}`;\n  } & UIToolInvocation<TOOLS[NAME]>;\n}>;\n\nexport type DynamicToolUIPart = {\n  type: 'dynamic-tool';\n\n  /**\n   * Name of the tool that is being called.\n   */\n  toolName: string;\n\n  /**\n   * ID of the tool call.\n   */\n  toolCallId: string;\n  title?: string;\n\n  /**\n   * Whether the tool call was executed by the provider.\n   */\n  providerExecuted?: boolean;\n} & (\n  | {\n      state: 'input-streaming';\n      input: unknown | undefined;\n      output?: never;\n      errorText?: never;\n    }\n  | {\n      state: 'input-available';\n      input: unknown;\n      output?: never;\n      errorText?: never;\n      callProviderMetadata?: ProviderMetadata;\n    }\n  | {\n      state: 'output-available';\n      input: unknown;\n      output: unknown;\n      errorText?: never;\n      callProviderMetadata?: ProviderMetadata;\n      preliminary?: boolean;\n    }\n  | {\n      state: 'output-error'; // TODO AI SDK 6: change to 'error' state\n      input: unknown;\n      output?: never;\n      errorText: string;\n      callProviderMetadata?: ProviderMetadata;\n    }\n);\n\n/**\n * Type guard to check if a message part is a text part.\n */\nexport function isTextUIPart(\n  part: UIMessagePart<UIDataTypes, UITools>,\n): part is TextUIPart {\n  return part.type === 'text';\n}\n\n/**\n * Type guard to check if a message part is a file part.\n */\nexport function isFileUIPart(\n  part: UIMessagePart<UIDataTypes, UITools>,\n): part is FileUIPart {\n  return part.type === 'file';\n}\n\n/**\n * Type guard to check if a message part is a reasoning part.\n */\nexport function isReasoningUIPart(\n  part: UIMessagePart<UIDataTypes, UITools>,\n): part is ReasoningUIPart {\n  return part.type === 'reasoning';\n}\n\n// TODO AI SDK 6: rename to isStaticToolUIPart\nexport function isToolUIPart<TOOLS extends UITools>(\n  part: UIMessagePart<UIDataTypes, TOOLS>,\n): part is ToolUIPart<TOOLS> {\n  return part.type.startsWith('tool-');\n}\n\nexport function isDynamicToolUIPart(\n  part: UIMessagePart<UIDataTypes, UITools>,\n): part is DynamicToolUIPart {\n  return part.type === 'dynamic-tool';\n}\n\nexport function isToolOrDynamicToolUIPart<TOOLS extends UITools>(\n  part: UIMessagePart<UIDataTypes, TOOLS>,\n): part is ToolUIPart<TOOLS> | DynamicToolUIPart {\n  return isToolUIPart(part) || isDynamicToolUIPart(part);\n}\n\nexport function getToolName<TOOLS extends UITools>(\n  part: ToolUIPart<TOOLS>,\n): keyof TOOLS {\n  return part.type.split('-').slice(1).join('-') as keyof TOOLS;\n}\n\nexport function getToolOrDynamicToolName(\n  part: ToolUIPart<UITools> | DynamicToolUIPart,\n): string {\n  return isDynamicToolUIPart(part) ? part.toolName : getToolName(part);\n}\n\nexport type InferUIMessageMetadata<T extends UIMessage> =\n  T extends UIMessage<infer METADATA> ? METADATA : unknown;\n\nexport type InferUIMessageData<T extends UIMessage> =\n  T extends UIMessage<unknown, infer DATA_TYPES> ? DATA_TYPES : UIDataTypes;\n\nexport type InferUIMessageTools<T extends UIMessage> =\n  T extends UIMessage<unknown, UIDataTypes, infer TOOLS> ? TOOLS : UITools;\n\nexport type InferUIMessageToolOutputs<UI_MESSAGE extends UIMessage> =\n  InferUIMessageTools<UI_MESSAGE>[keyof InferUIMessageTools<UI_MESSAGE>]['output'];\n\nexport type InferUIMessageToolCall<UI_MESSAGE extends UIMessage> =\n  | ValueOf<{\n      [NAME in keyof InferUIMessageTools<UI_MESSAGE>]: ToolCall<\n        NAME & string,\n        InferUIMessageTools<UI_MESSAGE>[NAME] extends { input: infer INPUT }\n          ? INPUT\n          : never\n      > & { dynamic?: false };\n    }>\n  | (ToolCall<string, unknown> & { dynamic: true });\n\nexport type InferUIMessagePart<UI_MESSAGE extends UIMessage> = UIMessagePart<\n  InferUIMessageData<UI_MESSAGE>,\n  InferUIMessageTools<UI_MESSAGE>\n>;\n", "import {\n  createStreamingUIMessageState,\n  processUIMessageStream,\n  StreamingUIMessageState,\n} from '../ui/process-ui-message-stream';\nimport { UIMessage } from '../ui/ui-messages';\nimport { ErrorHandler } from '../util/error-handler';\nimport { InferUIMessageChunk, UIMessageChunk } from './ui-message-chunks';\nimport { UIMessageStreamOnFinishCallback } from './ui-message-stream-on-finish-callback';\n\nexport function handleUIMessageStreamFinish<UI_MESSAGE extends UIMessage>({\n  messageId,\n  originalMessages = [],\n  onFinish,\n  onError,\n  stream,\n}: {\n  stream: ReadableStream<InferUIMessageChunk<UI_MESSAGE>>;\n\n  /**\n   * The message ID to use for the response message.\n   * If not provided, no id will be set for the response message.\n   */\n  messageId?: string;\n\n  /**\n   * The original messages.\n   */\n  originalMessages?: UI_MESSAGE[];\n\n  onError: ErrorHandler;\n\n  onFinish?: UIMessageStreamOnFinishCallback<UI_MESSAGE>;\n}): ReadableStream<InferUIMessageChunk<UI_MESSAGE>> {\n  // last message is only relevant for assistant messages\n  let lastMessage: UI_MESSAGE | undefined =\n    originalMessages?.[originalMessages.length - 1];\n  if (lastMessage?.role !== 'assistant') {\n    lastMessage = undefined;\n  } else {\n    // appending to the last message, so we need to use the same id\n    messageId = lastMessage.id;\n  }\n\n  let isAborted = false;\n\n  const idInjectedStream = stream.pipeThrough(\n    new TransformStream<\n      InferUIMessageChunk<UI_MESSAGE>,\n      InferUIMessageChunk<UI_MESSAGE>\n    >({\n      transform(chunk, controller) {\n        // when there is no messageId in the start chunk,\n        // but the user checked for persistence,\n        // inject the messageId into the chunk\n        if (chunk.type === 'start') {\n          const startChunk = chunk as UIMessageChunk & { type: 'start' };\n          if (startChunk.messageId == null && messageId != null) {\n            startChunk.messageId = messageId;\n          }\n        }\n\n        if (chunk.type === 'abort') {\n          isAborted = true;\n        }\n\n        controller.enqueue(chunk);\n      },\n    }),\n  );\n\n  if (onFinish == null) {\n    return idInjectedStream;\n  }\n\n  const state = createStreamingUIMessageState<UI_MESSAGE>({\n    lastMessage: lastMessage\n      ? (structuredClone(lastMessage) as UI_MESSAGE)\n      : undefined,\n    messageId: messageId ?? '', // will be overridden by the stream\n  });\n\n  const runUpdateMessageJob = async (\n    job: (options: {\n      state: StreamingUIMessageState<UI_MESSAGE>;\n      write: () => void;\n    }) => Promise<void>,\n  ) => {\n    await job({ state, write: () => {} });\n  };\n\n  let finishCalled = false;\n\n  const callOnFinish = async () => {\n    if (finishCalled || !onFinish) {\n      return;\n    }\n    finishCalled = true;\n\n    const isContinuation = state.message.id === lastMessage?.id;\n    await onFinish({\n      isAborted,\n      isContinuation,\n      responseMessage: state.message as UI_MESSAGE,\n      messages: [\n        ...(isContinuation ? originalMessages.slice(0, -1) : originalMessages),\n        state.message,\n      ] as UI_MESSAGE[],\n    });\n  };\n\n  return processUIMessageStream<UI_MESSAGE>({\n    stream: idInjectedStream,\n    runUpdateMessageJob,\n    onError,\n  }).pipeThrough(\n    new TransformStream<\n      InferUIMessageChunk<UI_MESSAGE>,\n      InferUIMessageChunk<UI_MESSAGE>\n    >({\n      transform(chunk, controller) {\n        controller.enqueue(chunk);\n      },\n      // @ts-expect-error cancel is still new and missing from types https://developer.mozilla.org/en-US/docs/Web/API/TransformStream#browser_compatibility\n      async cancel() {\n        await callOnFinish();\n      },\n\n      async flush() {\n        await callOnFinish();\n      },\n    }),\n  );\n}\n", "import { ServerResponse } from 'node:http';\nimport { prepareHeaders } from '../util/prepare-headers';\nimport { writeToServerResponse } from '../util/write-to-server-response';\nimport { JsonToSseTransformStream } from './json-to-sse-transform-stream';\nimport { UI_MESSAGE_STREAM_HEADERS } from './ui-message-stream-headers';\nimport { UIMessageChunk } from './ui-message-chunks';\nimport { UIMessageStreamResponseInit } from './ui-message-stream-response-init';\n\nexport function pipeUIMessageStreamToResponse({\n  response,\n  status,\n  statusText,\n  headers,\n  stream,\n  consumeSseStream,\n}: {\n  response: ServerResponse;\n  stream: ReadableStream<UIMessageChunk>;\n} & UIMessageStreamResponseInit): void {\n  let sseStream = stream.pipeThrough(new JsonToSseTransformStream());\n\n  // when the consumeSseStream is provided, we need to tee the stream\n  // and send the second part to the consumeSseStream function\n  // so that it can be consumed by the client independently\n  if (consumeSseStream) {\n    const [stream1, stream2] = sseStream.tee();\n    sseStream = stream1;\n    consumeSseStream({ stream: stream2 }); // no await (do not block the response)\n  }\n\n  writeToServerResponse({\n    response,\n    status,\n    statusText,\n    headers: Object.fromEntries(\n      prepareHeaders(headers, UI_MESSAGE_STREAM_HEADERS).entries(),\n    ),\n    stream: sseStream.pipeThrough(new TextEncoderStream()),\n  });\n}\n", "/**\n * A type that combines AsyncIterable and ReadableStream.\n * This allows a ReadableStream to be consumed using for-await-of syntax.\n */\nexport type AsyncIterableStream<T> = AsyncIterable<T> & ReadableStream<T>;\n\n/**\n * Wraps a ReadableStream and returns an object that is both a ReadableStream and an AsyncIterable.\n * This enables consumption of the stream using for-await-of, with proper resource cleanup on early exit or error.\n *\n * @template T The type of the stream's chunks.\n * @param source The source ReadableStream to wrap.\n * @returns An AsyncIterableStream that can be used as both a ReadableStream and an AsyncIterable.\n */\nexport function createAsyncIterableStream<T>(\n  source: ReadableStream<T>,\n): AsyncIterableStream<T> {\n  // Pipe through a TransformStream to ensure a fresh, unlocked stream.\n  const stream = source.pipeThrough(new TransformStream<T, T>());\n\n  /**\n   * Implements the async iterator protocol for the stream.\n   * Ensures proper cleanup (cancelling and releasing the reader) on completion, early exit, or error.\n   */\n  (stream as AsyncIterableStream<T>)[Symbol.asyncIterator] = function (\n    this: ReadableStream<T>,\n  ): AsyncIterator<T> {\n    const reader = this.getReader();\n\n    let finished = false;\n\n    /**\n     * Cleans up the reader by cancelling and releasing the lock.\n     */\n    async function cleanup(cancelStream: boolean) {\n      finished = true;\n      try {\n        if (cancelStream) {\n          await reader.cancel?.();\n        }\n      } finally {\n        try {\n          reader.releaseLock();\n        } catch {}\n      }\n    }\n\n    return {\n      /**\n       * Reads the next chunk from the stream.\n       * @returns A promise resolving to the next IteratorResult.\n       */\n      async next(): Promise<IteratorResult<T>> {\n        if (finished) {\n          return { done: true, value: undefined };\n        }\n\n        const { done, value } = await reader.read();\n\n        if (done) {\n          await cleanup(true);\n          return { done: true, value: undefined };\n        }\n\n        return { done: false, value };\n      },\n\n      /**\n       * Called on early exit (e.g., break from for-await).\n       * Ensures the stream is cancelled and resources are released.\n       * @returns A promise resolving to a completed IteratorResult.\n       */\n      async return(): Promise<IteratorResult<T>> {\n        await cleanup(true);\n        return { done: true, value: undefined };\n      },\n\n      /**\n       * Called on early exit with error.\n       * Ensures the stream is cancelled and resources are released, then rethrows the error.\n       * @param err The error to throw.\n       * @returns A promise that rejects with the provided error.\n       */\n      async throw(err: unknown): Promise<IteratorResult<T>> {\n        await cleanup(true);\n        throw err;\n      },\n    };\n  };\n\n  return stream as AsyncIterableStream<T>;\n}\n", "/**\n * Consumes a ReadableStream until it's fully read.\n *\n * This function reads the stream chunk by chunk until the stream is exhausted.\n * It doesn't process or return the data from the stream; it simply ensures\n * that the entire stream is read.\n *\n * @param {ReadableStream} stream - The ReadableStream to be consumed.\n * @returns {Promise<void>} A promise that resolves when the stream is fully consumed.\n */\nexport async function consumeStream({\n  stream,\n  onError,\n}: {\n  stream: ReadableStream;\n  onError?: (error: unknown) => void;\n}): Promise<void> {\n  const reader = stream.getReader();\n  try {\n    while (true) {\n      const { done } = await reader.read();\n      if (done) break;\n    }\n  } catch (error) {\n    onError?.(error);\n  } finally {\n    reader.releaseLock();\n  }\n}\n", "import { ErrorHandler } from './error-handler';\n\n/**\n * Creates a Promise with externally accessible resolve and reject functions.\n *\n * @template T - The type of the value that the Promise will resolve to.\n * @returns An object containing:\n *   - promise: A Promise that can be resolved or rejected externally.\n *   - resolve: A function to resolve the Promise with a value of type T.\n *   - reject: A function to reject the Promise with an error.\n */\nexport function createResolvablePromise<T = any>(): {\n  promise: Promise<T>;\n  resolve: (value: T) => void;\n  reject: ErrorHandler;\n} {\n  let resolve: (value: T) => void;\n  let reject: ErrorHandler;\n\n  const promise = new Promise<T>((res, rej) => {\n    resolve = res;\n    reject = rej;\n  });\n\n  return {\n    promise,\n    resolve: resolve!,\n    reject: reject!,\n  };\n}\n", "import { createResolvablePromise } from './create-resolvable-promise';\n\n/**\n * Creates a stitchable stream that can pipe one stream at a time.\n *\n * @template T - The type of values emitted by the streams.\n * @returns {Object} An object containing the stitchable stream and control methods.\n */\nexport function createStitchableStream<T>(): {\n  stream: ReadableStream<T>;\n  addStream: (innerStream: ReadableStream<T>) => void;\n  close: () => void;\n  terminate: () => void;\n} {\n  let innerStreamReaders: ReadableStreamDefaultReader<T>[] = [];\n  let controller: ReadableStreamDefaultController<T> | null = null;\n  let isClosed = false;\n  let waitForNewStream = createResolvablePromise<void>();\n\n  const terminate = () => {\n    isClosed = true;\n    waitForNewStream.resolve();\n\n    innerStreamReaders.forEach(reader => reader.cancel());\n    innerStreamReaders = [];\n    controller?.close();\n  };\n\n  const processPull = async () => {\n    // Case 1: Outer stream is closed and no more inner streams\n    if (isClosed && innerStreamReaders.length === 0) {\n      controller?.close();\n      return;\n    }\n\n    // Case 2: No inner streams available, but outer stream is open\n    // wait for a new inner stream to be added or the outer stream to close\n    if (innerStreamReaders.length === 0) {\n      waitForNewStream = createResolvablePromise<void>();\n      await waitForNewStream.promise;\n      return processPull();\n    }\n\n    try {\n      const { value, done } = await innerStreamReaders[0].read();\n\n      if (done) {\n        // Case 3: Current inner stream is done\n        innerStreamReaders.shift(); // Remove the finished stream\n\n        // Continue pulling from the next stream if available\n        if (innerStreamReaders.length > 0) {\n          await processPull();\n        } else if (isClosed) {\n          controller?.close();\n        }\n      } else {\n        // Case 4: Current inner stream returns an item\n        controller?.enqueue(value);\n      }\n    } catch (error) {\n      // Case 5: Current inner stream throws an error\n      controller?.error(error);\n      innerStreamReaders.shift(); // Remove the errored stream\n      terminate(); // we have errored, terminate all streams\n    }\n  };\n\n  return {\n    stream: new ReadableStream<T>({\n      start(controllerParam) {\n        controller = controllerParam;\n      },\n      pull: processPull,\n      async cancel() {\n        for (const reader of innerStreamReaders) {\n          await reader.cancel();\n        }\n        innerStreamReaders = [];\n        isClosed = true;\n      },\n    }),\n    addStream: (innerStream: ReadableStream<T>) => {\n      if (isClosed) {\n        throw new Error('Cannot add inner stream: outer stream is closed');\n      }\n\n      innerStreamReaders.push(innerStream.getReader());\n      waitForNewStream.resolve();\n    },\n\n    /**\n     * Gracefully close the outer stream. This will let the inner streams\n     * finish processing and then close the outer stream.\n     */\n    close: () => {\n      isClosed = true;\n      waitForNewStream.resolve();\n\n      if (innerStreamReaders.length === 0) {\n        controller?.close();\n      }\n    },\n\n    /**\n     * Immediately close the outer stream. This will cancel all inner streams\n     * and close the outer stream.\n     */\n    terminate,\n  };\n}\n", "/**\n * Delayed promise. It is only constructed once the value is accessed.\n * This is useful to avoid unhandled promise rejections when the promise is created\n * but not accessed.\n */\nexport class DelayedPromise<T> {\n  private status:\n    | { type: 'pending' }\n    | { type: 'resolved'; value: T }\n    | { type: 'rejected'; error: unknown } = { type: 'pending' };\n  private _promise: Promise<T> | undefined;\n  private _resolve: undefined | ((value: T) => void) = undefined;\n  private _reject: undefined | ((error: unknown) => void) = undefined;\n\n  get promise(): Promise<T> {\n    if (this._promise) {\n      return this._promise;\n    }\n\n    this._promise = new Promise<T>((resolve, reject) => {\n      if (this.status.type === 'resolved') {\n        resolve(this.status.value);\n      } else if (this.status.type === 'rejected') {\n        reject(this.status.error);\n      }\n\n      this._resolve = resolve;\n      this._reject = reject;\n    });\n\n    return this._promise;\n  }\n\n  resolve(value: T): void {\n    this.status = { type: 'resolved', value };\n\n    if (this._promise) {\n      this._resolve?.(value);\n    }\n  }\n\n  reject(error: unknown): void {\n    this.status = { type: 'rejected', error };\n\n    if (this._promise) {\n      this._reject?.(error);\n    }\n  }\n}\n", "// Shim for performance.now() to support environments that don't have it:\nexport function now(): number {\n  return globalThis?.performance?.now() ?? Date.now();\n}\n", "import {\n  LanguageModelV2CallWarning,\n  LanguageModelV2StreamPart,\n} from '@ai-sdk/provider';\nimport {\n  executeTool,\n  generateId,\n  getErrorMessage,\n  ModelMessage,\n} from '@ai-sdk/provider-utils';\nimport { Tracer } from '@opentelemetry/api';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { recordErrorOnSpan, recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { FinishReason, LanguageModelUsage, ProviderMetadata } from '../types';\nimport { Source } from '../types/language-model';\nimport { DefaultGeneratedFileWithType, GeneratedFile } from './generated-file';\nimport { parseToolCall } from './parse-tool-call';\nimport { TypedToolCall } from './tool-call';\nimport { ToolCallRepairFunction } from './tool-call-repair-function';\nimport { TypedToolError } from './tool-error';\nimport { TypedToolResult } from './tool-result';\nimport { ToolSet } from './tool-set';\n\nexport type SingleRequestTextStreamPart<TOOLS extends ToolSet> =\n  // Text blocks:\n  | {\n      type: 'text-start';\n      providerMetadata?: ProviderMetadata;\n      id: string;\n    }\n  | {\n      type: 'text-delta';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n      delta: string;\n    }\n  | {\n      type: 'text-end';\n      providerMetadata?: ProviderMetadata;\n      id: string;\n    }\n\n  // Reasoning blocks:\n  | {\n      type: 'reasoning-start';\n      providerMetadata?: ProviderMetadata;\n      id: string;\n    }\n  | {\n      type: 'reasoning-delta';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n      delta: string;\n    }\n  | {\n      type: 'reasoning-end';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n\n  // Tool calls:\n  | {\n      type: 'tool-input-start';\n      id: string;\n      toolName: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'tool-input-delta';\n      id: string;\n      delta: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | {\n      type: 'tool-input-end';\n      id: string;\n      providerMetadata?: ProviderMetadata;\n    }\n  | ({ type: 'source' } & Source)\n  | { type: 'file'; file: GeneratedFile } // different because of GeneratedFile object\n  | ({ type: 'tool-call' } & TypedToolCall<TOOLS>)\n  | ({ type: 'tool-result' } & TypedToolResult<TOOLS>)\n  | ({ type: 'tool-error' } & TypedToolError<TOOLS>)\n  | { type: 'file'; file: GeneratedFile } // different because of GeneratedFile object\n  | { type: 'stream-start'; warnings: LanguageModelV2CallWarning[] }\n  | {\n      type: 'response-metadata';\n      id?: string;\n      timestamp?: Date;\n      modelId?: string;\n    }\n  | {\n      type: 'finish';\n      finishReason: FinishReason;\n      usage: LanguageModelUsage;\n      providerMetadata?: ProviderMetadata;\n    }\n  | { type: 'error'; error: unknown }\n  | { type: 'raw'; rawValue: unknown };\n\nexport function runToolsTransformation<TOOLS extends ToolSet>({\n  tools,\n  generatorStream,\n  tracer,\n  telemetry,\n  system,\n  messages,\n  abortSignal,\n  repairToolCall,\n  experimental_context,\n}: {\n  tools: TOOLS | undefined;\n  generatorStream: ReadableStream<LanguageModelV2StreamPart>;\n  tracer: Tracer;\n  telemetry: TelemetrySettings | undefined;\n  system: string | undefined;\n  messages: ModelMessage[];\n  abortSignal: AbortSignal | undefined;\n  repairToolCall: ToolCallRepairFunction<TOOLS> | undefined;\n  experimental_context: unknown;\n}): ReadableStream<SingleRequestTextStreamPart<TOOLS>> {\n  // tool results stream\n  let toolResultsStreamController: ReadableStreamDefaultController<\n    SingleRequestTextStreamPart<TOOLS>\n  > | null = null;\n  const toolResultsStream = new ReadableStream<\n    SingleRequestTextStreamPart<TOOLS>\n  >({\n    start(controller) {\n      toolResultsStreamController = controller;\n    },\n  });\n\n  // keep track of outstanding tool results for stream closing:\n  const outstandingToolResults = new Set<string>();\n\n  // keep track of tool inputs for provider-side tool results\n  const toolInputs = new Map<string, unknown>();\n\n  let canClose = false;\n  let finishChunk:\n    | (SingleRequestTextStreamPart<TOOLS> & { type: 'finish' })\n    | undefined = undefined;\n\n  function attemptClose() {\n    // close the tool results controller if no more outstanding tool calls\n    if (canClose && outstandingToolResults.size === 0) {\n      // we delay sending the finish chunk until all tool results (incl. delayed ones)\n      // are received to ensure that the frontend receives tool results before a message\n      // finish event arrives.\n      if (finishChunk != null) {\n        toolResultsStreamController!.enqueue(finishChunk);\n      }\n\n      toolResultsStreamController!.close();\n    }\n  }\n\n  // forward stream\n  const forwardStream = new TransformStream<\n    LanguageModelV2StreamPart,\n    SingleRequestTextStreamPart<TOOLS>\n  >({\n    async transform(\n      chunk: LanguageModelV2StreamPart,\n      controller: TransformStreamDefaultController<\n        SingleRequestTextStreamPart<TOOLS>\n      >,\n    ) {\n      const chunkType = chunk.type;\n\n      switch (chunkType) {\n        // forward:\n        case 'stream-start':\n        case 'text-start':\n        case 'text-delta':\n        case 'text-end':\n        case 'reasoning-start':\n        case 'reasoning-delta':\n        case 'reasoning-end':\n        case 'tool-input-start':\n        case 'tool-input-delta':\n        case 'tool-input-end':\n        case 'source':\n        case 'response-metadata':\n        case 'error':\n        case 'raw': {\n          controller.enqueue(chunk);\n          break;\n        }\n\n        case 'file': {\n          controller.enqueue({\n            type: 'file',\n            file: new DefaultGeneratedFileWithType({\n              data: chunk.data,\n              mediaType: chunk.mediaType,\n            }),\n          });\n          break;\n        }\n\n        case 'finish': {\n          finishChunk = {\n            type: 'finish',\n            finishReason: chunk.finishReason,\n            usage: chunk.usage,\n            providerMetadata: chunk.providerMetadata,\n          };\n          break;\n        }\n\n        // process tool call:\n        case 'tool-call': {\n          try {\n            const toolCall = await parseToolCall({\n              toolCall: chunk,\n              tools,\n              repairToolCall,\n              system,\n              messages,\n            });\n\n            controller.enqueue(toolCall);\n\n            // handle invalid tool calls:\n            if (toolCall.invalid) {\n              toolResultsStreamController!.enqueue({\n                type: 'tool-error',\n                toolCallId: toolCall.toolCallId,\n                toolName: toolCall.toolName,\n                input: toolCall.input,\n                error: getErrorMessage(toolCall.error!),\n                dynamic: true,\n              });\n\n              break;\n            }\n\n            const tool = tools![toolCall.toolName];\n\n            toolInputs.set(toolCall.toolCallId, toolCall.input);\n\n            if (tool.onInputAvailable != null) {\n              await tool.onInputAvailable({\n                input: toolCall.input,\n                toolCallId: toolCall.toolCallId,\n                messages,\n                abortSignal,\n                experimental_context,\n              });\n            }\n\n            // Only execute tools that are not provider-executed:\n            if (tool.execute != null && toolCall.providerExecuted !== true) {\n              const toolExecutionId = generateId(); // use our own id to guarantee uniqueness\n              outstandingToolResults.add(toolExecutionId);\n\n              // Note: we don't await the tool execution here (by leaving out 'await' on recordSpan),\n              // because we want to process the next chunk as soon as possible.\n              // This is important for the case where the tool execution takes a long time.\n              recordSpan({\n                name: 'ai.toolCall',\n                attributes: selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    ...assembleOperationName({\n                      operationId: 'ai.toolCall',\n                      telemetry,\n                    }),\n                    'ai.toolCall.name': toolCall.toolName,\n                    'ai.toolCall.id': toolCall.toolCallId,\n                    'ai.toolCall.args': {\n                      output: () => JSON.stringify(toolCall.input),\n                    },\n                  },\n                }),\n                tracer,\n                fn: async span => {\n                  let output: unknown;\n\n                  try {\n                    const stream = executeTool({\n                      execute: tool.execute!.bind(tool),\n                      input: toolCall.input,\n                      options: {\n                        toolCallId: toolCall.toolCallId,\n                        messages,\n                        abortSignal,\n                        experimental_context,\n                      },\n                    });\n\n                    for await (const part of stream) {\n                      toolResultsStreamController!.enqueue({\n                        ...toolCall,\n                        type: 'tool-result',\n                        output: part.output,\n                        ...(part.type === 'preliminary' && {\n                          preliminary: true,\n                        }),\n                      });\n\n                      if (part.type === 'final') {\n                        output = part.output;\n                      }\n                    }\n                  } catch (error) {\n                    recordErrorOnSpan(span, error);\n                    toolResultsStreamController!.enqueue({\n                      ...toolCall,\n                      type: 'tool-error',\n                      error,\n                    } satisfies TypedToolError<TOOLS>);\n\n                    outstandingToolResults.delete(toolExecutionId);\n                    attemptClose();\n                    return;\n                  }\n\n                  outstandingToolResults.delete(toolExecutionId);\n                  attemptClose();\n\n                  // record telemetry\n                  try {\n                    span.setAttributes(\n                      selectTelemetryAttributes({\n                        telemetry,\n                        attributes: {\n                          'ai.toolCall.result': {\n                            output: () => JSON.stringify(output),\n                          },\n                        },\n                      }),\n                    );\n                  } catch (ignored) {\n                    // JSON stringify might fail if the result is not serializable,\n                    // in which case we just ignore it. In the future we might want to\n                    // add an optional serialize method to the tool interface and warn\n                    // if the result is not serializable.\n                  }\n                },\n              });\n            }\n          } catch (error) {\n            toolResultsStreamController!.enqueue({ type: 'error', error });\n          }\n\n          break;\n        }\n\n        case 'tool-result': {\n          const toolName = chunk.toolName as keyof TOOLS & string;\n\n          if (chunk.isError) {\n            toolResultsStreamController!.enqueue({\n              type: 'tool-error',\n              toolCallId: chunk.toolCallId,\n              toolName,\n              input: toolInputs.get(chunk.toolCallId),\n              providerExecuted: chunk.providerExecuted,\n              error: chunk.result,\n            } as TypedToolError<TOOLS>);\n          } else {\n            controller.enqueue({\n              type: 'tool-result',\n              toolCallId: chunk.toolCallId,\n              toolName,\n              input: toolInputs.get(chunk.toolCallId),\n              output: chunk.result,\n              providerExecuted: chunk.providerExecuted,\n            } as TypedToolResult<TOOLS>);\n          }\n          break;\n        }\n\n        default: {\n          const _exhaustiveCheck: never = chunkType;\n          throw new Error(`Unhandled chunk type: ${_exhaustiveCheck}`);\n        }\n      }\n    },\n\n    flush() {\n      canClose = true;\n      attemptClose();\n    },\n  });\n\n  // combine the generator stream and the tool results stream\n  return new ReadableStream<SingleRequestTextStreamPart<TOOLS>>({\n    async start(controller) {\n      // need to wait for both pipes so there are no dangling promises that\n      // can cause uncaught promise rejections when the stream is aborted\n      return Promise.all([\n        generatorStream.pipeThrough(forwardStream).pipeTo(\n          new WritableStream({\n            write(chunk) {\n              controller.enqueue(chunk);\n            },\n            close() {\n              // the generator stream controller is automatically closed when it's consumed\n            },\n          }),\n        ),\n        toolResultsStream.pipeTo(\n          new WritableStream({\n            write(chunk) {\n              controller.enqueue(chunk);\n            },\n            close() {\n              controller.close();\n            },\n          }),\n        ),\n      ]);\n    },\n  });\n}\n", "import {\n  AssistantContent,\n  FilePart,\n  ModelMessage,\n  TextPart,\n  ToolResultPart,\n} from '@ai-sdk/provider-utils';\nimport { ToolSet } from '../generate-text/tool-set';\nimport { createToolModelOutput } from '../prompt/create-tool-model-output';\nimport { MessageConversionError } from '../prompt/message-conversion-error';\nimport {\n  DataUIPart,\n  DynamicToolUIPart,\n  FileUIPart,\n  getToolName,\n  getToolOrDynamicToolName,\n  InferUIMessageData,\n  InferUIMessageTools,\n  isDataUIPart,\n  isDynamicToolUIPart,\n  isFileUIPart,\n  isReasoningUIPart,\n  isTextUIPart,\n  isToolOrDynamicToolUIPart,\n  isToolUIPart,\n  ReasoningUIPart,\n  TextUIPart,\n  ToolUIPart,\n  UIMessage,\n} from './ui-messages';\n\n/**\nConverts an array of UI messages from useChat into an array of ModelMessages that can be used\nwith the AI functions (e.g. `streamText`, `generateText`).\n\n@param messages - The UI messages to convert.\n@param options.tools - The tools to use.\n@param options.ignoreIncompleteToolCalls - Whether to ignore incomplete tool calls. Default is `false`.\n@param options.convertDataPart - Optional function to convert data parts to text or file model message parts. Returns `undefined` if the part should be ignored.\n\n@returns An array of ModelMessages.\n */\nexport function convertToModelMessages<UI_MESSAGE extends UIMessage>(\n  messages: Array<Omit<UI_MESSAGE, 'id'>>,\n  options?: {\n    tools?: ToolSet;\n    ignoreIncompleteToolCalls?: boolean;\n    convertDataPart?: (\n      part: DataUIPart<InferUIMessageData<UI_MESSAGE>>,\n    ) => TextPart | FilePart | undefined;\n  },\n): ModelMessage[] {\n  const modelMessages: ModelMessage[] = [];\n\n  if (options?.ignoreIncompleteToolCalls) {\n    messages = messages.map(message => ({\n      ...message,\n      parts: message.parts.filter(\n        part =>\n          !isToolOrDynamicToolUIPart(part) ||\n          (part.state !== 'input-streaming' &&\n            part.state !== 'input-available'),\n      ),\n    }));\n  }\n\n  for (const message of messages) {\n    switch (message.role) {\n      case 'system': {\n        const textParts = message.parts.filter(\n          (part): part is TextUIPart => part.type === 'text',\n        );\n\n        const providerMetadata = textParts.reduce((acc, part) => {\n          if (part.providerMetadata != null) {\n            return { ...acc, ...part.providerMetadata };\n          }\n          return acc;\n        }, {});\n\n        modelMessages.push({\n          role: 'system',\n          content: textParts.map(part => part.text).join(''),\n          ...(Object.keys(providerMetadata).length > 0\n            ? { providerOptions: providerMetadata }\n            : {}),\n        });\n        break;\n      }\n\n      case 'user': {\n        modelMessages.push({\n          role: 'user',\n          content: message.parts\n            .map((part): TextPart | FilePart | undefined => {\n              // Process text parts\n              if (isTextUIPart(part)) {\n                return {\n                  type: 'text' as const,\n                  text: part.text,\n                  ...(part.providerMetadata != null\n                    ? { providerOptions: part.providerMetadata }\n                    : {}),\n                };\n              }\n\n              // Process file parts\n              if (isFileUIPart(part)) {\n                return {\n                  type: 'file' as const,\n                  mediaType: part.mediaType,\n                  filename: part.filename,\n                  data: part.url,\n                  ...(part.providerMetadata != null\n                    ? { providerOptions: part.providerMetadata }\n                    : {}),\n                };\n              }\n\n              // Process data parts with converter if provided\n              if (isDataUIPart(part)) {\n                return options?.convertDataPart?.(\n                  part as DataUIPart<InferUIMessageData<UI_MESSAGE>>,\n                );\n              }\n            })\n            .filter((part): part is TextPart | FilePart => part != null),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        if (message.parts != null) {\n          let block: Array<\n            | TextUIPart\n            | ToolUIPart<InferUIMessageTools<UI_MESSAGE>>\n            | ReasoningUIPart\n            | FileUIPart\n            | DynamicToolUIPart\n            | DataUIPart<InferUIMessageData<UI_MESSAGE>>\n          > = [];\n\n          function processBlock() {\n            if (block.length === 0) {\n              return;\n            }\n\n            const content: AssistantContent = [];\n\n            for (const part of block) {\n              if (isTextUIPart(part)) {\n                content.push({\n                  type: 'text' as const,\n                  text: part.text,\n                  ...(part.providerMetadata != null\n                    ? { providerOptions: part.providerMetadata }\n                    : {}),\n                });\n              } else if (isFileUIPart(part)) {\n                content.push({\n                  type: 'file' as const,\n                  mediaType: part.mediaType,\n                  filename: part.filename,\n                  data: part.url,\n                });\n              } else if (isReasoningUIPart(part)) {\n                content.push({\n                  type: 'reasoning' as const,\n                  text: part.text,\n                  providerOptions: part.providerMetadata,\n                });\n              } else if (isDynamicToolUIPart(part)) {\n                const toolName = part.toolName;\n\n                if (part.state !== 'input-streaming') {\n                  content.push({\n                    type: 'tool-call' as const,\n                    toolCallId: part.toolCallId,\n                    toolName,\n                    input: part.input,\n                    ...(part.callProviderMetadata != null\n                      ? { providerOptions: part.callProviderMetadata }\n                      : {}),\n                  });\n                }\n              } else if (isToolUIPart(part)) {\n                const toolName = getToolName(part);\n\n                if (part.state !== 'input-streaming') {\n                  content.push({\n                    type: 'tool-call' as const,\n                    toolCallId: part.toolCallId,\n                    toolName: toolName as string,\n                    input:\n                      part.state === 'output-error'\n                        ? (part.input ?? part.rawInput)\n                        : part.input,\n                    providerExecuted: part.providerExecuted,\n                    ...(part.callProviderMetadata != null\n                      ? { providerOptions: part.callProviderMetadata }\n                      : {}),\n                  });\n\n                  if (\n                    part.providerExecuted === true &&\n                    (part.state === 'output-available' ||\n                      part.state === 'output-error')\n                  ) {\n                    content.push({\n                      type: 'tool-result',\n                      toolCallId: part.toolCallId,\n                      toolName: toolName as string,\n                      output: createToolModelOutput({\n                        output:\n                          part.state === 'output-error'\n                            ? part.errorText\n                            : part.output,\n                        tool: options?.tools?.[toolName],\n                        errorMode:\n                          part.state === 'output-error' ? 'json' : 'none',\n                      }),\n                    });\n                  }\n                }\n              } else if (isDataUIPart(part)) {\n                const dataPart = options?.convertDataPart?.(\n                  part as DataUIPart<InferUIMessageData<UI_MESSAGE>>,\n                );\n\n                if (dataPart != null) {\n                  content.push(dataPart);\n                }\n              } else {\n                const _exhaustiveCheck: never = part;\n                throw new Error(`Unsupported part: ${_exhaustiveCheck}`);\n              }\n            }\n\n            modelMessages.push({\n              role: 'assistant',\n              content,\n            });\n\n            // check if there are tool invocations with results in the block\n            const toolParts = block.filter(\n              part =>\n                (isToolUIPart(part) && part.providerExecuted !== true) ||\n                part.type === 'dynamic-tool',\n            ) as (\n              | ToolUIPart<InferUIMessageTools<UI_MESSAGE>>\n              | DynamicToolUIPart\n            )[];\n\n            // tool message with tool results\n            if (toolParts.length > 0) {\n              modelMessages.push({\n                role: 'tool',\n                content: toolParts\n                  .map((toolPart): ToolResultPart | null => {\n                    switch (toolPart.state) {\n                      case 'output-error':\n                      case 'output-available': {\n                        const toolName = getToolOrDynamicToolName(toolPart);\n\n                        return {\n                          type: 'tool-result',\n                          toolCallId: toolPart.toolCallId,\n                          toolName,\n                          output: createToolModelOutput({\n                            output:\n                              toolPart.state === 'output-error'\n                                ? toolPart.errorText\n                                : toolPart.output,\n                            tool: options?.tools?.[toolName],\n                            errorMode:\n                              toolPart.state === 'output-error'\n                                ? 'text'\n                                : 'none',\n                          }),\n                        };\n                      }\n                      default: {\n                        return null;\n                      }\n                    }\n                  })\n                  .filter(\n                    (output): output is NonNullable<typeof output> =>\n                      output != null,\n                  ),\n              });\n            }\n\n            // updates for next block\n            block = [];\n          }\n\n          for (const part of message.parts) {\n            if (\n              isTextUIPart(part) ||\n              isReasoningUIPart(part) ||\n              isFileUIPart(part) ||\n              isToolOrDynamicToolUIPart(part) ||\n              isDataUIPart(part)\n            ) {\n              block.push(part as (typeof block)[number]);\n            } else if (part.type === 'step-start') {\n              processBlock();\n            }\n          }\n\n          processBlock();\n\n          break;\n        }\n\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = message.role;\n        throw new MessageConversionError({\n          originalMessage: message,\n          message: `Unsupported role: ${_exhaustiveCheck}`,\n        });\n      }\n    }\n  }\n\n  return modelMessages;\n}\n\n/**\n@deprecated Use `convertToModelMessages` instead.\n */\n// TODO remove in AI SDK 6\nexport const convertToCoreMessages = convertToModelMessages;\n", "import { IdGenerator, ProviderOptions } from '@ai-sdk/provider-utils';\nimport {\n  generateText,\n  GenerateTextOnStepFinishCallback,\n} from '../generate-text/generate-text';\nimport { GenerateTextResult } from '../generate-text/generate-text-result';\nimport { Output } from '../generate-text/output';\nimport { PrepareStepFunction } from '../generate-text/prepare-step';\nimport { StopCondition } from '../generate-text/stop-condition';\nimport { streamText } from '../generate-text/stream-text';\nimport { StreamTextResult } from '../generate-text/stream-text-result';\nimport { ToolCallRepairFunction } from '../generate-text/tool-call-repair-function';\nimport { ToolSet } from '../generate-text/tool-set';\nimport { CallSettings } from '../prompt/call-settings';\nimport { Prompt } from '../prompt/prompt';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { LanguageModel, ToolChoice } from '../types/language-model';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { convertToModelMessages } from '../ui/convert-to-model-messages';\nimport { InferUITools, UIMessage } from '../ui/ui-messages';\n\nexport type AgentSettings<\n  TOOLS extends ToolSet,\n  OUTPUT = never,\n  OUTPUT_PARTIAL = never,\n> = CallSettings & {\n  /**\n   * The system prompt to use.\n   */\n  system?: string;\n\n  /**\nThe language model to use.\n   */\n  model: LanguageModel;\n\n  /**\nThe tools that the model can call. The model needs to support calling tools.\n*/\n  tools?: TOOLS;\n\n  /**\nThe tool choice strategy. Default: 'auto'.\n   */\n  toolChoice?: ToolChoice<NoInfer<TOOLS>>;\n\n  /**\nCondition for stopping the generation when there are tool results in the last step.\nWhen the condition is an array, any of the conditions can be met to stop the generation.\n\n@default stepCountIs(1)\n   */\n  stopWhen?:\n    | StopCondition<NoInfer<TOOLS>>\n    | Array<StopCondition<NoInfer<TOOLS>>>;\n\n  /**\nOptional telemetry configuration (experimental).\n   */\n  experimental_telemetry?: TelemetrySettings;\n\n  /**\nLimits the tools that are available for the model to call without\nchanging the tool call and result types in the result.\n   */\n  activeTools?: Array<keyof NoInfer<TOOLS>>;\n\n  /**\nOptional specification for parsing structured outputs from the LLM response.\n   */\n  experimental_output?: Output<OUTPUT, OUTPUT_PARTIAL>;\n\n  /**\n   * @deprecated Use `prepareStep` instead.\n   */\n  experimental_prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n  /**\nOptional function that you can use to provide different settings for a step.\n  */\n  prepareStep?: PrepareStepFunction<NoInfer<TOOLS>>;\n\n  /**\nA function that attempts to repair a tool call that failed to parse.\n   */\n  experimental_repairToolCall?: ToolCallRepairFunction<NoInfer<TOOLS>>;\n\n  /**\n  Callback that is called when each step (LLM call) is finished, including intermediate steps.\n  */\n  onStepFinish?: GenerateTextOnStepFinishCallback<NoInfer<TOOLS>>;\n\n  /**\n   * Context that is passed into tool calls.\n   *\n   * Experimental (can break in patch releases).\n   *\n   * @default undefined\n   */\n  experimental_context?: unknown;\n\n  /**\n   * Internal. For test use only. May change without notice.\n   */\n  _internal?: {\n    generateId?: IdGenerator;\n    currentDate?: () => Date;\n  };\n};\n\nexport class Agent<\n  TOOLS extends ToolSet,\n  OUTPUT = never,\n  OUTPUT_PARTIAL = never,\n> {\n  private readonly settings: AgentSettings<TOOLS, OUTPUT, OUTPUT_PARTIAL>;\n\n  constructor(settings: AgentSettings<TOOLS, OUTPUT, OUTPUT_PARTIAL>) {\n    this.settings = settings;\n  }\n\n  get tools(): TOOLS {\n    return this.settings.tools as TOOLS;\n  }\n\n  async generate(\n    options: Prompt & {\n      /**\nAdditional provider-specific metadata. They are passed through\nfrom the provider to the AI SDK and enable provider-specific\nresults that can be fully encapsulated in the provider.\n   */\n      providerMetadata?: ProviderMetadata;\n      /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n         */\n      providerOptions?: ProviderOptions;\n    },\n  ): Promise<GenerateTextResult<TOOLS, OUTPUT>> {\n    return generateText({ ...this.settings, ...options });\n  }\n\n  stream(\n    options: Prompt & {\n      /**\nAdditional provider-specific metadata. They are passed through\nfrom the provider to the AI SDK and enable provider-specific\nresults that can be fully encapsulated in the provider.\n   */\n      providerMetadata?: ProviderMetadata;\n      /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n         */\n      providerOptions?: ProviderOptions;\n    },\n  ): StreamTextResult<TOOLS, OUTPUT_PARTIAL> {\n    return streamText({ ...this.settings, ...options });\n  }\n\n  /**\n   * Creates a response object that streams UI messages to the client.\n   */\n  respond(options: {\n    messages: UIMessage<never, never, InferUITools<TOOLS>>[];\n  }): Response {\n    return this.stream({\n      prompt: convertToModelMessages(options.messages),\n    }).toUIMessageStreamResponse<\n      UIMessage<never, never, InferUITools<TOOLS>>\n    >();\n  }\n}\n\ntype InferAgentTools<AGENT> =\n  AGENT extends Agent<infer TOOLS, any, any> ? TOOLS : never;\n\n/**\n * Infer the UI message type of an agent.\n */\nexport type InferAgentUIMessage<AGENT> = UIMessage<\n  never,\n  never,\n  InferUITools<InferAgentTools<AGENT>>\n>;\n", "import { ProviderOptions, withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { resolveEmbeddingModel } from '../model/resolve-model';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { EmbeddingModel } from '../types';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { EmbedResult } from './embed-result';\nimport { VERSION } from '../version';\n\n/**\nEmbed a value using an embedding model. The type of the value is defined by the embedding model.\n\n@param model - The embedding model to use.\n@param value - The value that should be embedded.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the embedding, the value, and additional information.\n */\nexport async function embed<VALUE = string>({\n  model: modelArg,\n  value,\n  providerOptions,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n  experimental_telemetry: telemetry,\n}: {\n  /**\nThe embedding model to use.\n     */\n  model: EmbeddingModel<VALUE>;\n\n  /**\nThe value that should be embedded.\n   */\n  value: VALUE;\n\n  /**\nMaximum number of retries per embedding model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n\n  /**\n  Additional provider-specific options. They are passed through\n  to the provider from the AI SDK and enable provider-specific\n  functionality that can be fully encapsulated in the provider.\n  */\n  providerOptions?: ProviderOptions;\n\n  /**\n   * Optional telemetry configuration (experimental).\n   */\n  experimental_telemetry?: TelemetrySettings;\n}): Promise<EmbedResult<VALUE>> {\n  const model = resolveEmbeddingModel<VALUE>(modelArg);\n\n  const { maxRetries, retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model: model,\n    telemetry,\n    headers: headersWithUserAgent,\n    settings: { maxRetries },\n  });\n\n  const tracer = getTracer(telemetry);\n\n  return recordSpan({\n    name: 'ai.embed',\n    attributes: selectTelemetryAttributes({\n      telemetry,\n      attributes: {\n        ...assembleOperationName({ operationId: 'ai.embed', telemetry }),\n        ...baseTelemetryAttributes,\n        'ai.value': { input: () => JSON.stringify(value) },\n      },\n    }),\n    tracer,\n    fn: async span => {\n      const { embedding, usage, response, providerMetadata } = await retry(() =>\n        // nested spans to align with the embedMany telemetry data:\n        recordSpan({\n          name: 'ai.embed.doEmbed',\n          attributes: selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              ...assembleOperationName({\n                operationId: 'ai.embed.doEmbed',\n                telemetry,\n              }),\n              ...baseTelemetryAttributes,\n              // specific settings that only make sense on the outer level:\n              'ai.values': { input: () => [JSON.stringify(value)] },\n            },\n          }),\n          tracer,\n          fn: async doEmbedSpan => {\n            const modelResponse = await model.doEmbed({\n              values: [value],\n              abortSignal,\n              headers: headersWithUserAgent,\n              providerOptions,\n            });\n\n            const embedding = modelResponse.embeddings[0];\n            const usage = modelResponse.usage ?? { tokens: NaN };\n\n            doEmbedSpan.setAttributes(\n              selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  'ai.embeddings': {\n                    output: () =>\n                      modelResponse.embeddings.map(embedding =>\n                        JSON.stringify(embedding),\n                      ),\n                  },\n                  'ai.usage.tokens': usage.tokens,\n                },\n              }),\n            );\n\n            return {\n              embedding,\n              usage,\n              providerMetadata: modelResponse.providerMetadata,\n              response: modelResponse.response,\n            };\n          },\n        }),\n      );\n\n      span.setAttributes(\n        selectTelemetryAttributes({\n          telemetry,\n          attributes: {\n            'ai.embedding': { output: () => JSON.stringify(embedding) },\n            'ai.usage.tokens': usage.tokens,\n          },\n        }),\n      );\n\n      return new DefaultEmbedResult({\n        value,\n        embedding,\n        usage,\n        providerMetadata,\n        response,\n      });\n    },\n  });\n}\n\nclass DefaultEmbedResult<VALUE> implements EmbedResult<VALUE> {\n  readonly value: EmbedResult<VALUE>['value'];\n  readonly embedding: EmbedResult<VALUE>['embedding'];\n  readonly usage: EmbedResult<VALUE>['usage'];\n  readonly providerMetadata: EmbedResult<VALUE>['providerMetadata'];\n  readonly response: EmbedResult<VALUE>['response'];\n\n  constructor(options: {\n    value: EmbedResult<VALUE>['value'];\n    embedding: EmbedResult<VALUE>['embedding'];\n    usage: EmbedResult<VALUE>['usage'];\n    providerMetadata?: EmbedResult<VALUE>['providerMetadata'];\n    response?: EmbedResult<VALUE>['response'];\n  }) {\n    this.value = options.value;\n    this.embedding = options.embedding;\n    this.usage = options.usage;\n    this.providerMetadata = options.providerMetadata;\n    this.response = options.response;\n  }\n}\n", "import { ProviderOptions, withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { splitArray } from '../util/split-array';\nimport { UnsupportedModelVersionError } from '../error/unsupported-model-version-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { Embedding, EmbeddingModel, ProviderMetadata } from '../types';\nimport { resolveEmbeddingModel } from '../model/resolve-model';\nimport { EmbedManyResult } from './embed-many-result';\nimport { VERSION } from '../version';\n\n/**\nEmbed several values using an embedding model. The type of the value is defined\nby the embedding model.\n\n`embedMany` automatically splits large requests into smaller chunks if the model\nhas a limit on how many embeddings can be generated in a single call.\n\n@param model - The embedding model to use.\n@param values - The values that should be embedded.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the embeddings, the value, and additional information.\n */\nexport async function embedMany<VALUE = string>({\n  model: modelArg,\n  values,\n  maxParallelCalls = Infinity,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n  providerOptions,\n  experimental_telemetry: telemetry,\n}: {\n  /**\nThe embedding model to use.\n     */\n  model: EmbeddingModel<VALUE>;\n\n  /**\nThe values that should be embedded.\n   */\n  values: Array<VALUE>;\n\n  /**\nMaximum number of retries per embedding model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n\n  /**\n   * Optional telemetry configuration (experimental).\n   */\n  experimental_telemetry?: TelemetrySettings;\n\n  /**\n  Additional provider-specific options. They are passed through\n  to the provider from the AI SDK and enable provider-specific\n  functionality that can be fully encapsulated in the provider.\n  */\n  providerOptions?: ProviderOptions;\n\n  /**\n   * Maximum number of concurrent requests.\n   *\n   * @default Infinity\n   */\n  maxParallelCalls?: number;\n}): Promise<EmbedManyResult<VALUE>> {\n  const model = resolveEmbeddingModel<VALUE>(modelArg);\n\n  const { maxRetries, retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers: headersWithUserAgent,\n    settings: { maxRetries },\n  });\n\n  const tracer = getTracer(telemetry);\n\n  return recordSpan({\n    name: 'ai.embedMany',\n    attributes: selectTelemetryAttributes({\n      telemetry,\n      attributes: {\n        ...assembleOperationName({ operationId: 'ai.embedMany', telemetry }),\n        ...baseTelemetryAttributes,\n        // specific settings that only make sense on the outer level:\n        'ai.values': {\n          input: () => values.map(value => JSON.stringify(value)),\n        },\n      },\n    }),\n    tracer,\n    fn: async span => {\n      const [maxEmbeddingsPerCall, supportsParallelCalls] = await Promise.all([\n        model.maxEmbeddingsPerCall,\n        model.supportsParallelCalls,\n      ]);\n\n      // the model has not specified limits on\n      // how many embeddings can be generated in a single call\n      if (maxEmbeddingsPerCall == null || maxEmbeddingsPerCall === Infinity) {\n        const { embeddings, usage, response, providerMetadata } = await retry(\n          () => {\n            // nested spans to align with the embedMany telemetry data:\n            return recordSpan({\n              name: 'ai.embedMany.doEmbed',\n              attributes: selectTelemetryAttributes({\n                telemetry,\n                attributes: {\n                  ...assembleOperationName({\n                    operationId: 'ai.embedMany.doEmbed',\n                    telemetry,\n                  }),\n                  ...baseTelemetryAttributes,\n                  // specific settings that only make sense on the outer level:\n                  'ai.values': {\n                    input: () => values.map(value => JSON.stringify(value)),\n                  },\n                },\n              }),\n              tracer,\n              fn: async doEmbedSpan => {\n                const modelResponse = await model.doEmbed({\n                  values,\n                  abortSignal,\n                  headers: headersWithUserAgent,\n                  providerOptions,\n                });\n\n                const embeddings = modelResponse.embeddings;\n                const usage = modelResponse.usage ?? { tokens: NaN };\n\n                doEmbedSpan.setAttributes(\n                  selectTelemetryAttributes({\n                    telemetry,\n                    attributes: {\n                      'ai.embeddings': {\n                        output: () =>\n                          embeddings.map(embedding =>\n                            JSON.stringify(embedding),\n                          ),\n                      },\n                      'ai.usage.tokens': usage.tokens,\n                    },\n                  }),\n                );\n\n                return {\n                  embeddings,\n                  usage,\n                  providerMetadata: modelResponse.providerMetadata,\n                  response: modelResponse.response,\n                };\n              },\n            });\n          },\n        );\n\n        span.setAttributes(\n          selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              'ai.embeddings': {\n                output: () =>\n                  embeddings.map(embedding => JSON.stringify(embedding)),\n              },\n              'ai.usage.tokens': usage.tokens,\n            },\n          }),\n        );\n\n        return new DefaultEmbedManyResult({\n          values,\n          embeddings,\n          usage,\n          providerMetadata,\n          responses: [response],\n        });\n      }\n\n      // split the values into chunks that are small enough for the model:\n      const valueChunks = splitArray(values, maxEmbeddingsPerCall);\n\n      // serially embed the chunks:\n      const embeddings: Array<Embedding> = [];\n      const responses: Array<\n        | {\n            headers?: Record<string, string>;\n            body?: unknown;\n          }\n        | undefined\n      > = [];\n      let tokens = 0;\n      let providerMetadata: ProviderMetadata | undefined;\n\n      const parallelChunks = splitArray(\n        valueChunks,\n        supportsParallelCalls ? maxParallelCalls : 1,\n      );\n\n      for (const parallelChunk of parallelChunks) {\n        const results = await Promise.all(\n          parallelChunk.map(chunk => {\n            return retry(() => {\n              // nested spans to align with the embedMany telemetry data:\n              return recordSpan({\n                name: 'ai.embedMany.doEmbed',\n                attributes: selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    ...assembleOperationName({\n                      operationId: 'ai.embedMany.doEmbed',\n                      telemetry,\n                    }),\n                    ...baseTelemetryAttributes,\n                    // specific settings that only make sense on the outer level:\n                    'ai.values': {\n                      input: () => chunk.map(value => JSON.stringify(value)),\n                    },\n                  },\n                }),\n                tracer,\n                fn: async doEmbedSpan => {\n                  const modelResponse = await model.doEmbed({\n                    values: chunk,\n                    abortSignal,\n                    headers: headersWithUserAgent,\n                    providerOptions,\n                  });\n\n                  const embeddings = modelResponse.embeddings;\n                  const usage = modelResponse.usage ?? { tokens: NaN };\n\n                  doEmbedSpan.setAttributes(\n                    selectTelemetryAttributes({\n                      telemetry,\n                      attributes: {\n                        'ai.embeddings': {\n                          output: () =>\n                            embeddings.map(embedding =>\n                              JSON.stringify(embedding),\n                            ),\n                        },\n                        'ai.usage.tokens': usage.tokens,\n                      },\n                    }),\n                  );\n\n                  return {\n                    embeddings,\n                    usage,\n                    providerMetadata: modelResponse.providerMetadata,\n                    response: modelResponse.response,\n                  };\n                },\n              });\n            });\n          }),\n        );\n\n        for (const result of results) {\n          embeddings.push(...result.embeddings);\n          responses.push(result.response);\n          tokens += result.usage.tokens;\n          if (result.providerMetadata) {\n            if (!providerMetadata) {\n              providerMetadata = { ...result.providerMetadata };\n            } else {\n              for (const [providerName, metadata] of Object.entries(\n                result.providerMetadata,\n              )) {\n                providerMetadata[providerName] = {\n                  ...(providerMetadata[providerName] ?? {}),\n                  ...metadata,\n                };\n              }\n            }\n          }\n        }\n      }\n\n      span.setAttributes(\n        selectTelemetryAttributes({\n          telemetry,\n          attributes: {\n            'ai.embeddings': {\n              output: () =>\n                embeddings.map(embedding => JSON.stringify(embedding)),\n            },\n            'ai.usage.tokens': tokens,\n          },\n        }),\n      );\n\n      return new DefaultEmbedManyResult({\n        values,\n        embeddings,\n        usage: { tokens },\n        providerMetadata: providerMetadata,\n        responses,\n      });\n    },\n  });\n}\n\nclass DefaultEmbedManyResult<VALUE> implements EmbedManyResult<VALUE> {\n  readonly values: EmbedManyResult<VALUE>['values'];\n  readonly embeddings: EmbedManyResult<VALUE>['embeddings'];\n  readonly usage: EmbedManyResult<VALUE>['usage'];\n  readonly providerMetadata: EmbedManyResult<VALUE>['providerMetadata'];\n  readonly responses: EmbedManyResult<VALUE>['responses'];\n\n  constructor(options: {\n    values: EmbedManyResult<VALUE>['values'];\n    embeddings: EmbedManyResult<VALUE>['embeddings'];\n    usage: EmbedManyResult<VALUE>['usage'];\n    providerMetadata?: EmbedManyResult<VALUE>['providerMetadata'];\n    responses?: EmbedManyResult<VALUE>['responses'];\n  }) {\n    this.values = options.values;\n    this.embeddings = options.embeddings;\n    this.usage = options.usage;\n    this.providerMetadata = options.providerMetadata;\n    this.responses = options.responses;\n  }\n}\n", "/**\n * Splits an array into chunks of a specified size.\n *\n * @template T - The type of elements in the array.\n * @param {T[]} array - The array to split.\n * @param {number} chunkSize - The size of each chunk.\n * @returns {T[][]} - A new array containing the chunks.\n */\nexport function splitArray<T>(array: T[], chunkSize: number): T[][] {\n  if (chunkSize <= 0) {\n    throw new Error('chunkSize must be greater than 0');\n  }\n\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n\n  return result;\n}\n", "import { ImageModelV2, ImageModelV2ProviderMetadata } from '@ai-sdk/provider';\nimport { ProviderOptions, withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { NoImageGeneratedError } from '../error/no-image-generated-error';\nimport {\n  detectMediaType,\n  imageMediaTypeSignatures,\n} from '../util/detect-media-type';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { UnsupportedModelVersionError } from '../error/unsupported-model-version-error';\nimport {\n  DefaultGeneratedFile,\n  GeneratedFile,\n} from '../generate-text/generated-file';\nimport { ImageGenerationWarning } from '../types/image-model';\nimport { ImageModelResponseMetadata } from '../types/image-model-response-metadata';\nimport { GenerateImageResult } from './generate-image-result';\nimport { logWarnings } from '../logger/log-warnings';\nimport { VERSION } from '../version';\n\n/**\nGenerates images using an image model.\n\n@param model - The image model to use.\n@param prompt - The prompt that should be used to generate the image.\n@param n - Number of images to generate. Default: 1.\n@param size - Size of the images to generate. Must have the format `{width}x{height}`.\n@param aspectRatio - Aspect ratio of the images to generate. Must have the format `{width}:{height}`.\n@param seed - Seed for the image generation.\n@param providerOptions - Additional provider-specific options that are passed through to the provider\nas body parameters.\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the generated images.\n */\nexport async function generateImage({\n  model,\n  prompt,\n  n = 1,\n  maxImagesPerCall,\n  size,\n  aspectRatio,\n  seed,\n  providerOptions,\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n}: {\n  /**\nThe image model to use.\n     */\n  model: ImageModelV2;\n\n  /**\nThe prompt that should be used to generate the image.\n   */\n  prompt: string;\n\n  /**\nNumber of images to generate.\n   */\n  n?: number;\n\n  /**\nNumber of images to generate.\n   */\n  maxImagesPerCall?: number;\n\n  /**\nSize of the images to generate. Must have the format `{width}x{height}`. If not provided, the default size will be used.\n   */\n  size?: `${number}x${number}`;\n\n  /**\nAspect ratio of the images to generate. Must have the format `{width}:{height}`. If not provided, the default aspect ratio will be used.\n   */\n  aspectRatio?: `${number}:${number}`;\n\n  /**\nSeed for the image generation. If not provided, the default seed will be used.\n   */\n  seed?: number;\n\n  /**\nAdditional provider-specific options that are passed through to the provider\nas body parameters.\n\nThe outer record is keyed by the provider name, and the inner\nrecord is keyed by the provider-specific metadata key.\n```ts\n{\n  \"openai\": {\n    \"style\": \"vivid\"\n  }\n}\n```\n     */\n  providerOptions?: ProviderOptions;\n\n  /**\nMaximum number of retries per embedding model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n}): Promise<GenerateImageResult> {\n  if (model.specificationVersion !== 'v2') {\n    throw new UnsupportedModelVersionError({\n      version: model.specificationVersion,\n      provider: model.provider,\n      modelId: model.modelId,\n    });\n  }\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const { retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  // default to 1 if the model has not specified limits on\n  // how many images can be generated in a single call\n  const maxImagesPerCallWithDefault =\n    maxImagesPerCall ?? (await invokeModelMaxImagesPerCall(model)) ?? 1;\n\n  // parallelize calls to the model:\n  const callCount = Math.ceil(n / maxImagesPerCallWithDefault);\n  const callImageCounts = Array.from({ length: callCount }, (_, i) => {\n    if (i < callCount - 1) {\n      return maxImagesPerCallWithDefault;\n    }\n\n    const remainder = n % maxImagesPerCallWithDefault;\n    return remainder === 0 ? maxImagesPerCallWithDefault : remainder;\n  });\n\n  const results = await Promise.all(\n    callImageCounts.map(async callImageCount =>\n      retry(() =>\n        model.doGenerate({\n          prompt,\n          n: callImageCount,\n          abortSignal,\n          headers: headersWithUserAgent,\n          size,\n          aspectRatio,\n          seed,\n          providerOptions: providerOptions ?? {},\n        }),\n      ),\n    ),\n  );\n\n  // collect result images, warnings, and response metadata\n  const images: Array<DefaultGeneratedFile> = [];\n  const warnings: Array<ImageGenerationWarning> = [];\n  const responses: Array<ImageModelResponseMetadata> = [];\n  const providerMetadata: ImageModelV2ProviderMetadata = {};\n  for (const result of results) {\n    images.push(\n      ...result.images.map(\n        image =>\n          new DefaultGeneratedFile({\n            data: image,\n            mediaType:\n              detectMediaType({\n                data: image,\n                signatures: imageMediaTypeSignatures,\n              }) ?? 'image/png',\n          }),\n      ),\n    );\n    warnings.push(...result.warnings);\n\n    if (result.providerMetadata) {\n      for (const [providerName, metadata] of Object.entries<{\n        images: unknown;\n      }>(result.providerMetadata)) {\n        providerMetadata[providerName] ??= { images: [] };\n        providerMetadata[providerName].images.push(\n          ...result.providerMetadata[providerName].images,\n        );\n      }\n    }\n\n    responses.push(result.response);\n  }\n\n  logWarnings(warnings);\n\n  if (!images.length) {\n    throw new NoImageGeneratedError({ responses });\n  }\n\n  return new DefaultGenerateImageResult({\n    images,\n    warnings,\n    responses,\n    providerMetadata,\n  });\n}\n\nclass DefaultGenerateImageResult implements GenerateImageResult {\n  readonly images: Array<GeneratedFile>;\n  readonly warnings: Array<ImageGenerationWarning>;\n  readonly responses: Array<ImageModelResponseMetadata>;\n  readonly providerMetadata: ImageModelV2ProviderMetadata;\n\n  constructor(options: {\n    images: Array<GeneratedFile>;\n    warnings: Array<ImageGenerationWarning>;\n    responses: Array<ImageModelResponseMetadata>;\n    providerMetadata: ImageModelV2ProviderMetadata;\n  }) {\n    this.images = options.images;\n    this.warnings = options.warnings;\n    this.responses = options.responses;\n    this.providerMetadata = options.providerMetadata;\n  }\n\n  get image() {\n    return this.images[0];\n  }\n}\n\nasync function invokeModelMaxImagesPerCall(model: ImageModelV2) {\n  const isFunction = model.maxImagesPerCall instanceof Function;\n\n  if (!isFunction) {\n    return model.maxImagesPerCall;\n  }\n\n  return model.maxImagesPerCall({\n    modelId: model.modelId,\n  });\n}\n", "import { JSONValue } from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  FlexibleSchema,\n  InferSchema,\n  ProviderOptions,\n  withUserAgentSuffix,\n} from '@ai-sdk/provider-utils';\nimport { NoObjectGeneratedError } from '../error/no-object-generated-error';\nimport { extractReasoningContent } from '../generate-text/extract-reasoning-content';\nimport { extractTextContent } from '../generate-text/extract-text-content';\nimport { logWarnings } from '../logger/log-warnings';\nimport { resolveLanguageModel } from '../model/resolve-model';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModel,\n} from '../types/language-model';\nimport { LanguageModelRequestMetadata } from '../types/language-model-request-metadata';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { LanguageModelUsage } from '../types/usage';\nimport { DownloadFunction } from '../util/download/download-function';\nimport { prepareHeaders } from '../util/prepare-headers';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { VERSION } from '../version';\nimport { GenerateObjectResult } from './generate-object-result';\nimport { getOutputStrategy } from './output-strategy';\nimport { parseAndValidateObjectResultWithRepair } from './parse-and-validate-object-result';\nimport { RepairTextFunction } from './repair-text';\nimport { validateObjectGenerationInput } from './validate-object-generation-input';\n\nconst originalGenerateId = createIdGenerator({ prefix: 'aiobj', size: 24 });\n\n/**\nGenerate a structured, typed object for a given prompt and schema using a language model.\n\nThis function does not stream the output. If you want to stream the output, use `streamObject` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param schema - The schema of the object that the model should generate.\n@param schemaName - Optional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n@param schemaDescription - Optional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n\n@param output - The type of the output.\n\n- 'object': The output is an object.\n- 'array': The output is an array.\n- 'enum': The output is an enum.\n- 'no-schema': The output is not a schema.\n\n@param experimental_repairText - A function that attempts to repair the raw output of the model\nto enable JSON parsing.\n\n@param experimental_telemetry - Optional telemetry configuration (experimental).\n\n@param providerOptions - Additional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n\n@returns\nA result object that contains the generated object, the finish reason, the token usage, and additional information.\n */\nexport async function generateObject<\n  SCHEMA extends FlexibleSchema<unknown> = FlexibleSchema<JSONValue>,\n  OUTPUT extends\n    | 'object'\n    | 'array'\n    | 'enum'\n    | 'no-schema' = InferSchema<SCHEMA> extends string ? 'enum' : 'object',\n  RESULT = OUTPUT extends 'array'\n    ? Array<InferSchema<SCHEMA>>\n    : InferSchema<SCHEMA>,\n>(\n  options: Omit<CallSettings, 'stopSequences'> &\n    Prompt &\n    (OUTPUT extends 'enum'\n      ? {\n          /**\nThe enum values that the model should use.\n        */\n          enum: Array<RESULT>;\n          mode?: 'json';\n          output: 'enum';\n        }\n      : OUTPUT extends 'no-schema'\n        ? {}\n        : {\n            /**\nThe schema of the object that the model should generate.\n        */\n            schema: SCHEMA;\n\n            /**\nOptional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n        */\n            schemaName?: string;\n\n            /**\nOptional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n        */\n            schemaDescription?: string;\n\n            /**\nThe mode to use for object generation.\n\nThe schema is converted into a JSON schema and used in one of the following ways\n\n- 'auto': The provider will choose the best mode for the model.\n- 'tool': A tool with the JSON schema as parameters is provided and the provider is instructed to use it.\n- 'json': The JSON schema and an instruction are injected into the prompt. If the provider supports JSON mode, it is enabled. If the provider supports JSON grammars, the grammar is used.\n\nPlease note that most providers do not support all modes.\n\nDefault and recommended: 'auto' (best mode for the model).\n        */\n            mode?: 'auto' | 'json' | 'tool';\n          }) & {\n      output?: OUTPUT;\n\n      /**\n  The language model to use.\n       */\n      model: LanguageModel;\n      /**\n  A function that attempts to repair the raw output of the model\n  to enable JSON parsing.\n       */\n      experimental_repairText?: RepairTextFunction;\n\n      /**\n  Optional telemetry configuration (experimental).\n         */\n\n      experimental_telemetry?: TelemetrySettings;\n\n      /**\n  Custom download function to use for URLs.\n\n  By default, files are downloaded if the model does not support the URL for the given media type.\n       */\n      experimental_download?: DownloadFunction | undefined;\n\n      /**\n  Additional provider-specific options. They are passed through\n  to the provider from the AI SDK and enable provider-specific\n  functionality that can be fully encapsulated in the provider.\n   */\n      providerOptions?: ProviderOptions;\n\n      /**\n       * Internal. For test use only. May change without notice.\n       */\n      _internal?: {\n        generateId?: () => string;\n        currentDate?: () => Date;\n      };\n    },\n): Promise<GenerateObjectResult<RESULT>> {\n  const {\n    model: modelArg,\n    output = 'object',\n    system,\n    prompt,\n    messages,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    headers,\n    experimental_repairText: repairText,\n    experimental_telemetry: telemetry,\n    experimental_download: download,\n    providerOptions,\n    _internal: {\n      generateId = originalGenerateId,\n      currentDate = () => new Date(),\n    } = {},\n    ...settings\n  } = options;\n\n  const model = resolveLanguageModel(modelArg);\n\n  const enumValues = 'enum' in options ? options.enum : undefined;\n  const {\n    schema: inputSchema,\n    schemaDescription,\n    schemaName,\n  } = 'schema' in options ? options : {};\n\n  validateObjectGenerationInput({\n    output,\n    schema: inputSchema,\n    schemaName,\n    schemaDescription,\n    enumValues,\n  });\n\n  const { maxRetries, retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const outputStrategy = getOutputStrategy({\n    output,\n    schema: inputSchema,\n    enumValues,\n  });\n\n  const callSettings = prepareCallSettings(settings);\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const baseTelemetryAttributes = getBaseTelemetryAttributes({\n    model,\n    telemetry,\n    headers: headersWithUserAgent,\n    settings: { ...callSettings, maxRetries },\n  });\n\n  const tracer = getTracer(telemetry);\n\n  try {\n    return await recordSpan({\n      name: 'ai.generateObject',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.generateObject',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n          'ai.schema':\n            outputStrategy.jsonSchema != null\n              ? { input: () => JSON.stringify(outputStrategy.jsonSchema) }\n              : undefined,\n          'ai.schema.name': schemaName,\n          'ai.schema.description': schemaDescription,\n          'ai.settings.output': outputStrategy.type,\n        },\n      }),\n      tracer,\n      fn: async span => {\n        let result: string;\n        let finishReason: FinishReason;\n        let usage: LanguageModelUsage;\n        let warnings: CallWarning[] | undefined;\n        let response: LanguageModelResponseMetadata;\n        let request: LanguageModelRequestMetadata;\n        let resultProviderMetadata: ProviderMetadata | undefined;\n        let reasoning: string | undefined;\n\n        const standardizedPrompt = await standardizePrompt({\n          system,\n          prompt,\n          messages,\n        } as Prompt);\n\n        const promptMessages = await convertToLanguageModelPrompt({\n          prompt: standardizedPrompt,\n          supportedUrls: await model.supportedUrls,\n          download,\n        });\n\n        const generateResult = await retry(() =>\n          recordSpan({\n            name: 'ai.generateObject.doGenerate',\n            attributes: selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                ...assembleOperationName({\n                  operationId: 'ai.generateObject.doGenerate',\n                  telemetry,\n                }),\n                ...baseTelemetryAttributes,\n                'ai.prompt.messages': {\n                  input: () => stringifyForTelemetry(promptMessages),\n                },\n\n                // standardized gen-ai llm span attributes:\n                'gen_ai.system': model.provider,\n                'gen_ai.request.model': model.modelId,\n                'gen_ai.request.frequency_penalty':\n                  callSettings.frequencyPenalty,\n                'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                'gen_ai.request.presence_penalty': callSettings.presencePenalty,\n                'gen_ai.request.temperature': callSettings.temperature,\n                'gen_ai.request.top_k': callSettings.topK,\n                'gen_ai.request.top_p': callSettings.topP,\n              },\n            }),\n            tracer,\n            fn: async span => {\n              const result = await model.doGenerate({\n                responseFormat: {\n                  type: 'json',\n                  schema: outputStrategy.jsonSchema,\n                  name: schemaName,\n                  description: schemaDescription,\n                },\n                ...prepareCallSettings(settings),\n                prompt: promptMessages,\n                providerOptions,\n                abortSignal,\n                headers: headersWithUserAgent,\n              });\n\n              const responseData = {\n                id: result.response?.id ?? generateId(),\n                timestamp: result.response?.timestamp ?? currentDate(),\n                modelId: result.response?.modelId ?? model.modelId,\n                headers: result.response?.headers,\n                body: result.response?.body,\n              };\n\n              const text = extractTextContent(result.content);\n              const reasoning = extractReasoningContent(result.content);\n\n              if (text === undefined) {\n                throw new NoObjectGeneratedError({\n                  message:\n                    'No object generated: the model did not return a response.',\n                  response: responseData,\n                  usage: result.usage,\n                  finishReason: result.finishReason,\n                });\n              }\n\n              // Add response information to the span:\n              span.setAttributes(\n                selectTelemetryAttributes({\n                  telemetry,\n                  attributes: {\n                    'ai.response.finishReason': result.finishReason,\n                    'ai.response.object': { output: () => text },\n                    'ai.response.id': responseData.id,\n                    'ai.response.model': responseData.modelId,\n                    'ai.response.timestamp':\n                      responseData.timestamp.toISOString(),\n                    'ai.response.providerMetadata': JSON.stringify(\n                      result.providerMetadata,\n                    ),\n\n                    // TODO rename telemetry attributes to inputTokens and outputTokens\n                    'ai.usage.promptTokens': result.usage.inputTokens,\n                    'ai.usage.completionTokens': result.usage.outputTokens,\n\n                    // standardized gen-ai llm span attributes:\n                    'gen_ai.response.finish_reasons': [result.finishReason],\n                    'gen_ai.response.id': responseData.id,\n                    'gen_ai.response.model': responseData.modelId,\n                    'gen_ai.usage.input_tokens': result.usage.inputTokens,\n                    'gen_ai.usage.output_tokens': result.usage.outputTokens,\n                  },\n                }),\n              );\n\n              return {\n                ...result,\n                objectText: text,\n                reasoning,\n                responseData,\n              };\n            },\n          }),\n        );\n\n        result = generateResult.objectText;\n        finishReason = generateResult.finishReason;\n        usage = generateResult.usage;\n        warnings = generateResult.warnings;\n        resultProviderMetadata = generateResult.providerMetadata;\n        request = generateResult.request ?? {};\n        response = generateResult.responseData;\n        reasoning = generateResult.reasoning;\n\n        logWarnings(warnings);\n\n        const object = await parseAndValidateObjectResultWithRepair(\n          result,\n          outputStrategy,\n          repairText,\n          {\n            response,\n            usage,\n            finishReason,\n          },\n        );\n\n        // Add response information to the span:\n        span.setAttributes(\n          selectTelemetryAttributes({\n            telemetry,\n            attributes: {\n              'ai.response.finishReason': finishReason,\n              'ai.response.object': {\n                output: () => JSON.stringify(object),\n              },\n              'ai.response.providerMetadata': JSON.stringify(\n                resultProviderMetadata,\n              ),\n\n              // TODO rename telemetry attributes to inputTokens and outputTokens\n              'ai.usage.promptTokens': usage.inputTokens,\n              'ai.usage.completionTokens': usage.outputTokens,\n            },\n          }),\n        );\n\n        return new DefaultGenerateObjectResult({\n          object,\n          reasoning,\n          finishReason,\n          usage,\n          warnings,\n          request,\n          response,\n          providerMetadata: resultProviderMetadata,\n        });\n      },\n    });\n  } catch (error) {\n    throw wrapGatewayError(error);\n  }\n}\n\nclass DefaultGenerateObjectResult<T> implements GenerateObjectResult<T> {\n  readonly object: GenerateObjectResult<T>['object'];\n  readonly finishReason: GenerateObjectResult<T>['finishReason'];\n  readonly usage: GenerateObjectResult<T>['usage'];\n  readonly warnings: GenerateObjectResult<T>['warnings'];\n  readonly providerMetadata: GenerateObjectResult<T>['providerMetadata'];\n  readonly response: GenerateObjectResult<T>['response'];\n  readonly request: GenerateObjectResult<T>['request'];\n  readonly reasoning: GenerateObjectResult<T>['reasoning'];\n\n  constructor(options: {\n    object: GenerateObjectResult<T>['object'];\n    finishReason: GenerateObjectResult<T>['finishReason'];\n    usage: GenerateObjectResult<T>['usage'];\n    warnings: GenerateObjectResult<T>['warnings'];\n    providerMetadata: GenerateObjectResult<T>['providerMetadata'];\n    response: GenerateObjectResult<T>['response'];\n    request: GenerateObjectResult<T>['request'];\n    reasoning: GenerateObjectResult<T>['reasoning'];\n  }) {\n    this.object = options.object;\n    this.finishReason = options.finishReason;\n    this.usage = options.usage;\n    this.warnings = options.warnings;\n    this.providerMetadata = options.providerMetadata;\n    this.response = options.response;\n    this.request = options.request;\n    this.reasoning = options.reasoning;\n  }\n\n  toJsonResponse(init?: ResponseInit): Response {\n    return new Response(JSON.stringify(this.object), {\n      status: init?.status ?? 200,\n      headers: prepareHeaders(init?.headers, {\n        'content-type': 'application/json; charset=utf-8',\n      }),\n    });\n  }\n}\n", "import {\n  LanguageModelV2Content,\n  LanguageModelV2Reasoning,\n} from '@ai-sdk/provider';\n\nexport function extractReasoningContent(\n  content: LanguageModelV2Content[],\n): string | undefined {\n  const parts = content.filter(\n    (content): content is LanguageModelV2Reasoning =>\n      content.type === 'reasoning',\n  );\n\n  return parts.length === 0\n    ? undefined\n    : parts.map(content => content.text).join('\\n');\n}\n", "import {\n  isJSONArray,\n  isJSONObject,\n  JSONObject,\n  JSONSchema7,\n  JSONValue,\n  TypeValidationError,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  asSchema,\n  FlexibleSchema,\n  safeValidateTypes,\n  Schema,\n  ValidationResult,\n} from '@ai-sdk/provider-utils';\nimport { NoObjectGeneratedError } from '../error/no-object-generated-error';\nimport {\n  FinishReason,\n  LanguageModelResponseMetadata,\n  LanguageModelUsage,\n} from '../types';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../util/async-iterable-stream';\nimport { DeepPartial } from '../util/deep-partial';\nimport { ObjectStreamPart } from './stream-object-result';\n\nexport interface OutputStrategy<PARTIAL, RESULT, ELEMENT_STREAM> {\n  readonly type: 'object' | 'array' | 'enum' | 'no-schema';\n  readonly jsonSchema: JSONSchema7 | undefined;\n\n  validatePartialResult({\n    value,\n    textDelta,\n    isFinalDelta,\n  }: {\n    value: JSONValue;\n    textDelta: string;\n    isFirstDelta: boolean;\n    isFinalDelta: boolean;\n    latestObject: PARTIAL | undefined;\n  }): Promise<\n    ValidationResult<{\n      partial: PARTIAL;\n      textDelta: string;\n    }>\n  >;\n  validateFinalResult(\n    value: JSONValue | undefined,\n    context: {\n      text: string;\n      response: LanguageModelResponseMetadata;\n      usage: LanguageModelUsage;\n    },\n  ): Promise<ValidationResult<RESULT>>;\n\n  createElementStream(\n    originalStream: ReadableStream<ObjectStreamPart<PARTIAL>>,\n  ): ELEMENT_STREAM;\n}\n\nconst noSchemaOutputStrategy: OutputStrategy<JSONValue, JSONValue, never> = {\n  type: 'no-schema',\n  jsonSchema: undefined,\n\n  async validatePartialResult({ value, textDelta }) {\n    return { success: true, value: { partial: value, textDelta } };\n  },\n\n  async validateFinalResult(\n    value: JSONValue | undefined,\n    context: {\n      text: string;\n      response: LanguageModelResponseMetadata;\n      usage: LanguageModelUsage;\n      finishReason: FinishReason;\n    },\n  ): Promise<ValidationResult<JSONValue>> {\n    return value === undefined\n      ? {\n          success: false,\n          error: new NoObjectGeneratedError({\n            message: 'No object generated: response did not match schema.',\n            text: context.text,\n            response: context.response,\n            usage: context.usage,\n            finishReason: context.finishReason,\n          }),\n        }\n      : { success: true, value };\n  },\n\n  createElementStream() {\n    throw new UnsupportedFunctionalityError({\n      functionality: 'element streams in no-schema mode',\n    });\n  },\n};\n\nconst objectOutputStrategy = <OBJECT>(\n  schema: Schema<OBJECT>,\n): OutputStrategy<DeepPartial<OBJECT>, OBJECT, never> => ({\n  type: 'object',\n  jsonSchema: schema.jsonSchema,\n\n  async validatePartialResult({ value, textDelta }) {\n    return {\n      success: true,\n      value: {\n        // Note: currently no validation of partial results:\n        partial: value as DeepPartial<OBJECT>,\n        textDelta,\n      },\n    };\n  },\n\n  async validateFinalResult(\n    value: JSONValue | undefined,\n  ): Promise<ValidationResult<OBJECT>> {\n    return safeValidateTypes({ value, schema });\n  },\n\n  createElementStream() {\n    throw new UnsupportedFunctionalityError({\n      functionality: 'element streams in object mode',\n    });\n  },\n});\n\nconst arrayOutputStrategy = <ELEMENT>(\n  schema: Schema<ELEMENT>,\n): OutputStrategy<ELEMENT[], ELEMENT[], AsyncIterableStream<ELEMENT>> => {\n  // remove $schema from schema.jsonSchema:\n  const { $schema, ...itemSchema } = schema.jsonSchema;\n\n  return {\n    type: 'array',\n\n    // wrap in object that contains array of elements, since most LLMs will not\n    // be able to generate an array directly:\n    // possible future optimization: use arrays directly when model supports grammar-guided generation\n    jsonSchema: {\n      $schema: 'http://json-schema.org/draft-07/schema#',\n      type: 'object',\n      properties: {\n        elements: { type: 'array', items: itemSchema },\n      },\n      required: ['elements'],\n      additionalProperties: false,\n    },\n\n    async validatePartialResult({\n      value,\n      latestObject,\n      isFirstDelta,\n      isFinalDelta,\n    }) {\n      // check that the value is an object that contains an array of elements:\n      if (!isJSONObject(value) || !isJSONArray(value.elements)) {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause: 'value must be an object that contains an array of elements',\n          }),\n        };\n      }\n\n      const inputArray = value.elements as Array<JSONObject>;\n      const resultArray: Array<ELEMENT> = [];\n\n      for (let i = 0; i < inputArray.length; i++) {\n        const element = inputArray[i];\n        const result = await safeValidateTypes({ value: element, schema });\n\n        // special treatment for last processed element:\n        // ignore parse or validation failures, since they indicate that the\n        // last element is incomplete and should not be included in the result,\n        // unless it is the final delta\n        if (i === inputArray.length - 1 && !isFinalDelta) {\n          continue;\n        }\n\n        if (!result.success) {\n          return result;\n        }\n\n        resultArray.push(result.value);\n      }\n\n      // calculate delta:\n      const publishedElementCount = latestObject?.length ?? 0;\n\n      let textDelta = '';\n\n      if (isFirstDelta) {\n        textDelta += '[';\n      }\n\n      if (publishedElementCount > 0) {\n        textDelta += ',';\n      }\n\n      textDelta += resultArray\n        .slice(publishedElementCount) // only new elements\n        .map(element => JSON.stringify(element))\n        .join(',');\n\n      if (isFinalDelta) {\n        textDelta += ']';\n      }\n\n      return {\n        success: true,\n        value: {\n          partial: resultArray,\n          textDelta,\n        },\n      };\n    },\n\n    async validateFinalResult(\n      value: JSONValue | undefined,\n    ): Promise<ValidationResult<Array<ELEMENT>>> {\n      // check that the value is an object that contains an array of elements:\n      if (!isJSONObject(value) || !isJSONArray(value.elements)) {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause: 'value must be an object that contains an array of elements',\n          }),\n        };\n      }\n\n      const inputArray = value.elements as Array<JSONObject>;\n\n      // check that each element in the array is of the correct type:\n      for (const element of inputArray) {\n        const result = await safeValidateTypes({ value: element, schema });\n        if (!result.success) {\n          return result;\n        }\n      }\n\n      return { success: true, value: inputArray as Array<ELEMENT> };\n    },\n\n    createElementStream(\n      originalStream: ReadableStream<ObjectStreamPart<ELEMENT[]>>,\n    ) {\n      let publishedElements = 0;\n\n      return createAsyncIterableStream(\n        originalStream.pipeThrough(\n          new TransformStream<ObjectStreamPart<ELEMENT[]>, ELEMENT>({\n            transform(chunk, controller) {\n              switch (chunk.type) {\n                case 'object': {\n                  const array = chunk.object;\n\n                  // publish new elements one by one:\n                  for (\n                    ;\n                    publishedElements < array.length;\n                    publishedElements++\n                  ) {\n                    controller.enqueue(array[publishedElements]);\n                  }\n\n                  break;\n                }\n\n                case 'text-delta':\n                case 'finish':\n                case 'error': // suppress error (use onError instead)\n                  break;\n\n                default: {\n                  const _exhaustiveCheck: never = chunk;\n                  throw new Error(\n                    `Unsupported chunk type: ${_exhaustiveCheck}`,\n                  );\n                }\n              }\n            },\n          }),\n        ),\n      );\n    },\n  };\n};\n\nconst enumOutputStrategy = <ENUM extends string>(\n  enumValues: Array<ENUM>,\n): OutputStrategy<string, ENUM, never> => {\n  return {\n    type: 'enum',\n\n    // wrap in object that contains result, since most LLMs will not\n    // be able to generate an enum value directly:\n    // possible future optimization: use enums directly when model supports top-level enums\n    jsonSchema: {\n      $schema: 'http://json-schema.org/draft-07/schema#',\n      type: 'object',\n      properties: {\n        result: { type: 'string', enum: enumValues },\n      },\n      required: ['result'],\n      additionalProperties: false,\n    },\n\n    async validateFinalResult(\n      value: JSONValue | undefined,\n    ): Promise<ValidationResult<ENUM>> {\n      // check that the value is an object that contains an array of elements:\n      if (!isJSONObject(value) || typeof value.result !== 'string') {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause:\n              'value must be an object that contains a string in the \"result\" property.',\n          }),\n        };\n      }\n\n      const result = value.result as string;\n\n      return enumValues.includes(result as ENUM)\n        ? { success: true, value: result as ENUM }\n        : {\n            success: false,\n            error: new TypeValidationError({\n              value,\n              cause: 'value must be a string in the enum',\n            }),\n          };\n    },\n\n    async validatePartialResult({ value, textDelta }) {\n      if (!isJSONObject(value) || typeof value.result !== 'string') {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause:\n              'value must be an object that contains a string in the \"result\" property.',\n          }),\n        };\n      }\n\n      const result = value.result as string;\n      const possibleEnumValues = enumValues.filter(enumValue =>\n        enumValue.startsWith(result),\n      );\n\n      if (value.result.length === 0 || possibleEnumValues.length === 0) {\n        return {\n          success: false,\n          error: new TypeValidationError({\n            value,\n            cause: 'value must be a string in the enum',\n          }),\n        };\n      }\n\n      return {\n        success: true,\n        value: {\n          partial:\n            possibleEnumValues.length > 1 ? result : possibleEnumValues[0],\n          textDelta,\n        },\n      };\n    },\n\n    createElementStream() {\n      // no streaming in enum mode\n      throw new UnsupportedFunctionalityError({\n        functionality: 'element streams in enum mode',\n      });\n    },\n  };\n};\n\nexport function getOutputStrategy<SCHEMA>({\n  output,\n  schema,\n  enumValues,\n}: {\n  output: 'object' | 'array' | 'enum' | 'no-schema';\n  schema?: FlexibleSchema<SCHEMA>;\n  enumValues?: Array<SCHEMA>;\n}): OutputStrategy<any, any, any> {\n  switch (output) {\n    case 'object':\n      return objectOutputStrategy(asSchema(schema!));\n    case 'array':\n      return arrayOutputStrategy(asSchema(schema!));\n    case 'enum':\n      return enumOutputStrategy(enumValues! as Array<string>);\n    case 'no-schema':\n      return noSchemaOutputStrategy;\n    default: {\n      const _exhaustiveCheck: never = output;\n      throw new Error(`Unsupported output: ${_exhaustiveCheck}`);\n    }\n  }\n}\n", "import { JSONParseError, TypeValidationError } from '@ai-sdk/provider';\nimport { safeParseJSON } from '@ai-sdk/provider-utils';\nimport { NoObjectGeneratedError } from '../error/no-object-generated-error';\nimport type {\n  FinishReason,\n  LanguageModelResponseMetadata,\n  LanguageModelUsage,\n} from '../types';\nimport type { OutputStrategy } from './output-strategy';\nimport { RepairTextFunction } from './repair-text';\n\n/**\n * Parses and validates a result string by parsing it as JSON and validating against the output strategy.\n *\n * @param result - The result string to parse and validate\n * @param outputStrategy - The output strategy containing validation logic\n * @param context - Additional context for error reporting\n * @returns The validated result\n * @throws NoObjectGeneratedError if parsing or validation fails\n */\nasync function parseAndValidateObjectResult<RESULT>(\n  result: string,\n  outputStrategy: OutputStrategy<any, RESULT, any>,\n  context: {\n    response: LanguageModelResponseMetadata;\n    usage: LanguageModelUsage;\n    finishReason: FinishReason;\n  },\n): Promise<RESULT> {\n  const parseResult = await safeParseJSON({ text: result });\n\n  if (!parseResult.success) {\n    throw new NoObjectGeneratedError({\n      message: 'No object generated: could not parse the response.',\n      cause: parseResult.error,\n      text: result,\n      response: context.response,\n      usage: context.usage,\n      finishReason: context.finishReason,\n    });\n  }\n\n  const validationResult = await outputStrategy.validateFinalResult(\n    parseResult.value,\n    {\n      text: result,\n      response: context.response,\n      usage: context.usage,\n    },\n  );\n\n  if (!validationResult.success) {\n    throw new NoObjectGeneratedError({\n      message: 'No object generated: response did not match schema.',\n      cause: validationResult.error,\n      text: result,\n      response: context.response,\n      usage: context.usage,\n      finishReason: context.finishReason,\n    });\n  }\n\n  return validationResult.value;\n}\n\n/**\n * Parses and validates a result string by parsing it as JSON and validating against the output strategy.\n * If the result cannot be parsed, it attempts to repair the result using the repairText function.\n *\n * @param result - The result string to parse and validate\n * @param outputStrategy - The output strategy containing validation logic\n * @param repairText - A function that attempts to repair the result string\n * @param context - Additional context for error reporting\n * @returns The validated result\n * @throws NoObjectGeneratedError if parsing or validation fails\n */\nexport async function parseAndValidateObjectResultWithRepair<RESULT>(\n  result: string,\n  outputStrategy: OutputStrategy<any, RESULT, any>,\n  repairText: RepairTextFunction | undefined,\n  context: {\n    response: LanguageModelResponseMetadata;\n    usage: LanguageModelUsage;\n    finishReason: FinishReason;\n  },\n): Promise<RESULT> {\n  try {\n    return await parseAndValidateObjectResult(result, outputStrategy, context);\n  } catch (error) {\n    if (\n      repairText != null &&\n      NoObjectGeneratedError.isInstance(error) &&\n      (JSONParseError.isInstance(error.cause) ||\n        TypeValidationError.isInstance(error.cause))\n    ) {\n      const repairedText = await repairText({\n        text: result,\n        error: error.cause,\n      });\n      if (repairedText === null) {\n        throw error;\n      }\n      return await parseAndValidateObjectResult(\n        repairedText,\n        outputStrategy,\n        context,\n      );\n    }\n    throw error;\n  }\n}\n", "import { FlexibleSchema } from '@ai-sdk/provider-utils';\nimport { InvalidArgumentError } from '../error/invalid-argument-error';\n\nexport function validateObjectGenerationInput({\n  output,\n  schema,\n  schemaName,\n  schemaDescription,\n  enumValues,\n}: {\n  output?: 'object' | 'array' | 'enum' | 'no-schema';\n  schema?: FlexibleSchema<unknown>;\n  schemaName?: string;\n  schemaDescription?: string;\n  enumValues?: Array<unknown>;\n}) {\n  if (\n    output != null &&\n    output !== 'object' &&\n    output !== 'array' &&\n    output !== 'enum' &&\n    output !== 'no-schema'\n  ) {\n    throw new InvalidArgumentError({\n      parameter: 'output',\n      value: output,\n      message: 'Invalid output type.',\n    });\n  }\n\n  if (output === 'no-schema') {\n    if (schema != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schema',\n        value: schema,\n        message: 'Schema is not supported for no-schema output.',\n      });\n    }\n\n    if (schemaDescription != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schemaDescription',\n        value: schemaDescription,\n        message: 'Schema description is not supported for no-schema output.',\n      });\n    }\n\n    if (schemaName != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schemaName',\n        value: schemaName,\n        message: 'Schema name is not supported for no-schema output.',\n      });\n    }\n\n    if (enumValues != null) {\n      throw new InvalidArgumentError({\n        parameter: 'enumValues',\n        value: enumValues,\n        message: 'Enum values are not supported for no-schema output.',\n      });\n    }\n  }\n\n  if (output === 'object') {\n    if (schema == null) {\n      throw new InvalidArgumentError({\n        parameter: 'schema',\n        value: schema,\n        message: 'Schema is required for object output.',\n      });\n    }\n\n    if (enumValues != null) {\n      throw new InvalidArgumentError({\n        parameter: 'enumValues',\n        value: enumValues,\n        message: 'Enum values are not supported for object output.',\n      });\n    }\n  }\n\n  if (output === 'array') {\n    if (schema == null) {\n      throw new InvalidArgumentError({\n        parameter: 'schema',\n        value: schema,\n        message: 'Element schema is required for array output.',\n      });\n    }\n\n    if (enumValues != null) {\n      throw new InvalidArgumentError({\n        parameter: 'enumValues',\n        value: enumValues,\n        message: 'Enum values are not supported for array output.',\n      });\n    }\n  }\n\n  if (output === 'enum') {\n    if (schema != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schema',\n        value: schema,\n        message: 'Schema is not supported for enum output.',\n      });\n    }\n\n    if (schemaDescription != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schemaDescription',\n        value: schemaDescription,\n        message: 'Schema description is not supported for enum output.',\n      });\n    }\n\n    if (schemaName != null) {\n      throw new InvalidArgumentError({\n        parameter: 'schemaName',\n        value: schemaName,\n        message: 'Schema name is not supported for enum output.',\n      });\n    }\n\n    if (enumValues == null) {\n      throw new InvalidArgumentError({\n        parameter: 'enumValues',\n        value: enumValues,\n        message: 'Enum values are required for enum output.',\n      });\n    }\n\n    for (const value of enumValues) {\n      if (typeof value !== 'string') {\n        throw new InvalidArgumentError({\n          parameter: 'enumValues',\n          value,\n          message: 'Enum values must be strings.',\n        });\n      }\n    }\n  }\n}\n", "import {\n  JSONValue,\n  LanguageModelV2CallWarning,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  createIdGenerator,\n  FlexibleSchema,\n  ProviderOptions,\n  type InferSchema,\n} from '@ai-sdk/provider-utils';\nimport { ServerResponse } from 'http';\nimport { logWarnings } from '../logger/log-warnings';\nimport { resolveLanguageModel } from '../model/resolve-model';\nimport { CallSettings } from '../prompt/call-settings';\nimport { convertToLanguageModelPrompt } from '../prompt/convert-to-language-model-prompt';\nimport { prepareCallSettings } from '../prompt/prepare-call-settings';\nimport { Prompt } from '../prompt/prompt';\nimport { standardizePrompt } from '../prompt/standardize-prompt';\nimport { wrapGatewayError } from '../prompt/wrap-gateway-error';\nimport { assembleOperationName } from '../telemetry/assemble-operation-name';\nimport { getBaseTelemetryAttributes } from '../telemetry/get-base-telemetry-attributes';\nimport { getTracer } from '../telemetry/get-tracer';\nimport { recordSpan } from '../telemetry/record-span';\nimport { selectTelemetryAttributes } from '../telemetry/select-telemetry-attributes';\nimport { stringifyForTelemetry } from '../telemetry/stringify-for-telemetry';\nimport { TelemetrySettings } from '../telemetry/telemetry-settings';\nimport { createTextStreamResponse } from '../text-stream/create-text-stream-response';\nimport { pipeTextStreamToResponse } from '../text-stream/pipe-text-stream-to-response';\nimport {\n  CallWarning,\n  FinishReason,\n  LanguageModel,\n} from '../types/language-model';\nimport { LanguageModelRequestMetadata } from '../types/language-model-request-metadata';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { ProviderMetadata } from '../types/provider-metadata';\nimport { LanguageModelUsage } from '../types/usage';\nimport { DeepPartial, isDeepEqualData, parsePartialJson } from '../util';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../util/async-iterable-stream';\nimport { createStitchableStream } from '../util/create-stitchable-stream';\nimport { DelayedPromise } from '../util/delayed-promise';\nimport { DownloadFunction } from '../util/download/download-function';\nimport { now as originalNow } from '../util/now';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { getOutputStrategy, OutputStrategy } from './output-strategy';\nimport { parseAndValidateObjectResultWithRepair } from './parse-and-validate-object-result';\nimport { RepairTextFunction } from './repair-text';\nimport { ObjectStreamPart, StreamObjectResult } from './stream-object-result';\nimport { validateObjectGenerationInput } from './validate-object-generation-input';\n\nconst originalGenerateId = createIdGenerator({ prefix: 'aiobj', size: 24 });\n\n/**\nCallback that is set using the `onError` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamObjectOnErrorCallback = (event: {\n  error: unknown;\n}) => Promise<void> | void;\n\n/**\nCallback that is set using the `onFinish` option.\n\n@param event - The event that is passed to the callback.\n */\nexport type StreamObjectOnFinishCallback<RESULT> = (event: {\n  /**\nThe token usage of the generated response.\n*/\n  usage: LanguageModelUsage;\n\n  /**\nThe generated object. Can be undefined if the final object does not match the schema.\n*/\n  object: RESULT | undefined;\n\n  /**\nOptional error object. This is e.g. a TypeValidationError when the final object does not match the schema.\n*/\n  error: unknown | undefined;\n\n  /**\nResponse metadata.\n */\n  response: LanguageModelResponseMetadata;\n\n  /**\nWarnings from the model provider (e.g. unsupported settings).\n*/\n  warnings?: CallWarning[];\n\n  /**\nAdditional provider-specific metadata. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n*/\n  providerMetadata: ProviderMetadata | undefined;\n}) => Promise<void> | void;\n\n/**\nGenerate a structured, typed object for a given prompt and schema using a language model.\n\nThis function streams the output. If you do not want to stream the output, use `generateObject` instead.\n\n@param model - The language model to use.\n@param tools - Tools that are accessible to and can be called by the model. The model needs to support calling tools.\n\n@param system - A system message that will be part of the prompt.\n@param prompt - A simple text prompt. You can either use `prompt` or `messages` but not both.\n@param messages - A list of messages. You can either use `prompt` or `messages` but not both.\n\n@param maxOutputTokens - Maximum number of tokens to generate.\n@param temperature - Temperature setting.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topP - Nucleus sampling.\nThe value is passed through to the provider. The range depends on the provider and model.\nIt is recommended to set either `temperature` or `topP`, but not both.\n@param topK - Only sample from the top K options for each subsequent token.\nUsed to remove \"long tail\" low probability responses.\nRecommended for advanced use cases only. You usually only need to use temperature.\n@param presencePenalty - Presence penalty setting.\nIt affects the likelihood of the model to repeat information that is already in the prompt.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param frequencyPenalty - Frequency penalty setting.\nIt affects the likelihood of the model to repeatedly use the same words or phrases.\nThe value is passed through to the provider. The range depends on the provider and model.\n@param stopSequences - Stop sequences.\nIf set, the model will stop generating text when one of the stop sequences is generated.\n@param seed - The seed (integer) to use for random sampling.\nIf set and supported by the model, calls will generate deterministic results.\n\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@param schema - The schema of the object that the model should generate.\n@param schemaName - Optional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n@param schemaDescription - Optional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n\n@param output - The type of the output.\n\n- 'object': The output is an object.\n- 'array': The output is an array.\n- 'enum': The output is an enum.\n- 'no-schema': The output is not a schema.\n\n@param experimental_telemetry - Optional telemetry configuration (experimental).\n\n@param providerOptions - Additional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n\n@returns\nA result object for accessing the partial object stream and additional information.\n */\nexport function streamObject<\n  SCHEMA extends FlexibleSchema<unknown> = FlexibleSchema<JSONValue>,\n  OUTPUT extends\n    | 'object'\n    | 'array'\n    | 'enum'\n    | 'no-schema' = InferSchema<SCHEMA> extends string ? 'enum' : 'object',\n  RESULT = OUTPUT extends 'array'\n    ? Array<InferSchema<SCHEMA>>\n    : InferSchema<SCHEMA>,\n>(\n  options: Omit<CallSettings, 'stopSequences'> &\n    Prompt &\n    (OUTPUT extends 'enum'\n      ? {\n          /**\nThe enum values that the model should use.\n        */\n          enum: Array<RESULT>;\n          mode?: 'json';\n          output: 'enum';\n        }\n      : OUTPUT extends 'no-schema'\n        ? {}\n        : {\n            /**\nThe schema of the object that the model should generate.\n      */\n            schema: SCHEMA;\n\n            /**\nOptional name of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema name.\n      */\n            schemaName?: string;\n\n            /**\nOptional description of the output that should be generated.\nUsed by some providers for additional LLM guidance, e.g.\nvia tool or schema description.\n      */\n            schemaDescription?: string;\n\n            /**\nThe mode to use for object generation.\n\nThe schema is converted into a JSON schema and used in one of the following ways\n\n- 'auto': The provider will choose the best mode for the model.\n- 'tool': A tool with the JSON schema as parameters is provided and the provider is instructed to use it.\n- 'json': The JSON schema and an instruction are injected into the prompt. If the provider supports JSON mode, it is enabled. If the provider supports JSON grammars, the grammar is used.\n\nPlease note that most providers do not support all modes.\n\nDefault and recommended: 'auto' (best mode for the model).\n      */\n            mode?: 'auto' | 'json' | 'tool';\n          }) & {\n      output?: OUTPUT;\n\n      /**\nThe language model to use.\n     */\n      model: LanguageModel;\n\n      /**\nA function that attempts to repair the raw output of the model\nto enable JSON parsing.\n       */\n      experimental_repairText?: RepairTextFunction;\n\n      /**\nOptional telemetry configuration (experimental).\n       */\n\n      experimental_telemetry?: TelemetrySettings;\n\n      /**\n  Custom download function to use for URLs.\n\n  By default, files are downloaded if the model does not support the URL for the given media type.\n       */\n      experimental_download?: DownloadFunction | undefined;\n\n      /**\nAdditional provider-specific options. They are passed through\nto the provider from the AI SDK and enable provider-specific\nfunctionality that can be fully encapsulated in the provider.\n */\n      providerOptions?: ProviderOptions;\n\n      /**\nCallback that is invoked when an error occurs during streaming.\nYou can use it to log errors.\nThe stream processing will pause until the callback promise is resolved.\n     */\n      onError?: StreamObjectOnErrorCallback;\n\n      /**\nCallback that is called when the LLM response and the final object validation are finished.\n*/\n      onFinish?: StreamObjectOnFinishCallback<RESULT>;\n\n      /**\n       * Internal. For test use only. May change without notice.\n       */\n      _internal?: {\n        generateId?: () => string;\n        currentDate?: () => Date;\n        now?: () => number;\n      };\n    },\n): StreamObjectResult<\n  OUTPUT extends 'enum'\n    ? string\n    : OUTPUT extends 'array'\n      ? RESULT\n      : DeepPartial<RESULT>,\n  OUTPUT extends 'array' ? RESULT : RESULT,\n  OUTPUT extends 'array'\n    ? RESULT extends Array<infer U>\n      ? AsyncIterableStream<U>\n      : never\n    : never\n> {\n  const {\n    model,\n    output = 'object',\n    system,\n    prompt,\n    messages,\n    maxRetries,\n    abortSignal,\n    headers,\n    experimental_repairText: repairText,\n    experimental_telemetry: telemetry,\n    experimental_download: download,\n    providerOptions,\n    onError = ({ error }: { error: unknown }) => {\n      console.error(error);\n    },\n    onFinish,\n    _internal: {\n      generateId = originalGenerateId,\n      currentDate = () => new Date(),\n      now = originalNow,\n    } = {},\n    ...settings\n  } = options;\n\n  const enumValues =\n    'enum' in options && options.enum ? options.enum : undefined;\n\n  const {\n    schema: inputSchema,\n    schemaDescription,\n    schemaName,\n  } = 'schema' in options ? options : {};\n\n  validateObjectGenerationInput({\n    output,\n    schema: inputSchema,\n    schemaName,\n    schemaDescription,\n    enumValues,\n  });\n\n  const outputStrategy = getOutputStrategy({\n    output,\n    schema: inputSchema,\n    enumValues,\n  });\n\n  return new DefaultStreamObjectResult({\n    model,\n    telemetry,\n    headers,\n    settings,\n    maxRetries,\n    abortSignal,\n    outputStrategy,\n    system,\n    prompt,\n    messages,\n    schemaName,\n    schemaDescription,\n    providerOptions,\n    repairText,\n    onError,\n    onFinish,\n    download,\n    generateId,\n    currentDate,\n    now,\n  });\n}\n\nclass DefaultStreamObjectResult<PARTIAL, RESULT, ELEMENT_STREAM>\n  implements StreamObjectResult<PARTIAL, RESULT, ELEMENT_STREAM>\n{\n  private readonly _object = new DelayedPromise<RESULT>();\n  private readonly _usage = new DelayedPromise<LanguageModelUsage>();\n  private readonly _providerMetadata = new DelayedPromise<\n    ProviderMetadata | undefined\n  >();\n  private readonly _warnings = new DelayedPromise<CallWarning[] | undefined>();\n  private readonly _request =\n    new DelayedPromise<LanguageModelRequestMetadata>();\n  private readonly _response =\n    new DelayedPromise<LanguageModelResponseMetadata>();\n  private readonly _finishReason = new DelayedPromise<FinishReason>();\n\n  private readonly baseStream: ReadableStream<ObjectStreamPart<PARTIAL>>;\n\n  private readonly outputStrategy: OutputStrategy<\n    PARTIAL,\n    RESULT,\n    ELEMENT_STREAM\n  >;\n\n  constructor({\n    model: modelArg,\n    headers,\n    telemetry,\n    settings,\n    maxRetries: maxRetriesArg,\n    abortSignal,\n    outputStrategy,\n    system,\n    prompt,\n    messages,\n    schemaName,\n    schemaDescription,\n    providerOptions,\n    repairText,\n    onError,\n    onFinish,\n    download,\n    generateId,\n    currentDate,\n    now,\n  }: {\n    model: LanguageModel;\n    telemetry: TelemetrySettings | undefined;\n    headers: Record<string, string | undefined> | undefined;\n    settings: Omit<CallSettings, 'abortSignal' | 'headers'>;\n    maxRetries: number | undefined;\n    abortSignal: AbortSignal | undefined;\n    outputStrategy: OutputStrategy<PARTIAL, RESULT, ELEMENT_STREAM>;\n    system: Prompt['system'];\n    prompt: Prompt['prompt'];\n    messages: Prompt['messages'];\n    schemaName: string | undefined;\n    schemaDescription: string | undefined;\n    providerOptions: ProviderOptions | undefined;\n    repairText: RepairTextFunction | undefined;\n    onError: StreamObjectOnErrorCallback;\n    onFinish: StreamObjectOnFinishCallback<RESULT> | undefined;\n    download: DownloadFunction | undefined;\n    generateId: () => string;\n    currentDate: () => Date;\n    now: () => number;\n  }) {\n    const model = resolveLanguageModel(modelArg);\n\n    const { maxRetries, retry } = prepareRetries({\n      maxRetries: maxRetriesArg,\n      abortSignal,\n    });\n\n    const callSettings = prepareCallSettings(settings);\n\n    const baseTelemetryAttributes = getBaseTelemetryAttributes({\n      model,\n      telemetry,\n      headers,\n      settings: { ...callSettings, maxRetries },\n    });\n\n    const tracer = getTracer(telemetry);\n    const self = this;\n\n    const stitchableStream =\n      createStitchableStream<ObjectStreamPart<PARTIAL>>();\n\n    const eventProcessor = new TransformStream<\n      ObjectStreamPart<PARTIAL>,\n      ObjectStreamPart<PARTIAL>\n    >({\n      transform(chunk, controller) {\n        controller.enqueue(chunk);\n\n        if (chunk.type === 'error') {\n          onError({ error: wrapGatewayError(chunk.error) });\n        }\n      },\n    });\n\n    this.baseStream = stitchableStream.stream.pipeThrough(eventProcessor);\n\n    recordSpan({\n      name: 'ai.streamObject',\n      attributes: selectTelemetryAttributes({\n        telemetry,\n        attributes: {\n          ...assembleOperationName({\n            operationId: 'ai.streamObject',\n            telemetry,\n          }),\n          ...baseTelemetryAttributes,\n          // specific settings that only make sense on the outer level:\n          'ai.prompt': {\n            input: () => JSON.stringify({ system, prompt, messages }),\n          },\n          'ai.schema':\n            outputStrategy.jsonSchema != null\n              ? { input: () => JSON.stringify(outputStrategy.jsonSchema) }\n              : undefined,\n          'ai.schema.name': schemaName,\n          'ai.schema.description': schemaDescription,\n          'ai.settings.output': outputStrategy.type,\n        },\n      }),\n      tracer,\n      endWhenDone: false,\n      fn: async rootSpan => {\n        const standardizedPrompt = await standardizePrompt({\n          system,\n          prompt,\n          messages,\n        } as Prompt);\n\n        const callOptions = {\n          responseFormat: {\n            type: 'json' as const,\n            schema: outputStrategy.jsonSchema,\n            name: schemaName,\n            description: schemaDescription,\n          },\n          ...prepareCallSettings(settings),\n          prompt: await convertToLanguageModelPrompt({\n            prompt: standardizedPrompt,\n            supportedUrls: await model.supportedUrls,\n            download,\n          }),\n          providerOptions,\n          abortSignal,\n          headers,\n          includeRawChunks: false,\n        };\n\n        const transformer: Transformer<\n          LanguageModelV2StreamPart,\n          ObjectStreamInputPart\n        > = {\n          transform: (chunk, controller) => {\n            switch (chunk.type) {\n              case 'text-delta':\n                controller.enqueue(chunk.delta);\n                break;\n              case 'response-metadata':\n              case 'finish':\n              case 'error':\n              case 'stream-start':\n                controller.enqueue(chunk);\n                break;\n            }\n          },\n        };\n\n        const {\n          result: { stream, response, request },\n          doStreamSpan,\n          startTimestampMs,\n        } = await retry(() =>\n          recordSpan({\n            name: 'ai.streamObject.doStream',\n            attributes: selectTelemetryAttributes({\n              telemetry,\n              attributes: {\n                ...assembleOperationName({\n                  operationId: 'ai.streamObject.doStream',\n                  telemetry,\n                }),\n                ...baseTelemetryAttributes,\n                'ai.prompt.messages': {\n                  input: () => stringifyForTelemetry(callOptions.prompt),\n                },\n\n                // standardized gen-ai llm span attributes:\n                'gen_ai.system': model.provider,\n                'gen_ai.request.model': model.modelId,\n                'gen_ai.request.frequency_penalty':\n                  callSettings.frequencyPenalty,\n                'gen_ai.request.max_tokens': callSettings.maxOutputTokens,\n                'gen_ai.request.presence_penalty': callSettings.presencePenalty,\n                'gen_ai.request.temperature': callSettings.temperature,\n                'gen_ai.request.top_k': callSettings.topK,\n                'gen_ai.request.top_p': callSettings.topP,\n              },\n            }),\n            tracer,\n            endWhenDone: false,\n            fn: async doStreamSpan => ({\n              startTimestampMs: now(),\n              doStreamSpan,\n              result: await model.doStream(callOptions),\n            }),\n          }),\n        );\n\n        self._request.resolve(request ?? {});\n\n        // store information for onFinish callback:\n        let warnings: LanguageModelV2CallWarning[] | undefined;\n        let usage: LanguageModelUsage = {\n          inputTokens: undefined,\n          outputTokens: undefined,\n          totalTokens: undefined,\n        };\n        let finishReason: LanguageModelV2FinishReason | undefined;\n        let providerMetadata: ProviderMetadata | undefined;\n        let object: RESULT | undefined;\n        let error: unknown | undefined;\n\n        // pipe chunks through a transformation stream that extracts metadata:\n        let accumulatedText = '';\n        let textDelta = '';\n        let fullResponse: {\n          id: string;\n          timestamp: Date;\n          modelId: string;\n        } = {\n          id: generateId(),\n          timestamp: currentDate(),\n          modelId: model.modelId,\n        };\n\n        // Keep track of raw parse result before type validation, since e.g. Zod might\n        // change the object by mapping properties.\n        let latestObjectJson: JSONValue | undefined = undefined;\n        let latestObject: PARTIAL | undefined = undefined;\n        let isFirstChunk = true;\n        let isFirstDelta = true;\n\n        const transformedStream = stream\n          .pipeThrough(new TransformStream(transformer))\n          .pipeThrough(\n            new TransformStream<\n              string | ObjectStreamInputPart,\n              ObjectStreamPart<PARTIAL>\n            >({\n              async transform(chunk, controller): Promise<void> {\n                if (\n                  typeof chunk === 'object' &&\n                  chunk.type === 'stream-start'\n                ) {\n                  warnings = chunk.warnings;\n                  return; // stream start chunks are sent immediately and do not count as first chunk\n                }\n\n                // Telemetry event for first chunk:\n                if (isFirstChunk) {\n                  const msToFirstChunk = now() - startTimestampMs;\n\n                  isFirstChunk = false;\n\n                  doStreamSpan.addEvent('ai.stream.firstChunk', {\n                    'ai.stream.msToFirstChunk': msToFirstChunk,\n                  });\n\n                  doStreamSpan.setAttributes({\n                    'ai.stream.msToFirstChunk': msToFirstChunk,\n                  });\n                }\n\n                // process partial text chunks\n                if (typeof chunk === 'string') {\n                  accumulatedText += chunk;\n                  textDelta += chunk;\n\n                  const { value: currentObjectJson, state: parseState } =\n                    await parsePartialJson(accumulatedText);\n\n                  if (\n                    currentObjectJson !== undefined &&\n                    !isDeepEqualData(latestObjectJson, currentObjectJson)\n                  ) {\n                    const validationResult =\n                      await outputStrategy.validatePartialResult({\n                        value: currentObjectJson,\n                        textDelta,\n                        latestObject,\n                        isFirstDelta,\n                        isFinalDelta: parseState === 'successful-parse',\n                      });\n\n                    if (\n                      validationResult.success &&\n                      !isDeepEqualData(\n                        latestObject,\n                        validationResult.value.partial,\n                      )\n                    ) {\n                      // inside inner check to correctly parse the final element in array mode:\n                      latestObjectJson = currentObjectJson;\n                      latestObject = validationResult.value.partial;\n\n                      controller.enqueue({\n                        type: 'object',\n                        object: latestObject,\n                      });\n\n                      controller.enqueue({\n                        type: 'text-delta',\n                        textDelta: validationResult.value.textDelta,\n                      });\n\n                      textDelta = '';\n                      isFirstDelta = false;\n                    }\n                  }\n\n                  return;\n                }\n\n                switch (chunk.type) {\n                  case 'response-metadata': {\n                    fullResponse = {\n                      id: chunk.id ?? fullResponse.id,\n                      timestamp: chunk.timestamp ?? fullResponse.timestamp,\n                      modelId: chunk.modelId ?? fullResponse.modelId,\n                    };\n                    break;\n                  }\n\n                  case 'finish': {\n                    // send final text delta:\n                    if (textDelta !== '') {\n                      controller.enqueue({ type: 'text-delta', textDelta });\n                    }\n\n                    // store finish reason for telemetry:\n                    finishReason = chunk.finishReason;\n\n                    // store usage and metadata for promises and onFinish callback:\n                    usage = chunk.usage;\n                    providerMetadata = chunk.providerMetadata;\n\n                    controller.enqueue({\n                      ...chunk,\n                      usage,\n                      response: fullResponse,\n                    });\n\n                    // log warnings:\n                    logWarnings(warnings ?? []);\n\n                    // resolve promises that can be resolved now:\n                    self._usage.resolve(usage);\n                    self._providerMetadata.resolve(providerMetadata);\n                    self._warnings.resolve(warnings);\n                    self._response.resolve({\n                      ...fullResponse,\n                      headers: response?.headers,\n                    });\n                    self._finishReason.resolve(finishReason ?? 'unknown');\n\n                    try {\n                      object = await parseAndValidateObjectResultWithRepair(\n                        accumulatedText,\n                        outputStrategy,\n                        repairText,\n                        {\n                          response: fullResponse,\n                          usage,\n                          finishReason,\n                        },\n                      );\n                      self._object.resolve(object);\n                    } catch (e) {\n                      error = e;\n                      self._object.reject(e);\n                    }\n                    break;\n                  }\n\n                  default: {\n                    controller.enqueue(chunk);\n                    break;\n                  }\n                }\n              },\n\n              // invoke onFinish callback and resolve toolResults promise when the stream is about to close:\n              async flush(controller) {\n                try {\n                  const finalUsage = usage ?? {\n                    promptTokens: NaN,\n                    completionTokens: NaN,\n                    totalTokens: NaN,\n                  };\n\n                  doStreamSpan.setAttributes(\n                    selectTelemetryAttributes({\n                      telemetry,\n                      attributes: {\n                        'ai.response.finishReason': finishReason,\n                        'ai.response.object': {\n                          output: () => JSON.stringify(object),\n                        },\n                        'ai.response.id': fullResponse.id,\n                        'ai.response.model': fullResponse.modelId,\n                        'ai.response.timestamp':\n                          fullResponse.timestamp.toISOString(),\n                        'ai.response.providerMetadata':\n                          JSON.stringify(providerMetadata),\n\n                        'ai.usage.inputTokens': finalUsage.inputTokens,\n                        'ai.usage.outputTokens': finalUsage.outputTokens,\n                        'ai.usage.totalTokens': finalUsage.totalTokens,\n                        'ai.usage.reasoningTokens': finalUsage.reasoningTokens,\n                        'ai.usage.cachedInputTokens':\n                          finalUsage.cachedInputTokens,\n\n                        // standardized gen-ai llm span attributes:\n                        'gen_ai.response.finish_reasons': [finishReason],\n                        'gen_ai.response.id': fullResponse.id,\n                        'gen_ai.response.model': fullResponse.modelId,\n                        'gen_ai.usage.input_tokens': finalUsage.inputTokens,\n                        'gen_ai.usage.output_tokens': finalUsage.outputTokens,\n                      },\n                    }),\n                  );\n\n                  // finish doStreamSpan before other operations for correct timing:\n                  doStreamSpan.end();\n\n                  // Add response information to the root span:\n                  rootSpan.setAttributes(\n                    selectTelemetryAttributes({\n                      telemetry,\n                      attributes: {\n                        'ai.usage.inputTokens': finalUsage.inputTokens,\n                        'ai.usage.outputTokens': finalUsage.outputTokens,\n                        'ai.usage.totalTokens': finalUsage.totalTokens,\n                        'ai.usage.reasoningTokens': finalUsage.reasoningTokens,\n                        'ai.usage.cachedInputTokens':\n                          finalUsage.cachedInputTokens,\n                        'ai.response.object': {\n                          output: () => JSON.stringify(object),\n                        },\n                        'ai.response.providerMetadata':\n                          JSON.stringify(providerMetadata),\n                      },\n                    }),\n                  );\n\n                  // call onFinish callback:\n                  await onFinish?.({\n                    usage: finalUsage,\n                    object,\n                    error,\n                    response: {\n                      ...fullResponse,\n                      headers: response?.headers,\n                    },\n                    warnings,\n                    providerMetadata,\n                  });\n                } catch (error) {\n                  controller.enqueue({ type: 'error', error });\n                } finally {\n                  rootSpan.end();\n                }\n              },\n            }),\n          );\n\n        stitchableStream.addStream(transformedStream);\n      },\n    })\n      .catch(error => {\n        // add an empty stream with an error to break the stream:\n        stitchableStream.addStream(\n          new ReadableStream({\n            start(controller) {\n              controller.enqueue({ type: 'error', error });\n              controller.close();\n            },\n          }),\n        );\n      })\n      .finally(() => {\n        stitchableStream.close();\n      });\n\n    this.outputStrategy = outputStrategy;\n  }\n\n  get object() {\n    return this._object.promise;\n  }\n\n  get usage() {\n    return this._usage.promise;\n  }\n\n  get providerMetadata() {\n    return this._providerMetadata.promise;\n  }\n\n  get warnings() {\n    return this._warnings.promise;\n  }\n\n  get request() {\n    return this._request.promise;\n  }\n\n  get response() {\n    return this._response.promise;\n  }\n\n  get finishReason() {\n    return this._finishReason.promise;\n  }\n\n  get partialObjectStream(): AsyncIterableStream<PARTIAL> {\n    return createAsyncIterableStream(\n      this.baseStream.pipeThrough(\n        new TransformStream<ObjectStreamPart<PARTIAL>, PARTIAL>({\n          transform(chunk, controller) {\n            switch (chunk.type) {\n              case 'object':\n                controller.enqueue(chunk.object);\n                break;\n\n              case 'text-delta':\n              case 'finish':\n              case 'error': // suppress error (use onError instead)\n                break;\n\n              default: {\n                const _exhaustiveCheck: never = chunk;\n                throw new Error(`Unsupported chunk type: ${_exhaustiveCheck}`);\n              }\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get elementStream(): ELEMENT_STREAM {\n    return this.outputStrategy.createElementStream(this.baseStream);\n  }\n\n  get textStream(): AsyncIterableStream<string> {\n    return createAsyncIterableStream(\n      this.baseStream.pipeThrough(\n        new TransformStream<ObjectStreamPart<PARTIAL>, string>({\n          transform(chunk, controller) {\n            switch (chunk.type) {\n              case 'text-delta':\n                controller.enqueue(chunk.textDelta);\n                break;\n\n              case 'object':\n              case 'finish':\n              case 'error': // suppress error (use onError instead)\n                break;\n\n              default: {\n                const _exhaustiveCheck: never = chunk;\n                throw new Error(`Unsupported chunk type: ${_exhaustiveCheck}`);\n              }\n            }\n          },\n        }),\n      ),\n    );\n  }\n\n  get fullStream(): AsyncIterableStream<ObjectStreamPart<PARTIAL>> {\n    return createAsyncIterableStream(this.baseStream);\n  }\n\n  pipeTextStreamToResponse(response: ServerResponse, init?: ResponseInit) {\n    pipeTextStreamToResponse({\n      response,\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n\n  toTextStreamResponse(init?: ResponseInit): Response {\n    return createTextStreamResponse({\n      textStream: this.textStream,\n      ...init,\n    });\n  }\n}\n\nexport type ObjectStreamInputPart =\n  | string\n  | {\n      type: 'stream-start';\n      warnings: LanguageModelV2CallWarning[];\n    }\n  | {\n      type: 'error';\n      error: unknown;\n    }\n  | {\n      type: 'response-metadata';\n      id?: string;\n      timestamp?: Date;\n      modelId?: string;\n    }\n  | {\n      type: 'finish';\n      finishReason: LanguageModelV2FinishReason;\n      usage: LanguageModelV2Usage;\n      providerMetadata?: SharedV2ProviderMetadata;\n    };\n", "import { InvalidArgumentError } from '../error/invalid-argument-error';\n\n/**\n * Calculates the cosine similarity between two vectors. This is a useful metric for\n * comparing the similarity of two vectors such as embeddings.\n *\n * @param vector1 - The first vector.\n * @param vector2 - The second vector.\n *\n * @returns The cosine similarity between vector1 and vector2.\n * @returns 0 if either vector is the zero vector.\n *\n * @throws {InvalidArgumentError} If the vectors do not have the same length.\n */\nexport function cosineSimilarity(vector1: number[], vector2: number[]): number {\n  if (vector1.length !== vector2.length) {\n    throw new InvalidArgumentError({\n      parameter: 'vector1,vector2',\n      value: { vector1Length: vector1.length, vector2Length: vector2.length },\n      message: `Vectors must have the same length`,\n    });\n  }\n\n  const n = vector1.length;\n\n  if (n === 0) {\n    return 0; // Return 0 for empty vectors if no error is thrown\n  }\n\n  let magnitudeSquared1 = 0;\n  let magnitudeSquared2 = 0;\n  let dotProduct = 0;\n\n  for (let i = 0; i < n; i++) {\n    const value1 = vector1[i];\n    const value2 = vector2[i];\n\n    magnitudeSquared1 += value1 * value1;\n    magnitudeSquared2 += value2 * value2;\n    dotProduct += value1 * value2;\n  }\n\n  return magnitudeSquared1 === 0 || magnitudeSquared2 === 0\n    ? 0\n    : dotProduct /\n        (Math.sqrt(magnitudeSquared1) * Math.sqrt(magnitudeSquared2));\n}\n", "/**\n * Converts a data URL of type text/* to a text string.\n */\nexport function getTextFromDataUrl(dataUrl: string): string {\n  const [header, base64Content] = dataUrl.split(',');\n  const mediaType = header.split(';')[0].split(':')[1];\n\n  if (mediaType == null || base64Content == null) {\n    throw new Error('Invalid data URL format');\n  }\n\n  try {\n    return window.atob(base64Content);\n  } catch (error) {\n    throw new Error(`Error decoding data URL`);\n  }\n}\n", "/**\n * Performs a deep-equal comparison of two parsed JSON objects.\n *\n * @param {any} obj1 - The first object to compare.\n * @param {any} obj2 - The second object to compare.\n * @returns {boolean} - Returns true if the two objects are deeply equal, false otherwise.\n */\nexport function isDeepEqualData(obj1: any, obj2: any): boolean {\n  // Check for strict equality first\n  if (obj1 === obj2) return true;\n\n  // Check if either is null or undefined\n  if (obj1 == null || obj2 == null) return false;\n\n  // Check if both are objects\n  if (typeof obj1 !== 'object' && typeof obj2 !== 'object')\n    return obj1 === obj2;\n\n  // If they are not strictly equal, they both need to be Objects\n  if (obj1.constructor !== obj2.constructor) return false;\n\n  // Special handling for Date objects\n  if (obj1 instanceof Date && obj2 instanceof Date) {\n    return obj1.getTime() === obj2.getTime();\n  }\n\n  // Handle arrays: compare length and then perform a recursive deep comparison on each item\n  if (Array.isArray(obj1)) {\n    if (obj1.length !== obj2.length) return false;\n    for (let i = 0; i < obj1.length; i++) {\n      if (!isDeepEqualData(obj1[i], obj2[i])) return false;\n    }\n    return true; // All array elements matched\n  }\n\n  // Compare the set of keys in each object\n  const keys1 = Object.keys(obj1);\n  const keys2 = Object.keys(obj2);\n  if (keys1.length !== keys2.length) return false;\n\n  // Check each key-value pair recursively\n  for (const key of keys1) {\n    if (!keys2.includes(key)) return false;\n    if (!isDeepEqualData(obj1[key], obj2[key])) return false;\n  }\n\n  return true; // All keys and values matched\n}\n", "import { Job } from './job';\n\nexport class SerialJobExecutor {\n  private queue: Array<Job> = [];\n  private isProcessing = false;\n\n  private async processQueue() {\n    if (this.isProcessing) {\n      return;\n    }\n\n    this.isProcessing = true;\n\n    while (this.queue.length > 0) {\n      await this.queue[0]();\n      this.queue.shift();\n    }\n\n    this.isProcessing = false;\n  }\n\n  async run(job: Job): Promise<void> {\n    return new Promise<void>((resolve, reject) => {\n      this.queue.push(async () => {\n        try {\n          await job();\n          resolve();\n        } catch (error) {\n          reject(error);\n        }\n      });\n\n      void this.processQueue();\n    });\n  }\n}\n", "import { delay as delayFunction } from '@ai-sdk/provider-utils';\n\n/**\n * Creates a ReadableStream that emits the provided values with an optional delay between each value.\n *\n * @param options - The configuration options\n * @param options.chunks - Array of values to be emitted by the stream\n * @param options.initialDelayInMs - Optional initial delay in milliseconds before emitting the first value (default: 0). Can be set to `null` to skip the initial delay. The difference between `initialDelayInMs: null` and `initialDelayInMs: 0` is that `initialDelayInMs: null` will emit the values without any delay, while `initialDelayInMs: 0` will emit the values with a delay of 0 milliseconds.\n * @param options.chunkDelayInMs - Optional delay in milliseconds between emitting each value (default: 0). Can be set to `null` to skip the delay. The difference between `chunkDelayInMs: null` and `chunkDelayInMs: 0` is that `chunkDelayInMs: null` will emit the values without any delay, while `chunkDelayInMs: 0` will emit the values with a delay of 0 milliseconds.\n * @returns A ReadableStream that emits the provided values\n */\nexport function simulateReadableStream<T>({\n  chunks,\n  initialDelayInMs = 0,\n  chunkDelayInMs = 0,\n  _internal,\n}: {\n  chunks: T[];\n  initialDelayInMs?: number | null;\n  chunkDelayInMs?: number | null;\n  _internal?: {\n    delay?: (ms: number | null) => Promise<void>;\n  };\n}): ReadableStream<T> {\n  const delay = _internal?.delay ?? delayFunction;\n\n  let index = 0;\n\n  return new ReadableStream({\n    async pull(controller) {\n      if (index < chunks.length) {\n        await delay(index === 0 ? initialDelayInMs : chunkDelayInMs);\n        controller.enqueue(chunks[index++]);\n      } else {\n        controller.close();\n      }\n    },\n  });\n}\n", "import { JSONValue, SpeechModelV2 } from '@ai-sdk/provider';\nimport { ProviderOptions, withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { NoSpeechGeneratedError } from '../error/no-speech-generated-error';\nimport { UnsupportedModelVersionError } from '../error/unsupported-model-version-error';\nimport { logWarnings } from '../logger/log-warnings';\nimport { SpeechWarning } from '../types/speech-model';\nimport { SpeechModelResponseMetadata } from '../types/speech-model-response-metadata';\nimport {\n  audioMediaTypeSignatures,\n  detectMediaType,\n} from '../util/detect-media-type';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { SpeechResult } from './generate-speech-result';\nimport {\n  DefaultGeneratedAudioFile,\n  GeneratedAudioFile,\n} from './generated-audio-file';\nimport { VERSION } from '../version';\n/**\nGenerates speech audio using a speech model.\n\n@param model - The speech model to use.\n@param text - The text to convert to speech.\n@param voice - The voice to use for speech generation.\n@param outputFormat - The output format to use for speech generation e.g. \"mp3\", \"wav\", etc.\n@param instructions - Instructions for the speech generation e.g. \"Speak in a slow and steady tone\".\n@param speed - The speed of the speech generation.\n@param providerOptions - Additional provider-specific options that are passed through to the provider\nas body parameters.\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the generated audio data.\n */\nexport async function generateSpeech({\n  model,\n  text,\n  voice,\n  outputFormat,\n  instructions,\n  speed,\n  language,\n  providerOptions = {},\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n}: {\n  /**\nThe speech model to use.\n     */\n  model: SpeechModelV2;\n\n  /**\nThe text to convert to speech.\n   */\n  text: string;\n\n  /**\nThe voice to use for speech generation.\n   */\n  voice?: string;\n\n  /**\n   * The desired output format for the audio e.g. \"mp3\", \"wav\", etc.\n   */\n  outputFormat?: 'mp3' | 'wav' | (string & {});\n\n  /**\n    Instructions for the speech generation e.g. \"Speak in a slow and steady tone\".\n  */\n  instructions?: string;\n\n  /**\n  The speed of the speech generation.\n   */\n  speed?: number;\n\n  /**\n  The language for speech generation. This should be an ISO 639-1 language code (e.g. \"en\", \"es\", \"fr\")\n  or \"auto\" for automatic language detection. Provider support varies.\n   */\n  language?: string;\n\n  /**\nAdditional provider-specific options that are passed through to the provider\nas body parameters.\n\nThe outer record is keyed by the provider name, and the inner\nrecord is keyed by the provider-specific metadata key.\n```ts\n{\n  \"openai\": {}\n}\n```\n     */\n  providerOptions?: ProviderOptions;\n\n  /**\nMaximum number of retries per speech model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n}): Promise<SpeechResult> {\n  if (model.specificationVersion !== 'v2') {\n    throw new UnsupportedModelVersionError({\n      version: model.specificationVersion,\n      provider: model.provider,\n      modelId: model.modelId,\n    });\n  }\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const { retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const result = await retry(() =>\n    model.doGenerate({\n      text,\n      voice,\n      outputFormat,\n      instructions,\n      speed,\n      language,\n      abortSignal,\n      headers: headersWithUserAgent,\n      providerOptions,\n    }),\n  );\n\n  if (!result.audio || result.audio.length === 0) {\n    throw new NoSpeechGeneratedError({ responses: [result.response] });\n  }\n\n  logWarnings(result.warnings);\n\n  return new DefaultSpeechResult({\n    audio: new DefaultGeneratedAudioFile({\n      data: result.audio,\n      mediaType:\n        detectMediaType({\n          data: result.audio,\n          signatures: audioMediaTypeSignatures,\n        }) ?? 'audio/mp3',\n    }),\n    warnings: result.warnings,\n    responses: [result.response],\n    providerMetadata: result.providerMetadata,\n  });\n}\n\nclass DefaultSpeechResult implements SpeechResult {\n  readonly audio: GeneratedAudioFile;\n  readonly warnings: Array<SpeechWarning>;\n  readonly responses: Array<SpeechModelResponseMetadata>;\n  readonly providerMetadata: Record<string, Record<string, JSONValue>>;\n\n  constructor(options: {\n    audio: GeneratedAudioFile;\n    warnings: Array<SpeechWarning>;\n    responses: Array<SpeechModelResponseMetadata>;\n    providerMetadata: Record<string, Record<string, JSONValue>> | undefined;\n  }) {\n    this.audio = options.audio;\n    this.warnings = options.warnings;\n    this.responses = options.responses;\n    this.providerMetadata = options.providerMetadata ?? {};\n  }\n}\n", "import {\n  GeneratedFile,\n  DefaultGeneratedFile,\n} from '../generate-text/generated-file';\n\n/**\n * A generated audio file.\n */\nexport interface GeneratedAudioFile extends GeneratedFile {\n  /**\n   * Audio format of the file (e.g., 'mp3', 'wav', etc.)\n   */\n  readonly format: string;\n}\n\nexport class DefaultGeneratedAudioFile\n  extends DefaultGeneratedFile\n  implements GeneratedAudioFile\n{\n  readonly format: string;\n\n  constructor({\n    data,\n    mediaType,\n  }: {\n    data: string | Uint8Array;\n    mediaType: string;\n  }) {\n    super({ data, mediaType });\n    let format = 'mp3';\n\n    // If format is not provided, try to determine it from the media type\n    if (mediaType) {\n      const mediaTypeParts = mediaType.split('/');\n\n      if (mediaTypeParts.length === 2) {\n        // Handle special cases for audio formats\n        if (mediaType !== 'audio/mpeg') {\n          format = mediaTypeParts[1];\n        }\n      }\n    }\n\n    if (!format) {\n      // TODO this should be an AI SDK error\n      throw new Error(\n        'Audio format must be provided or determinable from media type',\n      );\n    }\n\n    this.format = format;\n  }\n}\n\nexport class DefaultGeneratedAudioFileWithType extends DefaultGeneratedAudioFile {\n  readonly type = 'audio';\n\n  constructor(options: {\n    data: string | Uint8Array;\n    mediaType: string;\n    format: string;\n  }) {\n    super(options);\n  }\n}\n", "import { LanguageModelV2CallOptions } from '@ai-sdk/provider';\nimport {\n  asSchema,\n  FlexibleSchema,\n  safeParseJSON,\n  safeValidateTypes,\n} from '@ai-sdk/provider-utils';\nimport { NoObjectGeneratedError } from '../error/no-object-generated-error';\nimport { FinishReason } from '../types/language-model';\nimport { LanguageModelResponseMetadata } from '../types/language-model-response-metadata';\nimport { LanguageModelUsage } from '../types/usage';\nimport { DeepPartial } from '../util/deep-partial';\nimport { parsePartialJson } from '../util/parse-partial-json';\n\nexport interface Output<OUTPUT, PARTIAL> {\n  readonly type: 'object' | 'text';\n\n  responseFormat: LanguageModelV2CallOptions['responseFormat'];\n\n  parsePartial(options: {\n    text: string;\n  }): Promise<{ partial: PARTIAL } | undefined>;\n\n  parseOutput(\n    options: { text: string },\n    context: {\n      response: LanguageModelResponseMetadata;\n      usage: LanguageModelUsage;\n      finishReason: FinishReason;\n    },\n  ): Promise<OUTPUT>;\n}\n\nexport const text = (): Output<string, string> => ({\n  type: 'text',\n\n  responseFormat: { type: 'text' },\n\n  async parsePartial({ text }: { text: string }) {\n    return { partial: text };\n  },\n\n  async parseOutput({ text }: { text: string }) {\n    return text;\n  },\n});\n\nexport const object = <OUTPUT>({\n  schema: inputSchema,\n}: {\n  schema: FlexibleSchema<OUTPUT>;\n}): Output<OUTPUT, DeepPartial<OUTPUT>> => {\n  const schema = asSchema(inputSchema);\n\n  return {\n    type: 'object',\n\n    responseFormat: {\n      type: 'json',\n      schema: schema.jsonSchema,\n    },\n\n    async parsePartial({ text }: { text: string }) {\n      const result = await parsePartialJson(text);\n\n      switch (result.state) {\n        case 'failed-parse':\n        case 'undefined-input':\n          return undefined;\n\n        case 'repaired-parse':\n        case 'successful-parse':\n          return {\n            // Note: currently no validation of partial results:\n            partial: result.value as DeepPartial<OUTPUT>,\n          };\n\n        default: {\n          const _exhaustiveCheck: never = result.state;\n          throw new Error(`Unsupported parse state: ${_exhaustiveCheck}`);\n        }\n      }\n    },\n\n    async parseOutput(\n      { text }: { text: string },\n      context: {\n        response: LanguageModelResponseMetadata;\n        usage: LanguageModelUsage;\n        finishReason: FinishReason;\n      },\n    ) {\n      const parseResult = await safeParseJSON({ text });\n\n      if (!parseResult.success) {\n        throw new NoObjectGeneratedError({\n          message: 'No object generated: could not parse the response.',\n          cause: parseResult.error,\n          text,\n          response: context.response,\n          usage: context.usage,\n          finishReason: context.finishReason,\n        });\n      }\n\n      const validationResult = await safeValidateTypes({\n        value: parseResult.value,\n        schema,\n      });\n\n      if (!validationResult.success) {\n        throw new NoObjectGeneratedError({\n          message: 'No object generated: response did not match schema.',\n          cause: validationResult.error,\n          text,\n          response: context.response,\n          usage: context.usage,\n          finishReason: context.finishReason,\n        });\n      }\n\n      return validationResult.value;\n    },\n  };\n};\n", "import {\n  AssistantModelMessage,\n  ModelMessage,\n  ToolModelMessage,\n} from '@ai-sdk/provider-utils';\n\n/**\n * Prunes model messages from a list of model messages.\n *\n * @param messages - The list of model messages to prune.\n * @param reasoning - How to remove reasoning content from assistant messages. Default is `'none'`.\n * @param toolCalls - How to prune tool call/results/approval content. Default is `[]`.\n * @param emptyMessages - Whether to keep or remove messages whose content is empty after pruning. Default is `'remove'`.\n *\n * @returns The pruned list of model messages.\n */\nexport function pruneMessages({\n  messages,\n  reasoning = 'none',\n  toolCalls = [],\n  emptyMessages = 'remove',\n}: {\n  messages: ModelMessage[];\n  reasoning?: 'all' | 'before-last-message' | 'none';\n  toolCalls?:\n    | 'all'\n    | 'before-last-message'\n    | `before-last-${number}-messages`\n    | 'none'\n    | Array<{\n        type: 'all' | 'before-last-message' | `before-last-${number}-messages`;\n        tools?: string[];\n      }>;\n  emptyMessages?: 'keep' | 'remove';\n}): ModelMessage[] {\n  // filter reasoning parts:\n  if (reasoning === 'all' || reasoning === 'before-last-message') {\n    messages = messages.map((message, messageIndex) => {\n      if (\n        message.role !== 'assistant' ||\n        typeof message.content === 'string' ||\n        (reasoning === 'before-last-message' &&\n          messageIndex === messages.length - 1)\n      ) {\n        return message;\n      }\n\n      return {\n        ...message,\n        content: message.content.filter(part => part.type !== 'reasoning'),\n      };\n    });\n  }\n\n  // filter tool calls, results, errors, and approvals:\n  if (toolCalls === 'none') {\n    toolCalls = [];\n  } else if (toolCalls === 'all') {\n    toolCalls = [{ type: 'all' }];\n  } else if (toolCalls === 'before-last-message') {\n    toolCalls = [{ type: 'before-last-message' }];\n  } else if (typeof toolCalls === 'string') {\n    toolCalls = [{ type: toolCalls }];\n  }\n\n  for (const toolCall of toolCalls) {\n    // determine how many trailing messages to keep:\n    const keepLastMessagesCount =\n      toolCall.type === 'all'\n        ? undefined\n        : toolCall.type === 'before-last-message'\n          ? 1\n          : Number(\n              toolCall.type\n                .slice('before-last-'.length)\n                .slice(0, -'-messages'.length),\n            );\n\n    // scan kept messages to identify tool calls and approvals that need to be kept:\n    const keptToolCallIds: Set<string> = new Set();\n    const keptApprovalIds: Set<string> = new Set();\n\n    if (keepLastMessagesCount != null) {\n      for (const message of messages.slice(0, -keepLastMessagesCount)) {\n        if (\n          (message.role === 'assistant' || message.role === 'tool') &&\n          typeof message.content !== 'string'\n        ) {\n          for (const part of message.content) {\n            if (part.type === 'tool-call' || part.type === 'tool-result') {\n              keptToolCallIds.add(part.toolCallId);\n            }\n          }\n        }\n      }\n    }\n\n    messages = messages.map((message, messageIndex) => {\n      if (\n        (message.role !== 'assistant' && message.role !== 'tool') ||\n        typeof message.content === 'string' ||\n        (keepLastMessagesCount &&\n          messageIndex >= messages.length - keepLastMessagesCount)\n      ) {\n        return message;\n      }\n\n      const toolCallIdToToolName: Record<string, string> = {};\n\n      return {\n        ...message,\n        content: message.content.filter(part => {\n          // keep non-tool parts:\n          if (part.type !== 'tool-call' && part.type !== 'tool-result') {\n            return true;\n          }\n\n          // track tool calls and approvals:\n          if (part.type === 'tool-call') {\n            toolCallIdToToolName[part.toolCallId] = part.toolName;\n          }\n\n          // keep parts that are associated with a tool call or approval that needs to be kept:\n          if (\n            (part.type === 'tool-call' || part.type === 'tool-result') &&\n            keptToolCallIds.has(part.toolCallId)\n          ) {\n            return true;\n          }\n\n          // keep parts that are not associated with a tool that should be removed:\n          return (\n            toolCall.tools != null && !toolCall.tools.includes(part.toolName)\n          );\n        }),\n      } as AssistantModelMessage | ToolModelMessage;\n    });\n  }\n\n  if (emptyMessages === 'remove') {\n    messages = messages.filter(message => message.content.length > 0);\n  }\n\n  return messages;\n}\n", "import { delay as originalDelay } from '@ai-sdk/provider-utils';\nimport { TextStreamPart } from './stream-text-result';\nimport { ToolSet } from './tool-set';\nimport { InvalidArgumentError } from '@ai-sdk/provider';\n\nconst CHUNKING_REGEXPS = {\n  word: /\\S+\\s+/m,\n  line: /\\n+/m,\n};\n\n/**\n * Detects the first chunk in a buffer.\n *\n * @param buffer - The buffer to detect the first chunk in.\n *\n * @returns The first detected chunk, or `undefined` if no chunk was detected.\n */\nexport type ChunkDetector = (buffer: string) => string | undefined | null;\n\n/**\n * Smooths text streaming output.\n *\n * @param delayInMs - The delay in milliseconds between each chunk. Defaults to 10ms. Can be set to `null` to skip the delay.\n * @param chunking - Controls how the text is chunked for streaming. Use \"word\" to stream word by word (default), \"line\" to stream line by line, or provide a custom RegExp pattern for custom chunking.\n *\n * @returns A transform stream that smooths text streaming output.\n */\nexport function smoothStream<TOOLS extends ToolSet>({\n  delayInMs = 10,\n  chunking = 'word',\n  _internal: { delay = originalDelay } = {},\n}: {\n  delayInMs?: number | null;\n  chunking?: 'word' | 'line' | RegExp | ChunkDetector;\n  /**\n   * Internal. For test use only. May change without notice.\n   */\n  _internal?: {\n    delay?: (delayInMs: number | null) => Promise<void>;\n  };\n} = {}): (options: {\n  tools: TOOLS;\n}) => TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>> {\n  let detectChunk: ChunkDetector;\n\n  if (typeof chunking === 'function') {\n    detectChunk = buffer => {\n      const match = chunking(buffer);\n\n      if (match == null) {\n        return null;\n      }\n\n      if (!match.length) {\n        throw new Error(`Chunking function must return a non-empty string.`);\n      }\n\n      if (!buffer.startsWith(match)) {\n        throw new Error(\n          `Chunking function must return a match that is a prefix of the buffer. Received: \"${match}\" expected to start with \"${buffer}\"`,\n        );\n      }\n\n      return match;\n    };\n  } else {\n    const chunkingRegex =\n      typeof chunking === 'string' ? CHUNKING_REGEXPS[chunking] : chunking;\n\n    if (chunkingRegex == null) {\n      throw new InvalidArgumentError({\n        argument: 'chunking',\n        message: `Chunking must be \"word\" or \"line\" or a RegExp. Received: ${chunking}`,\n      });\n    }\n\n    detectChunk = buffer => {\n      const match = chunkingRegex.exec(buffer);\n\n      if (!match) {\n        return null;\n      }\n\n      return buffer.slice(0, match.index) + match?.[0];\n    };\n  }\n\n  return () => {\n    let buffer = '';\n    let id = '';\n\n    return new TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>({\n      async transform(chunk, controller) {\n        if (chunk.type !== 'text-delta') {\n          if (buffer.length > 0) {\n            controller.enqueue({ type: 'text-delta', text: buffer, id });\n            buffer = '';\n          }\n\n          controller.enqueue(chunk);\n          return;\n        }\n\n        if (chunk.id !== id && buffer.length > 0) {\n          controller.enqueue({ type: 'text-delta', text: buffer, id });\n          buffer = '';\n        }\n\n        buffer += chunk.text;\n        id = chunk.id;\n\n        let match;\n\n        while ((match = detectChunk(buffer)) != null) {\n          controller.enqueue({ type: 'text-delta', text: match, id });\n          buffer = buffer.slice(match.length);\n\n          await delay(delayInMs);\n        }\n      },\n    });\n  };\n}\n", "import { LanguageModelV2CallOptions } from '@ai-sdk/provider';\nimport { LanguageModelMiddleware } from '../types';\nimport { mergeObjects } from '../util/merge-objects';\n\n/**\n * Applies default settings for a language model.\n */\nexport function defaultSettingsMiddleware({\n  settings,\n}: {\n  settings: Partial<{\n    maxOutputTokens?: LanguageModelV2CallOptions['maxOutputTokens'];\n    temperature?: LanguageModelV2CallOptions['temperature'];\n    stopSequences?: LanguageModelV2CallOptions['stopSequences'];\n    topP?: LanguageModelV2CallOptions['topP'];\n    topK?: LanguageModelV2CallOptions['topK'];\n    presencePenalty?: LanguageModelV2CallOptions['presencePenalty'];\n    frequencyPenalty?: LanguageModelV2CallOptions['frequencyPenalty'];\n    responseFormat?: LanguageModelV2CallOptions['responseFormat'];\n    seed?: LanguageModelV2CallOptions['seed'];\n    tools?: LanguageModelV2CallOptions['tools'];\n    toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n    headers?: LanguageModelV2CallOptions['headers'];\n    providerOptions?: LanguageModelV2CallOptions['providerOptions'];\n  }>;\n}): LanguageModelMiddleware {\n  return {\n    middlewareVersion: 'v2',\n    transformParams: async ({ params }) => {\n      return mergeObjects(settings, params) as LanguageModelV2CallOptions;\n    },\n  };\n}\n", "/**\n * Returns the index of the start of the searchedText in the text, or null if it\n * is not found.\n */\nexport function getPotentialStartIndex(\n  text: string,\n  searchedText: string,\n): number | null {\n  // Return null immediately if searchedText is empty.\n  if (searchedText.length === 0) {\n    return null;\n  }\n\n  // Check if the searchedText exists as a direct substring of text.\n  const directIndex = text.indexOf(searchedText);\n  if (directIndex !== -1) {\n    return directIndex;\n  }\n\n  // Otherwise, look for the largest suffix of \"text\" that matches\n  // a prefix of \"searchedText\". We go from the end of text inward.\n  for (let i = text.length - 1; i >= 0; i--) {\n    const suffix = text.substring(i);\n    if (searchedText.startsWith(suffix)) {\n      return i;\n    }\n  }\n\n  return null;\n}\n", "import type {\n  LanguageModelV2Content,\n  LanguageModelV2StreamPart,\n} from '@ai-sdk/provider';\nimport { LanguageModelMiddleware } from '../types/language-model-middleware';\nimport { getPotentialStartIndex } from '../util/get-potential-start-index';\n\n/**\n * Extract an XML-tagged reasoning section from the generated text and exposes it\n * as a `reasoning` property on the result.\n *\n * @param tagName - The name of the XML tag to extract reasoning from.\n * @param separator - The separator to use between reasoning and text sections.\n * @param startWithReasoning - Whether to start with reasoning tokens.\n */\nexport function extractReasoningMiddleware({\n  tagName,\n  separator = '\\n',\n  startWithReasoning = false,\n}: {\n  tagName: string;\n  separator?: string;\n  startWithReasoning?: boolean;\n}): LanguageModelMiddleware {\n  const openingTag = `<${tagName}>`;\n  const closingTag = `<\\/${tagName}>`;\n\n  return {\n    middlewareVersion: 'v2',\n    wrapGenerate: async ({ doGenerate }) => {\n      const { content, ...rest } = await doGenerate();\n\n      const transformedContent: LanguageModelV2Content[] = [];\n      for (const part of content) {\n        if (part.type !== 'text') {\n          transformedContent.push(part);\n          continue;\n        }\n\n        const text = startWithReasoning ? openingTag + part.text : part.text;\n\n        const regexp = new RegExp(`${openingTag}(.*?)${closingTag}`, 'gs');\n        const matches = Array.from(text.matchAll(regexp));\n\n        if (!matches.length) {\n          transformedContent.push(part);\n          continue;\n        }\n\n        const reasoningText = matches.map(match => match[1]).join(separator);\n\n        let textWithoutReasoning = text;\n        for (let i = matches.length - 1; i >= 0; i--) {\n          const match = matches[i];\n\n          const beforeMatch = textWithoutReasoning.slice(0, match.index);\n          const afterMatch = textWithoutReasoning.slice(\n            match.index! + match[0].length,\n          );\n\n          textWithoutReasoning =\n            beforeMatch +\n            (beforeMatch.length > 0 && afterMatch.length > 0 ? separator : '') +\n            afterMatch;\n        }\n\n        transformedContent.push({\n          type: 'reasoning',\n          text: reasoningText,\n        });\n\n        transformedContent.push({\n          type: 'text',\n          text: textWithoutReasoning,\n        });\n      }\n\n      return { content: transformedContent, ...rest };\n    },\n\n    wrapStream: async ({ doStream }) => {\n      const { stream, ...rest } = await doStream();\n\n      const reasoningExtractions: Record<\n        string,\n        {\n          isFirstReasoning: boolean;\n          isFirstText: boolean;\n          afterSwitch: boolean;\n          isReasoning: boolean;\n          buffer: string;\n          idCounter: number;\n          textId: string;\n        }\n      > = {};\n\n      let delayedTextStart: LanguageModelV2StreamPart | undefined;\n\n      return {\n        stream: stream.pipeThrough(\n          new TransformStream<\n            LanguageModelV2StreamPart,\n            LanguageModelV2StreamPart\n          >({\n            transform: (chunk, controller) => {\n              // do not send `text-start` before `reasoning-start`\n              // https://github.com/vercel/ai/issues/7774\n              if (chunk.type === 'text-start') {\n                delayedTextStart = chunk;\n                return;\n              }\n\n              if (chunk.type === 'text-end' && delayedTextStart) {\n                controller.enqueue(delayedTextStart);\n                delayedTextStart = undefined;\n              }\n\n              if (chunk.type !== 'text-delta') {\n                controller.enqueue(chunk);\n                return;\n              }\n\n              if (reasoningExtractions[chunk.id] == null) {\n                reasoningExtractions[chunk.id] = {\n                  isFirstReasoning: true,\n                  isFirstText: true,\n                  afterSwitch: false,\n                  isReasoning: startWithReasoning,\n                  buffer: '',\n                  idCounter: 0,\n                  textId: chunk.id,\n                };\n              }\n\n              const activeExtraction = reasoningExtractions[chunk.id];\n\n              activeExtraction.buffer += chunk.delta;\n\n              function publish(text: string) {\n                if (text.length > 0) {\n                  const prefix =\n                    activeExtraction.afterSwitch &&\n                    (activeExtraction.isReasoning\n                      ? !activeExtraction.isFirstReasoning\n                      : !activeExtraction.isFirstText)\n                      ? separator\n                      : '';\n\n                  if (\n                    activeExtraction.isReasoning &&\n                    (activeExtraction.afterSwitch ||\n                      activeExtraction.isFirstReasoning)\n                  ) {\n                    controller.enqueue({\n                      type: 'reasoning-start',\n                      id: `reasoning-${activeExtraction.idCounter}`,\n                    });\n                  }\n\n                  if (activeExtraction.isReasoning) {\n                    controller.enqueue({\n                      type: 'reasoning-delta',\n                      delta: prefix + text,\n                      id: `reasoning-${activeExtraction.idCounter}`,\n                    });\n                  } else {\n                    if (delayedTextStart) {\n                      controller.enqueue(delayedTextStart);\n                      delayedTextStart = undefined;\n                    }\n                    controller.enqueue({\n                      type: 'text-delta',\n                      delta: prefix + text,\n                      id: activeExtraction.textId,\n                    });\n                  }\n                  activeExtraction.afterSwitch = false;\n\n                  if (activeExtraction.isReasoning) {\n                    activeExtraction.isFirstReasoning = false;\n                  } else {\n                    activeExtraction.isFirstText = false;\n                  }\n                }\n              }\n\n              do {\n                const nextTag = activeExtraction.isReasoning\n                  ? closingTag\n                  : openingTag;\n\n                const startIndex = getPotentialStartIndex(\n                  activeExtraction.buffer,\n                  nextTag,\n                );\n\n                // no opening or closing tag found, publish the buffer\n                if (startIndex == null) {\n                  publish(activeExtraction.buffer);\n                  activeExtraction.buffer = '';\n                  break;\n                }\n\n                // publish text before the tag\n                publish(activeExtraction.buffer.slice(0, startIndex));\n\n                const foundFullMatch =\n                  startIndex + nextTag.length <= activeExtraction.buffer.length;\n\n                if (foundFullMatch) {\n                  activeExtraction.buffer = activeExtraction.buffer.slice(\n                    startIndex + nextTag.length,\n                  );\n\n                  // reasoning part finished:\n                  if (activeExtraction.isReasoning) {\n                    controller.enqueue({\n                      type: 'reasoning-end',\n                      id: `reasoning-${activeExtraction.idCounter++}`,\n                    });\n                  }\n\n                  activeExtraction.isReasoning = !activeExtraction.isReasoning;\n                  activeExtraction.afterSwitch = true;\n                } else {\n                  activeExtraction.buffer =\n                    activeExtraction.buffer.slice(startIndex);\n                  break;\n                }\n              } while (true);\n            },\n          }),\n        ),\n        ...rest,\n      };\n    },\n  };\n}\n", "import type { LanguageModelV2StreamPart } from '@ai-sdk/provider';\nimport { LanguageModelMiddleware } from '../types';\n\n/**\n * Simulates streaming chunks with the response from a generate call.\n */\nexport function simulateStreamingMiddleware(): LanguageModelMiddleware {\n  return {\n    middlewareVersion: 'v2',\n    wrapStream: async ({ doGenerate }) => {\n      const result = await doGenerate();\n\n      let id = 0;\n\n      const simulatedStream = new ReadableStream<LanguageModelV2StreamPart>({\n        start(controller) {\n          controller.enqueue({\n            type: 'stream-start',\n            warnings: result.warnings,\n          });\n\n          controller.enqueue({ type: 'response-metadata', ...result.response });\n\n          for (const part of result.content) {\n            switch (part.type) {\n              case 'text': {\n                if (part.text.length > 0) {\n                  controller.enqueue({ type: 'text-start', id: String(id) });\n                  controller.enqueue({\n                    type: 'text-delta',\n                    id: String(id),\n                    delta: part.text,\n                  });\n                  controller.enqueue({ type: 'text-end', id: String(id) });\n                  id++;\n                }\n                break;\n              }\n              case 'reasoning': {\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: String(id),\n                  providerMetadata: part.providerMetadata,\n                });\n                controller.enqueue({\n                  type: 'reasoning-delta',\n                  id: String(id),\n                  delta: part.text,\n                });\n                controller.enqueue({ type: 'reasoning-end', id: String(id) });\n                id++;\n                break;\n              }\n              default: {\n                controller.enqueue(part);\n                break;\n              }\n            }\n          }\n\n          controller.enqueue({\n            type: 'finish',\n            finishReason: result.finishReason,\n            usage: result.usage,\n            providerMetadata: result.providerMetadata,\n          });\n\n          controller.close();\n        },\n      });\n\n      return {\n        stream: simulatedStream,\n        request: result.request,\n        response: result.response,\n      };\n    },\n  };\n}\n", "import { LanguageModelV2, LanguageModelV2CallOptions } from '@ai-sdk/provider';\nimport { LanguageModelMiddleware } from '../types';\nimport { asArray } from '../util/as-array';\n\n/**\n * Wraps a LanguageModelV2 instance with middleware functionality.\n * This function allows you to apply middleware to transform parameters,\n * wrap generate operations, and wrap stream operations of a language model.\n *\n * @param options - Configuration options for wrapping the language model.\n * @param options.model - The original LanguageModelV2 instance to be wrapped.\n * @param options.middleware - The middleware to be applied to the language model. When multiple middlewares are provided, the first middleware will transform the input first, and the last middleware will be wrapped directly around the model.\n * @param options.modelId - Optional custom model ID to override the original model's ID.\n * @param options.providerId - Optional custom provider ID to override the original model's provider ID.\n * @returns A new LanguageModelV2 instance with middleware applied.\n */\nexport const wrapLanguageModel = ({\n  model,\n  middleware: middlewareArg,\n  modelId,\n  providerId,\n}: {\n  model: LanguageModelV2;\n  middleware: LanguageModelMiddleware | LanguageModelMiddleware[];\n  modelId?: string;\n  providerId?: string;\n}): LanguageModelV2 => {\n  return [...asArray(middlewareArg)]\n    .reverse()\n    .reduce((wrappedModel, middleware) => {\n      return doWrap({ model: wrappedModel, middleware, modelId, providerId });\n    }, model);\n};\n\nconst doWrap = ({\n  model,\n  middleware: {\n    transformParams,\n    wrapGenerate,\n    wrapStream,\n    overrideProvider,\n    overrideModelId,\n    overrideSupportedUrls,\n  },\n  modelId,\n  providerId,\n}: {\n  model: LanguageModelV2;\n  middleware: LanguageModelMiddleware;\n  modelId?: string;\n  providerId?: string;\n}): LanguageModelV2 => {\n  async function doTransform({\n    params,\n    type,\n  }: {\n    params: LanguageModelV2CallOptions;\n    type: 'generate' | 'stream';\n  }) {\n    return transformParams\n      ? await transformParams({ params, type, model })\n      : params;\n  }\n\n  return {\n    specificationVersion: 'v2',\n\n    provider: providerId ?? overrideProvider?.({ model }) ?? model.provider,\n    modelId: modelId ?? overrideModelId?.({ model }) ?? model.modelId,\n    supportedUrls: overrideSupportedUrls?.({ model }) ?? model.supportedUrls,\n\n    async doGenerate(\n      params: LanguageModelV2CallOptions,\n    ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n      const transformedParams = await doTransform({ params, type: 'generate' });\n      const doGenerate = async () => model.doGenerate(transformedParams);\n      const doStream = async () => model.doStream(transformedParams);\n      return wrapGenerate\n        ? wrapGenerate({\n            doGenerate,\n            doStream,\n            params: transformedParams,\n            model,\n          })\n        : doGenerate();\n    },\n\n    async doStream(\n      params: LanguageModelV2CallOptions,\n    ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n      const transformedParams = await doTransform({ params, type: 'stream' });\n      const doGenerate = async () => model.doGenerate(transformedParams);\n      const doStream = async () => model.doStream(transformedParams);\n      return wrapStream\n        ? wrapStream({ doGenerate, doStream, params: transformedParams, model })\n        : doStream();\n    },\n  };\n};\n", "import type { ProviderV2 } from '@ai-sdk/provider';\nimport { LanguageModelMiddleware } from '../types/language-model-middleware';\nimport { wrapLanguageModel } from './wrap-language-model';\n\n/**\n * Wraps a ProviderV2 instance with middleware functionality.\n * This function allows you to apply middleware to all language models\n * from the provider, enabling you to transform parameters, wrap generate\n * operations, and wrap stream operations for every language model.\n *\n * @param options - Configuration options for wrapping the provider.\n * @param options.provider - The original ProviderV2 instance to be wrapped.\n * @param options.languageModelMiddleware - The middleware to be applied to all language models from the provider. When multiple middlewares are provided, the first middleware will transform the input first, and the last middleware will be wrapped directly around the model.\n * @returns A new ProviderV2 instance with middleware applied to all language models.\n */\nexport function wrapProvider({\n  provider,\n  languageModelMiddleware,\n}: {\n  provider: ProviderV2;\n  languageModelMiddleware: LanguageModelMiddleware | LanguageModelMiddleware[];\n}): ProviderV2 {\n  const wrappedProvider = {\n    languageModel(modelId: string) {\n      let model = provider.languageModel(modelId);\n      model = wrapLanguageModel({\n        model,\n        middleware: languageModelMiddleware,\n      });\n      return model;\n    },\n    textEmbeddingModel: provider.textEmbeddingModel,\n    imageModel: provider.imageModel,\n    transcriptionModel: provider.transcriptionModel,\n    speechModel: provider.speechModel,\n  };\n\n  return wrappedProvider;\n}\n", "import {\n  EmbeddingModelV2,\n  ImageModelV2,\n  LanguageModelV2,\n  NoSuchModelError,\n  ProviderV2,\n  SpeechModelV2,\n  TranscriptionModelV2,\n} from '@ai-sdk/provider';\n\n/**\n * Creates a custom provider with specified language models, text embedding models, image models, transcription models, speech models, and an optional fallback provider.\n *\n * @param {Object} options - The options for creating the custom provider.\n * @param {Record<string, LanguageModel>} [options.languageModels] - A record of language models, where keys are model IDs and values are LanguageModel instances.\n * @param {Record<string, EmbeddingModel<string>>} [options.textEmbeddingModels] - A record of text embedding models, where keys are model IDs and values are EmbeddingModel<string> instances.\n * @param {Record<string, ImageModel>} [options.imageModels] - A record of image models, where keys are model IDs and values are ImageModel instances.\n * @param {Record<string, TranscriptionModel>} [options.transcriptionModels] - A record of transcription models, where keys are model IDs and values are TranscriptionModel instances.\n * @param {Record<string, SpeechModel>} [options.speechModels] - A record of speech models, where keys are model IDs and values are SpeechModel instances.\n * @param {Provider} [options.fallbackProvider] - An optional fallback provider to use when a requested model is not found in the custom provider.\n * @returns {Provider} A Provider object with languageModel, textEmbeddingModel, imageModel, transcriptionModel, and speechModel methods.\n *\n * @throws {NoSuchModelError} Throws when a requested model is not found and no fallback provider is available.\n */\nexport function customProvider<\n  LANGUAGE_MODELS extends Record<string, LanguageModelV2>,\n  EMBEDDING_MODELS extends Record<string, EmbeddingModelV2<string>>,\n  IMAGE_MODELS extends Record<string, ImageModelV2>,\n  TRANSCRIPTION_MODELS extends Record<string, TranscriptionModelV2>,\n  SPEECH_MODELS extends Record<string, SpeechModelV2>,\n>({\n  languageModels,\n  textEmbeddingModels,\n  imageModels,\n  transcriptionModels,\n  speechModels,\n  fallbackProvider,\n}: {\n  languageModels?: LANGUAGE_MODELS;\n  textEmbeddingModels?: EMBEDDING_MODELS;\n  imageModels?: IMAGE_MODELS;\n  transcriptionModels?: TRANSCRIPTION_MODELS;\n  speechModels?: SPEECH_MODELS;\n  fallbackProvider?: ProviderV2;\n}): ProviderV2 & {\n  languageModel(modelId: ExtractModelId<LANGUAGE_MODELS>): LanguageModelV2;\n  textEmbeddingModel(\n    modelId: ExtractModelId<EMBEDDING_MODELS>,\n  ): EmbeddingModelV2<string>;\n  imageModel(modelId: ExtractModelId<IMAGE_MODELS>): ImageModelV2;\n  transcriptionModel(\n    modelId: ExtractModelId<TRANSCRIPTION_MODELS>,\n  ): TranscriptionModelV2;\n  speechModel(modelId: ExtractModelId<SPEECH_MODELS>): SpeechModelV2;\n} {\n  return {\n    languageModel(modelId: ExtractModelId<LANGUAGE_MODELS>): LanguageModelV2 {\n      if (languageModels != null && modelId in languageModels) {\n        return languageModels[modelId];\n      }\n\n      if (fallbackProvider) {\n        return fallbackProvider.languageModel(modelId);\n      }\n\n      throw new NoSuchModelError({ modelId, modelType: 'languageModel' });\n    },\n\n    textEmbeddingModel(\n      modelId: ExtractModelId<EMBEDDING_MODELS>,\n    ): EmbeddingModelV2<string> {\n      if (textEmbeddingModels != null && modelId in textEmbeddingModels) {\n        return textEmbeddingModels[modelId];\n      }\n\n      if (fallbackProvider) {\n        return fallbackProvider.textEmbeddingModel(modelId);\n      }\n\n      throw new NoSuchModelError({ modelId, modelType: 'textEmbeddingModel' });\n    },\n\n    imageModel(modelId: ExtractModelId<IMAGE_MODELS>): ImageModelV2 {\n      if (imageModels != null && modelId in imageModels) {\n        return imageModels[modelId];\n      }\n\n      if (fallbackProvider?.imageModel) {\n        return fallbackProvider.imageModel(modelId);\n      }\n\n      throw new NoSuchModelError({ modelId, modelType: 'imageModel' });\n    },\n\n    transcriptionModel(\n      modelId: ExtractModelId<TRANSCRIPTION_MODELS>,\n    ): TranscriptionModelV2 {\n      if (transcriptionModels != null && modelId in transcriptionModels) {\n        return transcriptionModels[modelId];\n      }\n\n      if (fallbackProvider?.transcriptionModel) {\n        return fallbackProvider.transcriptionModel(modelId);\n      }\n\n      throw new NoSuchModelError({ modelId, modelType: 'transcriptionModel' });\n    },\n\n    speechModel(modelId: ExtractModelId<SPEECH_MODELS>): SpeechModelV2 {\n      if (speechModels != null && modelId in speechModels) {\n        return speechModels[modelId];\n      }\n\n      if (fallbackProvider?.speechModel) {\n        return fallbackProvider.speechModel(modelId);\n      }\n\n      throw new NoSuchModelError({ modelId, modelType: 'speechModel' });\n    },\n  };\n}\n\n/**\n * @deprecated Use `customProvider` instead.\n */\nexport const experimental_customProvider = customProvider;\n\ntype ExtractModelId<MODELS extends Record<string, unknown>> = Extract<\n  keyof MODELS,\n  string\n>;\n", "import { AISDKError, NoSuchModelError } from '@ai-sdk/provider';\n\nconst name = 'AI_NoSuchProviderError';\nconst marker = `vercel.ai.error.${name}`;\nconst symbol = Symbol.for(marker);\n\nexport class NoSuchProviderError extends NoSuchModelError {\n  private readonly [symbol] = true; // used in isInstance\n\n  readonly providerId: string;\n  readonly availableProviders: string[];\n\n  constructor({\n    modelId,\n    modelType,\n    providerId,\n    availableProviders,\n    message = `No such provider: ${providerId} (available providers: ${availableProviders.join()})`,\n  }: {\n    modelId: string;\n    modelType:\n      | 'languageModel'\n      | 'textEmbeddingModel'\n      | 'imageModel'\n      | 'transcriptionModel'\n      | 'speechModel';\n    providerId: string;\n    availableProviders: string[];\n    message?: string;\n  }) {\n    super({ errorName: name, modelId, modelType, message });\n\n    this.providerId = providerId;\n    this.availableProviders = availableProviders;\n  }\n\n  static isInstance(error: unknown): error is NoSuchProviderError {\n    return AISDKError.hasMarker(error, marker);\n  }\n}\n", "import {\n  EmbeddingModelV2,\n  ImageModelV2,\n  LanguageModelV2,\n  NoSuchModelError,\n  ProviderV2,\n  SpeechModelV2,\n  TranscriptionModelV2,\n} from '@ai-sdk/provider';\nimport { wrapLanguageModel } from '../middleware/wrap-language-model';\nimport { LanguageModelMiddleware } from '../types';\nimport { NoSuchProviderError } from './no-such-provider-error';\n\ntype ExtractLiteralUnion<T> = T extends string\n  ? string extends T\n    ? never\n    : T\n  : never;\n\nexport interface ProviderRegistryProvider<\n  PROVIDERS extends Record<string, ProviderV2> = Record<string, ProviderV2>,\n  SEPARATOR extends string = ':',\n> {\n  languageModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string\n      ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['languageModel']>>[0]>}`\n      : never,\n  ): LanguageModelV2;\n  languageModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never,\n  ): LanguageModelV2;\n\n  textEmbeddingModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string\n      ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['textEmbeddingModel']>>[0]>}`\n      : never,\n  ): EmbeddingModelV2<string>;\n  textEmbeddingModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never,\n  ): EmbeddingModelV2<string>;\n\n  imageModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string\n      ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['imageModel']>>[0]>}`\n      : never,\n  ): ImageModelV2;\n  imageModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never,\n  ): ImageModelV2;\n\n  transcriptionModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string\n      ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['transcriptionModel']>>[0]>}`\n      : never,\n  ): TranscriptionModelV2;\n  transcriptionModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never,\n  ): TranscriptionModelV2;\n\n  speechModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string\n      ? `${KEY & string}${SEPARATOR}${ExtractLiteralUnion<Parameters<NonNullable<PROVIDERS[KEY]['speechModel']>>[0]>}`\n      : never,\n  ): SpeechModelV2;\n  speechModel<KEY extends keyof PROVIDERS>(\n    id: KEY extends string ? `${KEY & string}${SEPARATOR}${string}` : never,\n  ): SpeechModelV2;\n}\n\n/**\n * Creates a registry for the given providers with optional middleware functionality.\n * This function allows you to register multiple providers and optionally apply middleware\n * to all language models from the registry, enabling you to transform parameters, wrap generate\n * operations, and wrap stream operations for every language model accessed through the registry.\n *\n * @param providers - A record of provider instances to be registered in the registry.\n * @param options - Configuration options for the provider registry.\n * @param options.separator - The separator used between provider ID and model ID in the combined identifier. Defaults to ':'.\n * @param options.languageModelMiddleware - Optional middleware to be applied to all language models from the registry. When multiple middlewares are provided, the first middleware will transform the input first, and the last middleware will be wrapped directly around the model.\n * @returns A new ProviderRegistryProvider instance that provides access to all registered providers with optional middleware applied to language models.\n */\nexport function createProviderRegistry<\n  PROVIDERS extends Record<string, ProviderV2>,\n  SEPARATOR extends string = ':',\n>(\n  providers: PROVIDERS,\n  {\n    separator = ':' as SEPARATOR,\n    languageModelMiddleware,\n  }: {\n    separator?: SEPARATOR;\n    languageModelMiddleware?:\n      | LanguageModelMiddleware\n      | LanguageModelMiddleware[];\n  } = {},\n): ProviderRegistryProvider<PROVIDERS, SEPARATOR> {\n  const registry = new DefaultProviderRegistry<PROVIDERS, SEPARATOR>({\n    separator,\n    languageModelMiddleware,\n  });\n\n  for (const [id, provider] of Object.entries(providers)) {\n    registry.registerProvider({ id, provider } as {\n      id: keyof PROVIDERS;\n      provider: PROVIDERS[keyof PROVIDERS];\n    });\n  }\n\n  return registry;\n}\n\n/**\n * @deprecated Use `createProviderRegistry` instead.\n */\nexport const experimental_createProviderRegistry = createProviderRegistry;\n\nclass DefaultProviderRegistry<\n  PROVIDERS extends Record<string, ProviderV2>,\n  SEPARATOR extends string,\n> implements ProviderRegistryProvider<PROVIDERS, SEPARATOR>\n{\n  private providers: PROVIDERS = {} as PROVIDERS;\n  private separator: SEPARATOR;\n  private languageModelMiddleware?:\n    | LanguageModelMiddleware\n    | LanguageModelMiddleware[];\n\n  constructor({\n    separator,\n    languageModelMiddleware,\n  }: {\n    separator: SEPARATOR;\n    languageModelMiddleware?:\n      | LanguageModelMiddleware\n      | LanguageModelMiddleware[];\n  }) {\n    this.separator = separator;\n    this.languageModelMiddleware = languageModelMiddleware;\n  }\n\n  registerProvider<K extends keyof PROVIDERS>({\n    id,\n    provider,\n  }: {\n    id: K;\n    provider: PROVIDERS[K];\n  }): void {\n    this.providers[id] = provider;\n  }\n\n  private getProvider(\n    id: string,\n    modelType:\n      | 'languageModel'\n      | 'textEmbeddingModel'\n      | 'imageModel'\n      | 'transcriptionModel'\n      | 'speechModel',\n  ): ProviderV2 {\n    const provider = this.providers[id as keyof PROVIDERS];\n\n    if (provider == null) {\n      throw new NoSuchProviderError({\n        modelId: id,\n        modelType,\n        providerId: id,\n        availableProviders: Object.keys(this.providers),\n      });\n    }\n\n    return provider;\n  }\n\n  private splitId(\n    id: string,\n    modelType:\n      | 'languageModel'\n      | 'textEmbeddingModel'\n      | 'imageModel'\n      | 'transcriptionModel'\n      | 'speechModel',\n  ): [string, string] {\n    const index = id.indexOf(this.separator);\n\n    if (index === -1) {\n      throw new NoSuchModelError({\n        modelId: id,\n        modelType,\n        message:\n          `Invalid ${modelType} id for registry: ${id} ` +\n          `(must be in the format \"providerId${this.separator}modelId\")`,\n      });\n    }\n\n    return [id.slice(0, index), id.slice(index + this.separator.length)];\n  }\n\n  languageModel<KEY extends keyof PROVIDERS>(\n    id: `${KEY & string}${SEPARATOR}${string}`,\n  ): LanguageModelV2 {\n    const [providerId, modelId] = this.splitId(id, 'languageModel');\n    let model = this.getProvider(providerId, 'languageModel').languageModel?.(\n      modelId,\n    );\n\n    if (model == null) {\n      throw new NoSuchModelError({ modelId: id, modelType: 'languageModel' });\n    }\n\n    if (this.languageModelMiddleware != null) {\n      model = wrapLanguageModel({\n        model,\n        middleware: this.languageModelMiddleware,\n      });\n    }\n\n    return model;\n  }\n\n  textEmbeddingModel<KEY extends keyof PROVIDERS>(\n    id: `${KEY & string}${SEPARATOR}${string}`,\n  ): EmbeddingModelV2<string> {\n    const [providerId, modelId] = this.splitId(id, 'textEmbeddingModel');\n    const provider = this.getProvider(providerId, 'textEmbeddingModel');\n\n    const model = provider.textEmbeddingModel?.(modelId);\n\n    if (model == null) {\n      throw new NoSuchModelError({\n        modelId: id,\n        modelType: 'textEmbeddingModel',\n      });\n    }\n\n    return model;\n  }\n\n  imageModel<KEY extends keyof PROVIDERS>(\n    id: `${KEY & string}${SEPARATOR}${string}`,\n  ): ImageModelV2 {\n    const [providerId, modelId] = this.splitId(id, 'imageModel');\n    const provider = this.getProvider(providerId, 'imageModel');\n\n    const model = provider.imageModel?.(modelId);\n\n    if (model == null) {\n      throw new NoSuchModelError({ modelId: id, modelType: 'imageModel' });\n    }\n\n    return model;\n  }\n\n  transcriptionModel<KEY extends keyof PROVIDERS>(\n    id: `${KEY & string}${SEPARATOR}${string}`,\n  ): TranscriptionModelV2 {\n    const [providerId, modelId] = this.splitId(id, 'transcriptionModel');\n    const provider = this.getProvider(providerId, 'transcriptionModel');\n\n    const model = provider.transcriptionModel?.(modelId);\n\n    if (model == null) {\n      throw new NoSuchModelError({\n        modelId: id,\n        modelType: 'transcriptionModel',\n      });\n    }\n\n    return model;\n  }\n\n  speechModel<KEY extends keyof PROVIDERS>(\n    id: `${KEY & string}${SEPARATOR}${string}`,\n  ): SpeechModelV2 {\n    const [providerId, modelId] = this.splitId(id, 'speechModel');\n    const provider = this.getProvider(providerId, 'speechModel');\n\n    const model = provider.speechModel?.(modelId);\n\n    if (model == null) {\n      throw new NoSuchModelError({ modelId: id, modelType: 'speechModel' });\n    }\n\n    return model;\n  }\n}\n", "import { JSONValue, TranscriptionModelV2 } from '@ai-sdk/provider';\nimport { ProviderOptions, withUserAgentSuffix } from '@ai-sdk/provider-utils';\nimport { NoTranscriptGeneratedError } from '../error/no-transcript-generated-error';\nimport { UnsupportedModelVersionError } from '../error/unsupported-model-version-error';\nimport { logWarnings } from '../logger/log-warnings';\nimport { DataContent } from '../prompt';\nimport { convertDataContentToUint8Array } from '../prompt/data-content';\nimport { TranscriptionWarning } from '../types/transcription-model';\nimport { TranscriptionModelResponseMetadata } from '../types/transcription-model-response-metadata';\nimport {\n  audioMediaTypeSignatures,\n  detectMediaType,\n} from '../util/detect-media-type';\nimport { download } from '../util/download/download';\nimport { prepareRetries } from '../util/prepare-retries';\nimport { TranscriptionResult } from './transcribe-result';\nimport { VERSION } from '../version';\n/**\nGenerates transcripts using a transcription model.\n\n@param model - The transcription model to use.\n@param audio - The audio data to transcribe as DataContent (string | Uint8Array | ArrayBuffer | Buffer) or a URL.\n@param providerOptions - Additional provider-specific options that are passed through to the provider\nas body parameters.\n@param maxRetries - Maximum number of retries. Set to 0 to disable retries. Default: 2.\n@param abortSignal - An optional abort signal that can be used to cancel the call.\n@param headers - Additional HTTP headers to be sent with the request. Only applicable for HTTP-based providers.\n\n@returns A result object that contains the generated transcript.\n */\nexport async function transcribe({\n  model,\n  audio,\n  providerOptions = {},\n  maxRetries: maxRetriesArg,\n  abortSignal,\n  headers,\n}: {\n  /**\nThe transcription model to use.\n     */\n  model: TranscriptionModelV2;\n\n  /**\nThe audio data to transcribe.\n   */\n  audio: DataContent | URL;\n\n  /**\nAdditional provider-specific options that are passed through to the provider\nas body parameters.\n\nThe outer record is keyed by the provider name, and the inner\nrecord is keyed by the provider-specific metadata key.\n```ts\n{\n  \"openai\": {\n    \"temperature\": 0\n  }\n}\n```\n     */\n  providerOptions?: ProviderOptions;\n\n  /**\nMaximum number of retries per transcript model call. Set to 0 to disable retries.\n\n@default 2\n   */\n  maxRetries?: number;\n\n  /**\nAbort signal.\n */\n  abortSignal?: AbortSignal;\n\n  /**\nAdditional headers to include in the request.\nOnly applicable for HTTP-based providers.\n */\n  headers?: Record<string, string>;\n}): Promise<TranscriptionResult> {\n  if (model.specificationVersion !== 'v2') {\n    throw new UnsupportedModelVersionError({\n      version: model.specificationVersion,\n      provider: model.provider,\n      modelId: model.modelId,\n    });\n  }\n\n  const { retry } = prepareRetries({\n    maxRetries: maxRetriesArg,\n    abortSignal,\n  });\n\n  const headersWithUserAgent = withUserAgentSuffix(\n    headers ?? {},\n    `ai/${VERSION}`,\n  );\n\n  const audioData =\n    audio instanceof URL\n      ? (await download({ url: audio })).data\n      : convertDataContentToUint8Array(audio);\n\n  const result = await retry(() =>\n    model.doGenerate({\n      audio: audioData,\n      abortSignal,\n      headers: headersWithUserAgent,\n      providerOptions,\n      mediaType:\n        detectMediaType({\n          data: audioData,\n          signatures: audioMediaTypeSignatures,\n        }) ?? 'audio/wav',\n    }),\n  );\n\n  logWarnings(result.warnings);\n\n  if (!result.text) {\n    throw new NoTranscriptGeneratedError({ responses: [result.response] });\n  }\n\n  return new DefaultTranscriptionResult({\n    text: result.text,\n    segments: result.segments,\n    language: result.language,\n    durationInSeconds: result.durationInSeconds,\n    warnings: result.warnings,\n    responses: [result.response],\n    providerMetadata: result.providerMetadata,\n  });\n}\n\nclass DefaultTranscriptionResult implements TranscriptionResult {\n  readonly text: string;\n  readonly segments: Array<{\n    text: string;\n    startSecond: number;\n    endSecond: number;\n  }>;\n  readonly language: string | undefined;\n  readonly durationInSeconds: number | undefined;\n  readonly warnings: Array<TranscriptionWarning>;\n  readonly responses: Array<TranscriptionModelResponseMetadata>;\n  readonly providerMetadata: Record<string, Record<string, JSONValue>>;\n\n  constructor(options: {\n    text: string;\n    segments: Array<{\n      text: string;\n      startSecond: number;\n      endSecond: number;\n    }>;\n    language: string | undefined;\n    durationInSeconds: number | undefined;\n    warnings: Array<TranscriptionWarning>;\n    responses: Array<TranscriptionModelResponseMetadata>;\n    providerMetadata: Record<string, Record<string, JSONValue>> | undefined;\n  }) {\n    this.text = options.text;\n    this.segments = options.segments;\n    this.language = options.language;\n    this.durationInSeconds = options.durationInSeconds;\n    this.warnings = options.warnings;\n    this.responses = options.responses;\n    this.providerMetadata = options.providerMetadata ?? {};\n  }\n}\n", "import { AISDKError } from '@ai-sdk/provider';\nimport { TranscriptionModelResponseMetadata } from '../types/transcription-model-response-metadata';\n\n/**\nError that is thrown when no transcript was generated.\n */\nexport class NoTranscriptGeneratedError extends AISDKError {\n  readonly responses: Array<TranscriptionModelResponseMetadata>;\n\n  constructor(options: {\n    responses: Array<TranscriptionModelResponseMetadata>;\n  }) {\n    super({\n      name: 'AI_NoTranscriptGeneratedError',\n      message: 'No transcript generated.',\n    });\n\n    this.responses = options.responses;\n  }\n}\n", "import {\n  parseJsonEventStream,\n  ParseResult,\n  withUserAgentSuffix,\n  getRuntimeEnvironmentUserAgent,\n} from '@ai-sdk/provider-utils';\nimport {\n  UIMessageChunk,\n  uiMessageChunkSchema,\n} from '../ui-message-stream/ui-message-chunks';\nimport { consumeStream } from '../util/consume-stream';\nimport { processTextStream } from './process-text-stream';\nimport { VERSION } from '../version';\n\n// use function to allow for mocking in tests:\nconst getOriginalFetch = () => fetch;\n\nexport async function callCompletionApi({\n  api,\n  prompt,\n  credentials,\n  headers,\n  body,\n  streamProtocol = 'data',\n  setCompletion,\n  setLoading,\n  setError,\n  setAbortController,\n  onFinish,\n  onError,\n  fetch = getOriginalFetch(),\n}: {\n  api: string;\n  prompt: string;\n  credentials: RequestCredentials | undefined;\n  headers: HeadersInit | undefined;\n  body: Record<string, any>;\n  streamProtocol: 'data' | 'text' | undefined;\n  setCompletion: (completion: string) => void;\n  setLoading: (loading: boolean) => void;\n  setError: (error: Error | undefined) => void;\n  setAbortController: (abortController: AbortController | null) => void;\n  onFinish: ((prompt: string, completion: string) => void) | undefined;\n  onError: ((error: Error) => void) | undefined;\n  fetch: ReturnType<typeof getOriginalFetch> | undefined;\n}) {\n  try {\n    setLoading(true);\n    setError(undefined);\n\n    const abortController = new AbortController();\n    setAbortController(abortController);\n\n    // Empty the completion immediately.\n    setCompletion('');\n\n    const response = await fetch(api, {\n      method: 'POST',\n      body: JSON.stringify({\n        prompt,\n        ...body,\n      }),\n      credentials,\n      headers: withUserAgentSuffix(\n        {\n          'Content-Type': 'application/json',\n          ...headers,\n        },\n        `ai-sdk/${VERSION}`,\n        getRuntimeEnvironmentUserAgent(),\n      ),\n      signal: abortController.signal,\n    }).catch(err => {\n      throw err;\n    });\n\n    if (!response.ok) {\n      throw new Error(\n        (await response.text()) ?? 'Failed to fetch the chat response.',\n      );\n    }\n\n    if (!response.body) {\n      throw new Error('The response body is empty.');\n    }\n\n    let result = '';\n\n    switch (streamProtocol) {\n      case 'text': {\n        await processTextStream({\n          stream: response.body,\n          onTextPart: chunk => {\n            result += chunk;\n            setCompletion(result);\n          },\n        });\n        break;\n      }\n      case 'data': {\n        await consumeStream({\n          stream: parseJsonEventStream({\n            stream: response.body,\n            schema: uiMessageChunkSchema,\n          }).pipeThrough(\n            new TransformStream<ParseResult<UIMessageChunk>, UIMessageChunk>({\n              async transform(part) {\n                if (!part.success) {\n                  throw part.error;\n                }\n\n                const streamPart = part.value;\n                if (streamPart.type === 'text-delta') {\n                  result += streamPart.delta;\n                  setCompletion(result);\n                } else if (streamPart.type === 'error') {\n                  throw new Error(streamPart.errorText);\n                }\n              },\n            }),\n          ),\n          onError: error => {\n            throw error;\n          },\n        });\n        break;\n      }\n      default: {\n        const exhaustiveCheck: never = streamProtocol;\n        throw new Error(`Unknown stream protocol: ${exhaustiveCheck}`);\n      }\n    }\n\n    if (onFinish) {\n      onFinish(prompt, result);\n    }\n\n    setAbortController(null);\n    return result;\n  } catch (err) {\n    // Ignore abort errors as they are expected.\n    if ((err as any).name === 'AbortError') {\n      setAbortController(null);\n      return null;\n    }\n\n    if (err instanceof Error) {\n      if (onError) {\n        onError(err);\n      }\n    }\n\n    setError(err as Error);\n  } finally {\n    setLoading(false);\n  }\n}\n", "export async function processTextStream({\n  stream,\n  onTextPart,\n}: {\n  stream: ReadableStream<Uint8Array>;\n  onTextPart: (chunk: string) => Promise<void> | void;\n}): Promise<void> {\n  const reader = stream.pipeThrough(new TextDecoderStream()).getReader();\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) {\n      break;\n    }\n    await onTextPart(value);\n  }\n}\n", "import {\n  generateId as generateIdFunc,\n  IdGenerator,\n  StandardSchemaV1,\n  Validator,\n} from '@ai-sdk/provider-utils';\nimport { UIMessageChunk } from '../ui-message-stream/ui-message-chunks';\nimport { consumeStream } from '../util/consume-stream';\nimport { SerialJobExecutor } from '../util/serial-job-executor';\nimport { ChatTransport } from './chat-transport';\nimport { convertFileListToFileUIParts } from './convert-file-list-to-file-ui-parts';\nimport { DefaultChatTransport } from './default-chat-transport';\nimport {\n  createStreamingUIMessageState,\n  processUIMessageStream,\n  StreamingUIMessageState,\n} from './process-ui-message-stream';\nimport {\n  InferUIMessageToolCall,\n  isToolOrDynamicToolUIPart,\n  ToolUIPart,\n  UIMessagePart,\n  UITools,\n  type DataUIPart,\n  type FileUIPart,\n  type InferUIMessageData,\n  type InferUIMessageMetadata,\n  type InferUIMessageTools,\n  type UIDataTypes,\n  type UIMessage,\n} from './ui-messages';\n\nexport type CreateUIMessage<UI_MESSAGE extends UIMessage> = Omit<\n  UI_MESSAGE,\n  'id' | 'role'\n> & {\n  id?: UI_MESSAGE['id'];\n  role?: UI_MESSAGE['role'];\n};\n\nexport type UIDataPartSchemas = Record<\n  string,\n  Validator<any> | StandardSchemaV1<any>\n>;\n\nexport type UIDataTypesToSchemas<T extends UIDataTypes> = {\n  [K in keyof T]: Validator<T[K]> | StandardSchemaV1<T[K]>;\n};\n\nexport type InferUIDataParts<T extends UIDataPartSchemas> = {\n  [K in keyof T]: T[K] extends Validator<infer U>\n    ? U\n    : T[K] extends StandardSchemaV1<infer U>\n      ? U\n      : unknown;\n};\n\nexport type ChatRequestOptions = {\n  /**\n  Additional headers that should be to be passed to the API endpoint.\n   */\n  headers?: Record<string, string> | Headers;\n\n  /**\n  Additional body JSON properties that should be sent to the API endpoint.\n   */\n  body?: object; // TODO JSONStringifyable\n\n  metadata?: unknown;\n};\n\nexport type ChatStatus = 'submitted' | 'streaming' | 'ready' | 'error';\n\ntype ActiveResponse<UI_MESSAGE extends UIMessage> = {\n  state: StreamingUIMessageState<UI_MESSAGE>;\n  abortController: AbortController;\n};\n\nexport interface ChatState<UI_MESSAGE extends UIMessage> {\n  status: ChatStatus;\n\n  error: Error | undefined;\n\n  messages: UI_MESSAGE[];\n  pushMessage: (message: UI_MESSAGE) => void;\n  popMessage: () => void;\n  replaceMessage: (index: number, message: UI_MESSAGE) => void;\n\n  snapshot: <T>(thing: T) => T;\n}\n\nexport type ChatOnErrorCallback = (error: Error) => void;\n\nexport type ChatOnToolCallCallback<UI_MESSAGE extends UIMessage = UIMessage> =\n  (options: {\n    toolCall: InferUIMessageToolCall<UI_MESSAGE>;\n  }) => void | PromiseLike<void>;\n\nexport type ChatOnDataCallback<UI_MESSAGE extends UIMessage> = (\n  dataPart: DataUIPart<InferUIMessageData<UI_MESSAGE>>,\n) => void;\n\n/**\n * Function that is called when the assistant response has finished streaming.\n *\n * @param message The assistant message that was streamed.\n * @param messages The full chat history, including the assistant message.\n *\n * @param isAbort Indicates whether the request has been aborted.\n * @param isDisconnect Indicates whether the request has been ended by a network error.\n * @param isError Indicates whether the request has been ended by an error.\n */\nexport type ChatOnFinishCallback<UI_MESSAGE extends UIMessage> = (options: {\n  message: UI_MESSAGE;\n  messages: UI_MESSAGE[];\n  isAbort: boolean;\n  isDisconnect: boolean;\n  isError: boolean;\n}) => void;\n\nexport interface ChatInit<UI_MESSAGE extends UIMessage> {\n  /**\n   * A unique identifier for the chat. If not provided, a random one will be\n   * generated.\n   */\n  id?: string;\n\n  messageMetadataSchema?:\n    | Validator<InferUIMessageMetadata<UI_MESSAGE>>\n    | StandardSchemaV1<InferUIMessageMetadata<UI_MESSAGE>>;\n  dataPartSchemas?: UIDataTypesToSchemas<InferUIMessageData<UI_MESSAGE>>;\n\n  messages?: UI_MESSAGE[];\n\n  /**\n   * A way to provide a function that is going to be used for ids for messages and the chat.\n   * If not provided the default AI SDK `generateId` is used.\n   */\n  generateId?: IdGenerator;\n\n  transport?: ChatTransport<UI_MESSAGE>;\n\n  /**\n   * Callback function to be called when an error is encountered.\n   */\n  onError?: ChatOnErrorCallback;\n\n  /**\n  Optional callback function that is invoked when a tool call is received.\n  Intended for automatic client-side tool execution.\n\n  You can optionally return a result for the tool call,\n  either synchronously or asynchronously.\n     */\n  onToolCall?: ChatOnToolCallCallback<UI_MESSAGE>;\n\n  /**\n   * Function that is called when the assistant response has finished streaming.\n   */\n  onFinish?: ChatOnFinishCallback<UI_MESSAGE>;\n\n  /**\n   * Optional callback function that is called when a data part is received.\n   *\n   * @param data The data part that was received.\n   */\n  onData?: ChatOnDataCallback<UI_MESSAGE>;\n\n  /**\n   * When provided, this function will be called when the stream is finished or a tool call is added\n   * to determine if the current messages should be resubmitted.\n   */\n  sendAutomaticallyWhen?: (options: {\n    messages: UI_MESSAGE[];\n  }) => boolean | PromiseLike<boolean>;\n}\n\nexport abstract class AbstractChat<UI_MESSAGE extends UIMessage> {\n  readonly id: string;\n  readonly generateId: IdGenerator;\n\n  protected state: ChatState<UI_MESSAGE>;\n\n  private messageMetadataSchema:\n    | Validator<InferUIMessageMetadata<UI_MESSAGE>>\n    | StandardSchemaV1<InferUIMessageMetadata<UI_MESSAGE>>\n    | undefined;\n  private dataPartSchemas:\n    | UIDataTypesToSchemas<InferUIMessageData<UI_MESSAGE>>\n    | undefined;\n  private readonly transport: ChatTransport<UI_MESSAGE>;\n  private onError?: ChatInit<UI_MESSAGE>['onError'];\n  private onToolCall?: ChatInit<UI_MESSAGE>['onToolCall'];\n  private onFinish?: ChatInit<UI_MESSAGE>['onFinish'];\n  private onData?: ChatInit<UI_MESSAGE>['onData'];\n  private sendAutomaticallyWhen?: ChatInit<UI_MESSAGE>['sendAutomaticallyWhen'];\n\n  private activeResponse: ActiveResponse<UI_MESSAGE> | undefined = undefined;\n  private jobExecutor = new SerialJobExecutor();\n\n  constructor({\n    generateId = generateIdFunc,\n    id = generateId(),\n    transport = new DefaultChatTransport(),\n    messageMetadataSchema,\n    dataPartSchemas,\n    state,\n    onError,\n    onToolCall,\n    onFinish,\n    onData,\n    sendAutomaticallyWhen,\n  }: Omit<ChatInit<UI_MESSAGE>, 'messages'> & {\n    state: ChatState<UI_MESSAGE>;\n  }) {\n    this.id = id;\n    this.transport = transport;\n    this.generateId = generateId;\n    this.messageMetadataSchema = messageMetadataSchema;\n    this.dataPartSchemas = dataPartSchemas;\n    this.state = state;\n    this.onError = onError;\n    this.onToolCall = onToolCall;\n    this.onFinish = onFinish;\n    this.onData = onData;\n    this.sendAutomaticallyWhen = sendAutomaticallyWhen;\n  }\n\n  /**\n   * Hook status:\n   *\n   * - `submitted`: The message has been sent to the API and we're awaiting the start of the response stream.\n   * - `streaming`: The response is actively streaming in from the API, receiving chunks of data.\n   * - `ready`: The full response has been received and processed; a new user message can be submitted.\n   * - `error`: An error occurred during the API request, preventing successful completion.\n   */\n  get status(): ChatStatus {\n    return this.state.status;\n  }\n\n  protected setStatus({\n    status,\n    error,\n  }: {\n    status: ChatStatus;\n    error?: Error;\n  }) {\n    if (this.status === status) return;\n\n    this.state.status = status;\n    this.state.error = error;\n  }\n\n  get error() {\n    return this.state.error;\n  }\n\n  get messages(): UI_MESSAGE[] {\n    return this.state.messages;\n  }\n\n  get lastMessage(): UI_MESSAGE | undefined {\n    return this.state.messages[this.state.messages.length - 1];\n  }\n\n  set messages(messages: UI_MESSAGE[]) {\n    this.state.messages = messages;\n  }\n\n  /**\n   * Appends or replaces a user message to the chat list. This triggers the API call to fetch\n   * the assistant's response.\n   *\n   * If a messageId is provided, the message will be replaced.\n   */\n  sendMessage = async (\n    message?:\n      | (CreateUIMessage<UI_MESSAGE> & {\n          text?: never;\n          files?: never;\n          messageId?: string;\n        })\n      | {\n          text: string;\n          files?: FileList | FileUIPart[];\n          metadata?: InferUIMessageMetadata<UI_MESSAGE>;\n          parts?: never;\n          messageId?: string;\n        }\n      | {\n          files: FileList | FileUIPart[];\n          metadata?: InferUIMessageMetadata<UI_MESSAGE>;\n          parts?: never;\n          messageId?: string;\n        },\n    options?: ChatRequestOptions,\n  ): Promise<void> => {\n    if (message == null) {\n      await this.makeRequest({\n        trigger: 'submit-message',\n        messageId: this.lastMessage?.id,\n        ...options,\n      });\n      return;\n    }\n\n    let uiMessage: CreateUIMessage<UI_MESSAGE>;\n\n    if ('text' in message || 'files' in message) {\n      const fileParts = Array.isArray(message.files)\n        ? message.files\n        : await convertFileListToFileUIParts(message.files);\n\n      uiMessage = {\n        parts: [\n          ...fileParts,\n          ...('text' in message && message.text != null\n            ? [{ type: 'text' as const, text: message.text }]\n            : []),\n        ],\n      } as UI_MESSAGE;\n    } else {\n      uiMessage = message;\n    }\n\n    if (message.messageId != null) {\n      const messageIndex = this.state.messages.findIndex(\n        m => m.id === message.messageId,\n      );\n\n      if (messageIndex === -1) {\n        throw new Error(`message with id ${message.messageId} not found`);\n      }\n\n      if (this.state.messages[messageIndex].role !== 'user') {\n        throw new Error(\n          `message with id ${message.messageId} is not a user message`,\n        );\n      }\n\n      // remove all messages after the message with the given id\n      this.state.messages = this.state.messages.slice(0, messageIndex + 1);\n\n      // update the message with the new content\n      this.state.replaceMessage(messageIndex, {\n        ...uiMessage,\n        id: message.messageId,\n        role: uiMessage.role ?? 'user',\n        metadata: message.metadata,\n      } as UI_MESSAGE);\n    } else {\n      this.state.pushMessage({\n        ...uiMessage,\n        id: uiMessage.id ?? this.generateId(),\n        role: uiMessage.role ?? 'user',\n        metadata: message.metadata,\n      } as UI_MESSAGE);\n    }\n\n    await this.makeRequest({\n      trigger: 'submit-message',\n      messageId: message.messageId,\n      ...options,\n    });\n  };\n\n  /**\n   * Regenerate the assistant message with the provided message id.\n   * If no message id is provided, the last assistant message will be regenerated.\n   */\n  regenerate = async ({\n    messageId,\n    ...options\n  }: {\n    messageId?: string;\n  } & ChatRequestOptions = {}): Promise<void> => {\n    const messageIndex =\n      messageId == null\n        ? this.state.messages.length - 1\n        : this.state.messages.findIndex(message => message.id === messageId);\n\n    if (messageIndex === -1) {\n      throw new Error(`message ${messageId} not found`);\n    }\n\n    // set the messages to the message before the assistant message\n    this.state.messages = this.state.messages.slice(\n      0,\n      // if the message is a user message, we need to include it in the request:\n      this.messages[messageIndex].role === 'assistant'\n        ? messageIndex\n        : messageIndex + 1,\n    );\n\n    await this.makeRequest({\n      trigger: 'regenerate-message',\n      messageId,\n      ...options,\n    });\n  };\n\n  /**\n   * Attempt to resume an ongoing streaming response.\n   */\n  resumeStream = async (options: ChatRequestOptions = {}): Promise<void> => {\n    await this.makeRequest({ trigger: 'resume-stream', ...options });\n  };\n\n  /**\n   * Clear the error state and set the status to ready if the chat is in an error state.\n   */\n  clearError = () => {\n    if (this.status === 'error') {\n      this.state.error = undefined;\n      this.setStatus({ status: 'ready' });\n    }\n  };\n\n  addToolOutput = async <TOOL extends keyof InferUIMessageTools<UI_MESSAGE>>({\n    state = 'output-available',\n    tool,\n    toolCallId,\n    output,\n    errorText,\n  }:\n    | {\n        state?: 'output-available';\n        tool: TOOL;\n        toolCallId: string;\n        output: InferUIMessageTools<UI_MESSAGE>[TOOL]['output'];\n        errorText?: never;\n      }\n    | {\n        state: 'output-error';\n        tool: TOOL;\n        toolCallId: string;\n        output?: never;\n        errorText: string;\n      }) =>\n    this.jobExecutor.run(async () => {\n      const messages = this.state.messages;\n      const lastMessage = messages[messages.length - 1];\n\n      this.state.replaceMessage(messages.length - 1, {\n        ...lastMessage,\n        parts: lastMessage.parts.map(part =>\n          isToolOrDynamicToolUIPart(part) && part.toolCallId === toolCallId\n            ? { ...part, state, output, errorText }\n            : part,\n        ),\n      });\n\n      // update the active response if it exists\n      if (this.activeResponse) {\n        this.activeResponse.state.message.parts =\n          this.activeResponse.state.message.parts.map(part =>\n            isToolOrDynamicToolUIPart(part) && part.toolCallId === toolCallId\n              ? ({\n                  ...part,\n                  state,\n                  output,\n                  errorText,\n                } as typeof part)\n              : part,\n          );\n      }\n\n      // automatically send the message if the sendAutomaticallyWhen function returns true\n      if (\n        this.status !== 'streaming' &&\n        this.status !== 'submitted' &&\n        this.sendAutomaticallyWhen?.({ messages: this.state.messages })\n      ) {\n        // no await to avoid deadlocking\n        this.makeRequest({\n          trigger: 'submit-message',\n          messageId: this.lastMessage?.id,\n        });\n      }\n    });\n\n  /** @deprecated Use addToolOutput */\n  addToolResult = this.addToolOutput;\n\n  /**\n   * Abort the current request immediately, keep the generated tokens if any.\n   */\n  stop = async () => {\n    if (this.status !== 'streaming' && this.status !== 'submitted') return;\n\n    if (this.activeResponse?.abortController) {\n      this.activeResponse.abortController.abort();\n    }\n  };\n\n  private async makeRequest({\n    trigger,\n    metadata,\n    headers,\n    body,\n    messageId,\n  }: {\n    trigger: 'submit-message' | 'resume-stream' | 'regenerate-message';\n    messageId?: string;\n  } & ChatRequestOptions) {\n    this.setStatus({ status: 'submitted', error: undefined });\n\n    const lastMessage = this.lastMessage;\n\n    let isAbort = false;\n    let isDisconnect = false;\n    let isError = false;\n\n    try {\n      const activeResponse = {\n        state: createStreamingUIMessageState({\n          lastMessage: this.state.snapshot(lastMessage),\n          messageId: this.generateId(),\n        }),\n        abortController: new AbortController(),\n      } as ActiveResponse<UI_MESSAGE>;\n\n      activeResponse.abortController.signal.addEventListener('abort', () => {\n        isAbort = true;\n      });\n\n      this.activeResponse = activeResponse;\n\n      let stream: ReadableStream<UIMessageChunk>;\n\n      if (trigger === 'resume-stream') {\n        const reconnect = await this.transport.reconnectToStream({\n          chatId: this.id,\n          metadata,\n          headers,\n          body,\n        });\n\n        if (reconnect == null) {\n          this.setStatus({ status: 'ready' });\n          return; // no active stream found, so we do not resume\n        }\n\n        stream = reconnect;\n      } else {\n        stream = await this.transport.sendMessages({\n          chatId: this.id,\n          messages: this.state.messages,\n          abortSignal: activeResponse.abortController.signal,\n          metadata,\n          headers,\n          body,\n          trigger,\n          messageId,\n        });\n      }\n\n      const runUpdateMessageJob = (\n        job: (options: {\n          state: StreamingUIMessageState<UI_MESSAGE>;\n          write: () => void;\n        }) => Promise<void>,\n      ) =>\n        // serialize the job execution to avoid race conditions:\n        this.jobExecutor.run(() =>\n          job({\n            state: activeResponse.state,\n            write: () => {\n              // streaming is set on first write (before it should be \"submitted\")\n              this.setStatus({ status: 'streaming' });\n\n              const replaceLastMessage =\n                activeResponse.state.message.id === this.lastMessage?.id;\n\n              if (replaceLastMessage) {\n                this.state.replaceMessage(\n                  this.state.messages.length - 1,\n                  activeResponse.state.message,\n                );\n              } else {\n                this.state.pushMessage(activeResponse.state.message);\n              }\n            },\n          }),\n        );\n\n      await consumeStream({\n        stream: processUIMessageStream({\n          stream,\n          onToolCall: this.onToolCall,\n          onData: this.onData,\n          messageMetadataSchema: this.messageMetadataSchema,\n          dataPartSchemas: this.dataPartSchemas,\n          runUpdateMessageJob,\n          onError: error => {\n            throw error;\n          },\n        }),\n        onError: error => {\n          throw error;\n        },\n      });\n\n      this.setStatus({ status: 'ready' });\n    } catch (err) {\n      // Ignore abort errors as they are expected.\n      if (isAbort || (err as any).name === 'AbortError') {\n        isAbort = true;\n        this.setStatus({ status: 'ready' });\n        return null;\n      }\n\n      isError = true;\n\n      // Network errors such as disconnected, timeout, etc.\n      if (\n        err instanceof TypeError &&\n        (err.message.toLowerCase().includes('fetch') ||\n          err.message.toLowerCase().includes('network'))\n      ) {\n        isDisconnect = true;\n      }\n\n      if (this.onError && err instanceof Error) {\n        this.onError(err);\n      }\n\n      this.setStatus({ status: 'error', error: err as Error });\n    } finally {\n      try {\n        this.onFinish?.({\n          message: this.activeResponse!.state.message,\n          messages: this.state.messages,\n          isAbort,\n          isDisconnect,\n          isError,\n        });\n      } catch (err) {\n        console.error(err);\n      }\n\n      this.activeResponse = undefined;\n    }\n\n    // automatically send the message if the sendAutomaticallyWhen function returns true\n    if (\n      this.sendAutomaticallyWhen?.({ messages: this.state.messages }) &&\n      !isError\n    ) {\n      await this.makeRequest({\n        trigger: 'submit-message',\n        messageId: this.lastMessage?.id,\n        metadata,\n        headers,\n        body,\n      });\n    }\n  }\n}\n", "import { FileUIPart } from './ui-messages';\n\nexport async function convertFileListToFileUIParts(\n  files: FileList | undefined,\n): Promise<Array<FileUIPart>> {\n  if (files == null) {\n    return [];\n  }\n\n  // React-native doesn't have a FileList global:\n  if (!globalThis.FileList || !(files instanceof globalThis.FileList)) {\n    throw new Error('FileList is not supported in the current environment');\n  }\n\n  return Promise.all(\n    Array.from(files).map(async file => {\n      const { name, type } = file;\n\n      const dataUrl = await new Promise<string>((resolve, reject) => {\n        const reader = new FileReader();\n        reader.onload = readerEvent => {\n          resolve(readerEvent.target?.result as string);\n        };\n        reader.onerror = error => reject(error);\n        reader.readAsDataURL(file);\n      });\n\n      return {\n        type: 'file',\n        mediaType: type,\n        filename: name,\n        url: dataUrl,\n      };\n    }),\n  );\n}\n", "import { parseJsonEventStream, ParseResult } from '@ai-sdk/provider-utils';\nimport {\n  UIMessageChunk,\n  uiMessageChunkSchema,\n} from '../ui-message-stream/ui-message-chunks';\nimport {\n  HttpChatTransport,\n  HttpChatTransportInitOptions,\n} from './http-chat-transport';\nimport { UIMessage } from './ui-messages';\n\nexport class DefaultChatTransport<\n  UI_MESSAGE extends UIMessage,\n> extends HttpChatTransport<UI_MESSAGE> {\n  constructor(options: HttpChatTransportInitOptions<UI_MESSAGE> = {}) {\n    super(options);\n  }\n\n  protected processResponseStream(\n    stream: ReadableStream<Uint8Array<ArrayBufferLike>>,\n  ): ReadableStream<UIMessageChunk> {\n    return parseJsonEventStream({\n      stream,\n      schema: uiMessageChunkSchema,\n    }).pipeThrough(\n      new TransformStream<ParseResult<UIMessageChunk>, UIMessageChunk>({\n        async transform(chunk, controller) {\n          if (!chunk.success) {\n            throw chunk.error;\n          }\n          controller.enqueue(chunk.value);\n        },\n      }),\n    );\n  }\n}\n", "import {\n  FetchFunction,\n  Resolvable,\n  normalizeHeaders,\n  resolve,\n  withUserAgentSuffix,\n  getRuntimeEnvironmentUserAgent,\n} from '@ai-sdk/provider-utils';\nimport { UIMessageChunk } from '../ui-message-stream/ui-message-chunks';\nimport { ChatTransport } from './chat-transport';\nimport { UIMessage } from './ui-messages';\nimport { VERSION } from '../version';\n\nexport type PrepareSendMessagesRequest<UI_MESSAGE extends UIMessage> = (\n  options: {\n    id: string;\n    messages: UI_MESSAGE[];\n    requestMetadata: unknown;\n    body: Record<string, any> | undefined;\n    credentials: RequestCredentials | undefined;\n    headers: HeadersInit | undefined;\n    api: string;\n  } & {\n    trigger: 'submit-message' | 'regenerate-message';\n    messageId: string | undefined;\n  },\n) =>\n  | {\n      body: object;\n      headers?: HeadersInit;\n      credentials?: RequestCredentials;\n      api?: string;\n    }\n  | PromiseLike<{\n      body: object;\n      headers?: HeadersInit;\n      credentials?: RequestCredentials;\n      api?: string;\n    }>;\n\nexport type PrepareReconnectToStreamRequest = (options: {\n  id: string;\n  requestMetadata: unknown;\n  body: Record<string, any> | undefined;\n  credentials: RequestCredentials | undefined;\n  headers: HeadersInit | undefined;\n  api: string;\n}) =>\n  | {\n      headers?: HeadersInit;\n      credentials?: RequestCredentials;\n      api?: string;\n    }\n  | PromiseLike<{\n      headers?: HeadersInit;\n      credentials?: RequestCredentials;\n      api?: string;\n    }>;\n\n/**\n * Options for the `HttpChatTransport` class.\n *\n * @param UI_MESSAGE - The type of message to be used in the chat.\n */\nexport type HttpChatTransportInitOptions<UI_MESSAGE extends UIMessage> = {\n  /**\n   * The API URL to be used for the chat transport.\n   * Defaults to '/api/chat'.\n   */\n  api?: string;\n\n  /**\n   * The credentials mode to be used for the fetch request.\n   * Possible values are: 'omit', 'same-origin', 'include'.\n   * Defaults to 'same-origin'.\n   */\n  credentials?: Resolvable<RequestCredentials>;\n\n  /**\n   * HTTP headers to be sent with the API request.\n   */\n  headers?: Resolvable<Record<string, string> | Headers>;\n\n  /**\n   * Extra body object to be sent with the API request.\n   * @example\n   * Send a `sessionId` to the API along with the messages.\n   * ```js\n   * useChat({\n   *   body: {\n   *     sessionId: '123',\n   *   }\n   * })\n   * ```\n   */\n  body?: Resolvable<object>;\n\n  /**\n  Custom fetch implementation. You can use it as a middleware to intercept requests,\n  or to provide a custom fetch implementation for e.g. testing.\n      */\n  fetch?: FetchFunction;\n\n  /**\n   * When a function is provided, it will be used\n   * to prepare the request body for the chat API. This can be useful for\n   * customizing the request body based on the messages and data in the chat.\n   *\n   * @param id The id of the chat.\n   * @param messages The current messages in the chat.\n   * @param requestBody The request body object passed in the chat request.\n   */\n  prepareSendMessagesRequest?: PrepareSendMessagesRequest<UI_MESSAGE>;\n\n  /**\n   * When a function is provided, it will be used\n   * to prepare the request body for the chat API. This can be useful for\n   * customizing the request body based on the messages and data in the chat.\n   *\n   * @param id The id of the chat.\n   * @param messages The current messages in the chat.\n   * @param requestBody The request body object passed in the chat request.\n   */\n  prepareReconnectToStreamRequest?: PrepareReconnectToStreamRequest;\n};\n\nexport abstract class HttpChatTransport<UI_MESSAGE extends UIMessage>\n  implements ChatTransport<UI_MESSAGE>\n{\n  protected api: string;\n  protected credentials: HttpChatTransportInitOptions<UI_MESSAGE>['credentials'];\n  protected headers: HttpChatTransportInitOptions<UI_MESSAGE>['headers'];\n  protected body: HttpChatTransportInitOptions<UI_MESSAGE>['body'];\n  protected fetch?: FetchFunction;\n  protected prepareSendMessagesRequest?: PrepareSendMessagesRequest<UI_MESSAGE>;\n  protected prepareReconnectToStreamRequest?: PrepareReconnectToStreamRequest;\n\n  constructor({\n    api = '/api/chat',\n    credentials,\n    headers,\n    body,\n    fetch,\n    prepareSendMessagesRequest,\n    prepareReconnectToStreamRequest,\n  }: HttpChatTransportInitOptions<UI_MESSAGE>) {\n    this.api = api;\n    this.credentials = credentials;\n    this.headers = headers;\n    this.body = body;\n    this.fetch = fetch;\n    this.prepareSendMessagesRequest = prepareSendMessagesRequest;\n    this.prepareReconnectToStreamRequest = prepareReconnectToStreamRequest;\n  }\n\n  async sendMessages({\n    abortSignal,\n    ...options\n  }: Parameters<ChatTransport<UI_MESSAGE>['sendMessages']>[0]) {\n    const resolvedBody = await resolve(this.body);\n    const resolvedHeaders = await resolve(this.headers);\n    const resolvedCredentials = await resolve(this.credentials);\n\n    const baseHeaders = {\n      ...normalizeHeaders(resolvedHeaders),\n      ...normalizeHeaders(options.headers),\n    };\n\n    const preparedRequest = await this.prepareSendMessagesRequest?.({\n      api: this.api,\n      id: options.chatId,\n      messages: options.messages,\n      body: { ...resolvedBody, ...options.body },\n      headers: baseHeaders,\n      credentials: resolvedCredentials,\n      requestMetadata: options.metadata,\n      trigger: options.trigger,\n      messageId: options.messageId,\n    });\n\n    const api = preparedRequest?.api ?? this.api;\n    const headers =\n      preparedRequest?.headers !== undefined\n        ? normalizeHeaders(preparedRequest.headers)\n        : baseHeaders;\n    const body =\n      preparedRequest?.body !== undefined\n        ? preparedRequest.body\n        : {\n            ...resolvedBody,\n            ...options.body,\n            id: options.chatId,\n            messages: options.messages,\n            trigger: options.trigger,\n            messageId: options.messageId,\n          };\n    const credentials = preparedRequest?.credentials ?? resolvedCredentials;\n\n    // avoid caching globalThis.fetch in case it is patched by other libraries\n    const fetch = this.fetch ?? globalThis.fetch;\n\n    const response = await fetch(api, {\n      method: 'POST',\n      headers: withUserAgentSuffix(\n        {\n          'Content-Type': 'application/json',\n          ...headers,\n        },\n        `ai-sdk/${VERSION}`,\n        getRuntimeEnvironmentUserAgent(),\n      ),\n      body: JSON.stringify(body),\n      credentials,\n      signal: abortSignal,\n    });\n\n    if (!response.ok) {\n      throw new Error(\n        (await response.text()) ?? 'Failed to fetch the chat response.',\n      );\n    }\n\n    if (!response.body) {\n      throw new Error('The response body is empty.');\n    }\n\n    return this.processResponseStream(response.body);\n  }\n\n  async reconnectToStream(\n    options: Parameters<ChatTransport<UI_MESSAGE>['reconnectToStream']>[0],\n  ): Promise<ReadableStream<UIMessageChunk> | null> {\n    const resolvedBody = await resolve(this.body);\n    const resolvedHeaders = await resolve(this.headers);\n    const resolvedCredentials = await resolve(this.credentials);\n\n    const baseHeaders = {\n      ...normalizeHeaders(resolvedHeaders),\n      ...normalizeHeaders(options.headers),\n    };\n\n    const preparedRequest = await this.prepareReconnectToStreamRequest?.({\n      api: this.api,\n      id: options.chatId,\n      body: { ...resolvedBody, ...options.body },\n      headers: baseHeaders,\n      credentials: resolvedCredentials,\n      requestMetadata: options.metadata,\n    });\n\n    const api = preparedRequest?.api ?? `${this.api}/${options.chatId}/stream`;\n    const headers =\n      preparedRequest?.headers !== undefined\n        ? normalizeHeaders(preparedRequest.headers)\n        : baseHeaders;\n    const credentials = preparedRequest?.credentials ?? resolvedCredentials;\n\n    // avoid caching globalThis.fetch in case it is patched by other libraries\n    const fetch = this.fetch ?? globalThis.fetch;\n\n    const response = await fetch(api, {\n      method: 'GET',\n      headers: withUserAgentSuffix(\n        headers,\n        `ai-sdk/${VERSION}`,\n        getRuntimeEnvironmentUserAgent(),\n      ),\n      credentials,\n    });\n\n    // no active stream found, so we do not resume\n    if (response.status === 204) {\n      return null;\n    }\n\n    if (!response.ok) {\n      throw new Error(\n        (await response.text()) ?? 'Failed to fetch the chat response.',\n      );\n    }\n\n    if (!response.body) {\n      throw new Error('The response body is empty.');\n    }\n\n    return this.processResponseStream(response.body);\n  }\n\n  protected abstract processResponseStream(\n    stream: ReadableStream<Uint8Array<ArrayBufferLike>>,\n  ): ReadableStream<UIMessageChunk>;\n}\n", "import { isToolOrDynamicToolUIPart, type UIMessage } from './ui-messages';\n\n/**\nCheck if the message is an assistant message with completed tool calls.\nThe last step of the message must have at least one tool invocation and\nall tool invocations must have a result.\n */\nexport function lastAssistantMessageIsCompleteWithToolCalls({\n  messages,\n}: {\n  messages: UIMessage[];\n}): boolean {\n  const message = messages[messages.length - 1];\n\n  if (!message) {\n    return false;\n  }\n\n  if (message.role !== 'assistant') {\n    return false;\n  }\n\n  const lastStepStartIndex = message.parts.reduce((lastIndex, part, index) => {\n    return part.type === 'step-start' ? index : lastIndex;\n  }, -1);\n\n  const lastStepToolInvocations = message.parts\n    .slice(lastStepStartIndex + 1)\n    .filter(isToolOrDynamicToolUIPart)\n    .filter(part => !part.providerExecuted);\n\n  return (\n    lastStepToolInvocations.length > 0 &&\n    lastStepToolInvocations.every(\n      part =>\n        part.state === 'output-available' || part.state === 'output-error',\n    )\n  );\n}\n", "import { UIMessageChunk } from '../ui-message-stream/ui-message-chunks';\n\nexport function transformTextToUiMessageStream({\n  stream,\n}: {\n  stream: ReadableStream<string>;\n}) {\n  return stream.pipeThrough(\n    new TransformStream<string, UIMessageChunk>({\n      start(controller) {\n        controller.enqueue({ type: 'start' });\n        controller.enqueue({ type: 'start-step' });\n        controller.enqueue({ type: 'text-start', id: 'text-1' });\n      },\n\n      async transform(part, controller) {\n        controller.enqueue({ type: 'text-delta', id: 'text-1', delta: part });\n      },\n\n      async flush(controller) {\n        controller.enqueue({ type: 'text-end', id: 'text-1' });\n        controller.enqueue({ type: 'finish-step' });\n        controller.enqueue({ type: 'finish' });\n      },\n    }),\n  );\n}\n", "import { UIMessageChunk } from '../ui-message-stream/ui-message-chunks';\nimport {\n  HttpChatTransport,\n  HttpChatTransportInitOptions,\n} from './http-chat-transport';\nimport { transformTextToUiMessageStream } from './transform-text-to-ui-message-stream';\nimport { UIMessage } from './ui-messages';\n\nexport class TextStreamChatTransport<\n  UI_MESSAGE extends UIMessage,\n> extends HttpChatTransport<UI_MESSAGE> {\n  constructor(options: HttpChatTransportInitOptions<UI_MESSAGE> = {}) {\n    super(options);\n  }\n\n  protected processResponseStream(\n    stream: ReadableStream<Uint8Array<ArrayBufferLike>>,\n  ): ReadableStream<UIMessageChunk> {\n    return transformTextToUiMessageStream({\n      stream: stream.pipeThrough(new TextDecoderStream()),\n    });\n  }\n}\n", "import { TypeValidationError } from '@ai-sdk/provider';\nimport {\n  lazyValidator,\n  StandardSchemaV1,\n  Tool,\n  validateTypes,\n  Validator,\n  zodSchema,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { InvalidArgumentError } from '../error';\nimport { providerMetadataSchema } from '../types/provider-metadata';\nimport {\n  DataUIPart,\n  InferUIMessageData,\n  InferUIMessageTools,\n  ToolUIPart,\n  UIMessage,\n} from './ui-messages';\n\nconst uiMessagesSchema = lazyValidator(() =>\n  zodSchema(\n    z.array(\n      z.object({\n        id: z.string(),\n        role: z.enum(['system', 'user', 'assistant']),\n        metadata: z.unknown().optional(),\n        parts: z.array(\n          z.union([\n            z.object({\n              type: z.literal('text'),\n              text: z.string(),\n              state: z.enum(['streaming', 'done']).optional(),\n              providerMetadata: providerMetadataSchema.optional(),\n            }),\n            z.object({\n              type: z.literal('reasoning'),\n              text: z.string(),\n              state: z.enum(['streaming', 'done']).optional(),\n              providerMetadata: providerMetadataSchema.optional(),\n            }),\n            z.object({\n              type: z.literal('source-url'),\n              sourceId: z.string(),\n              url: z.string(),\n              title: z.string().optional(),\n              providerMetadata: providerMetadataSchema.optional(),\n            }),\n            z.object({\n              type: z.literal('source-document'),\n              sourceId: z.string(),\n              mediaType: z.string(),\n              title: z.string(),\n              filename: z.string().optional(),\n              providerMetadata: providerMetadataSchema.optional(),\n            }),\n            z.object({\n              type: z.literal('file'),\n              mediaType: z.string(),\n              filename: z.string().optional(),\n              url: z.string(),\n              providerMetadata: providerMetadataSchema.optional(),\n            }),\n            z.object({\n              type: z.literal('step-start'),\n            }),\n            z.object({\n              type: z.string().startsWith('data-'),\n              id: z.string().optional(),\n              data: z.unknown(),\n            }),\n            z.object({\n              type: z.literal('dynamic-tool'),\n              toolName: z.string(),\n              toolCallId: z.string(),\n              state: z.literal('input-streaming'),\n              input: z.unknown().optional(),\n              providerExecuted: z.boolean().optional(),\n              output: z.never().optional(),\n              errorText: z.never().optional(),\n            }),\n            z.object({\n              type: z.literal('dynamic-tool'),\n              toolName: z.string(),\n              toolCallId: z.string(),\n              state: z.literal('input-available'),\n              input: z.unknown(),\n              providerExecuted: z.boolean().optional(),\n              output: z.never().optional(),\n              errorText: z.never().optional(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n            }),\n            z.object({\n              type: z.literal('dynamic-tool'),\n              toolName: z.string(),\n              toolCallId: z.string(),\n              state: z.literal('output-available'),\n              input: z.unknown(),\n              providerExecuted: z.boolean().optional(),\n              output: z.unknown(),\n              errorText: z.never().optional(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n              preliminary: z.boolean().optional(),\n            }),\n            z.object({\n              type: z.literal('dynamic-tool'),\n              toolName: z.string(),\n              toolCallId: z.string(),\n              state: z.literal('output-error'),\n              input: z.unknown(),\n              providerExecuted: z.boolean().optional(),\n              output: z.never().optional(),\n              errorText: z.string(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n            }),\n            z.object({\n              type: z.string().startsWith('tool-'),\n              toolCallId: z.string(),\n              state: z.literal('input-streaming'),\n              providerExecuted: z.boolean().optional(),\n              input: z.unknown().optional(),\n              output: z.never().optional(),\n              errorText: z.never().optional(),\n              approval: z.never().optional(),\n            }),\n            z.object({\n              type: z.string().startsWith('tool-'),\n              toolCallId: z.string(),\n              state: z.literal('input-available'),\n              providerExecuted: z.boolean().optional(),\n              input: z.unknown(),\n              output: z.never().optional(),\n              errorText: z.never().optional(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n              approval: z.never().optional(),\n            }),\n            z.object({\n              type: z.string().startsWith('tool-'),\n              toolCallId: z.string(),\n              state: z.literal('approval-requested'),\n              input: z.unknown(),\n              providerExecuted: z.boolean().optional(),\n              output: z.never().optional(),\n              errorText: z.never().optional(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n              approval: z.object({\n                id: z.string(),\n                approved: z.never().optional(),\n                reason: z.never().optional(),\n              }),\n            }),\n            z.object({\n              type: z.string().startsWith('tool-'),\n              toolCallId: z.string(),\n              state: z.literal('approval-responded'),\n              input: z.unknown(),\n              providerExecuted: z.boolean().optional(),\n              output: z.never().optional(),\n              errorText: z.never().optional(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n              approval: z.object({\n                id: z.string(),\n                approved: z.boolean(),\n                reason: z.string().optional(),\n              }),\n            }),\n            z.object({\n              type: z.string().startsWith('tool-'),\n              toolCallId: z.string(),\n              state: z.literal('output-available'),\n              providerExecuted: z.boolean().optional(),\n              input: z.unknown(),\n              output: z.unknown(),\n              errorText: z.never().optional(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n              preliminary: z.boolean().optional(),\n              approval: z\n                .object({\n                  id: z.string(),\n                  approved: z.literal(true),\n                  reason: z.string().optional(),\n                })\n                .optional(),\n            }),\n            z.object({\n              type: z.string().startsWith('tool-'),\n              toolCallId: z.string(),\n              state: z.literal('output-error'),\n              providerExecuted: z.boolean().optional(),\n              input: z.unknown(),\n              output: z.never().optional(),\n              errorText: z.string(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n              approval: z\n                .object({\n                  id: z.string(),\n                  approved: z.literal(true),\n                  reason: z.string().optional(),\n                })\n                .optional(),\n            }),\n            z.object({\n              type: z.string().startsWith('tool-'),\n              toolCallId: z.string(),\n              state: z.literal('output-denied'),\n              providerExecuted: z.boolean().optional(),\n              input: z.unknown(),\n              output: z.never().optional(),\n              errorText: z.never().optional(),\n              callProviderMetadata: providerMetadataSchema.optional(),\n              approval: z.object({\n                id: z.string(),\n                approved: z.literal(false),\n                reason: z.string().optional(),\n              }),\n            }),\n          ]),\n        ),\n      }),\n    ),\n  ),\n);\n\nexport type SafeValidateUIMessagesResult<UI_MESSAGE extends UIMessage> =\n  | {\n      success: true;\n      data: Array<UI_MESSAGE>;\n    }\n  | {\n      success: false;\n      error: Error;\n    };\n\n/**\n * Validates a list of UI messages like `validateUIMessages`,\n * but instead of throwing it returns `{ success: true, data }`\n * or `{ success: false, error }`.\n */\nexport async function safeValidateUIMessages<UI_MESSAGE extends UIMessage>({\n  messages,\n  metadataSchema,\n  dataSchemas,\n  tools,\n}: {\n  messages: unknown;\n  metadataSchema?:\n    | Validator<UIMessage['metadata']>\n    | StandardSchemaV1<unknown, UI_MESSAGE['metadata']>;\n  dataSchemas?: {\n    [NAME in keyof InferUIMessageData<UI_MESSAGE> & string]?:\n      | Validator<InferUIMessageData<UI_MESSAGE>[NAME]>\n      | StandardSchemaV1<unknown, InferUIMessageData<UI_MESSAGE>[NAME]>;\n  };\n  tools?: {\n    [NAME in keyof InferUIMessageTools<UI_MESSAGE> & string]?: Tool<\n      InferUIMessageTools<UI_MESSAGE>[NAME]['input'],\n      InferUIMessageTools<UI_MESSAGE>[NAME]['output']\n    >;\n  };\n}): Promise<SafeValidateUIMessagesResult<UI_MESSAGE>> {\n  try {\n    if (messages == null) {\n      return {\n        success: false,\n        error: new InvalidArgumentError({\n          parameter: 'messages',\n          value: messages,\n          message: 'messages parameter must be provided',\n        }),\n      };\n    }\n\n    const validatedMessages = await validateTypes({\n      value: messages,\n      schema: uiMessagesSchema,\n    });\n\n    if (metadataSchema) {\n      for (const message of validatedMessages) {\n        await validateTypes({\n          value: message.metadata,\n          schema: metadataSchema,\n        });\n      }\n    }\n\n    if (dataSchemas) {\n      for (const message of validatedMessages) {\n        const dataParts = message.parts.filter(part =>\n          part.type.startsWith('data-'),\n        ) as DataUIPart<InferUIMessageData<UI_MESSAGE>>[];\n\n        for (const dataPart of dataParts) {\n          const dataName = dataPart.type.slice(5);\n          const dataSchema = dataSchemas[dataName];\n\n          if (!dataSchema) {\n            return {\n              success: false,\n              error: new TypeValidationError({\n                value: dataPart.data,\n                cause: `No data schema found for data part ${dataName}`,\n              }),\n            };\n          }\n\n          await validateTypes({\n            value: dataPart.data,\n            schema: dataSchema,\n          });\n        }\n      }\n    }\n\n    if (tools) {\n      for (const message of validatedMessages) {\n        const toolParts = message.parts.filter(part =>\n          part.type.startsWith('tool-'),\n        ) as ToolUIPart<InferUIMessageTools<UI_MESSAGE>>[];\n\n        for (const toolPart of toolParts) {\n          const toolName = toolPart.type.slice(5);\n          const tool = tools[toolName];\n\n          if (!tool) {\n            return {\n              success: false,\n              error: new TypeValidationError({\n                value: toolPart.input,\n                cause: `No tool schema found for tool part ${toolName}`,\n              }),\n            };\n          }\n\n          if (\n            toolPart.state === 'input-available' ||\n            toolPart.state === 'output-available' ||\n            toolPart.state === 'output-error'\n          ) {\n            await validateTypes({\n              value: toolPart.input,\n              schema: tool.inputSchema,\n            });\n          }\n\n          if (toolPart.state === 'output-available' && tool.outputSchema) {\n            await validateTypes({\n              value: toolPart.output,\n              schema: tool.outputSchema,\n            });\n          }\n        }\n      }\n    }\n\n    return {\n      success: true,\n      data: validatedMessages as Array<UI_MESSAGE>,\n    };\n  } catch (error) {\n    const err = error as Error;\n\n    return {\n      success: false,\n      error: err,\n    };\n  }\n}\n\n/**\n * Validates a list of UI messages.\n *\n * Metadata, data parts, and generic tool call structures are only validated if\n * the corresponding schemas are provided. Otherwise, they are assumed to be\n * valid.\n */\nexport async function validateUIMessages<UI_MESSAGE extends UIMessage>({\n  messages,\n  metadataSchema,\n  dataSchemas,\n  tools,\n}: {\n  messages: unknown;\n  metadataSchema?:\n    | Validator<UIMessage['metadata']>\n    | StandardSchemaV1<unknown, UI_MESSAGE['metadata']>;\n  dataSchemas?: {\n    [NAME in keyof InferUIMessageData<UI_MESSAGE> & string]?:\n      | Validator<InferUIMessageData<UI_MESSAGE>[NAME]>\n      | StandardSchemaV1<unknown, InferUIMessageData<UI_MESSAGE>[NAME]>;\n  };\n  tools?: {\n    [NAME in keyof InferUIMessageTools<UI_MESSAGE> & string]?: Tool<\n      InferUIMessageTools<UI_MESSAGE>[NAME]['input'],\n      InferUIMessageTools<UI_MESSAGE>[NAME]['output']\n    >;\n  };\n}): Promise<Array<UI_MESSAGE>> {\n  const response = await safeValidateUIMessages({\n    messages,\n    metadataSchema,\n    dataSchemas,\n    tools,\n  });\n\n  if (!response.success) throw response.error;\n\n  return response.data;\n}\n", "import {\n  generateId as generateIdFunc,\n  getErrorMessage,\n  IdGenerator,\n} from '@ai-sdk/provider-utils';\nimport { UIMessage } from '../ui/ui-messages';\nimport { handleUIMessageStreamFinish } from './handle-ui-message-stream-finish';\nimport { InferUIMessageChunk } from './ui-message-chunks';\nimport { UIMessageStreamOnFinishCallback } from './ui-message-stream-on-finish-callback';\nimport { UIMessageStreamWriter } from './ui-message-stream-writer';\n\nexport function createUIMessageStream<UI_MESSAGE extends UIMessage>({\n  execute,\n  onError = getErrorMessage,\n  originalMessages,\n  onFinish,\n  generateId = generateIdFunc,\n}: {\n  execute: (options: {\n    writer: UIMessageStreamWriter<UI_MESSAGE>;\n  }) => Promise<void> | void;\n  onError?: (error: unknown) => string;\n\n  /**\n   * The original messages. If they are provided, persistence mode is assumed,\n   * and a message ID is provided for the response message.\n   */\n  originalMessages?: UI_MESSAGE[];\n\n  onFinish?: UIMessageStreamOnFinishCallback<UI_MESSAGE>;\n\n  generateId?: IdGenerator;\n}): ReadableStream<InferUIMessageChunk<UI_MESSAGE>> {\n  let controller!: ReadableStreamDefaultController<\n    InferUIMessageChunk<UI_MESSAGE>\n  >;\n\n  const ongoingStreamPromises: Promise<void>[] = [];\n\n  const stream = new ReadableStream({\n    start(controllerArg) {\n      controller = controllerArg;\n    },\n  });\n\n  function safeEnqueue(data: InferUIMessageChunk<UI_MESSAGE>) {\n    try {\n      controller.enqueue(data);\n    } catch (error) {\n      // suppress errors when the stream has been closed\n    }\n  }\n\n  try {\n    const result = execute({\n      writer: {\n        write(part: InferUIMessageChunk<UI_MESSAGE>) {\n          safeEnqueue(part);\n        },\n        merge(streamArg) {\n          ongoingStreamPromises.push(\n            (async () => {\n              const reader = streamArg.getReader();\n              while (true) {\n                const { done, value } = await reader.read();\n                if (done) break;\n                safeEnqueue(value);\n              }\n            })().catch(error => {\n              safeEnqueue({\n                type: 'error',\n                errorText: onError(error),\n              } as InferUIMessageChunk<UI_MESSAGE>);\n            }),\n          );\n        },\n        onError,\n      },\n    });\n\n    if (result) {\n      ongoingStreamPromises.push(\n        result.catch(error => {\n          safeEnqueue({\n            type: 'error',\n            errorText: onError(error),\n          } as InferUIMessageChunk<UI_MESSAGE>);\n        }),\n      );\n    }\n  } catch (error) {\n    safeEnqueue({\n      type: 'error',\n      errorText: onError(error),\n    } as InferUIMessageChunk<UI_MESSAGE>);\n  }\n\n  // Wait until all ongoing streams are done. This approach enables merging\n  // streams even after execute has returned, as long as there is still an\n  // open merged stream. This is important to e.g. forward new streams and\n  // from callbacks.\n  const waitForStreams: Promise<void> = new Promise(async resolve => {\n    while (ongoingStreamPromises.length > 0) {\n      await ongoingStreamPromises.shift();\n    }\n    resolve();\n  });\n\n  waitForStreams.finally(() => {\n    try {\n      controller.close();\n    } catch (error) {\n      // suppress errors when the stream has been closed\n    }\n  });\n\n  return handleUIMessageStreamFinish<UI_MESSAGE>({\n    stream,\n    messageId: generateId(),\n    originalMessages,\n    onFinish,\n    onError,\n  });\n}\n", "import { UIMessage } from '../ui/ui-messages';\nimport { UIMessageChunk } from './ui-message-chunks';\nimport {\n  createStreamingUIMessageState,\n  processUIMessageStream,\n  StreamingUIMessageState,\n} from '../ui/process-ui-message-stream';\nimport {\n  AsyncIterableStream,\n  createAsyncIterableStream,\n} from '../util/async-iterable-stream';\nimport { consumeStream } from '../util/consume-stream';\n\n/**\n * Transforms a stream of `UIMessageChunk`s into an `AsyncIterableStream` of `UIMessage`s.\n *\n * @param options.message - The last assistant message to use as a starting point when the conversation is resumed. Otherwise undefined.\n * @param options.stream - The stream of `UIMessageChunk`s to read.\n * @param options.terminateOnError - Whether to terminate the stream if an error occurs.\n * @param options.onError - A function that is called when an error occurs.\n *\n * @returns An `AsyncIterableStream` of `UIMessage`s. Each stream part is a different state of the same message\n * as it is being completed.\n */\nexport function readUIMessageStream<UI_MESSAGE extends UIMessage>({\n  message,\n  stream,\n  onError,\n  terminateOnError = false,\n}: {\n  message?: UI_MESSAGE;\n  stream: ReadableStream<UIMessageChunk>;\n  onError?: (error: unknown) => void;\n  terminateOnError?: boolean;\n}): AsyncIterableStream<UI_MESSAGE> {\n  let controller: ReadableStreamDefaultController<UI_MESSAGE> | undefined;\n  let hasErrored = false;\n\n  const outputStream = new ReadableStream<UI_MESSAGE>({\n    start(controllerParam) {\n      controller = controllerParam;\n    },\n  });\n\n  const state = createStreamingUIMessageState<UI_MESSAGE>({\n    messageId: message?.id ?? '',\n    lastMessage: message,\n  });\n\n  const handleError = (error: unknown) => {\n    onError?.(error);\n\n    if (!hasErrored && terminateOnError) {\n      hasErrored = true;\n      controller?.error(error);\n    }\n  };\n\n  consumeStream({\n    stream: processUIMessageStream({\n      stream,\n      runUpdateMessageJob(\n        job: (options: {\n          state: StreamingUIMessageState<UI_MESSAGE>;\n          write: () => void;\n        }) => Promise<void>,\n      ) {\n        return job({\n          state,\n          write: () => {\n            controller?.enqueue(structuredClone(state.message));\n          },\n        });\n      },\n      onError: handleError,\n    }),\n    onError: handleError,\n  }).finally(() => {\n    // Only close if no error occurred. Calling close() on an errored controller\n    // throws \"Invalid state: Controller is already closed\" TypeError.\n    if (!hasErrored) {\n      controller?.close();\n    }\n  });\n\n  return createAsyncIterableStream(outputStream);\n}\n", "import { useChat, type UseChatOptions } from \"@ai-sdk/react\";\nimport { getToolName, isToolUIPart } from \"ai\";\nimport type {\n  ChatInit,\n  ChatTransport,\n  UIMessage as Message,\n  UIMessage\n} from \"ai\";\nimport { DefaultChatTransport } from \"ai\";\nimport { nanoid } from \"nanoid\";\nimport { use, useCallback, useEffect, useMemo, useRef } from \"react\";\nimport type { OutgoingMessage } from \"./ai-types\";\nimport { MessageType } from \"./ai-types\";\nimport type { useAgent } from \"./react\";\n\nexport type AITool<Input = unknown, Output = unknown> = {\n  description?: string;\n  inputSchema?: unknown;\n  execute?: (input: Input) => Output | Promise<Output>;\n};\n\ntype GetInitialMessagesOptions = {\n  agent: string;\n  name: string;\n  url: string;\n};\n\n// v5 useChat parameters\ntype UseChatParams<M extends UIMessage = UIMessage> = ChatInit<M> &\n  UseChatOptions<M>;\n\n/**\n * Options for the useAgentChat hook\n */\ntype UseAgentChatOptions<\n  State,\n  ChatMessage extends UIMessage = UIMessage\n> = Omit<UseChatParams<ChatMessage>, \"fetch\"> & {\n  /** Agent connection from useAgent */\n  agent: ReturnType<typeof useAgent<State>>;\n  getInitialMessages?:\n    | undefined\n    | null\n    | ((options: GetInitialMessagesOptions) => Promise<ChatMessage[]>);\n  /** Request credentials */\n  credentials?: RequestCredentials;\n  /** Request headers */\n  headers?: HeadersInit;\n  /**\n   * @description Whether to automatically resolve tool calls that do not require human interaction.\n   * @experimental\n   */\n  experimental_automaticToolResolution?: boolean;\n  /**\n   * @description Tools object for automatic detection of confirmation requirements.\n   * Tools without execute function will require confirmation.\n   */\n  tools?: Record<string, AITool<unknown, unknown>>;\n  /**\n   * @description Manual override for tools requiring confirmation.\n   * If not provided, will auto-detect from tools object.\n   */\n  toolsRequiringConfirmation?: string[];\n  /**\n   * When true (default), automatically sends the next message only after\n   * all pending confirmation-required tool calls have been resolved.\n   * @default true\n   */\n  autoSendAfterAllConfirmationsResolved?: boolean;\n};\n\nconst requestCache = new Map<string, Promise<Message[]>>();\n\n/**\n * React hook for building AI chat interfaces using an Agent\n * @param options Chat options including the agent connection\n * @returns Chat interface controls and state with added clearHistory method\n */\n/**\n * Automatically detects which tools require confirmation based on their configuration.\n * Tools require confirmation if they have no execute function AND are not server-executed.\n * @param tools - Record of tool name to tool definition\n * @returns Array of tool names that require confirmation\n */\nexport function detectToolsRequiringConfirmation(\n  tools?: Record<string, AITool<unknown, unknown>>\n): string[] {\n  if (!tools) return [];\n\n  return Object.entries(tools)\n    .filter(([_name, tool]) => !tool.execute)\n    .map(([name]) => name);\n}\n\nexport function useAgentChat<\n  State = unknown,\n  ChatMessage extends UIMessage = UIMessage\n>(\n  options: UseAgentChatOptions<State, ChatMessage>\n): ReturnType<typeof useChat<ChatMessage>> & {\n  clearHistory: () => void;\n} {\n  const {\n    agent,\n    getInitialMessages,\n    messages: optionsInitialMessages,\n    experimental_automaticToolResolution,\n    tools,\n    toolsRequiringConfirmation: manualToolsRequiringConfirmation,\n    autoSendAfterAllConfirmationsResolved = true,\n    ...rest\n  } = options;\n\n  // Auto-detect tools requiring confirmation, or use manual override\n  const toolsRequiringConfirmation =\n    manualToolsRequiringConfirmation ?? detectToolsRequiringConfirmation(tools);\n\n  const agentUrl = new URL(\n    `${// @ts-expect-error we're using a protected _url property that includes query params\n    ((agent._url as string | null) || agent._pkurl)\n      ?.replace(\"ws://\", \"http://\")\n      .replace(\"wss://\", \"https://\")}`\n  );\n\n  agentUrl.searchParams.delete(\"_pk\");\n  const agentUrlString = agentUrl.toString();\n\n  // we need to include agent.name in cache key to prevent collisions during agent switching.\n  // The URL may be stale between updateProperties() and reconnect(), but agent.name\n  // is updated synchronously, so each thread gets its own cache entry\n  const initialMessagesCacheKey = `${agentUrlString}|${agent.agent ?? \"\"}|${agent.name ?? \"\"}`;\n\n  // Keep a ref to always point to the latest agent instance\n  const agentRef = useRef(agent);\n  useEffect(() => {\n    agentRef.current = agent;\n  }, [agent]);\n\n  async function defaultGetInitialMessagesFetch({\n    url\n  }: GetInitialMessagesOptions) {\n    const getMessagesUrl = new URL(url);\n    getMessagesUrl.pathname += \"/get-messages\";\n    const response = await fetch(getMessagesUrl.toString(), {\n      credentials: options.credentials,\n      headers: options.headers\n    });\n\n    if (!response.ok) {\n      console.warn(\n        `Failed to fetch initial messages: ${response.status} ${response.statusText}`\n      );\n      return [];\n    }\n\n    const text = await response.text();\n    if (!text.trim()) {\n      return [];\n    }\n\n    try {\n      return JSON.parse(text) as ChatMessage[];\n    } catch (error) {\n      console.warn(\"Failed to parse initial messages JSON:\", error);\n      return [];\n    }\n  }\n\n  const getInitialMessagesFetch =\n    getInitialMessages || defaultGetInitialMessagesFetch;\n\n  function doGetInitialMessages(\n    getInitialMessagesOptions: GetInitialMessagesOptions,\n    cacheKey: string\n  ) {\n    if (requestCache.has(cacheKey)) {\n      return requestCache.get(cacheKey)! as Promise<ChatMessage[]>;\n    }\n    const promise = getInitialMessagesFetch(getInitialMessagesOptions);\n    requestCache.set(cacheKey, promise);\n    return promise;\n  }\n\n  const initialMessagesPromise =\n    getInitialMessages === null\n      ? null\n      : doGetInitialMessages(\n          {\n            agent: agent.agent,\n            name: agent.name,\n            url: agentUrlString\n          },\n          initialMessagesCacheKey\n        );\n  const initialMessages = initialMessagesPromise\n    ? use(initialMessagesPromise)\n    : (optionsInitialMessages ?? []);\n\n  useEffect(() => {\n    if (!initialMessagesPromise) {\n      return;\n    }\n    requestCache.set(initialMessagesCacheKey, initialMessagesPromise!);\n    return () => {\n      if (\n        requestCache.get(initialMessagesCacheKey) === initialMessagesPromise\n      ) {\n        requestCache.delete(initialMessagesCacheKey);\n      }\n    };\n  }, [initialMessagesCacheKey, initialMessagesPromise]);\n\n  const aiFetch = useCallback(\n    async (request: RequestInfo | URL, options: RequestInit = {}) => {\n      const {\n        method,\n        keepalive,\n        headers,\n        body,\n        redirect,\n        integrity,\n        signal,\n        credentials,\n        mode,\n        referrer,\n        referrerPolicy,\n        window\n      } = options;\n      const id = nanoid(8);\n      const abortController = new AbortController();\n      let controller: ReadableStreamDefaultController;\n      const currentAgent = agentRef.current;\n\n      signal?.addEventListener(\"abort\", () => {\n        currentAgent.send(\n          JSON.stringify({\n            id,\n            type: MessageType.CF_AGENT_CHAT_REQUEST_CANCEL\n          })\n        );\n\n        // NOTE - If we wanted to, we could preserve the \"interrupted\" message here, with the code below\n        //        However, I think it might be the responsibility of the library user to implement that behavior manually?\n        //        Reasoning: This code could be subject to collisions, as it \"force saves\" the messages we have locally\n        //\n        // agent.send(JSON.stringify({\n        //   type: MessageType.CF_AGENT_CHAT_MESSAGES,\n        //   messages: ... /* some way of getting current messages ref? */\n        // }))\n\n        abortController.abort();\n        // Make sure to also close the stream (cf. https://github.com/cloudflare/agents-starter/issues/69)\n        controller.close();\n      });\n\n      currentAgent.addEventListener(\n        \"message\",\n        (event) => {\n          let data: OutgoingMessage<ChatMessage>;\n          try {\n            data = JSON.parse(event.data) as OutgoingMessage<ChatMessage>;\n          } catch (_error) {\n            // silently ignore invalid messages for now\n            // TODO: log errors with log levels\n            return;\n          }\n          if (data.type === MessageType.CF_AGENT_USE_CHAT_RESPONSE) {\n            if (data.id === id) {\n              if (data.error) {\n                controller.error(new Error(data.body));\n                abortController.abort();\n              } else {\n                // Only enqueue non-empty data to prevent JSON parsing errors\n                if (data.body?.trim()) {\n                  controller.enqueue(\n                    new TextEncoder().encode(`data: ${data.body}\\n\\n`)\n                  );\n                }\n                if (data.done) {\n                  controller.close();\n                  abortController.abort();\n                }\n              }\n            }\n          }\n        },\n        { signal: abortController.signal }\n      );\n\n      const stream = new ReadableStream({\n        start(c) {\n          controller = c;\n        }\n      });\n\n      currentAgent.send(\n        JSON.stringify({\n          id,\n          init: {\n            body,\n            credentials,\n            headers,\n            integrity,\n            keepalive,\n            method,\n            mode,\n            redirect,\n            referrer,\n            referrerPolicy,\n            window\n          },\n          type: MessageType.CF_AGENT_USE_CHAT_REQUEST,\n          url: request.toString()\n        })\n      );\n\n      return new Response(stream);\n    },\n    []\n  );\n\n  const customTransport: ChatTransport<ChatMessage> = useMemo(\n    () => ({\n      sendMessages: async (\n        options: Parameters<\n          typeof DefaultChatTransport.prototype.sendMessages\n        >[0]\n      ) => {\n        const transport = new DefaultChatTransport<ChatMessage>({\n          api: agentUrlString,\n          fetch: aiFetch\n        });\n        return transport.sendMessages(options);\n      },\n      reconnectToStream: async (\n        options: Parameters<\n          typeof DefaultChatTransport.prototype.reconnectToStream\n        >[0]\n      ) => {\n        const transport = new DefaultChatTransport<ChatMessage>({\n          api: agentUrlString,\n          fetch: aiFetch\n        });\n        return transport.reconnectToStream(options);\n      }\n    }),\n    [agentUrlString, aiFetch]\n  );\n\n  const useChatHelpers = useChat<ChatMessage>({\n    ...rest,\n    messages: initialMessages,\n    transport: customTransport,\n    id: agent._pk\n  });\n\n  const processedToolCalls = useRef(new Set<string>());\n\n  // Calculate pending confirmations for the latest assistant message\n  const lastMessage =\n    useChatHelpers.messages[useChatHelpers.messages.length - 1];\n\n  const pendingConfirmations = (() => {\n    if (!lastMessage || lastMessage.role !== \"assistant\") {\n      return { messageId: undefined, toolCallIds: new Set<string>() };\n    }\n\n    const pendingIds = new Set<string>();\n    for (const part of lastMessage.parts ?? []) {\n      if (\n        isToolUIPart(part) &&\n        part.state === \"input-available\" &&\n        toolsRequiringConfirmation.includes(getToolName(part))\n      ) {\n        pendingIds.add(part.toolCallId);\n      }\n    }\n    return { messageId: lastMessage.id, toolCallIds: pendingIds };\n  })();\n\n  const pendingConfirmationsRef = useRef(pendingConfirmations);\n  pendingConfirmationsRef.current = pendingConfirmations;\n\n  // tools can be a different object everytime it's called,\n  // which might lead to this effect being called multiple times with different tools objects.\n  // we need to fix this, but that's a bigger refactor.\n  // biome-ignore lint/correctness/useExhaustiveDependencies: we need to fix this\n  useEffect(() => {\n    if (!experimental_automaticToolResolution) {\n      return;\n    }\n\n    const lastMessage =\n      useChatHelpers.messages[useChatHelpers.messages.length - 1];\n    if (!lastMessage || lastMessage.role !== \"assistant\") {\n      return;\n    }\n\n    const toolCalls = lastMessage.parts.filter(\n      (part) =>\n        isToolUIPart(part) &&\n        part.state === \"input-available\" &&\n        !processedToolCalls.current.has(part.toolCallId)\n    );\n\n    if (toolCalls.length > 0) {\n      (async () => {\n        const toolCallsToResolve = toolCalls.filter(\n          (part) =>\n            isToolUIPart(part) &&\n            !toolsRequiringConfirmation.includes(getToolName(part)) &&\n            tools?.[getToolName(part)]?.execute // Only execute if client has execute function\n        );\n\n        if (toolCallsToResolve.length > 0) {\n          for (const part of toolCallsToResolve) {\n            if (isToolUIPart(part)) {\n              processedToolCalls.current.add(part.toolCallId);\n              let toolOutput = null;\n              const toolName = getToolName(part);\n              const tool = tools?.[toolName];\n\n              if (tool?.execute && part.input) {\n                try {\n                  toolOutput = await tool.execute(part.input);\n                } catch (error) {\n                  toolOutput = `Error executing tool: ${error instanceof Error ? error.message : String(error)}`;\n                }\n              }\n\n              await useChatHelpers.addToolResult({\n                toolCallId: part.toolCallId,\n                tool: toolName,\n                output: toolOutput\n              });\n            }\n          }\n          // If there are NO pending confirmations for the latest assistant message,\n          // we can continue the conversation. Otherwise, wait for the UI to resolve\n          // those confirmations; the addToolResult wrapper will send when the last\n          // pending confirmation is resolved.\n          if (pendingConfirmationsRef.current.toolCallIds.size === 0) {\n            useChatHelpers.sendMessage();\n          }\n        }\n      })();\n    }\n  }, [\n    useChatHelpers.messages,\n    experimental_automaticToolResolution,\n    useChatHelpers.addToolResult,\n    useChatHelpers.sendMessage,\n    toolsRequiringConfirmation\n  ]);\n\n  useEffect(() => {\n    function onClearHistory(event: MessageEvent) {\n      if (typeof event.data !== \"string\") return;\n      let data: OutgoingMessage;\n      try {\n        data = JSON.parse(event.data) as OutgoingMessage;\n      } catch (_error) {\n        return;\n      }\n      if (data.type === MessageType.CF_AGENT_CHAT_CLEAR) {\n        useChatHelpers.setMessages([]);\n      }\n    }\n\n    function onMessages(event: MessageEvent) {\n      if (typeof event.data !== \"string\") return;\n      let data: OutgoingMessage<ChatMessage>;\n      try {\n        data = JSON.parse(event.data) as OutgoingMessage<ChatMessage>;\n      } catch (_error) {\n        return;\n      }\n      if (data.type === MessageType.CF_AGENT_CHAT_MESSAGES) {\n        useChatHelpers.setMessages(data.messages);\n      }\n    }\n\n    agent.addEventListener(\"message\", onClearHistory);\n    agent.addEventListener(\"message\", onMessages);\n\n    return () => {\n      agent.removeEventListener(\"message\", onClearHistory);\n      agent.removeEventListener(\"message\", onMessages);\n    };\n  }, [agent, useChatHelpers.setMessages]);\n\n  // Wrapper that sends only when the last pending confirmation is resolved\n  const addToolResultAndSendMessage: typeof useChatHelpers.addToolResult =\n    async (args) => {\n      const { toolCallId } = args;\n\n      await useChatHelpers.addToolResult(args);\n\n      if (!autoSendAfterAllConfirmationsResolved) {\n        // always send immediately\n        useChatHelpers.sendMessage();\n        return;\n      }\n\n      // wait for all confirmations\n      const pending = pendingConfirmationsRef.current?.toolCallIds;\n      if (!pending) {\n        useChatHelpers.sendMessage();\n        return;\n      }\n\n      const wasLast = pending.size === 1 && pending.has(toolCallId);\n      if (pending.has(toolCallId)) {\n        pending.delete(toolCallId);\n      }\n\n      if (wasLast || pending.size === 0) {\n        useChatHelpers.sendMessage();\n      }\n    };\n\n  return {\n    ...useChatHelpers,\n    addToolResult: addToolResultAndSendMessage,\n    clearHistory: () => {\n      useChatHelpers.setMessages([]);\n      agent.send(\n        JSON.stringify({\n          type: MessageType.CF_AGENT_CHAT_CLEAR\n        })\n      );\n    },\n    setMessages: (\n      messages: Parameters<typeof useChatHelpers.setMessages>[0]\n    ) => {\n      useChatHelpers.setMessages(messages);\n      agent.send(\n        JSON.stringify({\n          messages: Array.isArray(messages) ? messages : [],\n          type: MessageType.CF_AGENT_CHAT_MESSAGES\n        })\n      );\n    }\n  };\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA,aAASA,UAAS,WAAW,MAAM;AAClC,UAAI,OAAO,cAAc,YAAY;AACpC,cAAM,IAAI,UAAU,2DAA2D,OAAO,SAAS,KAAK;AAAA,MACrG;AAIA,UAAI;AACJ,UAAI,eAAe;AAEnB,aAAO,SAAS,aAAa,YAAY;AACxC,qBAAa,SAAS;AAEtB,cAAM,MAAM,KAAK,IAAI;AACrB,cAAM,oBAAoB,MAAM;AAChC,cAAM,mBAAmB,OAAO;AAEhC,YAAI,oBAAoB,GAAG;AAC1B,yBAAe;AACf,oBAAU,MAAM,MAAM,UAAU;AAAA,QACjC,OAAO;AACN,sBAAY,WAAW,MAAM;AAC5B,2BAAe,KAAK,IAAI;AACxB,sBAAU,MAAM,MAAM,UAAU;AAAA,UACjC,GAAG,gBAAgB;AAAA,QACpB;AAAA,MACD;AAAA,IACD;AAEA,WAAO,UAAUA;AAAA;AAAA;;;AC7BjB;AAAA;AAAA;AAWA,KACG,WAAY;AACX,eAAS,GAAG,GAAG,GAAG;AAChB,eAAQ,MAAM,MAAM,MAAM,KAAK,IAAI,MAAM,IAAI,MAAQ,MAAM,KAAK,MAAM;AAAA,MACxE;AACA,eAAS,uBAAuB,WAAW,aAAa;AACtD,6BACE,WAAWC,OAAM,oBACf,oBAAoB,MACtB,QAAQ;AAAA,UACN;AAAA,QACF;AACF,YAAI,QAAQ,YAAY;AACxB,YAAI,CAAC,4BAA4B;AAC/B,cAAI,cAAc,YAAY;AAC9B,mBAAS,OAAO,WAAW,MACxB,QAAQ;AAAA,YACP;AAAA,UACF,GACC,6BAA6B;AAAA,QAClC;AACA,sBAAcC,UAAS;AAAA,UACrB,MAAM,EAAE,OAAc,YAAyB;AAAA,QACjD,CAAC;AACD,YAAI,OAAO,YAAY,CAAC,EAAE,MACxB,cAAc,YAAY,CAAC;AAC7B,QAAAC;AAAA,UACE,WAAY;AACV,iBAAK,QAAQ;AACb,iBAAK,cAAc;AACnB,mCAAuB,IAAI,KAAK,YAAY,EAAE,KAAW,CAAC;AAAA,UAC5D;AAAA,UACA,CAAC,WAAW,OAAO,WAAW;AAAA,QAChC;AACA,QAAAC;AAAA,UACE,WAAY;AACV,mCAAuB,IAAI,KAAK,YAAY,EAAE,KAAW,CAAC;AAC1D,mBAAO,UAAU,WAAY;AAC3B,qCAAuB,IAAI,KAAK,YAAY,EAAE,KAAW,CAAC;AAAA,YAC5D,CAAC;AAAA,UACH;AAAA,UACA,CAAC,SAAS;AAAA,QACZ;AACA,QAAAC,eAAc,KAAK;AACnB,eAAO;AAAA,MACT;AACA,eAAS,uBAAuB,MAAM;AACpC,YAAI,oBAAoB,KAAK;AAC7B,eAAO,KAAK;AACZ,YAAI;AACF,cAAI,YAAY,kBAAkB;AAClC,iBAAO,CAAC,SAAS,MAAM,SAAS;AAAA,QAClC,SAAS,OAAO;AACd,iBAAO;AAAA,QACT;AAAA,MACF;AACA,eAAS,uBAAuB,WAAW,aAAa;AACtD,eAAO,YAAY;AAAA,MACrB;AACA,sBAAgB,OAAO,kCACrB,eACE,OAAO,+BAA+B,+BACxC,+BAA+B,4BAA4B,MAAM,CAAC;AACpE,UAAIJ,SAAQ,iBACV,WAAW,eAAe,OAAO,OAAO,KAAK,OAAO,KAAK,IACzDC,YAAWD,OAAM,UACjBG,aAAYH,OAAM,WAClBE,mBAAkBF,OAAM,iBACxBI,iBAAgBJ,OAAM,eACtB,oBAAoB,OACpB,6BAA6B,OAC7B,OACE,gBAAgB,OAAO,UACvB,gBAAgB,OAAO,OAAO,YAC9B,gBAAgB,OAAO,OAAO,SAAS,gBACnC,yBACA;AACR,cAAQ,uBACN,WAAWA,OAAM,uBAAuBA,OAAM,uBAAuB;AACvE,sBAAgB,OAAO,kCACrB,eACE,OAAO,+BAA+B,8BACxC,+BAA+B,2BAA2B,MAAM,CAAC;AAAA,IACrE,GAAG;AAAA;AAAA;;;AC9FL;AAAA;AAAA;AAEA,QAAI,OAAuC;AACzC,aAAO,UAAU;AAAA,IACnB,OAAO;AACL,aAAO,UAAU;AAAA,IACnB;AAAA;AAAA;;;ACNA;AAAA;AAAA;AACA,QAAIK,aAAY,OAAO;AACvB,QAAI,mBAAmB,OAAO;AAC9B,QAAI,oBAAoB,OAAO;AAC/B,QAAI,eAAe,OAAO,UAAU;AACpC,QAAIC,YAAW,CAAC,QAAQ,QAAQ;AAC9B,eAASC,UAAQ;AACf,QAAAF,WAAU,QAAQE,QAAM,EAAE,KAAK,IAAIA,MAAI,GAAG,YAAY,KAAK,CAAC;AAAA,IAChE;AACA,QAAI,cAAc,CAAC,IAAI,MAAM,QAAQ,SAAS;AAC5C,UAAI,QAAQ,OAAO,SAAS,YAAY,OAAO,SAAS,YAAY;AAClE,iBAAS,OAAO,kBAAkB,IAAI;AACpC,cAAI,CAAC,aAAa,KAAK,IAAI,GAAG,KAAK,QAAQ;AACzC,YAAAF,WAAU,IAAI,KAAK,EAAE,KAAK,MAAM,KAAK,GAAG,GAAG,YAAY,EAAE,OAAO,iBAAiB,MAAM,GAAG,MAAM,KAAK,WAAW,CAAC;AAAA,MACvH;AACA,aAAO;AAAA,IACT;AACA,QAAI,eAAe,CAAC,QAAQ,YAAYA,WAAU,CAAC,GAAG,cAAc,EAAE,OAAO,KAAK,CAAC,GAAG,GAAG;AACzF,QAAI,sBAAsB,CAAC;AAC3B,IAAAC,UAAS,qBAAqB;AAAA,MAC5B,wBAAwB,MAAM;AAAA,MAC9B,YAAY,MAAME;AAAA,IACpB,CAAC;AACD,WAAO,UAAU,aAAa,mBAAmB;AACjD,QAAM,yBAAyB,OAAO,IAAI,yBAAyB;AACnE,aAASA,cAAa;AACpB,YAAM,aAAa;AACnB,aAAO,WAAW,sBAAsB,GAAG,MAAM,KAAK,CAAC;AAAA,IACzD;AAAA;AAAA;;;AC5BA;AAAA;AAAA;AACA,QAAIC,aAAY,OAAO;AACvB,QAAI,mBAAmB,OAAO;AAC9B,QAAI,oBAAoB,OAAO;AAC/B,QAAI,eAAe,OAAO,UAAU;AACpC,QAAIC,YAAW,CAAC,QAAQ,QAAQ;AAC9B,eAASC,UAAQ;AACf,QAAAF,WAAU,QAAQE,QAAM,EAAE,KAAK,IAAIA,MAAI,GAAG,YAAY,KAAK,CAAC;AAAA,IAChE;AACA,QAAI,cAAc,CAAC,IAAI,MAAM,QAAQ,SAAS;AAC5C,UAAI,QAAQ,OAAO,SAAS,YAAY,OAAO,SAAS,YAAY;AAClE,iBAAS,OAAO,kBAAkB,IAAI;AACpC,cAAI,CAAC,aAAa,KAAK,IAAI,GAAG,KAAK,QAAQ;AACzC,YAAAF,WAAU,IAAI,KAAK,EAAE,KAAK,MAAM,KAAK,GAAG,GAAG,YAAY,EAAE,OAAO,iBAAiB,MAAM,GAAG,MAAM,KAAK,WAAW,CAAC;AAAA,MACvH;AACA,aAAO;AAAA,IACT;AACA,QAAI,eAAe,CAAC,QAAQ,YAAYA,WAAU,CAAC,GAAG,cAAc,EAAE,OAAO,KAAK,CAAC,GAAG,GAAG;AACzF,QAAI,wBAAwB,CAAC;AAC7B,IAAAC,UAAS,uBAAuB;AAAA,MAC9B,YAAY,MAAM,mBAAmB;AAAA,MACrC,oBAAoB,MAAME;AAAA,MAC1B,wBAAwB,MAAM;AAAA,IAChC,CAAC;AACD,WAAO,UAAU,aAAa,qBAAqB;AACnD,QAAI,qBAAqB;AACzB,mBAAeA,sBAAqB;AAClC,aAAO;AAAA,IACT;AACA,aAAS,yBAAyB;AAChC,aAAO;AAAA,IACT;AAAA;AAAA;;;AC/BO,IAAM,cACX;;;ACoBK,IAAI,SAAS,CAAC,OAAO,OAAO;AACjC,MAAI,KAAK;AACT,MAAI,QAAQ,OAAO,gBAAgB,IAAI,WAAY,QAAQ,CAAE,CAAC;AAC9D,SAAO,QAAQ;AACb,UAAM,YAAkB,MAAM,IAAI,IAAI,EAAE;AAAA,EAC1C;AACA,SAAO;AACT;;;ACtBA,IAAAC,gBAAqE;AENrE,wBAA6B;ACK7B,IAAAC,gBAAgE;;;AELhE,IAAAC,gBAAmE;AACnE,kBAAqC;;;ACArC,mBAA6G;;;ACD7G;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAAM,cAAc;AACpB,IAAM,kBAAkB;AACxB,IAAM,eAAe;AACrB,IAAM,yBAAyB;;;ACH/B,IAAI,MAAM,OAAO,UAAU;AAEpB,SAAS,OAAO,KAAK,KAAK;AAChC,MAAI,MAAM;AACV,MAAI,QAAQ,IAAK,QAAO;AAExB,MAAI,OAAO,QAAQ,OAAK,IAAI,iBAAiB,IAAI,aAAa;AAC7D,QAAI,SAAS,KAAM,QAAO,IAAI,QAAQ,MAAM,IAAI,QAAQ;AACxD,QAAI,SAAS,OAAQ,QAAO,IAAI,SAAS,MAAM,IAAI,SAAS;AAE5D,QAAI,SAAS,OAAO;AACnB,WAAK,MAAI,IAAI,YAAY,IAAI,QAAQ;AACpC,eAAO,SAAS,OAAO,IAAI,GAAG,GAAG,IAAI,GAAG,CAAC,EAAE;AAAA,MAC5C;AACA,aAAO,QAAQ;AAAA,IAChB;AAEA,QAAI,CAAC,QAAQ,OAAO,QAAQ,UAAU;AACrC,YAAM;AACN,WAAK,QAAQ,KAAK;AACjB,YAAI,IAAI,KAAK,KAAK,IAAI,KAAK,EAAE,OAAO,CAAC,IAAI,KAAK,KAAK,IAAI,EAAG,QAAO;AACjE,YAAI,EAAE,QAAQ,QAAQ,CAAC,OAAO,IAAI,IAAI,GAAG,IAAI,IAAI,CAAC,EAAG,QAAO;AAAA,MAC7D;AACA,aAAO,OAAO,KAAK,GAAG,EAAE,WAAW;AAAA,IACpC;AAAA,EACD;AAEA,SAAO,QAAQ,OAAO,QAAQ;AAC/B;;;AFtBA,IAAM,iBAAiB,oBAAI,QAAQ;AAGnC,IAAM,OAAO,MAAI;AAAC;AAKlB,IAAM;AAAA;AAAA,EAA8B,KAAK;AAAA;AACzC,IAAM,SAAS;AACf,IAAM,cAAc,CAAC,MAAI,MAAM;AAC/B,IAAM,aAAa,CAAC,MAAI,OAAO,KAAK;AACpC,IAAM,eAAe,CAAC,GAAG,OAAK;AAAA,EACtB,GAAG;AAAA,EACH,GAAG;AACP;AACJ,IAAM,gBAAgB,CAAC,MAAI,WAAW,EAAE,IAAI;AAE5C,IAAM,cAAc,CAAC;AACrB,IAAM,gBAAgB,CAAC;AACvB,IAAM,gBAAgB;AAEtB,IAAM,kBAAkB,OAAO,UAAU;AACzC,IAAM,oBAAoB,OAAO,YAAY;AAC7C,IAAM,eAAe,mBAAmB,UAAU;AAClD,IAAM,2BAA2B,MAAI,mBAAmB,OAAO,OAAO,uBAAuB,KAAK;AAClG,IAAM,oBAAoB,CAACC,QAAO,QAAM;AACpC,QAAM,QAAQ,eAAe,IAAIA,MAAK;AACtC,SAAO;AAAA;AAAA,IAEH,MAAI,CAAC,YAAY,GAAG,KAAKA,OAAM,IAAI,GAAG,KAAK;AAAA;AAAA,IAE3C,CAAC,SAAO;AACJ,UAAI,CAAC,YAAY,GAAG,GAAG;AACnB,cAAM,OAAOA,OAAM,IAAI,GAAG;AAG1B,YAAI,EAAE,OAAO,gBAAgB;AACzB,wBAAc,GAAG,IAAI;AAAA,QACzB;AACA,cAAM,CAAC,EAAE,KAAK,aAAa,MAAM,IAAI,GAAG,QAAQ,WAAW;AAAA,MAC/D;AAAA,IACJ;AAAA;AAAA,IAEA,MAAM,CAAC;AAAA;AAAA,IAEP,MAAI;AACA,UAAI,CAAC,YAAY,GAAG,GAAG;AAEnB,YAAI,OAAO,cAAe,QAAO,cAAc,GAAG;AAAA,MACtD;AAEA,aAAO,CAAC,YAAY,GAAG,KAAKA,OAAM,IAAI,GAAG,KAAK;AAAA,IAClD;AAAA,EACJ;AACJ;AASI,IAAI,SAAS;AACjB,IAAM,WAAW,MAAI;AAErB,IAAM,CAAC,eAAe,cAAc,IAAI,mBAAmB,OAAO,mBAAmB;AAAA,EACjF,OAAO,iBAAiB,KAAK,MAAM;AAAA,EACnC,OAAO,oBAAoB,KAAK,MAAM;AAC1C,IAAI;AAAA,EACA;AAAA,EACA;AACJ;AACA,IAAM,YAAY,MAAI;AAClB,QAAM,kBAAkB,qBAAqB,SAAS;AACtD,SAAO,YAAY,eAAe,KAAK,oBAAoB;AAC/D;AACA,IAAM,YAAY,CAAC,aAAW;AAE1B,MAAI,mBAAmB;AACnB,aAAS,iBAAiB,oBAAoB,QAAQ;AAAA,EAC1D;AACA,gBAAc,SAAS,QAAQ;AAC/B,SAAO,MAAI;AACP,QAAI,mBAAmB;AACnB,eAAS,oBAAoB,oBAAoB,QAAQ;AAAA,IAC7D;AACA,mBAAe,SAAS,QAAQ;AAAA,EACpC;AACJ;AACA,IAAM,gBAAgB,CAAC,aAAW;AAE9B,QAAM,WAAW,MAAI;AACjB,aAAS;AACT,aAAS;AAAA,EACb;AAEA,QAAM,YAAY,MAAI;AAClB,aAAS;AAAA,EACb;AACA,gBAAc,UAAU,QAAQ;AAChC,gBAAc,WAAW,SAAS;AAClC,SAAO,MAAI;AACP,mBAAe,UAAU,QAAQ;AACjC,mBAAe,WAAW,SAAS;AAAA,EACvC;AACJ;AACA,IAAM,SAAS;AAAA,EACX;AAAA,EACA;AACJ;AACA,IAAM,uBAAuB;AAAA,EACzB;AAAA,EACA;AACJ;AAEA,IAAM,kBAAkB,CAAC,aAAAC,QAAM;AAC/B,IAAM,YAAY,CAAC,mBAAmB;AAEtC,IAAM,MAAM,CAAC,MAAI,yBAAyB,IAAI,OAAO,uBAAuB,EAAE,CAAC,IAAI,WAAW,GAAG,CAAC;AAIlG,IAAM,4BAA4B,YAAY,yBAAY;AAE1D,IAAM,sBAAsB,OAAO,cAAc,eAAe,UAAU;AAE1E,IAAM,iBAAiB,CAAC,aAAa,wBAAwB;AAAA,EACzD;AAAA,EACA;AACJ,EAAE,SAAS,oBAAoB,aAAa,KAAK,oBAAoB;AAMrE,IAAM,QAAQ,oBAAI,QAAQ;AAC1B,IAAM,cAAc,CAAC,UAAQ,OAAO,UAAU,SAAS,KAAK,KAAK;AACjE,IAAM,mBAAmB,CAAC,UAAU,SAAO,aAAa,WAAW,IAAI;AAEvE,IAAI,UAAU;AASd,IAAM,aAAa,CAAC,QAAM;AACtB,QAAM,OAAO,OAAO;AACpB,QAAM,WAAW,YAAY,GAAG;AAChC,QAAM,SAAS,iBAAiB,UAAU,MAAM;AAChD,QAAM,UAAU,iBAAiB,UAAU,QAAQ;AACnD,QAAM,gBAAgB,iBAAiB,UAAU,QAAQ;AACzD,MAAI;AACJ,MAAI;AACJ,MAAI,OAAO,GAAG,MAAM,OAAO,CAAC,UAAU,CAAC,SAAS;AAG5C,aAAS,MAAM,IAAI,GAAG;AACtB,QAAI,OAAQ,QAAO;AAInB,aAAS,EAAE,UAAU;AACrB,UAAM,IAAI,KAAK,MAAM;AACrB,QAAI,MAAM,QAAQ,GAAG,GAAG;AAEpB,eAAS;AACT,WAAI,QAAQ,GAAG,QAAQ,IAAI,QAAQ,SAAQ;AACvC,kBAAU,WAAW,IAAI,KAAK,CAAC,IAAI;AAAA,MACvC;AACA,YAAM,IAAI,KAAK,MAAM;AAAA,IACzB;AACA,QAAI,eAAe;AAEf,eAAS;AACT,YAAM,OAAO,OAAO,KAAK,GAAG,EAAE,KAAK;AACnC,aAAM,CAAC,YAAY,QAAQ,KAAK,IAAI,CAAC,GAAE;AACnC,YAAI,CAAC,YAAY,IAAI,KAAK,CAAC,GAAG;AAC1B,oBAAU,QAAQ,MAAM,WAAW,IAAI,KAAK,CAAC,IAAI;AAAA,QACrD;AAAA,MACJ;AACA,YAAM,IAAI,KAAK,MAAM;AAAA,IACzB;AAAA,EACJ,OAAO;AACH,aAAS,SAAS,IAAI,OAAO,IAAI,QAAQ,WAAW,IAAI,SAAS,IAAI,QAAQ,WAAW,KAAK,UAAU,GAAG,IAAI,KAAK;AAAA,EACvH;AACA,SAAO;AACX;AAEA,IAAM,YAAY,CAAC,QAAM;AACrB,MAAI,WAAW,GAAG,GAAG;AACjB,QAAI;AACA,YAAM,IAAI;AAAA,IACd,SAAS,KAAK;AAEV,YAAM;AAAA,IACV;AAAA,EACJ;AAGA,QAAM,OAAO;AAEb,QAAM,OAAO,OAAO,WAAW,OAAO,MAAM,QAAQ,GAAG,IAAI,IAAI,SAAS,OAAO,WAAW,GAAG,IAAI;AACjG,SAAO;AAAA,IACH;AAAA,IACA;AAAA,EACJ;AACJ;AAGA,IAAI,cAAc;AAClB,IAAM,eAAe,MAAI,EAAE;AAE3B,eAAe,kBAAkB,MAAM;AACnC,QAAM,CAACD,QAAO,MAAM,OAAO,KAAK,IAAI;AAGpC,QAAM,UAAU,aAAa;AAAA,IACzB,eAAe;AAAA,IACf,cAAc;AAAA,EAClB,GAAG,OAAO,UAAU,YAAY;AAAA,IAC5B,YAAY;AAAA,EAChB,IAAI,SAAS,CAAC,CAAC;AACf,MAAI,gBAAgB,QAAQ;AAC5B,QAAM,wBAAwB,QAAQ;AACtC,MAAI,iBAAiB,QAAQ;AAC7B,QAAM,kBAAkB,CAAC,UAAQ;AAC7B,WAAO,OAAO,0BAA0B,aAAa,sBAAsB,KAAK,IAAI,0BAA0B;AAAA,EAClH;AACA,QAAM,eAAe,QAAQ;AAG7B,MAAI,WAAW,IAAI,GAAG;AAClB,UAAM,YAAY;AAClB,UAAM,cAAc,CAAC;AACrB,UAAM,KAAKA,OAAM,KAAK;AACtB,eAAW,OAAO,IAAG;AACjB;AAAA;AAAA,QACA,CAAC,iBAAiB,KAAK,GAAG,KAAK,UAAUA,OAAM,IAAI,GAAG,EAAE,EAAE;AAAA,QAAG;AACzD,oBAAY,KAAK,GAAG;AAAA,MACxB;AAAA,IACJ;AACA,WAAO,QAAQ,IAAI,YAAY,IAAI,WAAW,CAAC;AAAA,EACnD;AACA,SAAO,YAAY,IAAI;AACvB,iBAAe,YAAY,IAAI;AAE3B,UAAM,CAAC,GAAG,IAAI,UAAU,EAAE;AAC1B,QAAI,CAAC,IAAK;AACV,UAAM,CAAC,KAAK,GAAG,IAAI,kBAAkBA,QAAO,GAAG;AAC/C,UAAM,CAAC,oBAAoB,UAAU,OAAO,OAAO,IAAI,eAAe,IAAIA,MAAK;AAC/E,UAAM,kBAAkB,MAAI;AACxB,YAAM,eAAe,mBAAmB,GAAG;AAC3C,YAAM,aAAa,WAAW,QAAQ,UAAU,IAAI,QAAQ,WAAW,IAAI,EAAE,MAAM,EAAE,IAAI,QAAQ,eAAe;AAChH,UAAI,YAAY;AAGZ,eAAO,MAAM,GAAG;AAChB,eAAO,QAAQ,GAAG;AAClB,YAAI,gBAAgB,aAAa,CAAC,GAAG;AACjC,iBAAO,aAAa,CAAC,EAAmB,YAAY,EAAE,KAAK,MAAI,IAAI,EAAE,IAAI;AAAA,QAC7E;AAAA,MACJ;AACA,aAAO,IAAI,EAAE;AAAA,IACjB;AAEA,QAAI,KAAK,SAAS,GAAG;AAEjB,aAAO,gBAAgB;AAAA,IAC3B;AACA,QAAI,OAAO;AACX,QAAI;AACJ,QAAI,UAAU;AAEd,UAAM,mBAAmB,aAAa;AACtC,aAAS,GAAG,IAAI;AAAA,MACZ;AAAA,MACA;AAAA,IACJ;AACA,UAAM,oBAAoB,CAAC,YAAY,cAAc;AACrD,UAAM,QAAQ,IAAI;AAIlB,UAAM,gBAAgB,MAAM;AAC5B,UAAM,cAAc,MAAM;AAC1B,UAAM,gBAAgB,YAAY,WAAW,IAAI,gBAAgB;AAEjE,QAAI,mBAAmB;AACnB,uBAAiB,WAAW,cAAc,IAAI,eAAe,eAAe,aAAa,IAAI;AAE7F,UAAI;AAAA,QACA,MAAM;AAAA,QACN,IAAI;AAAA,MACR,CAAC;AAAA,IACL;AACA,QAAI,WAAW,IAAI,GAAG;AAElB,UAAI;AACA,eAAO,KAAK,aAAa;AAAA,MAC7B,SAAS,KAAK;AAEV,gBAAQ;AACR,kBAAU;AAAA,MACd;AAAA,IACJ;AAEA,QAAI,QAAQ,cAAc,IAAI,GAAG;AAG7B,aAAO,MAAM,KAAK,MAAM,CAAC,QAAM;AAC3B,gBAAQ;AACR,kBAAU;AAAA,MACd,CAAC;AAID,UAAI,qBAAqB,SAAS,GAAG,EAAE,CAAC,GAAG;AACvC,YAAI,QAAS,OAAM;AACnB,eAAO;AAAA,MACX,WAAW,WAAW,qBAAqB,gBAAgB,KAAK,GAAG;AAG/D,wBAAgB;AAEhB,YAAI;AAAA,UACA,MAAM;AAAA,UACN,IAAI;AAAA,QACR,CAAC;AAAA,MACL;AAAA,IACJ;AAEA,QAAI,eAAe;AACf,UAAI,CAAC,SAAS;AAEV,YAAI,WAAW,aAAa,GAAG;AAC3B,gBAAM,qBAAqB,cAAc,MAAM,aAAa;AAC5D,cAAI;AAAA,YACA,MAAM;AAAA,YACN,OAAO;AAAA,YACP,IAAI;AAAA,UACR,CAAC;AAAA,QACL,OAAO;AAEH,cAAI;AAAA,YACA;AAAA,YACA,OAAO;AAAA,YACP,IAAI;AAAA,UACR,CAAC;AAAA,QACL;AAAA,MACJ;AAAA,IACJ;AAEA,aAAS,GAAG,EAAE,CAAC,IAAI,aAAa;AAEhC,YAAQ,QAAQ,gBAAgB,CAAC,EAAE,KAAK,MAAI;AAGxC,UAAI;AAAA,QACA,IAAI;AAAA,MACR,CAAC;AAAA,IACL,CAAC;AAED,QAAI,SAAS;AACT,UAAI,aAAc,OAAM;AACxB;AAAA,IACJ;AACA,WAAO;AAAA,EACX;AACJ;AAEA,IAAM,oBAAoB,CAAC,cAAc,SAAO;AAC5C,aAAU,OAAO,cAAa;AAC1B,QAAI,aAAa,GAAG,EAAE,CAAC,EAAG,cAAa,GAAG,EAAE,CAAC,EAAE,IAAI;AAAA,EACvD;AACJ;AACA,IAAM,YAAY,CAAC,UAAU,YAAU;AAMnC,MAAI,CAAC,eAAe,IAAI,QAAQ,GAAG;AAC/B,UAAM,OAAO,aAAa,sBAAsB,OAAO;AAGvD,UAAM,qBAAqB,uBAAO,OAAO,IAAI;AAC7C,UAAME,UAAS,eAAe,KAAK,WAAW,QAAQ;AACtD,QAAI,UAAU;AACd,UAAM,gBAAgB,uBAAO,OAAO,IAAI;AACxC,UAAM,YAAY,CAAC,KAAK,aAAW;AAC/B,YAAM,OAAO,cAAc,GAAG,KAAK,CAAC;AACpC,oBAAc,GAAG,IAAI;AACrB,WAAK,KAAK,QAAQ;AAClB,aAAO,MAAI,KAAK,OAAO,KAAK,QAAQ,QAAQ,GAAG,CAAC;AAAA,IACpD;AACA,UAAM,SAAS,CAAC,KAAK,OAAO,SAAO;AAC/B,eAAS,IAAI,KAAK,KAAK;AACvB,YAAM,OAAO,cAAc,GAAG;AAC9B,UAAI,MAAM;AACN,mBAAW,MAAM,MAAK;AAClB,aAAG,OAAO,IAAI;AAAA,QAClB;AAAA,MACJ;AAAA,IACJ;AACA,UAAM,eAAe,MAAI;AACrB,UAAI,CAAC,eAAe,IAAI,QAAQ,GAAG;AAE/B,uBAAe,IAAI,UAAU;AAAA,UACzB;AAAA,UACA,uBAAO,OAAO,IAAI;AAAA,UAClB,uBAAO,OAAO,IAAI;AAAA,UAClB,uBAAO,OAAO,IAAI;AAAA,UAClBA;AAAA,UACA;AAAA,UACA;AAAA,QACJ,CAAC;AACD,YAAI,CAAC,WAAW;AAOZ,gBAAM,eAAe,KAAK,UAAU,WAAW,KAAK,WAAW,kBAAkB,KAAK,WAAW,oBAAqC,WAAW,CAAC,CAAC;AACnJ,gBAAM,mBAAmB,KAAK,cAAc,WAAW,KAAK,WAAW,kBAAkB,KAAK,WAAW,oBAAqC,eAAe,CAAC,CAAC;AAC/J,oBAAU,MAAI;AACV,4BAAgB,aAAa;AAC7B,gCAAoB,iBAAiB;AAIrC,2BAAe,OAAO,QAAQ;AAAA,UAClC;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ;AACA,iBAAa;AAMb,WAAO;AAAA,MACH;AAAA,MACAA;AAAA,MACA;AAAA,MACA;AAAA,IACJ;AAAA,EACJ;AACA,SAAO;AAAA,IACH;AAAA,IACA,eAAe,IAAI,QAAQ,EAAE,CAAC;AAAA,EAClC;AACJ;AAGA,IAAM,eAAe,CAAC,GAAG,IAAI,QAAQ,YAAY,SAAO;AACpD,QAAM,gBAAgB,OAAO;AAC7B,QAAM,oBAAoB,KAAK;AAE/B,QAAM,UAAU,CAAC,GAAG,KAAK,OAAO,IAAI,QAAQ,MAAM,oBAAoB,IAAI,oBAAoB,OAAO,OAAO;AAC5G,MAAI,CAAC,YAAY,aAAa,KAAK,oBAAoB,eAAe;AAClE;AAAA,EACJ;AACA,aAAW,YAAY,SAAS,IAAI;AACxC;AACA,IAAM,UAAU;AAEhB,IAAM,CAAC,OAAO,MAAM,IAAI,UAAU,oBAAI,IAAI,CAAC;AAE3C,IAAM,gBAAgB;AAAA,EAAa;AAAA;AAAA,IAE/B,eAAe;AAAA,IACf,WAAW;AAAA,IACX,SAAS;AAAA,IACT;AAAA,IACA,aAAa;AAAA;AAAA,IAEb,mBAAmB;AAAA,IACnB,uBAAuB;AAAA,IACvB,mBAAmB;AAAA,IACnB,oBAAoB;AAAA;AAAA,IAEpB,oBAAoB,iBAAiB,MAAQ;AAAA,IAC7C,uBAAuB,IAAI;AAAA,IAC3B,kBAAkB,IAAI;AAAA,IACtB,gBAAgB,iBAAiB,MAAO;AAAA;AAAA,IAExC;AAAA,IACA,UAAU,MAAI;AAAA,IACd;AAAA,IACA;AAAA,IACA,UAAU,CAAC;AAAA,EACf;AAAA;AAAA,EACA;AAAM;AAEN,IAAM,eAAe,CAAC,GAAG,MAAI;AAEzB,QAAM,IAAI,aAAa,GAAG,CAAC;AAE3B,MAAI,GAAG;AACH,UAAM,EAAE,KAAK,IAAI,UAAU,GAAG,IAAI;AAClC,UAAM,EAAE,KAAK,IAAI,UAAU,GAAG,IAAI;AAClC,QAAI,MAAM,IAAI;AACV,QAAE,MAAM,GAAG,OAAO,EAAE;AAAA,IACxB;AACA,QAAI,MAAM,IAAI;AACV,QAAE,WAAW,aAAa,IAAI,EAAE;AAAA,IACpC;AAAA,EACJ;AACA,SAAO;AACX;AAEA,IAAM,uBAAmB,4BAAc,CAAC,CAAC;AACzC,IAAM,YAAY,CAAC,UAAQ;AACvB,QAAM,EAAE,MAAM,IAAI;AAClB,QAAM,mBAAe,yBAAW,gBAAgB;AAChD,QAAM,qBAAqB,WAAW,KAAK;AAC3C,QAAM,aAAS,sBAAQ,MAAI,qBAAqB,MAAM,YAAY,IAAI,OAAO;AAAA,IACzE;AAAA,IACA;AAAA,IACA;AAAA,EACJ,CAAC;AAED,QAAM,qBAAiB,sBAAQ,MAAI,qBAAqB,SAAS,aAAa,cAAc,MAAM,GAAG;AAAA,IACjG;AAAA,IACA;AAAA,IACA;AAAA,EACJ,CAAC;AAED,QAAM,WAAW,UAAU,OAAO;AAElC,QAAM,sBAAkB,qBAAO,SAAS;AACxC,MAAI,YAAY,CAAC,gBAAgB,SAAS;AACtC,oBAAgB,UAAU,UAAU,SAAS,eAAe,SAAS,KAAK,GAAG,MAAM;AAAA,EACvF;AACA,QAAM,eAAe,gBAAgB;AAErC,MAAI,cAAc;AACd,mBAAe,QAAQ,aAAa,CAAC;AACrC,mBAAe,SAAS,aAAa,CAAC;AAAA,EAC1C;AAEA,4BAA0B,MAAI;AAC1B,QAAI,cAAc;AACd,mBAAa,CAAC,KAAK,aAAa,CAAC,EAAE;AACnC,aAAO,aAAa,CAAC;AAAA,IACzB;AAAA,EACJ,GAAG,CAAC,CAAC;AACL,aAAO,4BAAc,iBAAiB,UAAU,aAAa,OAAO;AAAA,IAChE,OAAO;AAAA,EACX,CAAC,CAAC;AACN;;;AGnjBA,IAAM,kBAAkB;;;ACMxB,IAAAC,gBAA2C;AAI3C,IAAM,iBAAiB,mBAAmB,OAAO;AACjD,IAAM,MAAM,iBAAiB,OAAO,uBAAuB,CAAC;AAC5D,IAAM,gBAAgB,MAAI;AACtB,MAAI,gBAAgB;AAEhB,WAAO,yBAAyB,cAAAC;AAAA,EACpC;AACJ;AAEA,IAAM,YAAY,CAAC,SAAO;AACtB,SAAO,WAAW,KAAK,CAAC,CAAC,IAAI;AAAA,IACzB,KAAK,CAAC;AAAA,IACN,KAAK,CAAC;AAAA,IACN,KAAK,CAAC,KAAK,CAAC;AAAA,EAChB,IAAI;AAAA,IACA,KAAK,CAAC;AAAA,IACN;AAAA,KACC,KAAK,CAAC,MAAM,OAAO,KAAK,CAAC,IAAI,KAAK,CAAC,MAAM,CAAC;AAAA,EAC/C;AACJ;AAEA,IAAM,eAAe,MAAI;AACrB,QAAM,mBAAe,0BAAW,gBAAgB;AAChD,QAAM,mBAAe,uBAAQ,MAAI,aAAa,eAAe,YAAY,GAAG;AAAA,IACxE;AAAA,EACJ,CAAC;AACD,SAAO;AACX;AAWA,IAAM,aAAa,CAAC,eAAa,CAAC,MAAM,UAAU,WAAS;AAEnD,QAAM,UAAU,aAAa,IAAI,SAAO;AACpC,UAAM,CAAC,GAAG,IAAI,UAAU,IAAI;AAC5B,UAAM,CAAC,EAAE,EAAE,EAAE,OAAO,IAAI,eAAe,IAAI,KAAK;AAChD,QAAI,IAAI,WAAW,eAAe,GAAG;AAGjC,aAAO,SAAS,GAAG,IAAI;AAAA,IAC3B;AACA,UAAM,MAAM,QAAQ,GAAG;AACvB,QAAI,YAAY,GAAG,EAAG,QAAO,SAAS,GAAG,IAAI;AAC7C,WAAO,QAAQ,GAAG;AAClB,WAAO;AAAA,EACX;AACA,SAAO,WAAW,MAAM,SAAS,MAAM;AAC3C;AAEJ,IAAM,sBAAsB,IAAI,OAAO,UAAU;AAIjD,IAAM,WAAW,CAAC,SAAO;AACrB,SAAO,SAAS,cAAc,MAAM;AAEhC,UAAM,iBAAiB,aAAa;AAEpC,UAAM,CAAC,KAAK,IAAI,OAAO,IAAI,UAAU,IAAI;AAEzC,UAAM,SAAS,aAAa,gBAAgB,OAAO;AAEnD,QAAI,OAAO;AACX,UAAM,EAAE,KAAAC,KAAI,IAAI;AAChB,UAAMC,eAAcD,QAAO,CAAC,GAAG,OAAO,mBAAmB;AACzD,aAAQ,IAAIC,YAAW,QAAQ,OAAK;AAChC,aAAOA,YAAW,CAAC,EAAE,IAAI;AAAA,IAC7B;AACA,WAAO,KAAK,KAAK,MAAM,OAAO,WAAW,MAAM,MAAM;AAAA,EACzD;AACJ;AAIA,IAAM,oBAAoB,CAAC,KAAK,WAAW,aAAW;AAClD,QAAM,oBAAoB,UAAU,GAAG,MAAM,UAAU,GAAG,IAAI,CAAC;AAC/D,oBAAkB,KAAK,QAAQ;AAC/B,SAAO,MAAI;AACP,UAAM,QAAQ,kBAAkB,QAAQ,QAAQ;AAChD,QAAI,SAAS,GAAG;AAEZ,wBAAkB,KAAK,IAAI,kBAAkB,kBAAkB,SAAS,CAAC;AACzE,wBAAkB,IAAI;AAAA,IAC1B;AAAA,EACJ;AACJ;AAcA,cAAc;;;AL9Gd,IAAMC,QAAO,MAAI;AAAC;AAKlB,IAAMC;AAAA;AAAA,EAA8BD,MAAK;AAAA;AAwFzC,IAAME,OAAM,cAAAC,QAAM;AAAA;AAAA;AAAA;AAAA,CAIjB,CAAC,aAAW;AACT,UAAO,SAAS,QAAO;AAAA,IACnB,KAAK;AACD,YAAM;AAAA,IACV,KAAK;AACD,aAAO,SAAS;AAAA,IACpB,KAAK;AACD,YAAM,SAAS;AAAA,IACnB;AACI,eAAS,SAAS;AAClB,eAAS,KAAK,CAAC,MAAI;AACf,iBAAS,SAAS;AAClB,iBAAS,QAAQ;AAAA,MACrB,GAAG,CAAC,MAAI;AACJ,iBAAS,SAAS;AAClB,iBAAS,SAAS;AAAA,MACtB,CAAC;AACD,YAAM;AAAA,EACd;AACJ;AACA,IAAM,cAAc;AAAA,EAChB,QAAQ;AACZ;AACA,IAAM,gBAAgB,QAAQ,QAAQ,SAAW;AACjD,IAAM,gBAAgB,CAAC,MAAM,SAAS,WAAS;AAC3C,QAAM,EAAE,OAAAC,QAAO,SAAAC,UAAS,UAAU,cAAc,mBAAmB,mBAAmB,iBAAiB,mBAAmB,oBAAoB,iBAAiB,IAAI;AACnK,QAAM,CAAC,oBAAoB,UAAU,OAAO,OAAO,IAAI,eAAe,IAAID,MAAK;AAK/E,QAAM,CAAC,KAAK,KAAK,IAAI,UAAY,IAAI;AAErC,QAAM,wBAAoB,sBAAO,KAAK;AAGtC,QAAM,mBAAe,sBAAO,KAAK;AAEjC,QAAM,aAAS,sBAAO,GAAG;AACzB,QAAM,iBAAa,sBAAO,OAAO;AACjC,QAAM,gBAAY,sBAAO,MAAM;AAC/B,QAAM,YAAY,MAAI,UAAU;AAChC,QAAM,WAAW,MAAI,UAAU,EAAE,UAAU,KAAK,UAAU,EAAE,SAAS;AACrE,QAAM,CAAC,UAAU,UAAU,gBAAgB,eAAe,IAAI,kBAAkBA,QAAO,GAAG;AAC1F,QAAM,wBAAoB,sBAAO,CAAC,CAAC,EAAE;AAGrC,QAAM,WAAW,YAAc,YAAY,IAAI,YAAc,OAAO,QAAQ,IAAI,YAAc,OAAO,SAAS,GAAG,IAAI;AACrH,QAAM,UAAU,CAAC,MAAM,YAAU;AAC7B,eAAU,KAAK,mBAAkB;AAC7B,YAAM,IAAI;AACV,UAAI,MAAM,QAAQ;AACd,YAAI,CAACC,SAAQ,KAAK,CAAC,GAAG,QAAQ,CAAC,CAAC,GAAG;AAC/B,cAAI,CAAC,YAAc,KAAK,CAAC,CAAC,GAAG;AACzB,mBAAO;AAAA,UACX;AACA,cAAI,CAACA,SAAQ,cAAc,QAAQ,CAAC,CAAC,GAAG;AACpC,mBAAO;AAAA,UACX;AAAA,QACJ;AAAA,MACJ,OAAO;AACH,YAAI,QAAQ,CAAC,MAAM,KAAK,CAAC,GAAG;AACxB,iBAAO;AAAA,QACX;AAAA,MACJ;AAAA,IACJ;AACA,WAAO;AAAA,EACX;AACA,QAAM,kBAAc,uBAAQ,MAAI;AAC5B,UAAM,sBAAsB,MAAI;AAC5B,UAAI,CAAC,IAAK,QAAO;AACjB,UAAI,CAAC,QAAS,QAAO;AAErB,UAAI,CAAC,YAAc,iBAAiB,EAAG,QAAO;AAE9C,UAAI,UAAU,EAAE,SAAS,EAAG,QAAO;AACnC,UAAI,SAAU,QAAO;AACrB,aAAO,sBAAsB;AAAA,IACjC,GAAG;AAEH,UAAM,mBAAmB,CAAC,UAAQ;AAE9B,YAAM,WAAW,aAAa,KAAK;AACnC,aAAO,SAAS;AAChB,UAAI,CAAC,oBAAoB;AACrB,eAAO;AAAA,MACX;AACA,aAAO;AAAA,QACH,cAAc;AAAA,QACd,WAAW;AAAA,QACX,GAAG;AAAA,MACP;AAAA,IACJ;AACA,UAAMC,cAAa,SAAS;AAC5B,UAAM,cAAc,gBAAgB;AACpC,UAAM,iBAAiB,iBAAiBA,WAAU;AAClD,UAAM,iBAAiBA,gBAAe,cAAc,iBAAiB,iBAAiB,WAAW;AAIjG,QAAI,oBAAoB;AACxB,WAAO;AAAA,MACH,MAAI;AACA,cAAM,cAAc,iBAAiB,SAAS,CAAC;AAC/C,cAAM,gBAAgB,QAAQ,aAAa,iBAAiB;AAC5D,YAAI,eAAe;AAWf,4BAAkB,OAAO,YAAY;AACrC,4BAAkB,YAAY,YAAY;AAC1C,4BAAkB,eAAe,YAAY;AAC7C,4BAAkB,QAAQ,YAAY;AACtC,iBAAO;AAAA,QACX,OAAO;AACH,8BAAoB;AACpB,iBAAO;AAAA,QACX;AAAA,MACJ;AAAA,MACA,MAAI;AAAA,IACR;AAAA,EAEJ,GAAG;AAAA,IACCF;AAAA,IACA;AAAA,EACJ,CAAC;AAED,QAAM,aAAS,sCAAqB;AAAA,IAAY,CAAC,aAAW,eAAe,KAAK,CAAC,SAAS,SAAO;AACzF,UAAI,CAAC,QAAQ,MAAM,OAAO,EAAG,UAAS;AAAA,IAC1C,CAAC;AAAA;AAAA,IACL;AAAA,MACIA;AAAA,MACA;AAAA,IACJ;AAAA,EAAC,GAAG,YAAY,CAAC,GAAG,YAAY,CAAC,CAAC;AAClC,QAAM,iBAAiB,CAAC,kBAAkB;AAC1C,QAAM,iBAAiB,mBAAmB,GAAG,KAAK,mBAAmB,GAAG,EAAE,SAAS;AACnF,QAAM,aAAa,OAAO;AAC1B,QAAM,OAAO,YAAc,UAAU,IAAI,YAAY,cAAc,QAAQ,IAAIF,KAAI,QAAQ,IAAI,WAAW;AAC1G,QAAM,QAAQ,OAAO;AAErB,QAAM,mBAAe,sBAAO,IAAI;AAChC,QAAM,eAAe,mBAAmB,YAAc,UAAU,IAAI,YAAc,aAAa,OAAO,IAAI,OAAO,aAAa,UAAU,aAAa;AAIrJ,QAAM,+BAA+B,MAAI;AAErC,QAAI,kBAAkB,CAAC,YAAc,KAAK,EAAG,QAAO;AAEpD,QAAI,kBAAkB,CAAC,YAAc,iBAAiB,EAAG,QAAO;AAEhE,QAAI,UAAU,EAAE,SAAS,EAAG,QAAO;AAInC,QAAI,SAAU,QAAO,YAAc,IAAI,IAAI,QAAQ;AAGnD,WAAO,YAAc,IAAI,KAAK;AAAA,EAClC,GAAG;AAGH,QAAM,yBAAyB,CAAC,EAAE,OAAO,WAAW,kBAAkB;AACtE,QAAM,eAAe,YAAc,OAAO,YAAY,IAAI,yBAAyB,OAAO;AAC1F,QAAM,YAAY,YAAc,OAAO,SAAS,IAAI,yBAAyB,OAAO;AAGpF,QAAM,iBAAa;AAAA,IAAY,OAAO,mBAAiB;AACnD,YAAM,iBAAiB,WAAW;AAClC,UAAI,CAAC,OAAO,CAAC,kBAAkB,aAAa,WAAW,UAAU,EAAE,SAAS,GAAG;AAC3E,eAAO;AAAA,MACX;AACA,UAAI;AACJ,UAAI;AACJ,UAAI,UAAU;AACd,YAAM,OAAO,kBAAkB,CAAC;AAGhC,YAAM,wBAAwB,CAAC,MAAM,GAAG,KAAK,CAAC,KAAK;AAWlD,YAAM,oBAAoB,MAAI;AAC3B,YAAI,iBAAiB;AACjB,iBAAO,CAAC,aAAa,WAAW,QAAQ,OAAO,WAAW,kBAAkB;AAAA,QAChF;AACA,eAAO,QAAQ,OAAO;AAAA,MAC1B;AAEA,YAAM,aAAa;AAAA,QACf,cAAc;AAAA,QACd,WAAW;AAAA,MACf;AACA,YAAM,8BAA8B,MAAI;AACpC,iBAAS,UAAU;AAAA,MACvB;AACA,YAAM,eAAe,MAAI;AAErB,cAAM,cAAc,MAAM,GAAG;AAC7B,YAAI,eAAe,YAAY,CAAC,MAAM,SAAS;AAC3C,iBAAO,MAAM,GAAG;AAAA,QACpB;AAAA,MACJ;AAEA,YAAM,eAAe;AAAA,QACjB,cAAc;AAAA,MAClB;AAGA,UAAI,YAAc,SAAS,EAAE,IAAI,GAAG;AAChC,qBAAa,YAAY;AAAA,MAC7B;AACA,UAAI;AACA,YAAI,uBAAuB;AACvB,mBAAS,YAAY;AAGrB,cAAI,OAAO,kBAAkB,YAAc,SAAS,EAAE,IAAI,GAAG;AACzD,uBAAW,MAAI;AACX,kBAAI,WAAW,kBAAkB,GAAG;AAChC,0BAAU,EAAE,cAAc,KAAK,MAAM;AAAA,cACzC;AAAA,YACJ,GAAG,OAAO,cAAc;AAAA,UAC5B;AAGA,gBAAM,GAAG,IAAI;AAAA,YACT,eAAe,KAAK;AAAA,YACpB,aAAa;AAAA,UACjB;AAAA,QACJ;AAGA;AACA,SAAC,SAAS,OAAO,IAAI,MAAM,GAAG;AAC9B,kBAAU,MAAM;AAChB,YAAI,uBAAuB;AAGvB,qBAAW,cAAc,OAAO,gBAAgB;AAAA,QACpD;AAOA,YAAI,CAAC,MAAM,GAAG,KAAK,MAAM,GAAG,EAAE,CAAC,MAAM,SAAS;AAC1C,cAAI,uBAAuB;AACvB,gBAAI,kBAAkB,GAAG;AACrB,wBAAU,EAAE,YAAY,GAAG;AAAA,YAC/B;AAAA,UACJ;AACA,iBAAO;AAAA,QACX;AAEA,mBAAW,QAAQ;AAanB,cAAM,eAAe,SAAS,GAAG;AACjC,YAAI,CAAC,YAAc,YAAY;AAAA,SAC9B,WAAW,aAAa,CAAC;AAAA,QAC1B,WAAW,aAAa,CAAC;AAAA,QACzB,aAAa,CAAC,MAAM,IAAI;AACpB,sCAA4B;AAC5B,cAAI,uBAAuB;AACvB,gBAAI,kBAAkB,GAAG;AACrB,wBAAU,EAAE,YAAY,GAAG;AAAA,YAC/B;AAAA,UACJ;AACA,iBAAO;AAAA,QACX;AAGA,cAAM,YAAY,SAAS,EAAE;AAG7B,mBAAW,OAAOG,SAAQ,WAAW,OAAO,IAAI,YAAY;AAE5D,YAAI,uBAAuB;AACvB,cAAI,kBAAkB,GAAG;AACrB,sBAAU,EAAE,UAAU,SAAS,KAAK,MAAM;AAAA,UAC9C;AAAA,QACJ;AAAA,MACJ,SAAS,KAAK;AACV,qBAAa;AACb,cAAM,gBAAgB,UAAU;AAChC,cAAM,EAAE,mBAAmB,IAAI;AAE/B,YAAI,CAAC,cAAc,SAAS,GAAG;AAE3B,qBAAW,QAAQ;AAGnB,cAAI,yBAAyB,kBAAkB,GAAG;AAC9C,0BAAc,QAAQ,KAAK,KAAK,aAAa;AAC7C,gBAAI,uBAAuB,QAAQ,WAAa,kBAAkB,KAAK,mBAAmB,GAAG,GAAG;AAC5F,kBAAI,CAAC,UAAU,EAAE,qBAAqB,CAAC,UAAU,EAAE,yBAAyB,SAAS,GAAG;AAIpF,8BAAc,aAAa,KAAK,KAAK,eAAe,CAAC,UAAQ;AACzD,wBAAM,eAAe,mBAAmB,GAAG;AAC3C,sBAAI,gBAAgB,aAAa,CAAC,GAAG;AACjC,iCAAa,CAAC,EAAE,eAAiB,wBAAwB,KAAK;AAAA,kBAClE;AAAA,gBACJ,GAAG;AAAA,kBACC,aAAa,KAAK,cAAc,KAAK;AAAA,kBACrC,QAAQ;AAAA,gBACZ,CAAC;AAAA,cACL;AAAA,YACJ;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ;AAEA,gBAAU;AAEV,kCAA4B;AAC5B,aAAO;AAAA,IACX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAWA;AAAA,MACI;AAAA,MACAD;AAAA,IACJ;AAAA,EAAC;AAGD,QAAM,kBAAc;AAAA;AAAA,IACpB,IAAI,SAAO;AACP,aAAO,eAAeA,QAAO,OAAO,SAAS,GAAG,IAAI;AAAA,IACxD;AAAA;AAAA,IACA,CAAC;AAAA,EAAC;AAEF,4BAA0B,MAAI;AAC1B,eAAW,UAAU;AACrB,cAAU,UAAU;AAGpB,QAAI,CAAC,YAAc,UAAU,GAAG;AAC5B,mBAAa,UAAU;AAAA,IAC3B;AAAA,EACJ,CAAC;AAED,4BAA0B,MAAI;AAC1B,QAAI,CAAC,IAAK;AACV,UAAM,iBAAiB,WAAW,KAAK,WAAa,WAAW;AAC/D,QAAI,yBAAyB;AAC7B,QAAI,UAAU,EAAE,mBAAmB;AAC/B,YAAM,UAAU,KAAK,IAAI;AACzB,+BAAyB,UAAU,UAAU,EAAE;AAAA,IACnD;AAGA,UAAM,eAAe,CAAC,MAAM,OAAO,CAAC,MAAI;AACpC,UAAI,QAAQ,eAAiB,aAAa;AACtC,cAAM,MAAM,KAAK,IAAI;AACrB,YAAI,UAAU,EAAE,qBAAqB,MAAM,0BAA0B,SAAS,GAAG;AAC7E,mCAAyB,MAAM,UAAU,EAAE;AAC3C,yBAAe;AAAA,QACnB;AAAA,MACJ,WAAW,QAAQ,eAAiB,iBAAiB;AACjD,YAAI,UAAU,EAAE,yBAAyB,SAAS,GAAG;AACjD,yBAAe;AAAA,QACnB;AAAA,MACJ,WAAW,QAAQ,eAAiB,cAAc;AAC9C,eAAO,WAAW;AAAA,MACtB,WAAW,QAAQ,eAAiB,wBAAwB;AACxD,eAAO,WAAW,IAAI;AAAA,MAC1B;AACA;AAAA,IACJ;AACA,UAAM,cAAc,kBAAkB,KAAK,oBAAoB,YAAY;AAE3E,iBAAa,UAAU;AACvB,WAAO,UAAU;AACjB,sBAAkB,UAAU;AAE5B,aAAS;AAAA,MACL,IAAI;AAAA,IACR,CAAC;AAED,QAAI,6BAA6B;AAG7B,UAAI,CAAC,MAAM,GAAG,GAAG;AACb,YAAI,YAAc,IAAI,KAAK,WAAW;AAElC,yBAAe;AAAA,QACnB,OAAO;AAGH,cAAI,cAAc;AAAA,QACtB;AAAA,MACJ;AAAA,IACJ;AACA,WAAO,MAAI;AAEP,mBAAa,UAAU;AACvB,kBAAY;AAAA,IAChB;AAAA,EACJ,GAAG;AAAA,IACC;AAAA,EACJ,CAAC;AAED,4BAA0B,MAAI;AAC1B,QAAI;AACJ,aAAS,OAAO;AAGZ,YAAM,WAAW,WAAa,eAAe,IAAI,gBAAgB,SAAS,EAAE,IAAI,IAAI;AAIpF,UAAI,YAAY,UAAU,IAAI;AAC1B,gBAAQ,WAAW,SAAS,QAAQ;AAAA,MACxC;AAAA,IACJ;AACA,aAAS,UAAU;AAGf,UAAI,CAAC,SAAS,EAAE,UAAU,qBAAqB,UAAU,EAAE,UAAU,OAAO,sBAAsB,UAAU,EAAE,SAAS,IAAI;AACvH,mBAAW,WAAW,EAAE,KAAK,IAAI;AAAA,MACrC,OAAO;AAEH,aAAK;AAAA,MACT;AAAA,IACJ;AACA,SAAK;AACL,WAAO,MAAI;AACP,UAAI,OAAO;AACP,qBAAa,KAAK;AAClB,gBAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ,GAAG;AAAA,IACC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ,CAAC;AAED,mCAAc,YAAY;AAK1B,MAAI,UAAU;AACV,UAAM,kBAAkB,OAAO,YAAc,IAAI;AAIjD,QAAI,CAAC,mBAAmB,aAAa,iBAAiB;AAClD,YAAM,IAAI,MAAM,uDAAuD;AAAA,IAC3E;AAEA,QAAI,iBAAiB;AACjB,iBAAW,UAAU;AACrB,gBAAU,UAAU;AACpB,mBAAa,UAAU;AAAA,IAC3B;AACA,UAAM,MAAM,QAAQ,GAAG;AACvB,UAAM,YAAY,CAAC,YAAc,GAAG,KAAK,kBAAkB,YAAY,GAAG,IAAI;AAC9E,IAAAF,KAAI,SAAS;AACb,QAAI,CAAC,YAAc,KAAK,KAAK,iBAAiB;AAC1C,YAAM;AAAA,IACV;AACA,UAAM,eAAe,kBAAkB,WAAW,WAAW,IAAI;AACjE,QAAI,CAAC,YAAc,YAAY,KAAK,iBAAiB;AAEjD,mBAAa,SAAS;AAEtB,mBAAa,QAAQ;AAAA,IACzB;AACA,IAAAA,KAAI,YAAY;AAAA,EACpB;AACA,QAAM,cAAc;AAAA,IAChB,QAAQ;AAAA,IACR,IAAI,OAAQ;AACR,wBAAkB,OAAO;AACzB,aAAO;AAAA,IACX;AAAA,IACA,IAAI,QAAS;AACT,wBAAkB,QAAQ;AAC1B,aAAO;AAAA,IACX;AAAA,IACA,IAAI,eAAgB;AAChB,wBAAkB,eAAe;AACjC,aAAO;AAAA,IACX;AAAA,IACA,IAAI,YAAa;AACb,wBAAkB,YAAY;AAC9B,aAAO;AAAA,IACX;AAAA,EACJ;AACA,SAAO;AACX;AACA,IAAMK,aAAY,OAAS,eAAe,WAAa,gBAAgB;AAAA,EACnE,OAAO;AACX,CAAC;AAeG,IAAM,SAAS,SAAS,aAAa;;;AD7nBzC,IAAAC,gBAAqD;;;;;;;;;;;;;;;;;;;AFX9C,SAAS,SACd,IACA,QACG;AACH,SAAO,UAAU,WAAO,kBAAAC,SAAiB,IAAI,MAAM,IAAI;AACzD;ADPA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAAA,IAAA;AAGA,IAAM,iBAAN,MAEA;EASE,YAAY,kBAAgC,CAAC,GAAG;AARhD,iBAAA,MAAA,WAAA,MAAA;AACA,iBAAA,MAAA,SAAsB,OAAA;AACtB,iBAAA,MAAA,QAA4B,MAAA;AAE5B,iBAAA,MAAA,oBAAqB,oBAAI,IAAgB,CAAA;AACzC,iBAAA,MAAA,kBAAmB,oBAAI,IAAgB,CAAA;AACvC,iBAAA,MAAA,iBAAkB,oBAAI,IAAgB,CAAA;AAiCtC,SAAA,cAAc,CAAC,YAAwB;AACrC,mBAAA,MAAK,WAAY,aAAA,MAAK,SAAA,EAAU,OAAO,OAAO,CAAA;AAC9C,mBAAA,MAAK,sBAAA,EAAL,KAAA,IAAA;IACF;AAEA,SAAA,aAAa,MAAM;AACjB,mBAAA,MAAK,WAAY,aAAA,MAAK,SAAA,EAAU,MAAM,GAAG,EAAE,CAAA;AAC3C,mBAAA,MAAK,sBAAA,EAAL,KAAA,IAAA;IACF;AAEA,SAAA,iBAAiB,CAAC,OAAe,YAAwB;AACvD,mBAAA,MAAK,WAAY;QACf,GAAG,aAAA,MAAK,SAAA,EAAU,MAAM,GAAG,KAAK;;QAEhC,KAAK,SAAS,OAAO;QACrB,GAAG,aAAA,MAAK,SAAA,EAAU,MAAM,QAAQ,CAAC;MACnC,CAAA;AACA,mBAAA,MAAK,sBAAA,EAAL,KAAA,IAAA;IACF;AAEA,SAAA,WAAW,CAAI,UAAgB,gBAAgB,KAAK;AAEpD,SAAA,2BAAA,IAA8B,CAC5B,UACA,mBACiB;AACjB,YAAM,WAAW,iBACb,SAAS,UAAU,cAAc,IACjC;AACJ,mBAAA,MAAK,kBAAA,EAAmB,IAAI,QAAQ;AACpC,aAAO,MAAM;AACX,qBAAA,MAAK,kBAAA,EAAmB,OAAO,QAAQ;MACzC;IACF;AAEA,SAAA,yBAAA,IAA4B,CAAC,aAAuC;AAClE,mBAAA,MAAK,gBAAA,EAAiB,IAAI,QAAQ;AAClC,aAAO,MAAM;AACX,qBAAA,MAAK,gBAAA,EAAiB,OAAO,QAAQ;MACvC;IACF;AAEA,SAAA,wBAAA,IAA2B,CAAC,aAAuC;AACjE,mBAAA,MAAK,eAAA,EAAgB,IAAI,QAAQ;AACjC,aAAO,MAAM;AACX,qBAAA,MAAK,eAAA,EAAgB,OAAO,QAAQ;MACtC;IACF;AAEA,iBAAA,MAAA,wBAAyB,MAAM;AAC7B,mBAAA,MAAK,kBAAA,EAAmB,QAAQ,CAAA,aAAY,SAAS,CAAC;IACxD,CAAA;AAEA,iBAAA,MAAA,sBAAuB,MAAM;AAC3B,mBAAA,MAAK,gBAAA,EAAiB,QAAQ,CAAA,aAAY,SAAS,CAAC;IACtD,CAAA;AAEA,iBAAA,MAAA,qBAAsB,MAAM;AAC1B,mBAAA,MAAK,eAAA,EAAgB,QAAQ,CAAA,aAAY,SAAS,CAAC;IACrD,CAAA;AAzFE,iBAAA,MAAK,WAAY,eAAA;EACnB;EAEA,IAAI,SAAqB;AACvB,WAAO,aAAA,MAAK,OAAA;EACd;EAEA,IAAI,OAAO,WAAuB;AAChC,iBAAA,MAAK,SAAU,SAAA;AACf,iBAAA,MAAK,oBAAA,EAAL,KAAA,IAAA;EACF;EAEA,IAAI,QAA2B;AAC7B,WAAO,aAAA,MAAK,MAAA;EACd;EAEA,IAAI,MAAM,UAA6B;AACrC,iBAAA,MAAK,QAAS,QAAA;AACd,iBAAA,MAAK,mBAAA,EAAL,KAAA,IAAA;EACF;EAEA,IAAI,WAAyB;AAC3B,WAAO,aAAA,MAAK,SAAA;EACd;EAEA,IAAI,SAAS,aAA2B;AACtC,iBAAA,MAAK,WAAY,CAAC,GAAG,WAAW,CAAA;AAChC,iBAAA,MAAK,sBAAA,EAAL,KAAA,IAAA;EACF;AA8DF;AAnGE,YAAA,oBAAA,QAAA;AACA,UAAA,oBAAA,QAAA;AACA,SAAA,oBAAA,QAAA;AAEA,qBAAA,oBAAA,QAAA;AACA,mBAAA,oBAAA,QAAA;AACA,kBAAA,oBAAA,QAAA;AAkFA,yBAAA,oBAAA,QAAA;AAIA,uBAAA,oBAAA,QAAA;AAIA,sBAAA,oBAAA,QAAA;AAtGF,IAAA;AA2GO,IAAM,OAAN,cAEG,aAAyB;EAGjC,YAAY,EAAE,UAAU,GAAG,KAAK,GAAyB;AACvD,UAAM,QAAQ,IAAI,eAAe,QAAQ;AACzC,UAAM,EAAE,GAAG,MAAM,MAAM,CAAC;AAJ1B,iBAAA,MAAA,QAAA,MAAA;AAQA,SAAA,2BAAA,IAA8B,CAC5B,UACA,mBAEA,aAAA,MAAK,MAAA,EAAO,2BAA2B,EAAE,UAAU,cAAc;AAEnE,SAAA,yBAAA,IAA4B,CAAC,aAC3B,aAAA,MAAK,MAAA,EAAO,yBAAyB,EAAE,QAAQ;AAEjD,SAAA,wBAAA,IAA2B,CAAC,aAC1B,aAAA,MAAK,MAAA,EAAO,wBAAwB,EAAE,QAAQ;AAb9C,iBAAA,MAAK,QAAS,KAAA;EAChB;AAaF;AAnBE,SAAA,oBAAA,QAAA;ADtDK,SAAS,QAAkD;EAChE,uBAAuB;EACvB,SAAS;EACT,GAAG;AACL,IAAgC,CAAC,GAA+B;AAC9D,QAAM,cAAU;IACd,UAAU,UAAU,QAAQ,OAAO,IAAI,KAAK,OAAO;EACrD;AAEA,QAAM,qBACH,UAAU,WAAW,QAAQ,SAAS,QAAQ,WAC9C,QAAQ,WAAW,QAAQ,QAAQ,OAAO,QAAQ;AAErD,MAAI,oBAAoB;AACtB,YAAQ,UAAU,UAAU,UAAU,QAAQ,OAAO,IAAI,KAAK,OAAO;EACvE;AAEA,QAAM,YAAY,QAAQ,UAAU,QAAQ,KAAK;AAEjD,QAAM,0BAAsB;IAC1B,CAAC,WACC,QAAQ,QAAQ,2BAA2B,EAAE,QAAQ,cAAc;;;IAGrE,CAAC,gBAAgB,SAAS;EAC5B;AAEA,QAAM,eAAW;IACf;IACA,MAAM,QAAQ,QAAQ;IACtB,MAAM,QAAQ,QAAQ;EACxB;AAEA,QAAM,aAAS;IACb,QAAQ,QAAQ,yBAAyB;IACzC,MAAM,QAAQ,QAAQ;IACtB,MAAM,QAAQ,QAAQ;EACxB;AAEA,QAAM,YAAQ;IACZ,QAAQ,QAAQ,wBAAwB;IACxC,MAAM,QAAQ,QAAQ;IACtB,MAAM,QAAQ,QAAQ;EACxB;AAEA,QAAM,kBAAc;IAClB,CACE,kBACG;AACH,UAAI,OAAO,kBAAkB,YAAY;AACvC,wBAAgB,cAAc,QAAQ,QAAQ,QAAQ;MACxD;AACA,cAAQ,QAAQ,WAAW;IAC7B;IACA,CAAC,OAAO;EACV;AAEA,+BAAU,MAAM;AACd,QAAI,QAAQ;AACV,cAAQ,QAAQ,aAAa;IAC/B;EACF,GAAG,CAAC,QAAQ,OAAO,CAAC;AAEpB,SAAO;IACL,IAAI,QAAQ,QAAQ;IACpB;IACA;IACA,aAAa,QAAQ,QAAQ;IAC7B,YAAY,QAAQ,QAAQ;IAC5B,YAAY,QAAQ,QAAQ;IAC5B,MAAM,QAAQ,QAAQ;IACtB;IACA,cAAc,QAAQ,QAAQ;IAC9B;;;;IAIA,eAAe,QAAQ,QAAQ;IAC/B,eAAe,QAAQ,QAAQ;EACjC;AACF;;;AWxIO,SAAS,kBACX,SACiC;AACpC,SAAO,QAAQ;IACb,CAAC,iBAAiB,oBAAoB;MACpC,GAAG;MACH,GAAI,kBAAA,OAAA,iBAAkB,CAAC;IACzB;IACA,CAAC;EACH;AACF;AGJO,SAAS,uBAAuB,UAAoB;AACzD,SAAO,OAAO,YAAoB,CAAC,GAAG,SAAS,OAAO,CAAC;AACzD;ACIO,IAAM,oBAAoB,CAAC;EAChC;EACA,OAAO;EACP,WAAW;EACX,YAAY;AACd,IAKI,CAAC,MAAmB;AACtB,QAAM,YAAY,MAAM;AACtB,UAAM,iBAAiB,SAAS;AAChC,UAAM,QAAQ,IAAI,MAAM,IAAI;AAC5B,aAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,YAAM,CAAC,IAAI,SAAU,KAAK,OAAO,IAAI,iBAAkB,CAAC;IAC1D;AACA,WAAO,MAAM,KAAK,EAAE;EACtB;AAEA,MAAI,UAAU,MAAM;AAClB,WAAO;EACT;AAGA,MAAI,SAAS,SAAS,SAAS,GAAG;AAChC,UAAM,IAAI,qBAAqB;MAC7B,UAAU;MACV,SAAS,kBAAkB,SAAS,uCAAuC,QAAQ;IACrF,CAAC;EACH;AAEA,SAAO,MAAM,GAAG,MAAM,GAAG,SAAS,GAAG,UAAU,CAAC;AAClD;AAWO,IAAM,aAAa,kBAAkB;AIxDrC,SAASC,cAAa,OAAgC;AAC3D,UACG,iBAAiB,SAAS,iBAAiB,kBAC3C,MAAM,SAAS,gBACd,MAAM,SAAS;EACf,MAAM,SAAS;AAErB;ADJA,IAAM,8BAA8B,CAAC,gBAAgB,iBAAiB;AAE/D,SAAS,iBAAiB;EAC/B;EACA;EACA;AACF,GAIG;AACD,MAAIA,cAAa,KAAK,GAAG;AACvB,WAAO;EACT;AAGA,MACE,iBAAiB,aACjB,4BAA4B,SAAS,MAAM,QAAQ,YAAY,CAAC,GAChE;AACA,UAAM,QAAS,MAAc;AAE7B,QAAI,SAAS,MAAM;AAEjB,aAAO,IAAI,aAAa;QACtB,SAAS,0BAA0B,MAAM,OAAO;QAChD;QACA;QACA;QACA,aAAa;;MACf,CAAC;IACH;EACF;AAEA,SAAO;AACT;AEtCO,SAAS,+BACd,gBAAqB,YACb;AAFV,MAAAC,MAAAC,KAAA;AAIE,MAAI,cAAc,QAAQ;AACxB,WAAO;EACT;AAGA,OAAID,OAAA,cAAc,cAAd,OAAA,SAAAA,KAAyB,WAAW;AACtC,WAAO,WAAW,cAAc,UAAU,UAAU,YAAY,CAAC;EACnE;AAGA,OAAI,MAAAC,MAAA,cAAc,YAAd,OAAA,SAAAA,IAAuB,aAAvB,OAAA,SAAA,GAAiC,MAAM;AACzC,WAAO,mBAAmB,cAAc,QAAQ,QAAQ,UAAU,CAAC,CAAC;EACtE;AAEA,MAAI,cAAc,aAAa;AAC7B,WAAO;EACT;AAEA,SAAO;AACT;AChBO,SAAS,iBACd,SAKwB;AACxB,MAAI,WAAW,MAAM;AACnB,WAAO,CAAC;EACV;AAEA,QAAM,aAAqC,CAAC;AAE5C,MAAI,mBAAmB,SAAS;AAC9B,YAAQ,QAAQ,CAAC,OAAO,QAAQ;AAC9B,iBAAW,IAAI,YAAY,CAAC,IAAI;IAClC,CAAC;EACH,OAAO;AACL,QAAI,CAAC,MAAM,QAAQ,OAAO,GAAG;AAC3B,gBAAU,OAAO,QAAQ,OAAO;IAClC;AAEA,eAAW,CAAC,KAAK,KAAK,KAAK,SAAS;AAClC,UAAI,SAAS,MAAM;AACjB,mBAAW,IAAI,YAAY,CAAC,IAAI;MAClC;IACF;EACF;AAEA,SAAO;AACT;ACzBO,SAAS,oBACd,YACG,sBACqB;AACxB,QAAM,oBAAoB,IAAI,QAAQ,iBAAiB,OAAO,CAAC;AAE/D,QAAM,yBAAyB,kBAAkB,IAAI,YAAY,KAAK;AAEtE,oBAAkB;IAChB;IACA,CAAC,wBAAwB,GAAG,oBAAoB,EAAE,OAAO,OAAO,EAAE,KAAK,GAAG;EAC5E;AAEA,SAAO,OAAO,YAAY,kBAAkB,QAAQ,CAAC;AACvD;ACxBO,IAAM,UACX,OACI,WACA;ANMN,IAAM,mBAAmB,MAAM,WAAW;AAEnC,IAAM,aAAa,OAAU;EAClC;EACA,UAAU,CAAC;EACX;EACA;EACA;EACA,OAAAC,SAAQ,iBAAiB;AAC3B,MAOM;AACJ,MAAI;AACF,UAAM,WAAW,MAAMA,OAAM,KAAK;MAChC,QAAQ;MACR,SAAS;QACP;QACA,yBAAyB,OAAO;QAChC,+BAA+B;MACjC;MACA,QAAQ;IACV,CAAC;AAED,UAAM,kBAAkB,uBAAuB,QAAQ;AAEvD,QAAI,CAAC,SAAS,IAAI;AAChB,UAAI;AAKJ,UAAI;AACF,2BAAmB,MAAM,sBAAsB;UAC7C;UACA;UACA,mBAAmB,CAAC;QACtB,CAAC;MACH,SAAS,OAAO;AACd,YAAIH,cAAa,KAAK,KAAKI,aAAa,WAAW,KAAK,GAAG;AACzD,gBAAM;QACR;AAEA,cAAM,IAAIA,aAAa;UACrB,SAAS;UACT,OAAO;UACP,YAAY,SAAS;UACrB;UACA;UACA,mBAAmB,CAAC;QACtB,CAAC;MACH;AAEA,YAAM,iBAAiB;IACzB;AAEA,QAAI;AACF,aAAO,MAAM,0BAA0B;QACrC;QACA;QACA,mBAAmB,CAAC;MACtB,CAAC;IACH,SAAS,OAAO;AACd,UAAI,iBAAiB,OAAO;AAC1B,YAAIJ,cAAa,KAAK,KAAKI,aAAa,WAAW,KAAK,GAAG;AACzD,gBAAM;QACR;MACF;AAEA,YAAM,IAAIA,aAAa;QACrB,SAAS;QACT,OAAO;QACP,YAAY,SAAS;QACrB;QACA;QACA,mBAAmB,CAAC;MACtB,CAAC;IACH;EACF,SAAS,OAAO;AACd,UAAM,iBAAiB,EAAE,OAAO,KAAK,mBAAmB,CAAC,EAAE,CAAC;EAC9D;AACF;AUzFO,SAAS,oBAAoB;EAClC;EACA;AACF,GAGuB;AACrB,MAAI,OAAO,iBAAiB,UAAU;AACpC,WAAO;EACT;AAEA,MAAI,gBAAgB,QAAQ,OAAO,YAAY,aAAa;AAC1D,WAAO;EACT;AAEA,iBAAe,QAAQ,IAAI,uBAAuB;AAElD,MAAI,gBAAgB,QAAQ,OAAO,iBAAiB,UAAU;AAC5D,WAAO;EACT;AAEA,SAAO;AACT;AINA,IAAM,iBAAiB;AACvB,IAAM,uBAAuB;AAE7B,SAAS,OAAOC,OAAc;AAE5B,QAAM,MAAM,KAAK,MAAMA,KAAI;AAG3B,MAAI,QAAQ,QAAQ,OAAO,QAAQ,UAAU;AAC3C,WAAO;EACT;AAEA,MACE,eAAe,KAAKA,KAAI,MAAM,SAC9B,qBAAqB,KAAKA,KAAI,MAAM,OACpC;AACA,WAAO;EACT;AAGA,SAAO,OAAO,GAAG;AACnB;AAEA,SAAS,OAAO,KAAU;AACxB,MAAI,OAAO,CAAC,GAAG;AAEf,SAAO,KAAK,QAAQ;AAClB,UAAM,QAAQ;AACd,WAAO,CAAC;AAER,eAAW,QAAQ,OAAO;AACxB,UAAI,OAAO,UAAU,eAAe,KAAK,MAAM,WAAW,GAAG;AAC3D,cAAM,IAAI,YAAY,8CAA8C;MACtE;AAEA,UACE,OAAO,UAAU,eAAe,KAAK,MAAM,aAAa,KACxD,OAAO,UAAU,eAAe,KAAK,KAAK,aAAa,WAAW,GAClE;AACA,cAAM,IAAI,YAAY,8CAA8C;MACtE;AAEA,iBAAW,OAAO,MAAM;AACtB,cAAM,QAAQ,KAAK,GAAG;AACtB,YAAI,SAAS,OAAO,UAAU,UAAU;AACtC,eAAK,KAAK,KAAK;QACjB;MACF;IACF;EACF;AACA,SAAO;AACT;AAEO,SAAS,gBAAgBA,OAAc;AAE5C,QAAM,EAAE,gBAAgB,IAAI;AAC5B,QAAM,kBAAkB;AACxB,MAAI;AACF,WAAO,OAAOA,KAAI;EACpB,UAAA;AACE,UAAM,kBAAkB;EAC1B;AACF;AE/EO,IAAM,kBAAkB,OAAO,IAAI,qBAAqB;AA0BxD,SAAS,UACd,UAKmB;AACnB,SAAO,EAAE,CAAC,eAAe,GAAG,MAAM,SAAS;AAC7C;AAEO,SAAS,YAAY,OAAoC;AAC9D,SACE,OAAO,UAAU,YACjB,UAAU,QACV,mBAAmB,SACnB,MAAM,eAAe,MAAM,QAC3B,cAAc;AAElB;AAUO,SAAS,cACd,iBACuB;AAEvB,MAAIC;AACJ,SAAO,MAAM;AACX,QAAIA,cAAa,MAAM;AACrBA,mBAAY,gBAAgB;IAC9B;AACA,WAAOA;EACT;AACF;AAkBO,SAAS,YACd,OACmB;AACnB,SAAO,YAAY,KAAK,IACpB,QACA,OAAO,UAAU,aACf,MAAM,IACN,wBAAwB,KAAK;AACrC;AAEO,SAAS,wBACd,gBACmB;AACnB,SAAO,UAAU,OAAM,UAAS;AAC9B,UAAM,SAAS,MAAM,eAAe,WAAW,EAAE,SAAS,KAAK;AAE/D,WAAO,OAAO,UAAU,OACpB,EAAE,SAAS,MAAM,OAAO,OAAO,MAAM,IACrC;MACE,SAAS;MACT,OAAO,IAAI,oBAAoB;QAC7B;QACA,OAAO,OAAO;MAChB,CAAC;IACH;EACN,CAAC;AACH;ADvGA,eAAsB,cAAsB;EAC1C;EACA;AACF,GAGoB;AAClB,QAAM,SAAS,MAAMC,mBAAkB,EAAE,OAAO,OAAO,CAAC;AAExD,MAAI,CAAC,OAAO,SAAS;AACnB,UAAMC,oBAAoB,KAAK,EAAE,OAAO,OAAO,OAAO,MAAM,CAAC;EAC/D;AAEA,SAAO,OAAO;AAChB;AAWA,eAAsBD,mBAA0B;EAC9C;EACA;AACF,GAcE;AACA,QAAMD,aAAY,YAAY,MAAM;AAEpC,MAAI;AACF,QAAIA,WAAU,YAAY,MAAM;AAC9B,aAAO,EAAE,SAAS,MAAM,OAAwB,UAAU,MAAM;IAClE;AAEA,UAAM,SAAS,MAAMA,WAAU,SAAS,KAAK;AAE7C,QAAI,OAAO,SAAS;AAClB,aAAO,EAAE,SAAS,MAAM,OAAO,OAAO,OAAO,UAAU,MAAM;IAC/D;AAEA,WAAO;MACL,SAAS;MACT,OAAOE,oBAAoB,KAAK,EAAE,OAAO,OAAO,OAAO,MAAM,CAAC;MAC9D,UAAU;IACZ;EACF,SAAS,OAAO;AACd,WAAO;MACL,SAAS;MACT,OAAOA,oBAAoB,KAAK,EAAE,OAAO,OAAO,MAAM,CAAC;MACvD,UAAU;IACZ;EACF;AACF;AFjDA,eAAsB,UAAa;EACjC,MAAAH;EACA;AACF,GAGe;AACb,MAAI;AACF,UAAM,QAAQ,gBAAgBA,KAAI;AAElC,QAAI,UAAU,MAAM;AAClB,aAAO;IACT;AAEA,WAAO,cAAiB,EAAE,OAAO,OAAO,CAAC;EAC3C,SAAS,OAAO;AACd,QACE,eAAe,WAAW,KAAK,KAC/BG,oBAAoB,WAAW,KAAK,GACpC;AACA,YAAM;IACR;AAEA,UAAM,IAAI,eAAe,EAAE,MAAAH,OAAM,OAAO,MAAM,CAAC;EACjD;AACF;AAgCA,eAAsB,cAAiB;EACrC,MAAAA;EACA;AACF,GAG4B;AAC1B,MAAI;AACF,UAAM,QAAQ,gBAAgBA,KAAI;AAElC,QAAI,UAAU,MAAM;AAClB,aAAO,EAAE,SAAS,MAAM,OAAmB,UAAU,MAAM;IAC7D;AAEA,WAAO,MAAME,mBAAqB,EAAE,OAAO,OAAO,CAAC;EACrD,SAAS,OAAO;AACd,WAAO;MACL,SAAS;MACT,OAAO,eAAe,WAAW,KAAK,IAClC,QACA,IAAI,eAAe,EAAE,MAAAF,OAAM,OAAO,MAAM,CAAC;MAC7C,UAAU;IACZ;EACF;AACF;AItGO,SAAS,qBAAwB;EACtC;EACA;AACF,GAGmC;AACjC,SAAO,OACJ,YAAY,IAAI,kBAAkB,CAAC,EACnC,YAAY,IAAI,wBAAwB,CAAC,EACzC;IACC,IAAI,gBAAoD;MACtD,MAAM,UAAU,EAAE,KAAK,GAAG,YAAY;AAEpC,YAAI,SAAS,UAAU;AACrB;QACF;AAEA,mBAAW,QAAQ,MAAM,cAAc,EAAE,MAAM,MAAM,OAAO,CAAC,CAAC;MAChE;IACF,CAAC;EACH;AACJ;AErBA,IAAMI,oBAAmB,MAAM,WAAW;AAEnC,IAAM,gBAAgB,OAAU;EACrC;EACA;EACA;EACA;EACA;EACA;EACA,OAAAC;AACF,MASE,UAAU;EACR;EACA,SAAS;IACP,gBAAgB;IAChB,GAAG;EACL;EACA,MAAM;IACJ,SAAS,KAAK,UAAU,IAAI;IAC5B,QAAQ;EACV;EACA;EACA;EACA;EACA,OAAAA;AACF,CAAC;AAgCI,IAAM,YAAY,OAAU;EACjC;EACA,UAAU,CAAC;EACX;EACA;EACA;EACA;EACA,OAAAC,SAAQC,kBAAiB;AAC3B,MAWM;AACJ,MAAI;AACF,UAAM,WAAW,MAAMD,OAAM,KAAK;MAChC,QAAQ;MACR,SAAS;QACP;QACA,yBAAyB,OAAO;QAChC,+BAA+B;MACjC;MACA,MAAM,KAAK;MACX,QAAQ;IACV,CAAC;AAED,UAAM,kBAAkB,uBAAuB,QAAQ;AAEvD,QAAI,CAAC,SAAS,IAAI;AAChB,UAAI;AAKJ,UAAI;AACF,2BAAmB,MAAM,sBAAsB;UAC7C;UACA;UACA,mBAAmB,KAAK;QAC1B,CAAC;MACH,SAAS,OAAO;AACd,YAAIE,cAAa,KAAK,KAAKC,aAAa,WAAW,KAAK,GAAG;AACzD,gBAAM;QACR;AAEA,cAAM,IAAIA,aAAa;UACrB,SAAS;UACT,OAAO;UACP,YAAY,SAAS;UACrB;UACA;UACA,mBAAmB,KAAK;QAC1B,CAAC;MACH;AAEA,YAAM,iBAAiB;IACzB;AAEA,QAAI;AACF,aAAO,MAAM,0BAA0B;QACrC;QACA;QACA,mBAAmB,KAAK;MAC1B,CAAC;IACH,SAAS,OAAO;AACd,UAAI,iBAAiB,OAAO;AAC1B,YAAID,cAAa,KAAK,KAAKC,aAAa,WAAW,KAAK,GAAG;AACzD,gBAAM;QACR;MACF;AAEA,YAAM,IAAIA,aAAa;QACrB,SAAS;QACT,OAAO;QACP,YAAY,SAAS;QACrB;QACA;QACA,mBAAmB,KAAK;MAC1B,CAAC;IACH;EACF,SAAS,OAAO;AACd,UAAM,iBAAiB,EAAE,OAAO,KAAK,mBAAmB,KAAK,OAAO,CAAC;EACvE;AACF;AI3JA,eAAsB,QAAW,OAAkC;AAEjE,MAAI,OAAO,UAAU,YAAY;AAC/B,YAAS,MAAmB;EAC9B;AAGA,SAAO,QAAQ,QAAQ,KAAU;AACnC;ACDO,IAAM,iCACX,CAAI;EACF;EACA;EACA;AACF,MAKA,OAAO,EAAE,UAAU,KAAK,kBAAkB,MAAM;AAC9C,QAAM,eAAe,MAAM,SAAS,KAAK;AACzC,QAAM,kBAAkB,uBAAuB,QAAQ;AAGvD,MAAI,aAAa,KAAK,MAAM,IAAI;AAC9B,WAAO;MACL;MACA,OAAO,IAAIC,aAAa;QACtB,SAAS,SAAS;QAClB;QACA;QACA,YAAY,SAAS;QACrB;QACA;QACA,aAAa,eAAA,OAAA,SAAA,YAAc,QAAA;MAC7B,CAAC;IACH;EACF;AAGA,MAAI;AACF,UAAM,cAAc,MAAM,UAAU;MAClC,MAAM;MACN,QAAQ;IACV,CAAC;AAED,WAAO;MACL;MACA,OAAO,IAAIA,aAAa;QACtB,SAAS,eAAe,WAAW;QACnC;QACA;QACA,YAAY,SAAS;QACrB;QACA;QACA,MAAM;QACN,aAAa,eAAA,OAAA,SAAA,YAAc,UAAU,WAAA;MACvC,CAAC;IACH;EACF,SAAS,YAAY;AACnB,WAAO;MACL;MACA,OAAO,IAAIA,aAAa;QACtB,SAAS,SAAS;QAClB;QACA;QACA,YAAY,SAAS;QACrB;QACA;QACA,aAAa,eAAA,OAAA,SAAA,YAAc,QAAA;MAC7B,CAAC;IACH;EACF;AACF;AAEK,IAAM,mCACX,CACE,gBAEF,OAAO,EAAE,SAAS,MAA8B;AAC9C,QAAM,kBAAkB,uBAAuB,QAAQ;AAEvD,MAAI,SAAS,QAAQ,MAAM;AACzB,UAAM,IAAI,uBAAuB,CAAC,CAAC;EACrC;AAEA,SAAO;IACL;IACA,OAAO,qBAAqB;MAC1B,QAAQ,SAAS;MACjB,QAAQ;IACV,CAAC;EACH;AACF;AAqCK,IAAM,4BACX,CAAI,mBACJ,OAAO,EAAE,UAAU,KAAK,kBAAkB,MAAM;AAC9C,QAAM,eAAe,MAAM,SAAS,KAAK;AAEzC,QAAM,eAAe,MAAM,cAAc;IACvC,MAAM;IACN,QAAQ;EACV,CAAC;AAED,QAAM,kBAAkB,uBAAuB,QAAQ;AAEvD,MAAI,CAAC,aAAa,SAAS;AACzB,UAAM,IAAIC,aAAa;MACrB,SAAS;MACT,OAAO,aAAa;MACpB,YAAY,SAAS;MACrB;MACA;MACA;MACA;IACF,CAAC;EACH;AAEA,SAAO;IACL;IACA,OAAO,aAAa;IACpB,UAAU,aAAa;EACzB;AACF;AEvKK,IAAM,kBAAkB,CAAC,OAAiB,UAAoB;AACnE,MAAI,IAAI;AACR,SAAO,IAAI,MAAM,UAAU,IAAI,MAAM,QAAQ,KAAK;AAChD,QAAI,MAAM,CAAC,MAAM,MAAM,CAAC,EAAG;EAC7B;AACA,SAAO,EAAE,MAAM,SAAS,GAAG,SAAS,GAAG,GAAG,MAAM,MAAM,CAAC,CAAC,EAAE,KAAK,GAAG;AACpE;ACIO,IAAM,iBAAiB;EAC5B;AACF;AAoDO,IAAM,iBAA0B;EACrC,MAAM;EACN,cAAc;EACd,UAAU,CAAC,GAAG;EACd,gBAAgB;EAChB,cAAc;EACd,cAAc;EACd,aAAa;EACb,0BAA0B;EAC1B,6BAA6B;EAC7B,8BAA8B;EAC9B,gBAAgB;EAChB,cAAc;EACd,aAAa,CAAC;EACd,eAAe;EACf,iBAAiB;EACjB,iBAAiB;EACjB,eAAe;EACf,gBAAgB;EAChB,cAAc;AAChB;AAEO,IAAM,oBAAoB,CAC/B,YAEC,OAAO,YAAY,WAChB;EACE,GAAG;EACH,MAAM;AACR,IACA;EACE,GAAG;EACH,GAAG;AACL;AE/FC,SAAS,cAAkC;AAChD,SAAO,CAAC;AACV;ACQO,SAAS,cAAc,KAAkB,MAAY;AAZ5D,MAAAC,MAAAC,KAAA;AAaE,QAAM,MAA4B;IAChC,MAAM;EACR;AACA,QACED,OAAA,IAAI,SAAJ,OAAA,SAAAA,KAAU,WACV,MAAAC,MAAA,IAAI,SAAJ,OAAA,SAAAA,IAAU,SAAV,OAAA,SAAA,GAAgB,cAAa,sBAAsB,QACnD;AACA,QAAI,QAAQ,SAAS,IAAI,KAAK,MAAM;MAClC,GAAG;MACH,aAAa,CAAC,GAAG,KAAK,aAAa,OAAO;IAC5C,CAAC;EACH;AAEA,MAAI,IAAI,WAAW;AACjB,QAAI,WAAW,IAAI,UAAU;EAC/B;AACA,MAAI,IAAI,WAAW;AACjB,QAAI,WAAW,IAAI,UAAU;EAC/B;AACA,MAAI,IAAI,aAAa;AACnB,QAAI,WAAW,IAAI,YAAY;AAC/B,QAAI,WAAW,IAAI,YAAY;EACjC;AACA,SAAO;AACT;ACzBO,SAAS,eAAe,KAA0C;AACvE,QAAM,MAA6B;IACjC,MAAM;IACN,QAAQ;EACV;AAEA,MAAI,CAAC,IAAI,OAAQ,QAAO;AAExB,aAAW,SAAS,IAAI,QAAQ;AAC9B,YAAQ,MAAM,MAAM;MAClB,KAAK;AACH,YAAI,MAAM,WAAW;AACnB,cAAI,UAAU,MAAM;QACtB,OAAO;AACL,cAAI,mBAAmB,MAAM;QAC/B;AACA;MACF,KAAK;AACH,YAAI,MAAM,WAAW;AACnB,cAAI,UAAU,MAAM;QACtB,OAAO;AACL,cAAI,mBAAmB,MAAM;QAC/B;AAEA;MACF,KAAK;AACH,YAAI,aAAa,MAAM;AACvB;IACJ;EACF;AACA,SAAO;AACT;ACvCO,SAAS,kBAA0C;AACxD,SAAO,EAAE,MAAM,UAAU;AAC3B;ACFO,SAAS,gBAAgB,MAA0B,MAAY;AACpE,SAAO,SAAS,KAAK,KAAK,MAAM,IAAI;AACtC;ACFO,IAAM,gBAAgB,CAAC,KAAuB,SAAe;AAClE,SAAO,SAAS,IAAI,UAAU,MAAM,IAAI;AAC1C;ACSO,SAAS,aACd,KACA,MACA,sBACqB;AACrB,QAAM,WAAW,wBAAA,OAAA,uBAAwB,KAAK;AAE9C,MAAI,MAAM,QAAQ,QAAQ,GAAG;AAC3B,WAAO;MACL,OAAO,SAAS,IAAI,CAAC,MAAM,MAAM,aAAa,KAAK,MAAM,IAAI,CAAC;IAChE;EACF;AAEA,UAAQ,UAAU;IAChB,KAAK;IACL,KAAK;AACH,aAAO;QACL,MAAM;QACN,QAAQ;MACV;IACF,KAAK;AACH,aAAO;QACL,MAAM;QACN,QAAQ;MACV;IACF,KAAK;AACH,aAAO,kBAAkB,GAAG;EAChC;AACF;AAEA,IAAM,oBAAoB,CAAC,QAAoB;AAC7C,QAAM,MAA2B;IAC/B,MAAM;IACN,QAAQ;EACV;AAEA,aAAW,SAAS,IAAI,QAAQ;AAC9B,YAAQ,MAAM,MAAM;MAClB,KAAK;AACH,YAAI,UAAU,MAAM;AACpB;MACF,KAAK;AACH,YAAI,UAAU,MAAM;AACpB;IACJ;EACF;AAEA,SAAO;AACT;AC1DO,SAAS,gBACd,MACA,MACoC;AACpC,SAAO;IACL,GAAG,SAAS,KAAK,UAAU,MAAM,IAAI;IACrC,SAAS,KAAK,aAAa;EAC7B;AACF;ACPO,SAAS,gBACd,MACA,MAC6B;AAC7B,SAAO,KAAK,mBAAmB,UAC3B,SAAS,KAAK,OAAO,MAAM,IAAI,IAC/B,YAAY;AAClB;ACNO,SAAS,aAAa,KAAsC;AACjE,SAAO;IACL,MAAM;IACN,MAAM,MAAM,KAAK,IAAI,MAAM;EAC7B;AACF;ACDA,IAAM,yBAAyB,CAC7B,SACiC;AACjC,MAAI,UAAU,QAAQ,KAAK,SAAS,SAAU,QAAO;AACrD,SAAO,WAAW;AACpB;AAEO,SAAS,qBACd,KACA,MACoD;AACpD,QAAM,QAAQ;IACZ,SAAS,IAAI,KAAK,MAAM;MACtB,GAAG;MACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,GAAG;IACjD,CAAC;IACD,SAAS,IAAI,MAAM,MAAM;MACvB,GAAG;MACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,GAAG;IACjD,CAAC;EACH,EAAE,OAAO,CAAC,MAA4B,CAAC,CAAC,CAAC;AAEzC,QAAM,cAAiC,CAAC;AAExC,QAAM,QAAQ,CAAA,WAAU;AACtB,QAAI,uBAAuB,MAAM,GAAG;AAClC,kBAAY,KAAK,GAAG,OAAO,KAAK;IAClC,OAAO;AACL,UAAI,eAAgC;AACpC,UACE,0BAA0B,UAC1B,OAAO,yBAAyB,OAChC;AACA,cAAM,EAAE,sBAAsB,GAAG,KAAK,IAAI;AAC1C,uBAAe;MACjB;AACA,kBAAY,KAAK,YAAY;IAC/B;EACF,CAAC;AACD,SAAO,YAAY,SAAS,EAAE,OAAO,YAAY,IAAI;AACvD;ACxCO,SAAS,gBAAgB,KAA4C;AAC1E,QAAM,aAAa,OAAO,IAAI;AAC9B,MACE,eAAe,YACf,eAAe,YACf,eAAe,aACf,eAAe,UACf;AACA,WAAO;MACL,MAAM,MAAM,QAAQ,IAAI,KAAK,IAAI,UAAU;IAC7C;EACF;AAEA,SAAO;IACL,MAAM,eAAe,WAAW,YAAY;IAC5C,OAAO,IAAI;EACb;AACF;AEzBA,IAAI,aAAiC;AAQ9B,IAAM,cAAc;;;;EAIzB,MAAM;EACN,OAAO;EACP,MAAM;;;;EAIN,OACE;;;;;;;;;;;;EAYF,OAAO,MAAM;AACX,QAAI,eAAe,QAAW;AAC5B,mBAAa;QACX;QACA;MACF;IACF;AACA,WAAO;EACT;;;;EAIA,MAAM;;;;EAIN,MAAM;EACN,UACE;;;;EAIF,MAAM;EACN,UACE;EACF,QAAQ;EACR,WACE;EACF,QAAQ;EACR,KAAK;AACP;AA2BO,SAAS,eACd,KACA,MACuB;AACvB,QAAM,MAA6B;IACjC,MAAM;EACR;AAEA,MAAI,IAAI,QAAQ;AACd,eAAW,SAAS,IAAI,QAAQ;AAC9B,cAAQ,MAAM,MAAM;QAClB,KAAK;AACH,cAAI,YACF,OAAO,IAAI,cAAc,WACrB,KAAK,IAAI,IAAI,WAAW,MAAM,KAAK,IACnC,MAAM;AACZ;QACF,KAAK;AACH,cAAI,YACF,OAAO,IAAI,cAAc,WACrB,KAAK,IAAI,IAAI,WAAW,MAAM,KAAK,IACnC,MAAM;AAEZ;QACF,KAAK;AACH,kBAAQ,KAAK,eAAe;YAC1B,KAAK;AACH,wBAAU,KAAK,SAAS,MAAM,SAAS,IAAI;AAC3C;YACF,KAAK;AACH,wBAAU,KAAK,aAAa,MAAM,SAAS,IAAI;AAC/C;YACF,KAAK;AACH,yBAAW,KAAK,YAAY,OAAO,MAAM,SAAS,IAAI;AACtD;UACJ;AAEA;QACF,KAAK;AACH,oBAAU,KAAK,OAAO,MAAM,SAAS,IAAI;AACzC;QACF,KAAK;AACH,oBAAU,KAAK,QAAQ,MAAM,SAAS,IAAI;AAC1C;QACF,KAAK;AACH,qBAAW,KAAK,MAAM,OAAO,MAAM,SAAS,IAAI;AAChD;QACF,KAAK;AACH,qBAAW,KAAK,YAAY,MAAM,MAAM,SAAS,IAAI;AACrD;QACF,KAAK;AACH,qBAAW,KAAK,YAAY,OAAO,MAAM,SAAS,IAAI;AACtD;QACF,KAAK;AACH;YACE;YACA,OAAO,IAAI,wBAAwB,MAAM,OAAO,IAAI,CAAC,EAAE;YACvD,MAAM;YACN;UACF;AACA;QACF,KAAK;AACH;YACE;YACA,OAAO,GAAG,wBAAwB,MAAM,OAAO,IAAI,CAAC,GAAG;YACvD,MAAM;YACN;UACF;AACA;QACF,KAAK;AACH,oBAAU,KAAK,aAAa,MAAM,SAAS,IAAI;AAC/C;QACF,KAAK;AACH,oBAAU,KAAK,QAAQ,MAAM,SAAS,IAAI;AAC1C;QACF,KAAK;AACH,oBAAU,KAAK,QAAQ,MAAM,SAAS,IAAI;AAC1C;QACF,KAAK;AACH,oBAAU,KAAK,YAAY,MAAM,SAAS,IAAI;AAC9C;QACF,KAAK;AACH,cAAI,YACF,OAAO,IAAI,cAAc,WACrB,KAAK,IAAI,IAAI,WAAW,MAAM,KAAK,IACnC,MAAM;AACZ,cAAI,YACF,OAAO,IAAI,cAAc,WACrB,KAAK,IAAI,IAAI,WAAW,MAAM,KAAK,IACnC,MAAM;AACZ;QACF,KAAK,YAAY;AACf;YACE;YACA,OAAO,wBAAwB,MAAM,OAAO,IAAI,CAAC;YACjD,MAAM;YACN;UACF;AACA;QACF;QACA,KAAK,MAAM;AACT,cAAI,MAAM,YAAY,MAAM;AAC1B,sBAAU,KAAK,QAAQ,MAAM,SAAS,IAAI;UAC5C;AACA,cAAI,MAAM,YAAY,MAAM;AAC1B,sBAAU,KAAK,QAAQ,MAAM,SAAS,IAAI;UAC5C;AACA;QACF;QACA,KAAK;AACH,qBAAW,KAAK,YAAY,WAAW,MAAM,SAAS,IAAI;AAC1D;QACF,KAAK;AACH,qBAAW,KAAK,YAAY,KAAK,MAAM,SAAS,IAAI;AACpD;QACF,KAAK,QAAQ;AACX,cAAI,MAAM,YAAY,MAAM;AAC1B,uBAAW,KAAK,YAAY,UAAU,MAAM,SAAS,IAAI;UAC3D;AACA,cAAI,MAAM,YAAY,MAAM;AAC1B,uBAAW,KAAK,YAAY,UAAU,MAAM,SAAS,IAAI;UAC3D;AACA;QACF;QACA,KAAK;AACH,qBAAW,KAAK,YAAY,MAAM,GAAG,MAAM,SAAS,IAAI;AACxD;QACF,KAAK,QAAQ;AACX,qBAAW,KAAK,YAAY,MAAM,MAAM,SAAS,IAAI;AACrD;QACF;QACA,KAAK,UAAU;AACb,kBAAQ,KAAK,gBAAgB;YAC3B,KAAK,iBAAiB;AACpB,wBAAU,KAAK,UAAiB,MAAM,SAAS,IAAI;AACnD;YACF;YAEA,KAAK,0BAA0B;AAC7B,kBAAI,kBAAkB;AACtB;YACF;YAEA,KAAK,eAAe;AAClB,yBAAW,KAAK,YAAY,QAAQ,MAAM,SAAS,IAAI;AACvD;YACF;UACF;AACA;QACF;QACA,KAAK,UAAU;AACb,qBAAW,KAAK,YAAY,QAAQ,MAAM,SAAS,IAAI;QACzD;QACA,KAAK;QACL,KAAK;QACL,KAAK;AACH;QACF;AAEG,UAAA,kBAAC,MAAa;UAAC,GAAG,KAAK;MAC5B;IACF;EACF;AAEA,SAAO;AACT;AAEA,SAAS,wBAAwB,SAAiB,MAAoB;AACpE,SAAO,KAAK,oBAAoB,WAC5B,sBAAsB,OAAO,IAC7B;AACN;AAEA,IAAM,gBAAgB,IAAI;EACxB;AACF;AAEA,SAAS,sBAAsB,QAAgB;AAC7C,MAAI,SAAS;AAEb,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,QAAI,CAAC,cAAc,IAAI,OAAO,CAAC,CAAC,GAAG;AACjC,gBAAU;IACZ;AAEA,cAAU,OAAO,CAAC;EACpB;AAEA,SAAO;AACT;AAGA,SAAS,UACP,QACA,OACA,SACA,MACA;AAhSF,MAAAD;AAiSE,MAAI,OAAO,YAAUA,OAAA,OAAO,UAAP,OAAA,SAAAA,KAAc,KAAK,CAAA,MAAK,EAAE,MAAA,IAAS;AACtD,QAAI,CAAC,OAAO,OAAO;AACjB,aAAO,QAAQ,CAAC;IAClB;AAEA,QAAI,OAAO,QAAQ;AACjB,aAAO,MAAO,KAAK;QACjB,QAAQ,OAAO;MACjB,CAAC;AACD,aAAO,OAAO;IAChB;AAEA,WAAO,MAAO,KAAK;MACjB,QAAQ;MACR,GAAI,WACF,KAAK,iBAAiB,EAAE,cAAc,EAAE,QAAQ,QAAQ,EAAE;IAC9D,CAAC;EACH,OAAO;AACL,WAAO,SAAS;EAClB;AACF;AAGA,SAAS,WACP,QACA,OACA,SACA,MACA;AA7TF,MAAAA;AA8TE,MAAI,OAAO,aAAWA,OAAA,OAAO,UAAP,OAAA,SAAAA,KAAc,KAAK,CAAA,MAAK,EAAE,OAAA,IAAU;AACxD,QAAI,CAAC,OAAO,OAAO;AACjB,aAAO,QAAQ,CAAC;IAClB;AAEA,QAAI,OAAO,SAAS;AAClB,aAAO,MAAO,KAAK;QACjB,SAAS,OAAO;MAClB,CAAC;AACD,aAAO,OAAO;IAChB;AAEA,WAAO,MAAO,KAAK;MACjB,SAAS,yBAAyB,OAAO,IAAI;MAC7C,GAAI,WACF,KAAK,iBAAiB,EAAE,cAAc,EAAE,SAAS,QAAQ,EAAE;IAC/D,CAAC;EACH,OAAO;AACL,WAAO,UAAU,yBAAyB,OAAO,IAAI;EACvD;AACF;AAGA,SAAS,yBAAyB,OAAe,MAAoB;AArVrE,MAAAA;AAsVE,MAAI,CAAC,KAAK,mBAAmB,CAAC,MAAM,OAAO;AACzC,WAAO,MAAM;EACf;AAGA,QAAM,QAAQ;IACZ,GAAG,MAAM,MAAM,SAAS,GAAG;;IAC3B,GAAG,MAAM,MAAM,SAAS,GAAG;;IAC3B,GAAG,MAAM,MAAM,SAAS,GAAG;;EAC7B;AAGA,QAAM,SAAS,MAAM,IAAI,MAAM,OAAO,YAAY,IAAI,MAAM;AAC5D,MAAI,UAAU;AACd,MAAI,YAAY;AAChB,MAAI,cAAc;AAClB,MAAI,cAAc;AAElB,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,QAAI,WAAW;AACb,iBAAW,OAAO,CAAC;AACnB,kBAAY;AACZ;IACF;AAEA,QAAI,MAAM,GAAG;AACX,UAAI,aAAa;AACf,YAAI,OAAO,CAAC,EAAE,MAAM,OAAO,GAAG;AAC5B,cAAI,aAAa;AACf,uBAAW,OAAO,CAAC;AACnB,uBAAW,GAAG,OAAO,IAAI,CAAC,CAAC,IAAI,OAAO,CAAC,CAAC,GAAG,YAAY;AACvD,0BAAc;UAChB,WAAW,OAAO,IAAI,CAAC,MAAM,SAAOA,OAAA,OAAO,IAAI,CAAC,MAAZ,OAAA,SAAAA,KAAe,MAAM,OAAA,IAAU;AACjE,uBAAW,OAAO,CAAC;AACnB,0BAAc;UAChB,OAAO;AACL,uBAAW,GAAG,OAAO,CAAC,CAAC,GAAG,OAAO,CAAC,EAAE,YAAY,CAAC;UACnD;AACA;QACF;MACF,WAAW,OAAO,CAAC,EAAE,MAAM,OAAO,GAAG;AACnC,mBAAW,IAAI,OAAO,CAAC,CAAC,GAAG,OAAO,CAAC,EAAE,YAAY,CAAC;AAClD;MACF;IACF;AAEA,QAAI,MAAM,GAAG;AACX,UAAI,OAAO,CAAC,MAAM,KAAK;AACrB,mBAAW;;AACX;MACF,WAAW,OAAO,CAAC,MAAM,KAAK;AAC5B,mBAAW;;AACX;MACF;IACF;AAEA,QAAI,MAAM,KAAK,OAAO,CAAC,MAAM,KAAK;AAChC,iBAAW,cAAc,GAAG,OAAO,CAAC,CAAC;IAAS,IAAI,OAAO,CAAC,CAAC;;AAC3D;IACF;AAEA,eAAW,OAAO,CAAC;AACnB,QAAI,OAAO,CAAC,MAAM,MAAM;AACtB,kBAAY;IACd,WAAW,eAAe,OAAO,CAAC,MAAM,KAAK;AAC3C,oBAAc;IAChB,WAAW,CAAC,eAAe,OAAO,CAAC,MAAM,KAAK;AAC5C,oBAAc;IAChB;EACF;AAEA,MAAI;AACF,QAAI,OAAO,OAAO;EACpB,SAAQ,GAAA;AACN,YAAQ;MACN,sCAAsC,KAAK,YAAY;QACrD;MACF,CAAC;IACH;AACA,WAAO,MAAM;EACf;AAEA,SAAO;AACT;ADlZO,SAAS,eACd,KACA,MACuB;AA1BzB,MAAAA,MAAAC,KAAA,IAAA,IAAA,IAAA;AA2BE,QAAM,SAAgC;IACpC,MAAM;IACN,uBACED,OAAA,SAAS,IAAI,UAAU,MAAM;MAC3B,GAAG;MACH,aAAa,CAAC,GAAG,KAAK,aAAa,sBAAsB;IAC3D,CAAC,MAHD,OAAAA,OAGM,KAAK;EACf;AAEA,QACEC,MAAA,IAAI,YAAJ,OAAA,SAAAA,IAAa,KAAK,cAAaC,sBAAsB,eACrD,KAAA,IAAI,QAAQ,KAAK,WAAjB,OAAA,SAAA,GAAyB,SACzB;AACA,UAAM,EAAE,MAAM,GAAG,QAAQ,IAAI,eAAe,IAAI,QAAQ,MAAM,IAAI;AAElE,WAAO;MACL,GAAG;MACH,eAAe;IACjB;EACF,aAAW,KAAA,IAAI,YAAJ,OAAA,SAAA,GAAa,KAAK,cAAaA,sBAAsB,SAAS;AACvE,WAAO;MACL,GAAG;MACH,eAAe;QACb,MAAM,IAAI,QAAQ,KAAK;MACzB;IACF;EACF,aACE,KAAA,IAAI,YAAJ,OAAA,SAAA,GAAa,KAAK,cAAaA,sBAAsB,cACrD,IAAI,QAAQ,KAAK,KAAK,KAAK,aAAaA,sBAAsB,eAC9D,KAAA,IAAI,QAAQ,KAAK,KAAK,KAAK,WAA3B,OAAA,SAAA,GAAmC,SACnC;AACA,UAAM,EAAE,MAAM,GAAG,QAAQ,IAAI;MAC3B,IAAI,QAAQ;MACZ;IACF;AAEA,WAAO;MACL,GAAG;MACH,eAAe;IACjB;EACF;AAEA,SAAO;AACT;AEpDO,SAAS,YACd,KACA,MAC4C;AAC5C,MAAI,KAAK,gBAAgB,UAAU;AACjC,WAAO,eAAe,KAAK,IAAI;EACjC;AAEA,QAAM,OACJ,SAAS,IAAI,QAAQ,MAAM;IACzB,GAAG;IACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,SAAS,GAAG;EAC1D,CAAC,KAAK,YAAY;AACpB,QAAM,SACJ,SAAS,IAAI,UAAU,MAAM;IAC3B,GAAG;IACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,SAAS,GAAG;EAC1D,CAAC,KAAK,YAAY;AACpB,SAAO;IACL,MAAM;IACN,UAAU;IACV,OAAO;MACL,MAAM;MACN,OAAO,CAAC,MAAM,MAAM;MACpB,UAAU;MACV,UAAU;IACZ;EACF;AACF;ACvCO,SAAS,mBACd,KAC2B;AAC3B,QAAMC,UAAS,IAAI;AACnB,QAAM,aAAa,OAAO,KAAK,IAAI,MAAM,EAAE,OAAO,CAAC,QAAgB;AACjE,WAAO,OAAOA,QAAOA,QAAO,GAAG,CAAC,MAAM;EACxC,CAAC;AAED,QAAM,eAAe,WAAW,IAAI,CAAC,QAAgBA,QAAO,GAAG,CAAC;AAEhE,QAAM,cAAc,MAAM;IACxB,IAAI,IAAI,aAAa,IAAI,CAAC,WAA4B,OAAO,MAAM,CAAC;EACtE;AAEA,SAAO;IACL,MACE,YAAY,WAAW,IACnB,YAAY,CAAC,MAAM,WACjB,WACA,WACF,CAAC,UAAU,QAAQ;IACzB,MAAM;EACR;AACF;ACxBO,SAAS,gBAAkD;AAChE,SAAO,EAAE,KAAK,YAAY,EAAE;AAC9B;ACJO,SAAS,eAAoC;AAClD,SAAO;IACL,MAAM;EACR;AACF;ACEO,IAAM,oBAAoB;EAC/B,WAAW;EACX,WAAW;EACX,WAAW;EACX,YAAY;EACZ,SAAS;AACX;AAsBO,SAAS,cACd,KACA,MACkE;AAClE,QAAM,UACJ,IAAI,mBAAmB,MAAM,MAAM,KAAK,IAAI,QAAQ,OAAO,CAAC,IAAI,IAAI;AAGtE,MACE,QAAQ;IACN,CAAA,MACE,EAAE,KAAK,YAAY,sBAClB,CAAC,EAAE,KAAK,UAAU,CAAC,EAAE,KAAK,OAAO;EACtC,GACA;AAGA,UAAM,QAAQ,QAAQ,OAAO,CAACC,QAA+B,MAAM;AACjE,YAAM,OAAO,kBAAkB,EAAE,KAAK,QAAwB;AAC9D,aAAO,QAAQ,CAACA,OAAM,SAAS,IAAI,IAAI,CAAC,GAAGA,QAAO,IAAI,IAAIA;IAC5D,GAAG,CAAC,CAAC;AAEL,WAAO;MACL,MAAM,MAAM,SAAS,IAAI,QAAQ,MAAM,CAAC;IAC1C;EACF,WACE,QAAQ,MAAM,CAAA,MAAK,EAAE,KAAK,aAAa,gBAAgB,CAAC,EAAE,WAAW,GACrE;AAGA,UAAM,QAAQ,QAAQ;MACpB,CAAC,KAA6B,MAA+B;AAC3D,cAAM,OAAO,OAAO,EAAE,KAAK;AAC3B,gBAAQ,MAAM;UACZ,KAAK;UACL,KAAK;UACL,KAAK;AACH,mBAAO,CAAC,GAAG,KAAK,IAAI;UACtB,KAAK;AACH,mBAAO,CAAC,GAAG,KAAK,SAAkB;UACpC,KAAK;AACH,gBAAI,EAAE,KAAK,UAAU,KAAM,QAAO,CAAC,GAAG,KAAK,MAAe;UAC5D,KAAK;UACL,KAAK;UACL,KAAK;UACL;AACE,mBAAO;QACX;MACF;MACA,CAAC;IACH;AAEA,QAAI,MAAM,WAAW,QAAQ,QAAQ;AAGnC,YAAM,cAAc,MAAM,OAAO,CAAC,GAAG,GAAG,MAAM,EAAE,QAAQ,CAAC,MAAM,CAAC;AAChE,aAAO;QACL,MAAM,YAAY,SAAS,IAAI,cAAc,YAAY,CAAC;QAC1D,MAAM,QAAQ;UACZ,CAAC,KAAK,MAAM;AACV,mBAAO,IAAI,SAAS,EAAE,KAAK,KAAK,IAAI,MAAM,CAAC,GAAG,KAAK,EAAE,KAAK,KAAK;UACjE;UACA,CAAC;QACH;MACF;IACF;EACF,WAAW,QAAQ,MAAM,CAAA,MAAK,EAAE,KAAK,aAAa,SAAS,GAAG;AAC5D,WAAO;MACL,MAAM;MACN,MAAM,QAAQ;QACZ,CAAC,KAAe,MAAM;UACpB,GAAG;UACH,GAAG,EAAE,KAAK,OAAO,OAAO,CAACC,OAAc,CAAC,IAAI,SAASA,EAAC,CAAC;QACzD;QACA,CAAC;MACH;IACF;EACF;AAEA,SAAO,QAAQ,KAAK,IAAI;AAC1B;AAEA,IAAM,UAAU,CACd,KACA,SACqE;AACrE,QAAM,SACH,IAAI,mBAAmB,MACpB,MAAM,KAAK,IAAI,QAAQ,OAAO,CAAC,IAC/B,IAAI,SAEP;IAAI,CAAC,GAAG,MACP,SAAS,EAAE,MAAM;MACf,GAAG;MACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,GAAG,CAAC,EAAE;IACpD,CAAC;EACH,EACC;IACC,CAAC,MACC,CAAC,CAAC,MACD,CAAC,KAAK,gBACJ,OAAO,MAAM,YAAY,OAAO,KAAK,CAAC,EAAE,SAAS;EACxD;AAEF,SAAO,MAAM,SAAS,EAAE,MAAM,IAAI;AACpC;AChIO,SAAS,iBACd,KACA,MACqC;AACrC,MACE,CAAC,aAAa,aAAa,aAAa,cAAc,SAAS,EAAE;IAC/D,IAAI,UAAU,KAAK;EACrB,MACC,CAAC,IAAI,UAAU,KAAK,UAAU,CAAC,IAAI,UAAU,KAAK,OAAO,SAC1D;AACA,WAAO;MACL,MAAM;QACJ,kBACE,IAAI,UAAU,KAAK,QACrB;QACA;MACF;IACF;EACF;AAEA,QAAM,OAAO,SAAS,IAAI,UAAU,MAAM;IACxC,GAAG;IACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,GAAG;EACjD,CAAC;AAED,SAAO,QAAQ,EAAE,OAAO,CAAC,MAAM,EAAE,MAAM,OAAO,CAAC,EAAE;AACnD;AC9BO,SAAS,eAAe,KAA0C;AACvE,QAAM,MAA6B;IACjC,MAAM;EACR;AAEA,MAAI,CAAC,IAAI,OAAQ,QAAO;AAExB,aAAW,SAAS,IAAI,QAAQ;AAC9B,YAAQ,MAAM,MAAM;MAClB,KAAK;AACH,YAAI,OAAO;AACX;MACF,KAAK;AACH,YAAI,MAAM,WAAW;AACnB,cAAI,UAAU,MAAM;QACtB,OAAO;AACL,cAAI,mBAAmB,MAAM;QAC/B;AACA;MACF,KAAK;AACH,YAAI,MAAM,WAAW;AACnB,cAAI,UAAU,MAAM;QACtB,OAAO;AACL,cAAI,mBAAmB,MAAM;QAC/B;AACA;MACF,KAAK;AACH,YAAI,aAAa,MAAM;AACvB;IACJ;EACF;AACA,SAAO;AACT;AC/BO,SAAS,eAAe,KAAmB,MAAY;AAC5D,QAAM,SAAgC;IACpC,MAAM;IACN,YAAY,CAAC;EACf;AAEA,QAAM,WAAqB,CAAC;AAE5B,QAAM,QAAQ,IAAI,MAAM;AAExB,aAAW,YAAY,OAAO;AAC5B,QAAI,UAAU,MAAM,QAAQ;AAE5B,QAAI,YAAY,UAAa,QAAQ,SAAS,QAAW;AACvD;IACF;AAEA,UAAM,eAAe,eAAe,OAAO;AAE3C,UAAM,YAAY,SAAS,QAAQ,MAAM;MACvC,GAAG;MACH,aAAa,CAAC,GAAG,KAAK,aAAa,cAAc,QAAQ;MACzD,cAAc,CAAC,GAAG,KAAK,aAAa,cAAc,QAAQ;IAC5D,CAAC;AAED,QAAI,cAAc,QAAW;AAC3B;IACF;AAEA,WAAO,WAAW,QAAQ,IAAI;AAE9B,QAAI,CAAC,cAAc;AACjB,eAAS,KAAK,QAAQ;IACxB;EACF;AAEA,MAAI,SAAS,QAAQ;AACnB,WAAO,WAAW;EACpB;AAEA,QAAM,uBAAuB,2BAA2B,KAAK,IAAI;AAEjE,MAAI,yBAAyB,QAAW;AACtC,WAAO,uBAAuB;EAChC;AAEA,SAAO;AACT;AAEA,SAAS,2BAA2B,KAAmB,MAAY;AACjE,MAAI,IAAI,SAAS,KAAK,aAAa,YAAY;AAC7C,WAAO,SAAS,IAAI,SAAS,MAAM;MACjC,GAAG;MACH,aAAa,CAAC,GAAG,KAAK,aAAa,sBAAsB;IAC3D,CAAC;EACH;AAEA,UAAQ,IAAI,aAAa;IACvB,KAAK;AACH,aAAO,KAAK;IACd,KAAK;AACH,aAAO,KAAK;IACd,KAAK;AACH,aAAO,KAAK,6BAA6B,WACrC,KAAK,8BACL,KAAK;EACb;AACF;AAEA,SAAS,eAAe,QAA6B;AACnD,MAAI;AACF,WAAO,OAAO,WAAW;EAC3B,SAAQ,GAAA;AACN,WAAO;EACT;AACF;ACjFO,IAAM,mBAAmB,CAC9B,KACA,SACgC;AATlC,MAAAL;AAUE,MAAI,KAAK,YAAY,SAAS,QAAMA,OAAA,KAAK,iBAAL,OAAA,SAAAA,KAAmB,SAAA,IAAY;AACjE,WAAO,SAAS,IAAI,UAAU,MAAM,IAAI;EAC1C;AAEA,QAAM,cAAc,SAAS,IAAI,UAAU,MAAM;IAC/C,GAAG;IACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,GAAG;EACjD,CAAC;AAED,SAAO,cACH,EAAE,OAAO,CAAC,EAAE,KAAK,YAAY,EAAE,GAAG,WAAW,EAAE,IAC/C,YAAY;AAClB;AChBO,IAAM,mBAAmB,CAC9B,KACA,SACuD;AACvD,MAAI,KAAK,iBAAiB,SAAS;AACjC,WAAO,SAAS,IAAI,GAAG,MAAM,IAAI;EACnC,WAAW,KAAK,iBAAiB,UAAU;AACzC,WAAO,SAAS,IAAI,IAAI,MAAM,IAAI;EACpC;AAEA,QAAM,IAAI,SAAS,IAAI,GAAG,MAAM;IAC9B,GAAG;IACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,GAAG;EACjD,CAAC;AACD,QAAM,IAAI,SAAS,IAAI,IAAI,MAAM;IAC/B,GAAG;IACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,IAAI,MAAM,GAAG;EAC3D,CAAC;AAED,SAAO;IACL,OAAO,CAAC,GAAG,CAAC,EAAE,OAAO,CAAC,MAA4B,MAAM,MAAS;EACnE;AACF;ACvBO,SAAS,gBACd,KACA,MAC6B;AAC7B,SAAO,SAAS,IAAI,KAAK,MAAM,IAAI;AACrC;ACGO,SAAS,YAAY,KAAgB,MAAgC;AAC1E,QAAM,QAAQ,SAAS,IAAI,UAAU,MAAM;IACzC,GAAG;IACH,aAAa,CAAC,GAAG,KAAK,aAAa,OAAO;EAC5C,CAAC;AAED,QAAM,SAA6B;IACjC,MAAM;IACN,aAAa;IACb;EACF;AAEA,MAAI,IAAI,SAAS;AACf,WAAO,WAAW,IAAI,QAAQ;EAChC;AAEA,MAAI,IAAI,SAAS;AACf,WAAO,WAAW,IAAI,QAAQ;EAChC;AAEA,SAAO;AACT;AChBO,SAAS,cACd,KACA,MACsB;AACtB,MAAI,IAAI,MAAM;AACZ,WAAO;MACL,MAAM;MACN,UAAU,IAAI,MAAM;MACpB,OAAO,IAAI,MACR;QAAI,CAAC,GAAG,MACP,SAAS,EAAE,MAAM;UACf,GAAG;UACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,GAAG,CAAC,EAAE;QACpD,CAAC;MACH,EACC;QACC,CAAC,KAAwB,MAAO,MAAM,SAAY,MAAM,CAAC,GAAG,KAAK,CAAC;QAClE,CAAC;MACH;MACF,iBAAiB,SAAS,IAAI,KAAK,MAAM;QACvC,GAAG;QACH,aAAa,CAAC,GAAG,KAAK,aAAa,iBAAiB;MACtD,CAAC;IACH;EACF,OAAO;AACL,WAAO;MACL,MAAM;MACN,UAAU,IAAI,MAAM;MACpB,UAAU,IAAI,MAAM;MACpB,OAAO,IAAI,MACR;QAAI,CAAC,GAAG,MACP,SAAS,EAAE,MAAM;UACf,GAAG;UACH,aAAa,CAAC,GAAG,KAAK,aAAa,SAAS,GAAG,CAAC,EAAE;QACpD,CAAC;MACH,EACC;QACC,CAAC,KAAwB,MAAO,MAAM,SAAY,MAAM,CAAC,GAAG,KAAK,CAAC;QAClE,CAAC;MACH;IACJ;EACF;AACF;ACtDO,SAAS,oBAA8C;AAC5D,SAAO;IACL,KAAK,YAAY;EACnB;AACF;ACNO,SAAS,kBAA0C;AACxD,SAAO,YAAY;AACrB;ACFO,IAAM,mBAAmB,CAAC,KAA0B,SAAe;AACxE,SAAO,SAAS,IAAI,UAAU,MAAM,IAAI;AAC1C;A9B8BO,IAAM,eAAe,CAC1B,KACA,UACA,SACiD;AACjD,UAAQ,UAAU;IAChB,KAAKE,sBAAsB;AACzB,aAAO,eAAe,KAAK,IAAI;IACjC,KAAKA,sBAAsB;AACzB,aAAO,eAAe,GAAG;IAC3B,KAAKA,sBAAsB;AACzB,aAAO,eAAe,KAAK,IAAI;IACjC,KAAKA,sBAAsB;AACzB,aAAO,eAAe,GAAG;IAC3B,KAAKA,sBAAsB;AACzB,aAAO,gBAAgB;IACzB,KAAKA,sBAAsB;AACzB,aAAO,aAAa,KAAK,IAAI;IAC/B,KAAKA,sBAAsB;AACzB,aAAO,kBAAkB;IAC3B,KAAKA,sBAAsB;AACzB,aAAO,aAAa;IACtB,KAAKA,sBAAsB;AACzB,aAAO,cAAc,KAAK,IAAI;IAChC,KAAKA,sBAAsB;IAC3B,KAAKA,sBAAsB;AACzB,aAAO,cAAc,KAAK,IAAI;IAChC,KAAKA,sBAAsB;AACzB,aAAO,qBAAqB,KAAK,IAAI;IACvC,KAAKA,sBAAsB;AACzB,aAAO,cAAc,KAAK,IAAI;IAChC,KAAKA,sBAAsB;AACzB,aAAO,eAAe,KAAK,IAAI;IACjC,KAAKA,sBAAsB;AACzB,aAAO,gBAAgB,GAAG;IAC5B,KAAKA,sBAAsB;AACzB,aAAO,aAAa,GAAG;IACzB,KAAKA,sBAAsB;AACzB,aAAO,mBAAmB,GAAG;IAC/B,KAAKA,sBAAsB;AACzB,aAAO,iBAAiB,KAAK,IAAI;IACnC,KAAKA,sBAAsB;AACzB,aAAO,iBAAiB,KAAK,IAAI;IACnC,KAAKA,sBAAsB;AACzB,aAAO,YAAY,KAAK,IAAI;IAC9B,KAAKA,sBAAsB;AACzB,aAAO,YAAY,KAAK,IAAI;IAC9B,KAAKA,sBAAsB;AACzB,aAAO,MAAO,IAAY,OAAO,EAAE;IACrC,KAAKA,sBAAsB;AACzB,aAAO,gBAAgB,KAAK,IAAI;IAClC,KAAKA,sBAAsB;IAC3B,KAAKA,sBAAsB;AACzB,aAAO,cAAc;IACvB,KAAKA,sBAAsB;AACzB,aAAO,gBAAgB,KAAK,IAAI;IAClC,KAAKA,sBAAsB;AACzB,aAAO,YAAY;IACrB,KAAKA,sBAAsB;AACzB,aAAO,gBAAgB;IACzB,KAAKA,sBAAsB;AACzB,aAAO,gBAAgB,KAAK,IAAI;IAClC,KAAKA,sBAAsB;AACzB,aAAO,gBAAgB,KAAK,IAAI;IAClC,KAAKA,sBAAsB;AACzB,aAAO,iBAAiB,KAAK,IAAI;IACnC,KAAKA,sBAAsB;AACzB,aAAO,cAAc,KAAK,IAAI;IAChC,KAAKA,sBAAsB;AACzB,aAAO,iBAAiB,KAAK,IAAI;IACnC,KAAKA,sBAAsB;IAC3B,KAAKA,sBAAsB;IAC3B,KAAKA,sBAAsB;AACzB,aAAO;IACT;AAEE,aAAQ,kBAAC,MAAa,QAAW,QAAQ;EAC7C;AACF;A+B1GO,SAAS,SACd,KACA,MACA,kBAAkB,OACW;AAZ/B,MAAAF;AAaE,QAAM,WAAW,KAAK,KAAK,IAAI,GAAG;AAElC,MAAI,KAAK,UAAU;AACjB,UAAM,kBAAiBA,OAAA,KAAK,aAAL,OAAA,SAAAA,KAAA;MAAA;MACrB;MACA;MACA;MACA;IAAA;AAGF,QAAI,mBAAmB,gBAAgB;AACrC,aAAO;IACT;EACF;AAEA,MAAI,YAAY,CAAC,iBAAiB;AAChC,UAAM,aAAa,QAAQ,UAAU,IAAI;AAEzC,QAAI,eAAe,QAAW;AAC5B,aAAO;IACT;EACF;AAEA,QAAM,UAAgB,EAAE,KAAK,MAAM,KAAK,aAAa,YAAY,OAAU;AAE3E,OAAK,KAAK,IAAI,KAAK,OAAO;AAE1B,QAAM,qBAAqB,aAAa,KAAM,IAAY,UAAU,IAAI;AAGxE,QAAMM,cACJ,OAAO,uBAAuB,aAC1B,SAAS,mBAAmB,GAAG,IAAI,IACnC;AAEN,MAAIA,aAAY;AACd,YAAQ,KAAK,MAAMA,WAAU;EAC/B;AAEA,MAAI,KAAK,aAAa;AACpB,UAAM,oBAAoB,KAAK,YAAYA,aAAY,KAAK,IAAI;AAEhE,YAAQ,aAAaA;AAErB,WAAO;EACT;AAEA,UAAQ,aAAaA;AAErB,SAAOA;AACT;AAEA,IAAM,UAAU,CACd,MACA,SAMe;AACf,UAAQ,KAAK,cAAc;IACzB,KAAK;AACH,aAAO,EAAE,MAAM,KAAK,KAAK,KAAK,GAAG,EAAE;IACrC,KAAK;AACH,aAAO,EAAE,MAAM,gBAAgB,KAAK,aAAa,KAAK,IAAI,EAAE;IAC9D,KAAK;IACL,KAAK,QAAQ;AACX,UACE,KAAK,KAAK,SAAS,KAAK,YAAY,UACpC,KAAK,KAAK,MAAM,CAAC,OAAO,UAAU,KAAK,YAAY,KAAK,MAAM,KAAK,GACnE;AACA,gBAAQ;UACN,mCAAmC,KAAK,YAAY;YAClD;UACF,CAAC;QACH;AAEA,eAAO,YAAY;MACrB;AAEA,aAAO,KAAK,iBAAiB,SAAS,YAAY,IAAI;IACxD;EACF;AACF;AAEA,IAAM,UAAU,CACd,KACA,MACAA,gBACoB;AACpB,MAAI,IAAI,aAAa;AACnBA,gBAAW,cAAc,IAAI;EAC/B;AACA,SAAOA;AACT;AC5FO,IAAM,UAAU,CAAC,YAA8C;AACpE,QAAM,WAAW,kBAAkB,OAAO;AAC1C,QAAM,cACJ,SAAS,SAAS,SACd,CAAC,GAAG,SAAS,UAAU,SAAS,gBAAgB,SAAS,IAAI,IAC7D,SAAS;AACf,SAAO;IACL,GAAG;IACH;IACA,cAAc;IACd,MAAM,IAAI;MACR,OAAO,QAAQ,SAAS,WAAW,EAAE,IAAI,CAAC,CAACC,QAAM,GAAG,MAAM;QACxD,IAAI;QACJ;UACE,KAAK,IAAI;UACT,MAAM,CAAC,GAAG,SAAS,UAAU,SAAS,gBAAgBA,MAAI;;UAE1D,YAAY;QACd;MACF,CAAC;IACH;EACF;AACF;AC/BA,IAAM,kBAAkB,CACtB,QACA,YAMG;AAfL,MAAAP;AAgBE,QAAM,OAAO,QAAQ,OAAO;AAE5B,MAAI,cACF,OAAO,YAAY,YAAY,QAAQ,cACnC,OAAO,QAAQ,QAAQ,WAAW,EAAE;IAClC,CAAC,KAAyC,CAACO,QAAMC,OAAM,MAAG;AArBpE,UAAAR;AAqBwE,aAAA;QAC5D,GAAG;QACH,CAACO,MAAI,IACHP,OAAA;UACEQ,QAAO;UACP;YACE,GAAG;YACH,aAAa,CAAC,GAAG,KAAK,UAAU,KAAK,gBAAgBD,MAAI;UAC3D;UACA;QACF,MAPA,OAAAP,OAOK,YAAY;MACrB;IAAA;IACA,CAAC;EACH,IACA;AAEN,QAAMO,SACJ,OAAO,YAAY,WACf,WACA,WAAA,OAAA,SAAA,QAAS,kBAAiB,UACxB,SACA,WAAA,OAAA,SAAA,QAAS;AAEjB,QAAM,QACJP,OAAA;IACE,OAAO;IACPO,WAAS,SACL,OACA;MACE,GAAG;MACH,aAAa,CAAC,GAAG,KAAK,UAAU,KAAK,gBAAgBA,MAAI;IAC3D;IACJ;EACF,MATA,OAAAP,OASM,YAAY;AAEpB,QAAM,QACJ,OAAO,YAAY,YACnB,QAAQ,SAAS,UACjB,QAAQ,iBAAiB,UACrB,QAAQ,OACR;AAEN,MAAI,UAAU,QAAW;AACvB,SAAK,QAAQ;EACf;AAEA,QAAM,WACJO,WAAS,SACL,cACE;IACE,GAAG;IACH,CAAC,KAAK,cAAc,GAAG;EACzB,IACA,OACF;IACE,MAAM;MACJ,GAAI,KAAK,iBAAiB,aAAa,CAAC,IAAI,KAAK;MACjD,KAAK;MACLA;IACF,EAAE,KAAK,GAAG;IACV,CAAC,KAAK,cAAc,GAAG;MACrB,GAAG;MACH,CAACA,MAAI,GAAG;IACV;EACF;AAEN,WAAS,UAAU;AAEnB,SAAO;AACT;ACpDA,IAAO,6BAAQ;ArChCR,SAAS,WACdE,YACA,SASgB;AAjBlB,MAAAT;AAmBE,QAAM,iBAAgBA,OAAA,WAAA,OAAA,SAAA,QAAS,kBAAT,OAAAA,OAA0B;AAEhD,SAAO;;IAEL,MACE,2BAAgBS,YAAW;MACzB,cAAc,gBAAgB,SAAS;IACzC,CAAC;IACH;MACE,UAAU,OAAM,UAAS;AACvB,cAAM,SAAS,MAAMA,WAAU,eAAe,KAAK;AACnD,eAAO,OAAO,UACV,EAAE,SAAS,MAAM,OAAO,OAAO,KAAK,IACpC,EAAE,SAAS,OAAO,OAAO,OAAO,MAAM;MAC5C;IACF;EACF;AACF;AAEO,SAAS,WACdA,YACA,SASgB;AAjDlB,MAAAT;AAmDE,QAAM,iBAAgBA,OAAA,WAAA,OAAA,SAAA,QAAS,kBAAT,OAAAA,OAA0B;AAEhD,SAAO;;IAEL,MACK,aAAaS,YAAW;MACzB,QAAQ;MACR,IAAI;MACJ,QAAQ,gBAAgB,QAAQ;IAClC,CAAC;IACH;MACE,UAAU,OAAM,UAAS;AACvB,cAAM,SAAS,MAAS,eAAeA,YAAW,KAAK;AACvD,eAAO,OAAO,UACV,EAAE,SAAS,MAAM,OAAO,OAAO,KAAK,IACpC,EAAE,SAAS,OAAO,OAAO,OAAO,MAAM;MAC5C;IACF;EACF;AACF;AAEO,SAAS,aACdA,YACyC;AAEzC,SAAO,UAAUA;AACnB;AAEO,SAAS,UACdA,YAGA,SASgB;AAChB,MAAI,aAAaA,UAAS,GAAG;AAC3B,WAAO,WAAWA,YAAW,OAAO;EACtC,OAAO;AACL,WAAO,WAAWA,YAAW,OAAO;EACtC;AACF;AsCzFA,IAAM,eAAe,OAAO,IAAI,kBAAkB;AAkE3C,SAAS,WACdC,aACA;EACE;AACF,IAII,CAAC,GACW;AAChB,SAAO;IACL,CAAC,YAAY,GAAG;IAChB,OAAO;;IACP,CAAC,eAAe,GAAG;IACnB,IAAI,aAAa;AACf,UAAI,OAAOA,gBAAe,YAAY;AACpCA,sBAAaA,YAAW;MAC1B;AACA,aAAOA;IACT;IACA;EACF;AACF;AAEA,SAAS,SAAS,OAAiC;AACjD,SACE,OAAO,UAAU,YACjB,UAAU,QACV,gBAAgB,SAChB,MAAM,YAAY,MAAM,QACxB,gBAAgB,SAChB,cAAc;AAElB;AAEO,SAASC,UACd,QACgB;AAChB,SAAO,UAAU,OACb,WAAW;IACT,YAAY,CAAC;IACb,sBAAsB;EACxB,CAAC,IACD,SAAS,MAAM,IACb,SACA,OAAO,WAAW,aAChB,OAAO,IACP,UAAU,MAAM;AAC1B;ACxHA,IAAM,EAAE,MAAM,KAAK,IAAI;ACHhB,SAAS,qBAAqB,KAAyB;AAC5D,SAAO,OAAA,OAAA,SAAA,IAAK,QAAQ,OAAO,EAAA;AAC7B;;;AmBFA,kBAA2B;AAC3B,IAAAC,eAAmC;AZDnC,IAAM,SAAS;AACf,IAAM,SAAS,OAAO,IAAI,MAAM;AADhC,IAAA;AAAA,IAAA;AAGO,IAAe,eAAf,MAAe,uBAAqB,KAAA,OACvB,KAAA,QADuB,IAAM;EAQ/C,YAAY;IACV;IACA,aAAa;IACb;EACF,GAIG;AACD,UAAM,OAAO;AAhBf,SAAkB,EAAA,IAAU;AAiB1B,SAAK,aAAa;AAClB,SAAK,QAAQ;EACf;;;;;;EAOA,OAAO,WAAW,OAAuC;AACvD,WAAO,cAAa,UAAU,KAAK;EACrC;EAEA,OAAO,UAAU,OAAuC;AACtD,WACE,OAAO,UAAU,YACjB,UAAU,QACV,UAAU,SACT,MAAc,MAAM,MAAM;EAE/B;AACF;ACxCA,IAAM,OAAO;AACb,IAAMC,UAAS,2BAA2B,IAAI;AAC9C,IAAMC,UAAS,OAAO,IAAID,OAAM;AAJhC,IAAAE;AAAA,IAAAC;AASO,IAAM,6BAAN,MAAM,qCAAmCA,MAAA,cAC5BD,MAAAD,SAD4BE,KAAa;EAM3D,YAAY;IACV,UAAU;IACV,aAAa;IACb;EACF,IAII,CAAC,GAAG;AACN,UAAM,EAAE,SAAS,YAAY,MAAM,CAAC;AAdtC,SAAkBD,GAAAA,IAAU;AAE5B,SAAS,OAAO;AAChB,SAAS,OAAO;EAYhB;EAEA,OAAO,WAAW,OAAqD;AACrE,WAAO,aAAa,UAAU,KAAK,KAAKD,WAAU;EACpD;;;;EAKA,OAAO,sBAAsB;IAC3B;IACA;IACA,UAAU;IACV,aAAa;IACb;EACF,GAM+B;AAC7B,QAAI;AAEJ,QAAI,gBAAgB;AAClB,0BAAoB;;;;;IAKtB,WAAW,mBAAmB;AAC5B,0BAAoB;;;;;IAKtB,OAAO;AACL,0BAAoB;;;;;;;;IAQtB;AAEA,WAAO,IAAI,4BAA2B;MACpC,SAAS;MACT;MACA;IACF,CAAC;EACH;AACF;AC5EA,IAAMG,QAAO;AACb,IAAMJ,UAAS,2BAA2BI,KAAI;AAC9C,IAAMH,UAAS,OAAO,IAAID,OAAM;AAJhC,IAAAE;AAAA,IAAAC;AASO,IAAM,6BAAN,eAAyCA,MAAA,cAC5BD,MAAAD,SAD4BE,KAAa;EAM3D,YAAY;IACV,UAAU;IACV,aAAa;IACb;EACF,IAII,CAAC,GAAG;AACN,UAAM,EAAE,SAAS,YAAY,MAAM,CAAC;AAdtC,SAAkBD,GAAAA,IAAU;AAE5B,SAAS,OAAOE;AAChB,SAAS,OAAO;EAYhB;EAEA,OAAO,WAAW,OAAqD;AACrE,WAAO,aAAa,UAAU,KAAK,KAAKH,WAAU;EACpD;AACF;AC5BA,IAAMG,QAAO;AACb,IAAMJ,UAAS,2BAA2BI,KAAI;AAC9C,IAAMH,UAAS,OAAO,IAAID,OAAM;AAJhC,IAAAE;AAAA,IAAAC;AASO,IAAM,wBAAN,eAAoCA,MAAA,cACvBD,MAAAD,SADuBE,KAAa;EAMtD,YAAY;IACV,UAAU;IACV,aAAa;IACb;EACF,IAII,CAAC,GAAG;AACN,UAAM,EAAE,SAAS,YAAY,MAAM,CAAC;AAdtC,SAAkBD,GAAAA,IAAU;AAE5B,SAAS,OAAOE;AAChB,SAAS,OAAO;EAYhB;EAEA,OAAO,WAAW,OAAgD;AAChE,WAAO,aAAa,UAAU,KAAK,KAAKH,WAAU;EACpD;AACF;AC1BA,IAAMG,QAAO;AACb,IAAMJ,UAAS,2BAA2BI,KAAI;AAC9C,IAAMH,UAAS,OAAO,IAAID,OAAM;AAEzB,IAAM,2BAA2B;EAAc,MACpD;IACE,iBAAE,OAAO;MACP,SAAS,iBAAE,OAAO;IACpB,CAAC;EACH;AACF;AAdA,IAAAE;AAAA,IAAAC;AAmBO,IAAM,4BAAN,eAAwCA,MAAA,cAC3BD,MAAAD,SAD2BE,KAAa;EAO1D,YAAY;IACV,UAAU;IACV,aAAa;IACb;IACA;EACF,IAKI,CAAC,GAAG;AACN,UAAM,EAAE,SAAS,YAAY,MAAM,CAAC;AAjBtC,SAAkBD,GAAAA,IAAU;AAE5B,SAAS,OAAOE;AAChB,SAAS,OAAO;AAed,SAAK,UAAU;EACjB;EAEA,OAAO,WAAW,OAAoD;AACpE,WAAO,aAAa,UAAU,KAAK,KAAKH,WAAU;EACpD;AACF;AC1CA,IAAMG,QAAO;AACb,IAAMJ,UAAS,2BAA2BI,KAAI;AAC9C,IAAMH,UAAS,OAAO,IAAID,OAAM;AAJhC,IAAAE;AAAA,IAAAC;AASO,IAAM,6BAAN,eAAyCA,MAAA,cAC5BD,MAAAD,SAD4BE,KAAa;EAM3D,YAAY;IACV,UAAU;IACV,aAAa;IACb;EACF,IAII,CAAC,GAAG;AACN,UAAM,EAAE,SAAS,YAAY,MAAM,CAAC;AAdtC,SAAkBD,GAAAA,IAAU;AAE5B,SAAS,OAAOE;AAChB,SAAS,OAAO;EAYhB;EAEA,OAAO,WAAW,OAAqD;AACrE,WAAO,aAAa,UAAU,KAAK,KAAKH,WAAU;EACpD;AACF;AC3BA,IAAMG,QAAO;AACb,IAAMJ,UAAS,2BAA2BI,KAAI;AAC9C,IAAMH,UAAS,OAAO,IAAID,OAAM;AALhC,IAAAE;AAAA,IAAAC;AAUO,IAAM,uBAAN,eAAmCA,MAAA,cACtBD,MAAAD,SADsBE,KAAa;EAQrD,YAAY;IACV,UAAU;IACV,aAAa;IACb;IACA;IACA;EACF,IAMI,CAAC,GAAG;AACN,UAAM,EAAE,SAAS,YAAY,MAAM,CAAC;AApBtC,SAAkBD,GAAAA,IAAU;AAE5B,SAAS,OAAOE;AAChB,SAAS,OAAO;AAkBd,SAAK,WAAW;AAChB,SAAK,kBAAkB;EACzB;EAEA,OAAO,WAAW,OAA+C;AAC/D,WAAO,aAAa,UAAU,KAAK,KAAKH,WAAU;EACpD;AACF;APpBA,eAAsB,+BAA+B;EACnD;EACA;EACA,iBAAiB;EACjB;EACA;AACF,GAM0B;AACxB,QAAM,cAAc,MAAMI,mBAAkB;IAC1C,OAAO;IACP,QAAQ;EACV,CAAC;AAED,MAAI,CAAC,YAAY,SAAS;AACxB,WAAO,IAAI,qBAAqB;MAC9B,SAAS,kCAAkC,cAAc;MACzD;MACA;MACA,iBAAiB,YAAY;MAC7B;IACF,CAAC;EACH;AAEA,QAAM,oBAA0C,YAAY;AAC5D,QAAM,YAAY,kBAAkB,MAAM;AAC1C,QAAM,UAAU,kBAAkB,MAAM;AAExC,UAAQ,WAAW;IACjB,KAAK;AACH,aAAO,2BAA2B,sBAAsB;QACtD,gBAAgB,eAAe;QAC/B,mBAAmB,eAAe;QAClC;QACA;MACF,CAAC;IACH,KAAK;AACH,aAAO,IAAI,2BAA2B,EAAE,SAAS,YAAY,MAAM,CAAC;IACtE,KAAK;AACH,aAAO,IAAI,sBAAsB,EAAE,SAAS,YAAY,MAAM,CAAC;IACjE,KAAK,mBAAmB;AACtB,YAAM,cAAc,MAAMA,mBAAkB;QAC1C,OAAO,kBAAkB,MAAM;QAC/B,QAAQ;MACV,CAAC;AAED,aAAO,IAAI,0BAA0B;QACnC;QACA;QACA,SAAS,YAAY,UAAU,YAAY,MAAM,UAAU;QAC3D;MACF,CAAC;IACH;IACA,KAAK;AACH,aAAO,IAAI,2BAA2B,EAAE,SAAS,YAAY,MAAM,CAAC;IACtE;AACE,aAAO,IAAI,2BAA2B,EAAE,SAAS,YAAY,MAAM,CAAC;EACxE;AACF;AAEA,IAAM,6BAA6BC;EAAc,MAC/CC;IACEC,iBAAE,OAAO;MACP,OAAOA,iBAAE,OAAO;QACd,SAASA,iBAAE,OAAO;QAClB,MAAMA,iBAAE,OAAO,EAAE,QAAQ;QACzB,OAAOA,iBAAE,QAAQ,EAAE,QAAQ;QAC3B,MAAMA,iBAAE,MAAM,CAACA,iBAAE,OAAO,GAAGA,iBAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;MAClD,CAAC;IACH,CAAC;EACH;AACF;AD1FO,SAAS,eACd,OACA,YACA;AAPF,MAAAN;AAQE,MAAI,aAAa,WAAW,KAAK,GAAG;AAClC,WAAO;EACT;AAEA,MAAI,aAAa,WAAW,KAAK,GAAG;AAClC,WAAO,+BAA+B;MACpC,UAAU,uBAAuB,KAAK;MACtC,aAAYA,OAAA,MAAM,eAAN,OAAAA,OAAoB;MAChC,gBAAgB;MAChB,OAAO;MACP;IACF,CAAC;EACH;AAEA,SAAO,+BAA+B;IACpC,UAAU,CAAC;IACX,YAAY;IACZ,gBACE,iBAAiB,QACb,2BAA2B,MAAM,OAAO,KACxC;IACN,OAAO;IACP;EACF,CAAC;AACH;AS9BO,SAAS,uBAAuB,OAA8B;AACnE,MAAI,MAAM,SAAS,QAAW;AAC5B,WAAO,MAAM;EACf;AACA,MAAI,MAAM,gBAAgB,MAAM;AAC9B,QAAI;AACF,aAAO,KAAK,MAAM,MAAM,YAAY;IACtC,SAAQ,GAAA;AACN,aAAO,MAAM;IACf;EACF;AACA,SAAO,CAAC;AACV;ACPO,IAAM,6BAA6B;AAE1C,eAAsB,gBACpB,SACA;AACA,QAAM,SAAS,MAAMG,mBAAkB;IACrC,OAAO,QAAQ,0BAA0B;IACzC,QAAQ;EACV,CAAC;AAED,SAAO,OAAO,UAAU,OAAO,QAAQ;AACzC;AAEA,IAAM,0BAA0BC;EAAc,MAC5CC,UAAUC,iBAAE,MAAM,CAACA,iBAAE,QAAQ,SAAS,GAAGA,iBAAE,QAAQ,MAAM,CAAC,CAAC,CAAC;AAC9D;ACIO,IAAM,uBAAN,MAA2B;EAChC,YAA6B,QAAoC;AAApC,SAAA,SAAA;EAAqC;EAElE,MAAM,qBAA4D;AAChE,QAAI;AACF,YAAM,EAAE,MAAM,IAAI,MAAM,WAAW;QACjC,KAAK,GAAG,KAAK,OAAO,OAAO;QAC3B,SAAS,MAAM,QAAQ,KAAK,OAAO,QAAQ,CAAC;QAC5C,2BAA2B;UACzB;QACF;QACA,uBAAuB,+BAA+B;UACpD,aAAaA,iBAAE,IAAI;UACnB,gBAAgB,CAAA,SAAQ;QAC1B,CAAC;QACD,OAAO,KAAK,OAAO;MACrB,CAAC;AAED,aAAO;IACT,SAAS,OAAO;AACd,YAAM,MAAM,eAAe,KAAK;IAClC;EACF;EAEA,MAAM,aAA8C;AAClD,QAAI;AACF,YAAM,UAAU,IAAI,IAAI,KAAK,OAAO,OAAO;AAE3C,YAAM,EAAE,MAAM,IAAI,MAAM,WAAW;QACjC,KAAK,GAAG,QAAQ,MAAM;QACtB,SAAS,MAAM,QAAQ,KAAK,OAAO,QAAQ,CAAC;QAC5C,2BAA2B;UACzB;QACF;QACA,uBAAuB,+BAA+B;UACpD,aAAaA,iBAAE,IAAI;UACnB,gBAAgB,CAAA,SAAQ;QAC1B,CAAC;QACD,OAAO,KAAK,OAAO;MACrB,CAAC;AAED,aAAO;IACT,SAAS,OAAO;AACd,YAAM,MAAM,eAAe,KAAK;IAClC;EACF;AACF;AAEA,IAAM,uCAAuCF;EAAc,MACzDC;IACEC,iBAAE,OAAO;MACP,QAAQA,iBAAE;QACRA,iBAAE,OAAO;UACP,IAAIA,iBAAE,OAAO;UACb,MAAMA,iBAAE,OAAO;UACf,aAAaA,iBAAE,OAAO,EAAE,QAAQ;UAChC,SAASA,iBACN,OAAO;YACN,OAAOA,iBAAE,OAAO;YAChB,QAAQA,iBAAE,OAAO;YACjB,kBAAkBA,iBAAE,OAAO,EAAE,QAAQ;YACrC,mBAAmBA,iBAAE,OAAO,EAAE,QAAQ;UACxC,CAAC,EACA;YACC,CAAC,EAAE,OAAO,QAAQ,kBAAkB,kBAAkB,OAAO;cAC3D;cACA;cACA,GAAI,mBACA,EAAE,mBAAmB,iBAAiB,IACtC,CAAC;cACL,GAAI,oBACA,EAAE,0BAA0B,kBAAkB,IAC9C,CAAC;YACP;UACF,EACC,QAAQ;UACX,eAAeA,iBAAE,OAAO;YACtB,sBAAsBA,iBAAE,QAAQ,IAAI;YACpC,UAAUA,iBAAE,OAAO;YACnB,SAASA,iBAAE,OAAO;UACpB,CAAC;UACD,WAAWA,iBAAE,KAAK,CAAC,YAAY,aAAa,OAAO,CAAC,EAAE,QAAQ;QAChE,CAAC;MACH;IACF,CAAC;EACH;AACF;AAEA,IAAM,+BAA+BF;EAAc,MACjDC;IACEC,iBACG,OAAO;MACN,SAASA,iBAAE,OAAO;MAClB,YAAYA,iBAAE,OAAO;IACvB,CAAC,EACA,UAAU,CAAC,EAAE,SAAS,WAAW,OAAO;MACvC;MACA,WAAW;IACb,EAAE;EACN;AACF;AClGO,IAAM,uBAAN,MAAsD;EAI3D,YACW,SACQ,QACjB;AAFS,SAAA,UAAA;AACQ,SAAA,SAAA;AALnB,SAAS,uBAAuB;AAChC,SAAS,gBAAgB,EAAE,OAAO,CAAC,IAAI,EAAE;EAKtC;EAEH,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEA,MAAc,QAAQ,SAAuD;AAC3E,UAAM,EAAE,aAAa,cAAc,GAAG,qBAAqB,IAAI;AAE/D,WAAO;MACL,MAAM,KAAK,qBAAqB,oBAAoB;MACpD,UAAU,CAAC;IACb;EACF;EAEA,MAAM,WACJ,SAC6D;AAC7D,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AACrD,UAAM,EAAE,YAAY,IAAI;AAExB,UAAM,kBAAkB,MAAMC,QAAQ,KAAK,OAAO,QAAQ,CAAC;AAE3D,QAAI;AACF,YAAM;QACJ;QACA,OAAO;QACP,UAAU;MACZ,IAAI,MAAM,cAAc;QACtB,KAAK,KAAK,OAAO;QACjB,SAAS;UACP;UACA,QAAQ;UACR,KAAK,sBAAsB,KAAK,SAAS,KAAK;UAC9C,MAAMA,QAAQ,KAAK,OAAO,WAAW;QACvC;QACA,MAAM;QACN,2BAA2BC,0BAA0BF,iBAAE,IAAI,CAAC;QAC5D,uBAAuBG,+BAA+B;UACpD,aAAaH,iBAAE,IAAI;UACnB,gBAAgB,CAAA,SAAQ;QAC1B,CAAC;QACD,GAAI,eAAe,EAAE,YAAY;QACjC,OAAO,KAAK,OAAO;MACrB,CAAC;AAED,aAAO;QACL,GAAG;QACH,SAAS,EAAE,MAAM,KAAK;QACtB,UAAU,EAAE,SAAS,iBAAiB,MAAM,YAAY;QACxD;MACF;IACF,SAAS,OAAO;AACd,YAAM,MAAM,eAAe,OAAO,MAAM,gBAAgB,eAAe,CAAC;IAC1E;EACF;EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM,EAAE,MAAM,SAAS,IAAI,MAAM,KAAK,QAAQ,OAAO;AACrD,UAAM,EAAE,YAAY,IAAI;AAExB,UAAM,kBAAkB,MAAMC,QAAQ,KAAK,OAAO,QAAQ,CAAC;AAE3D,QAAI;AACF,YAAM,EAAE,OAAO,UAAU,gBAAgB,IAAI,MAAM,cAAc;QAC/D,KAAK,KAAK,OAAO;QACjB,SAAS;UACP;UACA,QAAQ;UACR,KAAK,sBAAsB,KAAK,SAAS,IAAI;UAC7C,MAAMA,QAAQ,KAAK,OAAO,WAAW;QACvC;QACA,MAAM;QACN,2BAA2B,iCAAiCD,iBAAE,IAAI,CAAC;QACnE,uBAAuBG,+BAA+B;UACpD,aAAaH,iBAAE,IAAI;UACnB,gBAAgB,CAAA,SAAQ;QAC1B,CAAC;QACD,GAAI,eAAe,EAAE,YAAY;QACjC,OAAO,KAAK,OAAO;MACrB,CAAC;AAED,aAAO;QACL,QAAQ,SAAS;UACf,IAAI,gBAGF;YACA,MAAM,YAAY;AAChB,kBAAI,SAAS,SAAS,GAAG;AACvB,2BAAW,QAAQ,EAAE,MAAM,gBAAgB,SAAS,CAAC;cACvD;YACF;YACA,UAAU,OAAO,YAAY;AAC3B,kBAAI,MAAM,SAAS;AACjB,sBAAM,aAAa,MAAM;AAIzB,oBAAI,WAAW,SAAS,SAAS,CAAC,QAAQ,kBAAkB;AAC1D;gBACF;AAEA,oBACE,WAAW,SAAS,uBACpB,WAAW,aACX,OAAO,WAAW,cAAc,UAChC;AACA,6BAAW,YAAY,IAAI,KAAK,WAAW,SAAS;gBACtD;AAEA,2BAAW,QAAQ,UAAU;cAC/B,OAAO;AACL,2BAAW;kBACR,MAA6C;gBAChD;cACF;YACF;UACF,CAAC;QACH;QACA,SAAS,EAAE,MAAM,KAAK;QACtB,UAAU,EAAE,SAAS,gBAAgB;MACvC;IACF,SAAS,OAAO;AACd,YAAM,MAAM,eAAe,OAAO,MAAM,gBAAgB,eAAe,CAAC;IAC1E;EACF;EAEQ,WAAW,MAAe;AAChC,WACE,QAAQ,OAAO,SAAS,YAAY,UAAU,QAAQ,KAAK,SAAS;EAExE;;;;;;;EAQQ,qBAAqB,SAAqC;AAChE,eAAW,WAAW,QAAQ,QAAQ;AACpC,iBAAW,QAAQ,QAAQ,SAAS;AAClC,YAAI,KAAK,WAAW,IAAI,GAAG;AACzB,gBAAM,WAAW;AAIjB,cAAI,SAAS,gBAAgB,YAAY;AACvC,kBAAM,SAAS,WAAW,KAAK,SAAS,IAAI;AAC5C,kBAAM,aAAa,OAAO,KAAK,MAAM,EAAE,SAAS,QAAQ;AACxD,qBAAS,OAAO,IAAI;cAClB,QAAQ,SAAS,aAAa,0BAA0B,WAAW,UAAU;YAC/E;UACF;QACF;MACF;IACF;AACA,WAAO;EACT;EAEQ,SAAS;AACf,WAAO,GAAG,KAAK,OAAO,OAAO;EAC/B;EAEQ,sBAAsB,SAAiB,WAAoB;AACjE,WAAO;MACL,2CAA2C;MAC3C,wBAAwB;MACxB,+BAA+B,OAAO,SAAS;IACjD;EACF;AACF;AC9LO,IAAM,wBAAN,MAAgE;EAKrE,YACW,SACQ,QAIjB;AALS,SAAA,UAAA;AACQ,SAAA,SAAA;AANnB,SAAS,uBAAuB;AAChC,SAAS,uBAAuB;AAChC,SAAS,wBAAwB;EAQ9B;EAEH,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;EACrB;EAEA,MAAM,QAAQ;IACZ;IACA;IACA;IACA;EACF,GAEE;AA3CJ,QAAAN;AA4CI,UAAM,kBAAkB,MAAMO,QAAQ,KAAK,OAAO,QAAQ,CAAC;AAC3D,QAAI;AACF,YAAM;QACJ;QACA,OAAO;QACP;MACF,IAAI,MAAMG,cAAc;QACtB,KAAK,KAAK,OAAO;QACjB,SAASC;UACP;UACA,WAAA,OAAA,UAAW,CAAC;UACZ,KAAK,sBAAsB;UAC3B,MAAMJ,QAAQ,KAAK,OAAO,WAAW;QACvC;QACA,MAAM;UACJ,OAAO,OAAO,WAAW,IAAI,OAAO,CAAC,IAAI;UACzC,GAAI,kBAAkB,EAAE,gBAAgB,IAAI,CAAC;QAC/C;QACA,2BAA2BC;UACzB;QACF;QACA,uBAAuBC,+BAA+B;UACpD,aAAaH,iBAAE,IAAI;UACnB,gBAAgB,CAAA,SAAQ;QAC1B,CAAC;QACD,GAAI,eAAe,EAAE,YAAY;QACjC,OAAO,KAAK,OAAO;MACrB,CAAC;AAED,aAAO;QACL,YAAY,aAAa;QACzB,QAAON,OAAA,aAAa,UAAb,OAAAA,OAAsB;QAC7B,kBACE,aAAa;QACf,UAAU,EAAE,SAAS,iBAAiB,MAAM,SAAS;MACvD;IACF,SAAS,OAAO;AACd,YAAM,MAAM,eAAe,OAAO,MAAM,gBAAgB,eAAe,CAAC;IAC1E;EACF;EAEQ,SAAS;AACf,WAAO,GAAG,KAAK,OAAO,OAAO;EAC/B;EAEQ,wBAAwB;AAC9B,WAAO;MACL,4CAA4C;MAC5C,eAAe,KAAK;IACtB;EACF;AACF;AAEA,IAAM,iCAAiCI;EAAc,MACnDC;IACEC,iBAAE,OAAO;MACP,YAAYA,iBAAE,MAAMA,iBAAE,MAAMA,iBAAE,OAAO,CAAC,CAAC;MACvC,OAAOA,iBAAE,OAAO,EAAE,QAAQA,iBAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;MAChD,kBAAkBA,iBACf,OAAOA,iBAAE,OAAO,GAAGA,iBAAE,OAAOA,iBAAE,OAAO,GAAGA,iBAAE,QAAQ,CAAC,CAAC,EACpD,SAAS;IACd,CAAC;EACH;AACF;ACxGA,eAAsB,qBAAkD;AAHxE,MAAAN;AAIE,UAAOA,WAAA,wBAAW,EAAE,YAAb,OAAA,SAAAA,KAAuB,aAAA;AAChC;ACHO,IAAMY,WACX,OACI,UACA;AhBqFN,IAAM,8BAA8B;AAK7B,SAAS,sBACd,UAAmC,CAAC,GACnB;AAjGnB,MAAAZ,MAAAC;AAkGE,MAAI,kBAAgE;AACpE,MAAI,gBAAqD;AACzD,QAAM,sBACJD,OAAA,QAAQ,+BAAR,OAAAA,OAAsC,MAAO,KAAK;AACpD,MAAI,gBAAgB;AAEpB,QAAM,WACJC,MAAA,qBAAqB,QAAQ,OAAO,MAApC,OAAAA,MACA;AAEF,QAAM,aAAa,YAAY;AAC7B,UAAM,OAAO,MAAM,oBAAoB,OAAO;AAC9C,QAAI,MAAM;AACR,aAAO;QACL;UACE,eAAe,UAAU,KAAK,KAAK;UACnC,+BAA+B;UAC/B,CAAC,0BAA0B,GAAG,KAAK;UACnC,GAAG,QAAQ;QACb;QACA,kBAAkBW,QAAO;MAC3B;IACF;AAEA,UAAM,2BAA2B,sBAAsB;MACrD,gBAAgB;MAChB,mBAAmB;MACnB,YAAY;IACd,CAAC;EACH;AAEA,QAAM,oBAAoB,MAAM;AAC9B,UAAM,eAAe,oBAAoB;MACvC,cAAc;MACd,yBAAyB;IAC3B,CAAC;AACD,UAAM,cAAc,oBAAoB;MACtC,cAAc;MACd,yBAAyB;IAC3B,CAAC;AACD,UAAM,SAAS,oBAAoB;MACjC,cAAc;MACd,yBAAyB;IAC3B,CAAC;AAED,WAAO,YAAY;AACjB,YAAM,YAAY,MAAM,mBAAmB;AAC3C,aAAO;QACL,GAAI,gBAAgB,EAAE,yBAAyB,aAAa;QAC5D,GAAI,eAAe,EAAE,uBAAuB,YAAY;QACxD,GAAI,UAAU,EAAE,kBAAkB,OAAO;QACzC,GAAI,aAAa,EAAE,sBAAsB,UAAU;MACrD;IACF;EACF;AAEA,QAAM,sBAAsB,CAAC,YAA4B;AACvD,WAAO,IAAI,qBAAqB,SAAS;MACvC,UAAU;MACV;MACA,SAAS;MACT,OAAO,QAAQ;MACf,aAAa,kBAAkB;IACjC,CAAC;EACH;AAEA,QAAM,qBAAqB,YAAY;AApKzC,QAAAZ,MAAAC,KAAA;AAqKI,UAAM,OAAM,MAAAA,OAAAD,OAAA,QAAQ,cAAR,OAAA,SAAAA,KAAmB,gBAAnB,OAAA,SAAAC,IAAA,KAAAD,IAAAA,EAAmC,QAAA,MAAnC,OAAA,KAAgD,KAAK,IAAI;AACrE,QAAI,CAAC,mBAAmB,MAAM,gBAAgB,oBAAoB;AAChE,sBAAgB;AAEhB,wBAAkB,IAAI,qBAAqB;QACzC;QACA,SAAS;QACT,OAAO,QAAQ;MACjB,CAAC,EACE,mBAAmB,EACnB,KAAK,CAAA,aAAY;AAChB,wBAAgB;AAChB,eAAO;MACT,CAAC,EACA,MAAM,OAAO,UAAmB;AAC/B,cAAM,MAAM;UACV;UACA,MAAM,gBAAgB,MAAM,WAAW,CAAC;QAC1C;MACF,CAAC;IACL;AAEA,WAAO,gBAAgB,QAAQ,QAAQ,aAAa,IAAI;EAC1D;AAEA,QAAM,aAAa,YAAY;AAC7B,WAAO,IAAI,qBAAqB;MAC9B;MACA,SAAS;MACT,OAAO,QAAQ;IACjB,CAAC,EACE,WAAW,EACX,MAAM,OAAO,UAAmB;AAC/B,YAAM,MAAM;QACV;QACA,MAAM,gBAAgB,MAAM,WAAW,CAAC;MAC1C;IACF,CAAC;EACL;AAEA,QAAM,WAAW,SAAU,SAAyB;AAClD,QAAI,YAAY;AACd,YAAM,IAAI;QACR;MACF;IACF;AAEA,WAAO,oBAAoB,OAAO;EACpC;AAEA,WAAS,qBAAqB;AAC9B,WAAS,aAAa;AACtB,WAAS,aAAa,CAAC,YAAoB;AACzC,UAAM,IAAI,iBAAiB,EAAE,SAAS,WAAW,aAAa,CAAC;EACjE;AACA,WAAS,gBAAgB;AACzB,WAAS,qBAAqB,CAAC,YAAqC;AAClE,WAAO,IAAI,sBAAsB,SAAS;MACxC,UAAU;MACV;MACA,SAAS;MACT,OAAO,QAAQ;MACf,aAAa,kBAAkB;IACjC,CAAC;EACH;AAEA,SAAO;AACT;AAEO,IAAM,UAAU,sBAAsB;AAE7C,eAAsB,oBACpB,SAIQ;AACR,QAAM,SAAS,oBAAoB;IACjC,cAAc,QAAQ;IACtB,yBAAyB;EAC3B,CAAC;AAED,MAAI,QAAQ;AACV,WAAO;MACL,OAAO;MACP,YAAY;IACd;EACF;AAEA,MAAI;AACF,UAAM,YAAY,UAAM,iCAAmB;AAC3C,WAAO;MACL,OAAO;MACP,YAAY;IACd;EACF,SAAQ,GAAA;AACN,WAAO;EACT;AACF;;;;;;;;AmBrQA,IAAMa,QAAO;AACb,IAAMC,UAAS,mBAAmBD,KAAI;AACtC,IAAME,UAAS,OAAO,IAAID,OAAM;AAJhC,IAAAE;AAUoBC,MAAAC;AIRpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAME,WAAS,OAAO,IAAID,QAAM;AAJhC,IAAAE;AAOoBC,OAAAC;ACJpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AALhC,IAAAH;AAQoBI,OAAAC;ACNpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AAJhC,IAAAH;AAOoBI,OAAAC;ACJpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AALhC,IAAAH;AAcoBI,OAAAC;ACTpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AAPhC,IAAAH;AAoBO,IAAM,yBAAN,cAAqCI,WAAW;EAuBrD,YAAY;IACV,UAAU;IACV;IACA,MAAAC;IACA;IACA;IACA;EACF,GAOG;AACD,UAAM,EAAE,MAAAH,QAAM,SAAS,MAAM,CAAC;AArChC,SAAkBF,IAAAA,IAAU;AAuC1B,SAAK,OAAOK;AACZ,SAAK,WAAW;AAChB,SAAK,QAAQ;AACb,SAAK,eAAe;EACtB;EAEA,OAAO,WAAW,OAAiD;AACjE,WAAOD,WAAW,UAAU,OAAOD,QAAM;EAC3C;AACF;AAhDoBH,OAAAC;ACnBpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AAJhC,IAAAH;AAUoBM,OAAAC;AERpB,IAAMC,QAAO;AACb,IAAMC,WAAS,mBAAmBD,KAAI;AACtC,IAAME,WAAS,OAAO,IAAID,QAAM;AAJhC,IAAAE;AAOoBC,OAAAC;ACHpB,IAAMC,QAAO;AACb,IAAMC,UAAS,mBAAmBD,KAAI;AACtC,IAAMD,UAAS,OAAO,IAAIE,OAAM;AANhC,IAAAH;AASoBI,MAAAC;AEPpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAME,WAAS,OAAO,IAAID,QAAM;AAJhC,IAAAE;AAOoBC,OAAAC;ACLpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AAJhC,IAAAH;AAOoBI,OAAAC;ACJpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AALhC,IAAAH;AAQoBI,OAAAC;ACNpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AAJhC,IAAAH;AAOoBI,OAAAC;ACLpB,IAAMC,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAMD,WAAS,OAAO,IAAIE,QAAM;AAJhC,IAAAH;AAYoBI,OAAAC;AIXb,IAAMC,WACX,OACI,WACA;AESC,IAAM,oBAA4C,iBAAE,MAAM;EAC/D,iBAAE,OAAO;EACT,iBAAE,WAAW,UAAU;EACvB,iBAAE,WAAW,WAAW;EACxB,iBAAE;;IAEA,CAAC,UAAiC;AAnBtC,UAAAC,MAAAC;AAoBM,cAAAA,OAAAD,OAAA,WAAW,WAAX,OAAA,SAAAA,KAAmB,SAAS,KAAA,MAA5B,OAAAC,MAAsC;IAAA;IACxC,EAAE,SAAS,mBAAmB;EAChC;AACF,CAAC;AQpBM,IAAM,kBAAwCC,iBAAE;EAAK,MAC1DA,iBAAE,MAAM;IACNA,iBAAE,KAAK;IACPA,iBAAE,OAAO;IACTA,iBAAE,OAAO;IACTA,iBAAE,QAAQ;IACVA,iBAAE,OAAOA,iBAAE,OAAO,GAAG,eAAe;IACpCA,iBAAE,MAAM,eAAe;EACzB,CAAC;AACH;ADAO,IAAM,yBAAsDA,iBAAE;EACnEA,iBAAE,OAAO;EACTA,iBAAE,OAAOA,iBAAE,OAAO,GAAG,eAAe;AACtC;AEEO,IAAM,iBAAsCA,iBAAE,OAAO;EAC1D,MAAMA,iBAAE,QAAQ,MAAM;EACtB,MAAMA,iBAAE,OAAO;EACf,iBAAiB,uBAAuB,SAAS;AACnD,CAAC;AAKM,IAAM,kBAAwCA,iBAAE,OAAO;EAC5D,MAAMA,iBAAE,QAAQ,OAAO;EACvB,OAAOA,iBAAE,MAAM,CAAC,mBAAmBA,iBAAE,WAAW,GAAG,CAAC,CAAC;EACrD,WAAWA,iBAAE,OAAO,EAAE,SAAS;EAC/B,iBAAiB,uBAAuB,SAAS;AACnD,CAAC;AAKM,IAAM,iBAAsCA,iBAAE,OAAO;EAC1D,MAAMA,iBAAE,QAAQ,MAAM;EACtB,MAAMA,iBAAE,MAAM,CAAC,mBAAmBA,iBAAE,WAAW,GAAG,CAAC,CAAC;EACpD,UAAUA,iBAAE,OAAO,EAAE,SAAS;EAC9B,WAAWA,iBAAE,OAAO;EACpB,iBAAiB,uBAAuB,SAAS;AACnD,CAAC;AAKM,IAAM,sBAAgDA,iBAAE,OAAO;EACpE,MAAMA,iBAAE,QAAQ,WAAW;EAC3B,MAAMA,iBAAE,OAAO;EACf,iBAAiB,uBAAuB,SAAS;AACnD,CAAC;AAkCM,IAAM,qBAA8CA,iBAAE,OAAO;EAClE,MAAMA,iBAAE,QAAQ,WAAW;EAC3B,YAAYA,iBAAE,OAAO;EACrB,UAAUA,iBAAE,OAAO;EACnB,OAAOA,iBAAE,QAAQ;EACjB,iBAAiB,uBAAuB,SAAS;EACjD,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;AACzC,CAAC;AAKM,IAAM,eACXA,iBAAE,mBAAmB,QAAQ;EAC3BA,iBAAE,OAAO;IACP,MAAMA,iBAAE,QAAQ,MAAM;IACtB,OAAOA,iBAAE,OAAO;EAClB,CAAC;EACDA,iBAAE,OAAO;IACP,MAAMA,iBAAE,QAAQ,MAAM;IACtB,OAAO;EACT,CAAC;EACDA,iBAAE,OAAO;IACP,MAAMA,iBAAE,QAAQ,YAAY;IAC5B,OAAOA,iBAAE,OAAO;EAClB,CAAC;EACDA,iBAAE,OAAO;IACP,MAAMA,iBAAE,QAAQ,YAAY;IAC5B,OAAO;EACT,CAAC;EACDA,iBAAE,OAAO;IACP,MAAMA,iBAAE,QAAQ,SAAS;IACzB,OAAOA,iBAAE;MACPA,iBAAE,MAAM;QACNA,iBAAE,OAAO;UACP,MAAMA,iBAAE,QAAQ,MAAM;UACtB,MAAMA,iBAAE,OAAO;QACjB,CAAC;QACDA,iBAAE,OAAO;UACP,MAAMA,iBAAE,QAAQ,OAAO;UACvB,MAAMA,iBAAE,OAAO;UACf,WAAWA,iBAAE,OAAO;QACtB,CAAC;MACH,CAAC;IACH;EACF,CAAC;AACH,CAAC;AAKI,IAAM,uBAAkDA,iBAAE,OAAO;EACtE,MAAMA,iBAAE,QAAQ,aAAa;EAC7B,YAAYA,iBAAE,OAAO;EACrB,UAAUA,iBAAE,OAAO;EACnB,QAAQ;EACR,iBAAiB,uBAAuB,SAAS;AACnD,CAAC;AHtHM,IAAM,2BAA0DA,iBAAE;EACvE;IACE,MAAMA,iBAAE,QAAQ,QAAQ;IACxB,SAASA,iBAAE,OAAO;IAClB,iBAAiB,uBAAuB,SAAS;EACnD;AACF;AAcO,IAAM,yBAAsDC,iBAAE,OAAO;EAC1E,MAAMA,iBAAE,QAAQ,MAAM;EACtB,SAASA,iBAAE,MAAM;IACfA,iBAAE,OAAO;IACTA,iBAAE,MAAMA,iBAAE,MAAM,CAAC,gBAAgB,iBAAiB,cAAc,CAAC,CAAC;EACpE,CAAC;EACD,iBAAiB,uBAAuB,SAAS;AACnD,CAAC;AAcM,IAAM,8BACXC,iBAAE,OAAO;EACP,MAAMA,iBAAE,QAAQ,WAAW;EAC3B,SAASA,iBAAE,MAAM;IACfA,iBAAE,OAAO;IACTA,iBAAE;MACAA,iBAAE,MAAM;QACN;QACA;QACA;QACA;QACA;MACF,CAAC;IACH;EACF,CAAC;EACD,iBAAiB,uBAAuB,SAAS;AACnD,CAAC;AAcI,IAAM,yBAAsDC,iBAAE,OAAO;EAC1E,MAAMA,iBAAE,QAAQ,MAAM;EACtB,SAASA,iBAAE,MAAM,oBAAoB;EACrC,iBAAiB,uBAAuB,SAAS;AACnD,CAAC;AAcM,IAAM,qBAA8CC,iBAAE,MAAM;EACjE;EACA;EACA;EACA;AACF,CAAC;A/B1DD,IAAM,qBAAqB,kBAAkB;EAC3C,QAAQ;EACR,MAAM;AACR,CAAC;A2D/DM,IAAM,2BAAN,cAAuC,gBAAiC;EAC7E,cAAc;AACZ,UAAM;MACJ,UAAU,MAAM,YAAY;AAC1B,mBAAW,QAAQ,SAAS,KAAK,UAAU,IAAI,CAAC;;CAAM;MACxD;MACA,MAAM,YAAY;AAChB,mBAAW,QAAQ,kBAAkB;MACvC;IACF,CAAC;EACH;AACF;AKGO,IAAM,uBAAuB;EAAc,MAChD;IACEC,iBAAE,MAAM;MACNA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,YAAY;QAC5B,IAAIA,iBAAE,OAAO;QACb,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,YAAY;QAC5B,IAAIA,iBAAE,OAAO;QACb,OAAOA,iBAAE,OAAO;QAChB,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,UAAU;QAC1B,IAAIA,iBAAE,OAAO;QACb,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,OAAO;QACvB,WAAWA,iBAAE,OAAO;MACtB,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,kBAAkB;QAClC,YAAYA,iBAAE,OAAO;QACrB,UAAUA,iBAAE,OAAO;QACnB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;QACvC,SAASA,iBAAE,QAAQ,EAAE,SAAS;MAChC,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,kBAAkB;QAClC,YAAYA,iBAAE,OAAO;QACrB,gBAAgBA,iBAAE,OAAO;MAC3B,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,sBAAsB;QACtC,YAAYA,iBAAE,OAAO;QACrB,UAAUA,iBAAE,OAAO;QACnB,OAAOA,iBAAE,QAAQ;QACjB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;QACvC,kBAAkB,uBAAuB,SAAS;QAClD,SAASA,iBAAE,QAAQ,EAAE,SAAS;MAChC,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,kBAAkB;QAClC,YAAYA,iBAAE,OAAO;QACrB,UAAUA,iBAAE,OAAO;QACnB,OAAOA,iBAAE,QAAQ;QACjB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;QACvC,kBAAkB,uBAAuB,SAAS;QAClD,SAASA,iBAAE,QAAQ,EAAE,SAAS;QAC9B,WAAWA,iBAAE,OAAO;MACtB,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,uBAAuB;QACvC,YAAYA,iBAAE,OAAO;QACrB,QAAQA,iBAAE,QAAQ;QAClB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;QACvC,SAASA,iBAAE,QAAQ,EAAE,SAAS;QAC9B,aAAaA,iBAAE,QAAQ,EAAE,SAAS;MACpC,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,mBAAmB;QACnC,YAAYA,iBAAE,OAAO;QACrB,WAAWA,iBAAE,OAAO;QACpB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;QACvC,SAASA,iBAAE,QAAQ,EAAE,SAAS;MAChC,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,iBAAiB;QACjC,IAAIA,iBAAE,OAAO;QACb,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,iBAAiB;QACjC,IAAIA,iBAAE,OAAO;QACb,OAAOA,iBAAE,OAAO;QAChB,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,eAAe;QAC/B,IAAIA,iBAAE,OAAO;QACb,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,YAAY;QAC5B,UAAUA,iBAAE,OAAO;QACnB,KAAKA,iBAAE,OAAO;QACd,OAAOA,iBAAE,OAAO,EAAE,SAAS;QAC3B,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,iBAAiB;QACjC,UAAUA,iBAAE,OAAO;QACnB,WAAWA,iBAAE,OAAO;QACpB,OAAOA,iBAAE,OAAO;QAChB,UAAUA,iBAAE,OAAO,EAAE,SAAS;QAC9B,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,MAAM;QACtB,KAAKA,iBAAE,OAAO;QACd,WAAWA,iBAAE,OAAO;QACpB,kBAAkB,uBAAuB,SAAS;MACpD,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE;UACN,CAAC,UACC,OAAO,UAAU,YAAY,MAAM,WAAW,OAAO;UACvD,EAAE,SAAS,+BAA+B;QAC5C;QACA,IAAIA,iBAAE,OAAO,EAAE,SAAS;QACxB,MAAMA,iBAAE,QAAQ;QAChB,WAAWA,iBAAE,QAAQ,EAAE,SAAS;MAClC,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,YAAY;MAC9B,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,aAAa;MAC/B,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,OAAO;QACvB,WAAWA,iBAAE,OAAO,EAAE,SAAS;QAC/B,iBAAiBA,iBAAE,QAAQ,EAAE,SAAS;MACxC,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,QAAQ;QACxB,iBAAiBA,iBAAE,QAAQ,EAAE,SAAS;MACxC,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,OAAO;MACzB,CAAC;MACDA,iBAAE,aAAa;QACb,MAAMA,iBAAE,QAAQ,kBAAkB;QAClC,iBAAiBA,iBAAE,QAAQ;MAC7B,CAAC;IACH,CAAC;EACH;AACF;AGhIO,SAAS,QAAQ,OAAuB;AAC7C,QAAM,QAAiB,CAAC,MAAM;AAC9B,MAAI,iBAAiB;AACrB,MAAI,eAA8B;AAElC,WAAS,kBAAkB,MAAc,GAAW,WAAkB;AACpE;AACE,cAAQ,MAAM;QACZ,KAAK,KAAK;AACR,2BAAiB;AACjB,gBAAM,IAAI;AACV,gBAAM,KAAK,SAAS;AACpB,gBAAM,KAAK,eAAe;AAC1B;QACF;QAEA,KAAK;QACL,KAAK;QACL,KAAK,KAAK;AACR,2BAAiB;AACjB,yBAAe;AACf,gBAAM,IAAI;AACV,gBAAM,KAAK,SAAS;AACpB,gBAAM,KAAK,gBAAgB;AAC3B;QACF;QAEA,KAAK,KAAK;AACR,gBAAM,IAAI;AACV,gBAAM,KAAK,SAAS;AACpB,gBAAM,KAAK,eAAe;AAC1B;QACF;QACA,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK,KAAK;AACR,2BAAiB;AACjB,gBAAM,IAAI;AACV,gBAAM,KAAK,SAAS;AACpB,gBAAM,KAAK,eAAe;AAC1B;QACF;QAEA,KAAK,KAAK;AACR,2BAAiB;AACjB,gBAAM,IAAI;AACV,gBAAM,KAAK,SAAS;AACpB,gBAAM,KAAK,qBAAqB;AAChC;QACF;QAEA,KAAK,KAAK;AACR,2BAAiB;AACjB,gBAAM,IAAI;AACV,gBAAM,KAAK,SAAS;AACpB,gBAAM,KAAK,oBAAoB;AAC/B;QACF;MACF;IACF;EACF;AAEA,WAAS,wBAAwB,MAAc,GAAW;AACxD,YAAQ,MAAM;MACZ,KAAK,KAAK;AACR,cAAM,IAAI;AACV,cAAM,KAAK,2BAA2B;AACtC;MACF;MACA,KAAK,KAAK;AACR,yBAAiB;AACjB,cAAM,IAAI;AACV;MACF;IACF;EACF;AAEA,WAAS,uBAAuB,MAAc,GAAW;AACvD,YAAQ,MAAM;MACZ,KAAK,KAAK;AACR,cAAM,IAAI;AACV,cAAM,KAAK,0BAA0B;AACrC;MACF;MACA,KAAK,KAAK;AACR,yBAAiB;AACjB,cAAM,IAAI;AACV;MACF;IACF;EACF;AAEA,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,UAAM,OAAO,MAAM,CAAC;AACpB,UAAM,eAAe,MAAM,MAAM,SAAS,CAAC;AAE3C,YAAQ,cAAc;MACpB,KAAK;AACH,0BAAkB,MAAM,GAAG,QAAQ;AACnC;MAEF,KAAK,uBAAuB;AAC1B,gBAAQ,MAAM;UACZ,KAAK,KAAK;AACR,kBAAM,IAAI;AACV,kBAAM,KAAK,mBAAmB;AAC9B;UACF;UACA,KAAK,KAAK;AACR,6BAAiB;AACjB,kBAAM,IAAI;AACV;UACF;QACF;AACA;MACF;MAEA,KAAK,6BAA6B;AAChC,gBAAQ,MAAM;UACZ,KAAK,KAAK;AACR,kBAAM,IAAI;AACV,kBAAM,KAAK,mBAAmB;AAC9B;UACF;QACF;AACA;MACF;MAEA,KAAK,qBAAqB;AACxB,gBAAQ,MAAM;UACZ,KAAK,KAAK;AACR,kBAAM,IAAI;AACV,kBAAM,KAAK,yBAAyB;AACpC;UACF;QACF;AACA;MACF;MAEA,KAAK,2BAA2B;AAC9B,gBAAQ,MAAM;UACZ,KAAK,KAAK;AACR,kBAAM,IAAI;AACV,kBAAM,KAAK,4BAA4B;AAEvC;UACF;QACF;AACA;MACF;MAEA,KAAK,8BAA8B;AACjC,0BAAkB,MAAM,GAAG,2BAA2B;AACtD;MACF;MAEA,KAAK,6BAA6B;AAChC,gCAAwB,MAAM,CAAC;AAC/B;MACF;MAEA,KAAK,iBAAiB;AACpB,gBAAQ,MAAM;UACZ,KAAK,KAAK;AACR,kBAAM,IAAI;AACV,6BAAiB;AACjB;UACF;UAEA,KAAK,MAAM;AACT,kBAAM,KAAK,sBAAsB;AACjC;UACF;UAEA,SAAS;AACP,6BAAiB;UACnB;QACF;AAEA;MACF;MAEA,KAAK,sBAAsB;AACzB,gBAAQ,MAAM;UACZ,KAAK,KAAK;AACR,6BAAiB;AACjB,kBAAM,IAAI;AACV;UACF;UAEA,SAAS;AACP,6BAAiB;AACjB,8BAAkB,MAAM,GAAG,0BAA0B;AACrD;UACF;QACF;AACA;MACF;MAEA,KAAK,4BAA4B;AAC/B,gBAAQ,MAAM;UACZ,KAAK,KAAK;AACR,kBAAM,IAAI;AACV,kBAAM,KAAK,0BAA0B;AACrC;UACF;UAEA,KAAK,KAAK;AACR,6BAAiB;AACjB,kBAAM,IAAI;AACV;UACF;UAEA,SAAS;AACP,6BAAiB;AACjB;UACF;QACF;AAEA;MACF;MAEA,KAAK,4BAA4B;AAC/B,0BAAkB,MAAM,GAAG,0BAA0B;AACrD;MACF;MAEA,KAAK,wBAAwB;AAC3B,cAAM,IAAI;AACV,yBAAiB;AAEjB;MACF;MAEA,KAAK,iBAAiB;AACpB,gBAAQ,MAAM;UACZ,KAAK;UACL,KAAK;UACL,KAAK;UACL,KAAK;UACL,KAAK;UACL,KAAK;UACL,KAAK;UACL,KAAK;UACL,KAAK;UACL,KAAK,KAAK;AACR,6BAAiB;AACjB;UACF;UAEA,KAAK;UACL,KAAK;UACL,KAAK;UACL,KAAK,KAAK;AACR;UACF;UAEA,KAAK,KAAK;AACR,kBAAM,IAAI;AAEV,gBAAI,MAAM,MAAM,SAAS,CAAC,MAAM,4BAA4B;AAC1D,qCAAuB,MAAM,CAAC;YAChC;AAEA,gBAAI,MAAM,MAAM,SAAS,CAAC,MAAM,6BAA6B;AAC3D,sCAAwB,MAAM,CAAC;YACjC;AAEA;UACF;UAEA,KAAK,KAAK;AACR,kBAAM,IAAI;AAEV,gBAAI,MAAM,MAAM,SAAS,CAAC,MAAM,6BAA6B;AAC3D,sCAAwB,MAAM,CAAC;YACjC;AAEA;UACF;UAEA,KAAK,KAAK;AACR,kBAAM,IAAI;AAEV,gBAAI,MAAM,MAAM,SAAS,CAAC,MAAM,4BAA4B;AAC1D,qCAAuB,MAAM,CAAC;YAChC;AAEA;UACF;UAEA,SAAS;AACP,kBAAM,IAAI;AACV;UACF;QACF;AAEA;MACF;MAEA,KAAK,kBAAkB;AACrB,cAAM,iBAAiB,MAAM,UAAU,cAAe,IAAI,CAAC;AAE3D,YACE,CAAC,QAAQ,WAAW,cAAc,KAClC,CAAC,OAAO,WAAW,cAAc,KACjC,CAAC,OAAO,WAAW,cAAc,GACjC;AACA,gBAAM,IAAI;AAEV,cAAI,MAAM,MAAM,SAAS,CAAC,MAAM,6BAA6B;AAC3D,oCAAwB,MAAM,CAAC;UACjC,WAAW,MAAM,MAAM,SAAS,CAAC,MAAM,4BAA4B;AACjE,mCAAuB,MAAM,CAAC;UAChC;QACF,OAAO;AACL,2BAAiB;QACnB;AAEA;MACF;IACF;EACF;AAEA,MAAI,SAAS,MAAM,MAAM,GAAG,iBAAiB,CAAC;AAE9C,WAAS,IAAI,MAAM,SAAS,GAAG,KAAK,GAAG,KAAK;AAC1C,UAAM,QAAQ,MAAM,CAAC;AAErB,YAAQ,OAAO;MACb,KAAK,iBAAiB;AACpB,kBAAU;AACV;MACF;MAEA,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK,6BAA6B;AAChC,kBAAU;AACV;MACF;MAEA,KAAK;MACL,KAAK;MACL,KAAK,4BAA4B;AAC/B,kBAAU;AACV;MACF;MAEA,KAAK,kBAAkB;AACrB,cAAM,iBAAiB,MAAM,UAAU,cAAe,MAAM,MAAM;AAElE,YAAI,OAAO,WAAW,cAAc,GAAG;AACrC,oBAAU,OAAO,MAAM,eAAe,MAAM;QAC9C,WAAW,QAAQ,WAAW,cAAc,GAAG;AAC7C,oBAAU,QAAQ,MAAM,eAAe,MAAM;QAC/C,WAAW,OAAO,WAAW,cAAc,GAAG;AAC5C,oBAAU,OAAO,MAAM,eAAe,MAAM;QAC9C;MACF;IACF;EACF;AAEA,SAAO;AACT;AD5YA,eAAsBC,kBAAiB,UAOpC;AACD,MAAI,aAAa,QAAW;AAC1B,WAAO,EAAE,OAAO,QAAW,OAAO,kBAAkB;EACtD;AAEA,MAAI,SAAS,MAAMC,cAAc,EAAE,MAAM,SAAS,CAAC;AAEnD,MAAI,OAAO,SAAS;AAClB,WAAO,EAAE,OAAO,OAAO,OAAO,OAAO,mBAAmB;EAC1D;AAEA,WAAS,MAAMA,cAAc,EAAE,MAAM,QAAQ,QAAQ,EAAE,CAAC;AAExD,MAAI,OAAO,SAAS;AAClB,WAAO,EAAE,OAAO,OAAO,OAAO,OAAO,iBAAiB;EACxD;AAEA,SAAO,EAAE,OAAO,QAAW,OAAO,eAAe;AACnD;AE8TO,SAAS,aACd,MAC2B;AAC3B,SAAO,KAAK,KAAK,WAAW,OAAO;AACrC;AAcO,SAAS,YACd,MACa;AACb,SAAO,KAAK,KAAK,MAAM,GAAG,EAAE,MAAM,CAAC,EAAE,KAAK,GAAG;AAC/C;AdvRA,IAAMC,sBAAqBC,kBAAkB;EAC3C,QAAQ;EACR,MAAM;AACR,CAAC;A8BhDD,IAAMC,sBAAqBC,kBAAkB,EAAE,QAAQ,SAAS,MAAM,GAAG,CAAC;AKY1E,IAAMC,sBAAqBC,kBAAkB,EAAE,QAAQ,SAAS,MAAM,GAAG,CAAC;AQzD1E,IAAA,iBAAA,CAAA;AAAAC,UAAA,gBAAA;EAAA,QAAA,MAAA;EAAA,MAAA,MAAA;AAAA,CAAA;AAiCO,IAAM,OAAO,OAA+B;EACjD,MAAM;EAEN,gBAAgB,EAAE,MAAM,OAAO;EAE/B,MAAM,aAAa,EAAE,MAAAC,MAAK,GAAqB;AAC7C,WAAO,EAAE,SAASA,MAAK;EACzB;EAEA,MAAM,YAAY,EAAE,MAAAA,MAAK,GAAqB;AAC5C,WAAOA;EACT;AACF;AAEO,IAAM,SAAS,CAAS;EAC7B,QAAQ;AACV,MAE2C;AACzC,QAAM,SAASC,UAAS,WAAW;AAEnC,SAAO;IACL,MAAM;IAEN,gBAAgB;MACd,MAAM;MACN,QAAQ,OAAO;IACjB;IAEA,MAAM,aAAa,EAAE,MAAAD,MAAK,GAAqB;AAC7C,YAAM,SAAS,MAAME,kBAAiBF,KAAI;AAE1C,cAAQ,OAAO,OAAO;QACpB,KAAK;QACL,KAAK;AACH,iBAAO;QAET,KAAK;QACL,KAAK;AACH,iBAAO;;YAEL,SAAS,OAAO;UAClB;QAEF,SAAS;AACP,gBAAM,mBAA0B,OAAO;AACvC,gBAAM,IAAI,MAAM,4BAA4B,gBAAgB,EAAE;QAChE;MACF;IACF;IAEA,MAAM,YACJ,EAAE,MAAAA,MAAK,GACP,SAKA;AACA,YAAM,cAAc,MAAMG,cAAc,EAAE,MAAAH,MAAK,CAAC;AAEhD,UAAI,CAAC,YAAY,SAAS;AACxB,cAAM,IAAI,uBAAuB;UAC/B,SAAS;UACT,OAAO,YAAY;UACnB,MAAAA;UACA,UAAU,QAAQ;UAClB,OAAO,QAAQ;UACf,cAAc,QAAQ;QACxB,CAAC;MACH;AAEA,YAAM,mBAAmB,MAAMI,mBAAkB;QAC/C,OAAO,YAAY;QACnB;MACF,CAAC;AAED,UAAI,CAAC,iBAAiB,SAAS;AAC7B,cAAM,IAAI,uBAAuB;UAC/B,SAAS;UACT,OAAO,iBAAiB;UACxB,MAAAJ;UACA,UAAU,QAAQ;UAClB,OAAO,QAAQ;UACf,cAAc,QAAQ;QACxB,CAAC;MACH;AAEA,aAAO,iBAAiB;IAC1B;EACF;AACF;AU1HA,IAAMK,SAAO;AACb,IAAMC,WAAS,mBAAmBD,MAAI;AACtC,IAAME,WAAS,OAAO,IAAID,QAAM;AAJhC,IAAAE;AAOoBC,OAAAC;ASuHb,IAAe,oBAAf,MAEP;EASE,YAAY;IACV,MAAM;IACN;IACA;IACA;IACA,OAAAC;IACA;IACA;EACF,GAA6C;AAC3C,SAAK,MAAM;AACX,SAAK,cAAc;AACnB,SAAK,UAAU;AACf,SAAK,OAAO;AACZ,SAAK,QAAQA;AACb,SAAK,6BAA6B;AAClC,SAAK,kCAAkC;EACzC;EAEA,MAAM,aAAa;IACjB;IACA,GAAG;EACL,GAA6D;AA9J/D,QAAAC,MAAAC,KAAA,IAAA,IAAA;AA+JI,UAAM,eAAe,MAAM,QAAQ,KAAK,IAAI;AAC5C,UAAM,kBAAkB,MAAM,QAAQ,KAAK,OAAO;AAClD,UAAM,sBAAsB,MAAM,QAAQ,KAAK,WAAW;AAE1D,UAAM,cAAc;MAClB,GAAG,iBAAiB,eAAe;MACnC,GAAG,iBAAiB,QAAQ,OAAO;IACrC;AAEA,UAAM,kBAAkB,QAAMD,OAAA,KAAK,+BAAL,OAAA,SAAAA,KAAA,KAAA,MAAkC;MAC9D,KAAK,KAAK;MACV,IAAI,QAAQ;MACZ,UAAU,QAAQ;MAClB,MAAM,EAAE,GAAG,cAAc,GAAG,QAAQ,KAAK;MACzC,SAAS;MACT,aAAa;MACb,iBAAiB,QAAQ;MACzB,SAAS,QAAQ;MACjB,WAAW,QAAQ;IACrB,CAAA;AAEA,UAAM,OAAMC,MAAA,mBAAA,OAAA,SAAA,gBAAiB,QAAjB,OAAAA,MAAwB,KAAK;AACzC,UAAM,WACJ,mBAAA,OAAA,SAAA,gBAAiB,aAAY,SACzB,iBAAiB,gBAAgB,OAAO,IACxC;AACN,UAAM,QACJ,mBAAA,OAAA,SAAA,gBAAiB,UAAS,SACtB,gBAAgB,OAChB;MACE,GAAG;MACH,GAAG,QAAQ;MACX,IAAI,QAAQ;MACZ,UAAU,QAAQ;MAClB,SAAS,QAAQ;MACjB,WAAW,QAAQ;IACrB;AACN,UAAM,eAAc,KAAA,mBAAA,OAAA,SAAA,gBAAiB,gBAAjB,OAAA,KAAgC;AAGpD,UAAMF,UAAQ,KAAA,KAAK,UAAL,OAAA,KAAc,WAAW;AAEvC,UAAM,WAAW,MAAMA,OAAM,KAAK;MAChC,QAAQ;MACR,SAASG;QACP;UACE,gBAAgB;UAChB,GAAG;QACL;QACA,UAAUC,QAAO;QACjBC,+BAA+B;MACjC;MACA,MAAM,KAAK,UAAU,IAAI;MACzB;MACA,QAAQ;IACV,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI;SACP,KAAA,MAAM,SAAS,KAAK,MAApB,OAAA,KAA0B;MAC7B;IACF;AAEA,QAAI,CAAC,SAAS,MAAM;AAClB,YAAM,IAAI,MAAM,6BAA6B;IAC/C;AAEA,WAAO,KAAK,sBAAsB,SAAS,IAAI;EACjD;EAEA,MAAM,kBACJ,SACgD;AAvOpD,QAAAJ,MAAAC,KAAA,IAAA,IAAA;AAwOI,UAAM,eAAe,MAAM,QAAQ,KAAK,IAAI;AAC5C,UAAM,kBAAkB,MAAM,QAAQ,KAAK,OAAO;AAClD,UAAM,sBAAsB,MAAM,QAAQ,KAAK,WAAW;AAE1D,UAAM,cAAc;MAClB,GAAG,iBAAiB,eAAe;MACnC,GAAG,iBAAiB,QAAQ,OAAO;IACrC;AAEA,UAAM,kBAAkB,QAAMD,OAAA,KAAK,oCAAL,OAAA,SAAAA,KAAA,KAAA,MAAuC;MACnE,KAAK,KAAK;MACV,IAAI,QAAQ;MACZ,MAAM,EAAE,GAAG,cAAc,GAAG,QAAQ,KAAK;MACzC,SAAS;MACT,aAAa;MACb,iBAAiB,QAAQ;IAC3B,CAAA;AAEA,UAAM,OAAMC,MAAA,mBAAA,OAAA,SAAA,gBAAiB,QAAjB,OAAAA,MAAwB,GAAG,KAAK,GAAG,IAAI,QAAQ,MAAM;AACjE,UAAM,WACJ,mBAAA,OAAA,SAAA,gBAAiB,aAAY,SACzB,iBAAiB,gBAAgB,OAAO,IACxC;AACN,UAAM,eAAc,KAAA,mBAAA,OAAA,SAAA,gBAAiB,gBAAjB,OAAA,KAAgC;AAGpD,UAAMF,UAAQ,KAAA,KAAK,UAAL,OAAA,KAAc,WAAW;AAEvC,UAAM,WAAW,MAAMA,OAAM,KAAK;MAChC,QAAQ;MACR,SAASG;QACP;QACA,UAAUC,QAAO;QACjBC,+BAA+B;MACjC;MACA;IACF,CAAC;AAGD,QAAI,SAAS,WAAW,KAAK;AAC3B,aAAO;IACT;AAEA,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI;SACP,KAAA,MAAM,SAAS,KAAK,MAApB,OAAA,KAA0B;MAC7B;IACF;AAEA,QAAI,CAAC,SAAS,MAAM;AAClB,YAAM,IAAI,MAAM,6BAA6B;IAC/C;AAEA,WAAO,KAAK,sBAAsB,SAAS,IAAI;EACjD;AAKF;ADxRO,IAAM,uBAAN,cAEG,kBAA8B;EACtC,YAAY,UAAoD,CAAC,GAAG;AAClE,UAAM,OAAO;EACf;EAEU,sBACR,QACgC;AAChC,WAAOC,qBAAqB;MAC1B;MACA,QAAQ;IACV,CAAC,EAAE;MACD,IAAI,gBAA6D;QAC/D,MAAM,UAAU,OAAO,YAAY;AACjC,cAAI,CAAC,MAAM,SAAS;AAClB,kBAAM,MAAM;UACd;AACA,qBAAW,QAAQ,MAAM,KAAK;QAChC;MACF,CAAC;IACH;EACF;AACF;AKfA,IAAM,mBAAmBC;EAAc,MACrCC;IACEC,iBAAE;MACAA,iBAAE,OAAO;QACP,IAAIA,iBAAE,OAAO;QACb,MAAMA,iBAAE,KAAK,CAAC,UAAU,QAAQ,WAAW,CAAC;QAC5C,UAAUA,iBAAE,QAAQ,EAAE,SAAS;QAC/B,OAAOA,iBAAE;UACPA,iBAAE,MAAM;YACNA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,MAAM;cACtB,MAAMA,iBAAE,OAAO;cACf,OAAOA,iBAAE,KAAK,CAAC,aAAa,MAAM,CAAC,EAAE,SAAS;cAC9C,kBAAkB,uBAAuB,SAAS;YACpD,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,WAAW;cAC3B,MAAMA,iBAAE,OAAO;cACf,OAAOA,iBAAE,KAAK,CAAC,aAAa,MAAM,CAAC,EAAE,SAAS;cAC9C,kBAAkB,uBAAuB,SAAS;YACpD,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,YAAY;cAC5B,UAAUA,iBAAE,OAAO;cACnB,KAAKA,iBAAE,OAAO;cACd,OAAOA,iBAAE,OAAO,EAAE,SAAS;cAC3B,kBAAkB,uBAAuB,SAAS;YACpD,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,iBAAiB;cACjC,UAAUA,iBAAE,OAAO;cACnB,WAAWA,iBAAE,OAAO;cACpB,OAAOA,iBAAE,OAAO;cAChB,UAAUA,iBAAE,OAAO,EAAE,SAAS;cAC9B,kBAAkB,uBAAuB,SAAS;YACpD,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,MAAM;cACtB,WAAWA,iBAAE,OAAO;cACpB,UAAUA,iBAAE,OAAO,EAAE,SAAS;cAC9B,KAAKA,iBAAE,OAAO;cACd,kBAAkB,uBAAuB,SAAS;YACpD,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,YAAY;YAC9B,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,OAAO,EAAE,WAAW,OAAO;cACnC,IAAIA,iBAAE,OAAO,EAAE,SAAS;cACxB,MAAMA,iBAAE,QAAQ;YAClB,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,cAAc;cAC9B,UAAUA,iBAAE,OAAO;cACnB,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,iBAAiB;cAClC,OAAOA,iBAAE,QAAQ,EAAE,SAAS;cAC5B,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,MAAM,EAAE,SAAS;YAChC,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,cAAc;cAC9B,UAAUA,iBAAE,OAAO;cACnB,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,iBAAiB;cAClC,OAAOA,iBAAE,QAAQ;cACjB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,MAAM,EAAE,SAAS;cAC9B,sBAAsB,uBAAuB,SAAS;YACxD,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,cAAc;cAC9B,UAAUA,iBAAE,OAAO;cACnB,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,kBAAkB;cACnC,OAAOA,iBAAE,QAAQ;cACjB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,QAAQA,iBAAE,QAAQ;cAClB,WAAWA,iBAAE,MAAM,EAAE,SAAS;cAC9B,sBAAsB,uBAAuB,SAAS;cACtD,aAAaA,iBAAE,QAAQ,EAAE,SAAS;YACpC,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,QAAQ,cAAc;cAC9B,UAAUA,iBAAE,OAAO;cACnB,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,cAAc;cAC/B,OAAOA,iBAAE,QAAQ;cACjB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,OAAO;cACpB,sBAAsB,uBAAuB,SAAS;YACxD,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,OAAO,EAAE,WAAW,OAAO;cACnC,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,iBAAiB;cAClC,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,OAAOA,iBAAE,QAAQ,EAAE,SAAS;cAC5B,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,MAAM,EAAE,SAAS;cAC9B,UAAUA,iBAAE,MAAM,EAAE,SAAS;YAC/B,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,OAAO,EAAE,WAAW,OAAO;cACnC,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,iBAAiB;cAClC,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,OAAOA,iBAAE,QAAQ;cACjB,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,MAAM,EAAE,SAAS;cAC9B,sBAAsB,uBAAuB,SAAS;cACtD,UAAUA,iBAAE,MAAM,EAAE,SAAS;YAC/B,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,OAAO,EAAE,WAAW,OAAO;cACnC,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,oBAAoB;cACrC,OAAOA,iBAAE,QAAQ;cACjB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,MAAM,EAAE,SAAS;cAC9B,sBAAsB,uBAAuB,SAAS;cACtD,UAAUA,iBAAE,OAAO;gBACjB,IAAIA,iBAAE,OAAO;gBACb,UAAUA,iBAAE,MAAM,EAAE,SAAS;gBAC7B,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC7B,CAAC;YACH,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,OAAO,EAAE,WAAW,OAAO;cACnC,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,oBAAoB;cACrC,OAAOA,iBAAE,QAAQ;cACjB,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,MAAM,EAAE,SAAS;cAC9B,sBAAsB,uBAAuB,SAAS;cACtD,UAAUA,iBAAE,OAAO;gBACjB,IAAIA,iBAAE,OAAO;gBACb,UAAUA,iBAAE,QAAQ;gBACpB,QAAQA,iBAAE,OAAO,EAAE,SAAS;cAC9B,CAAC;YACH,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,OAAO,EAAE,WAAW,OAAO;cACnC,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,kBAAkB;cACnC,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,OAAOA,iBAAE,QAAQ;cACjB,QAAQA,iBAAE,QAAQ;cAClB,WAAWA,iBAAE,MAAM,EAAE,SAAS;cAC9B,sBAAsB,uBAAuB,SAAS;cACtD,aAAaA,iBAAE,QAAQ,EAAE,SAAS;cAClC,UAAUA,iBACP,OAAO;gBACN,IAAIA,iBAAE,OAAO;gBACb,UAAUA,iBAAE,QAAQ,IAAI;gBACxB,QAAQA,iBAAE,OAAO,EAAE,SAAS;cAC9B,CAAC,EACA,SAAS;YACd,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,OAAO,EAAE,WAAW,OAAO;cACnC,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,cAAc;cAC/B,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,OAAOA,iBAAE,QAAQ;cACjB,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,OAAO;cACpB,sBAAsB,uBAAuB,SAAS;cACtD,UAAUA,iBACP,OAAO;gBACN,IAAIA,iBAAE,OAAO;gBACb,UAAUA,iBAAE,QAAQ,IAAI;gBACxB,QAAQA,iBAAE,OAAO,EAAE,SAAS;cAC9B,CAAC,EACA,SAAS;YACd,CAAC;YACDA,iBAAE,OAAO;cACP,MAAMA,iBAAE,OAAO,EAAE,WAAW,OAAO;cACnC,YAAYA,iBAAE,OAAO;cACrB,OAAOA,iBAAE,QAAQ,eAAe;cAChC,kBAAkBA,iBAAE,QAAQ,EAAE,SAAS;cACvC,OAAOA,iBAAE,QAAQ;cACjB,QAAQA,iBAAE,MAAM,EAAE,SAAS;cAC3B,WAAWA,iBAAE,MAAM,EAAE,SAAS;cAC9B,sBAAsB,uBAAuB,SAAS;cACtD,UAAUA,iBAAE,OAAO;gBACjB,IAAIA,iBAAE,OAAO;gBACb,UAAUA,iBAAE,QAAQ,KAAK;gBACzB,QAAQA,iBAAE,OAAO,EAAE,SAAS;cAC9B,CAAC;YACH,CAAC;UACH,CAAC;QACH;MACF,CAAC;IACH;EACF;AACF;;;;AGtJA,IAAM,eAAe,oBAAI,IAAA;AAazB,SAAgB,iCACd,OACU;AACV,MAAI,CAAC,MAAO,QAAO,CAAA;AAEnB,SAAO,OAAO,QAAQ,KAAA,EACnB,OAAA,CAAQ,CAAC,OAAOC,MAAAA,MAAU,CAACA,OAAK,OAAA,EAChC,IAAA,CAAK,CAACC,MAAA,MAAUA,MAAA;;AAGrB,SAAgB,aAId,SAGA;AACA,QAAM,EACJ,OACA,oBACA,UAAU,wBACV,sCACA,OACA,4BAA4B,kCAC5B,wCAAwC,MACxC,GAAG,KAAA,IACD;AAGJ,QAAM,6BACJ,oCAAoC,iCAAiC,KAAA;AAEvE,QAAM,WAAW,IAAI,IACnB,IACE,MAAM,QAA0B,MAAM,SACpC,QAAQ,SAAS,SAAA,EAClB,QAAQ,UAAU,UAAA,CAAW,EAAA;AAGlC,WAAS,aAAa,OAAO,KAAA;AAC7B,QAAM,iBAAiB,SAAS,SAAA;AAKhC,QAAM,0BAA0B,GAAG,cAAA,IAAkB,MAAM,SAAS,EAAA,IAAM,MAAM,QAAQ,EAAA;AAGxF,QAAM,eAAW,sBAAO,KAAA;AACxB,+BAAA,MAAgB;AACd,aAAS,UAAU;KAClB,CAAC,KAAA,CAAM;AAEV,iBAAe,+BAA+B,EAC5C,IAAA,GAC4B;AAC5B,UAAM,iBAAiB,IAAI,IAAI,GAAA;AAC/B,mBAAe,YAAY;AAC3B,UAAM,WAAW,MAAM,MAAM,eAAe,SAAA,GAAY;MACtD,aAAa,QAAQ;MACrB,SAAS,QAAQ;KAClB;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,cAAQ,KACN,qCAAqC,SAAS,MAAA,IAAU,SAAS,UAAA,EAAA;AAEnE,aAAO,CAAA;;AAGT,UAAMC,QAAO,MAAM,SAAS,KAAA;AAC5B,QAAI,CAACA,MAAK,KAAA,EACR,QAAO,CAAA;AAGT,QAAI;AACF,aAAO,KAAK,MAAMA,KAAA;aACX,OAAO;AACd,cAAQ,KAAK,0CAA0C,KAAA;AACvD,aAAO,CAAA;;;AAIX,QAAM,0BACJ,sBAAsB;AAExB,WAAS,qBACP,2BACA,UACA;AACA,QAAI,aAAa,IAAI,QAAA,EACnB,QAAO,aAAa,IAAI,QAAA;AAE1B,UAAM,UAAU,wBAAwB,yBAAA;AACxC,iBAAa,IAAI,UAAU,OAAA;AAC3B,WAAO;;AAGT,QAAM,yBACJ,uBAAuB,OACnB,OACA,qBACE;IACE,OAAO,MAAM;IACb,MAAM,MAAM;IACZ,KAAK;KAEP,uBAAA;AAER,QAAM,kBAAkB,6BACpB,mBAAI,sBAAA,IACH,0BAA0B,CAAA;AAE/B,+BAAA,MAAgB;AACd,QAAI,CAAC,uBACH;AAEF,iBAAa,IAAI,yBAAyB,sBAAA;AAC1C,WAAA,MAAa;AACX,UACE,aAAa,IAAI,uBAAA,MAA6B,uBAE9C,cAAa,OAAO,uBAAA;;KAGvB,CAAC,yBAAyB,sBAAA,CAAuB;AAEpD,QAAM,cAAU,2BACd,OAAO,SAA4B,YAAuB,CAAA,MAAO;AAC/D,UAAM,EACJ,QACA,WACA,SACA,MACA,UACA,WACA,QACA,aACA,MACA,UACA,gBACA,QAAAC,QAAA,IACEC;AACJ,UAAM,KAAK,OAAO,CAAA;AAClB,UAAM,kBAAkB,IAAI,gBAAA;AAC5B,QAAIC;AACJ,UAAM,eAAe,SAAS;AAE9B,YAAQ,iBAAiB,SAAA,MAAe;AACtC,mBAAa,KACX,KAAK,UAAU;QACb;QACA,MAAM,YAAY;OACnB,CAAC;AAYJ,sBAAgB,MAAA;AAEhB,iBAAW,MAAA;;AAGb,iBAAa,iBACX,WAAA,CACC,UAAU;AACT,UAAIC;AACJ,UAAI;AACF,eAAO,KAAK,MAAM,MAAM,IAAA;eACjBC,SAAQ;AAGf;;AAEF,UAAI,KAAK,SAAS,YAAY,4BAC5B;YAAI,KAAK,OAAO,GACd,KAAI,KAAK,OAAO;AACd,qBAAW,MAAM,IAAI,MAAM,KAAK,IAAA,CAAK;AACrC,0BAAgB,MAAA;eACX;AAEL,cAAI,KAAK,MAAM,KAAA,EACb,YAAW,QACT,IAAI,YAAA,EAAc,OAAO,SAAS,KAAK,IAAA;;CAAK,CAAM;AAGtD,cAAI,KAAK,MAAM;AACb,uBAAW,MAAA;AACX,4BAAgB,MAAA;;;;OAM1B,EAAE,QAAQ,gBAAgB,OAAA,CAAQ;AAGpC,UAAM,SAAS,IAAI,eAAe,EAChC,MAAM,GAAG;AACP,mBAAa;OAEhB;AAED,iBAAa,KACX,KAAK,UAAU;MACb;MACA,MAAM;QACJ;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,QAAAJ;;MAEF,MAAM,YAAY;MAClB,KAAK,QAAQ,SAAA;KACd,CAAC;AAGJ,WAAO,IAAI,SAAS,MAAA;KAEtB,CAAA,CAAE;AAGJ,QAAMK,sBAA8C,uBAAA,OAC3C;IACL,cAAc,OACZ,cAGG;AAKH,aAJkB,IAAI,qBAAkC;QACtD,KAAK;QACL,OAAO;OACR,EACgB,aAAaJ,SAAAA;;IAEhC,mBAAmB,OACjB,cAGG;AAKH,aAJkB,IAAI,qBAAkC;QACtD,KAAK;QACL,OAAO;OACR,EACgB,kBAAkBA,SAAAA;;MAGvC,CAAC,gBAAgB,OAAA,CAAQ;AAG3B,QAAM,iBAAiB,QAAqB;IAC1C,GAAG;IACH,UAAU;IACV,WAAW;IACX,IAAI,MAAM;GACX;AAED,QAAM,yBAAqB,sBAAO,oBAAI,IAAA,CAAa;AAGnD,QAAM,cACJ,eAAe,SAAS,eAAe,SAAS,SAAS,CAAA;AAE3D,QAAM,wBAAA,MAA8B;AAClC,QAAI,CAAC,eAAe,YAAY,SAAS,YACvC,QAAO;MAAE,WAAW;MAAW,aAAa,oBAAI,IAAA;;AAGlD,UAAM,aAAa,oBAAI,IAAA;AACvB,eAAW,QAAQ,YAAY,SAAS,CAAA,EACtC,KACE,aAAa,IAAA,KACb,KAAK,UAAU,qBACf,2BAA2B,SAAS,YAAY,IAAA,CAAK,EAErD,YAAW,IAAI,KAAK,UAAA;AAGxB,WAAO;MAAE,WAAW,YAAY;MAAI,aAAa;;;AAGnD,QAAM,8BAA0B,sBAAO,oBAAA;AACvC,0BAAwB,UAAU;AAMlC,+BAAA,MAAgB;AACd,QAAI,CAAC,qCACH;AAGF,UAAMK,gBACJ,eAAe,SAAS,eAAe,SAAS,SAAS,CAAA;AAC3D,QAAI,CAACA,iBAAeA,cAAY,SAAS,YACvC;AAGF,UAAM,YAAYA,cAAY,MAAM,OAAA,CACjC,SACC,aAAa,IAAA,KACb,KAAK,UAAU,qBACf,CAAC,mBAAmB,QAAQ,IAAI,KAAK,UAAA,CAAW;AAGpD,QAAI,UAAU,SAAS,EACrB,EAAC,YAAY;AACX,YAAM,qBAAqB,UAAU,OAAA,CAClC,SACC,aAAa,IAAA,KACb,CAAC,2BAA2B,SAAS,YAAY,IAAA,CAAK,KACtD,QAAQ,YAAY,IAAA,CAAK,GAAG,OAAA;AAGhC,UAAI,mBAAmB,SAAS,GAAG;AACjC,mBAAW,QAAQ,mBACjB,KAAI,aAAa,IAAA,GAAO;AACtB,6BAAmB,QAAQ,IAAI,KAAK,UAAA;AACpC,cAAI,aAAa;AACjB,gBAAM,WAAW,YAAY,IAAA;AAC7B,gBAAMT,SAAO,QAAQ,QAAA;AAErB,cAAIA,QAAM,WAAW,KAAK,MACxB,KAAI;AACF,yBAAa,MAAMA,OAAK,QAAQ,KAAK,KAAA;mBAC9B,OAAO;AACd,yBAAa,yBAAyB,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAA,CAAM;;AAIhG,gBAAM,eAAe,cAAc;YACjC,YAAY,KAAK;YACjB,MAAM;YACN,QAAQ;WACT;;AAOL,YAAI,wBAAwB,QAAQ,YAAY,SAAS,EACvD,gBAAe,YAAA;;;KAKtB;IACD,eAAe;IACf;IACA,eAAe;IACf,eAAe;IACf;GACD;AAED,+BAAA,MAAgB;AACd,aAAS,eAAe,OAAqB;AAC3C,UAAI,OAAO,MAAM,SAAS,SAAU;AACpC,UAAIU;AACJ,UAAI;AACF,eAAO,KAAK,MAAM,MAAM,IAAA;eACjBH,SAAQ;AACf;;AAEF,UAAI,KAAK,SAAS,YAAY,oBAC5B,gBAAe,YAAY,CAAA,CAAE;;AAIjC,aAAS,WAAW,OAAqB;AACvC,UAAI,OAAO,MAAM,SAAS,SAAU;AACpC,UAAID;AACJ,UAAI;AACF,eAAO,KAAK,MAAM,MAAM,IAAA;eACjBC,SAAQ;AACf;;AAEF,UAAI,KAAK,SAAS,YAAY,uBAC5B,gBAAe,YAAY,KAAK,QAAA;;AAIpC,UAAM,iBAAiB,WAAW,cAAA;AAClC,UAAM,iBAAiB,WAAW,UAAA;AAElC,WAAA,MAAa;AACX,YAAM,oBAAoB,WAAW,cAAA;AACrC,YAAM,oBAAoB,WAAW,UAAA;;KAEtC,CAAC,OAAO,eAAe,WAAA,CAAY;AAGtC,QAAMI,8BACJ,OAAO,SAAS;AACd,UAAM,EAAE,WAAA,IAAe;AAEvB,UAAM,eAAe,cAAc,IAAA;AAEnC,QAAI,CAAC,uCAAuC;AAE1C,qBAAe,YAAA;AACf;;AAIF,UAAM,UAAU,wBAAwB,SAAS;AACjD,QAAI,CAAC,SAAS;AACZ,qBAAe,YAAA;AACf;;AAGF,UAAM,UAAU,QAAQ,SAAS,KAAK,QAAQ,IAAI,UAAA;AAClD,QAAI,QAAQ,IAAI,UAAA,EACd,SAAQ,OAAO,UAAA;AAGjB,QAAI,WAAW,QAAQ,SAAS,EAC9B,gBAAe,YAAA;;AAIrB,SAAO;IACL,GAAG;IACH,eAAe;IACf,cAAA,MAAoB;AAClB,qBAAe,YAAY,CAAA,CAAE;AAC7B,YAAM,KACJ,KAAK,UAAU,EACb,MAAM,YAAY,oBAAA,CACnB,CAAC;;IAGN,aAAA,CACE,aACG;AACH,qBAAe,YAAY,QAAA;AAC3B,YAAM,KACJ,KAAK,UAAU;QACb,UAAU,MAAM,QAAQ,QAAA,IAAY,WAAW,CAAA;QAC/C,MAAM,YAAY;OACnB,CAAC;;;;",
  "names": ["throttle", "React", "useState", "useLayoutEffect", "useEffect", "useDebugValue", "__defProp", "__export", "name", "getContext", "__defProp", "__export", "name", "getVercelOidcToken", "import_react", "import_react", "import_react", "cache", "React", "mutate", "import_react", "React", "use", "middleware", "noop", "UNDEFINED", "use", "React", "cache", "compare", "cachedData", "SWRConfig", "import_react", "throttleFunction", "isAbortError", "_a", "_b", "fetch", "APICallError", "text", "validator", "safeValidateTypes", "TypeValidationError", "getOriginalFetch", "fetch", "fetch", "getOriginalFetch", "isAbortError", "APICallError", "APICallError", "APICallError", "_a", "_b", "ZodFirstPartyTypeKind", "object", "types", "x", "jsonSchema", "name", "schema", "zodSchema", "jsonSchema", "asSchema", "import_oidc", "marker", "symbol", "_a", "_b", "name", "safeValidateTypes", "lazyValidator", "zodSchema", "z", "resolve", "createJsonResponseHandler", "createJsonErrorResponseHandler", "postJsonToApi", "combineHeaders", "VERSION", "name", "marker", "symbol", "_a", "_a", "symbol", "name", "marker", "symbol", "_a", "_a", "symbol", "name", "marker", "_a", "symbol", "name", "marker", "_a", "symbol", "name", "marker", "_a", "symbol", "name", "marker", "AISDKError", "text", "_a", "symbol", "name", "marker", "symbol", "_a", "_a", "symbol", "name", "marker", "_a", "symbol", "name", "marker", "symbol", "_a", "_a", "symbol", "name", "marker", "_a", "symbol", "name", "marker", "_a", "symbol", "name", "marker", "_a", "symbol", "name", "marker", "_a", "symbol", "VERSION", "_a", "_b", "z", "z", "z", "z", "z", "z", "parsePartialJson", "safeParseJSON", "originalGenerateId", "createIdGenerator", "originalGenerateId", "createIdGenerator", "originalGenerateId", "createIdGenerator", "__export", "text", "asSchema", "parsePartialJson", "safeParseJSON", "safeValidateTypes", "name", "marker", "symbol", "_a", "_a", "symbol", "fetch", "_a", "_b", "withUserAgentSuffix", "VERSION", "getRuntimeEnvironmentUserAgent", "parseJsonEventStream", "lazyValidator", "zodSchema", "z", "tool", "name", "text", "window", "options", "controller: ReadableStreamDefaultController", "data: OutgoingMessage<ChatMessage>", "_error", "customTransport: ChatTransport<ChatMessage>", "lastMessage", "data: OutgoingMessage", "addToolResultAndSendMessage: typeof useChatHelpers.addToolResult"]
}
